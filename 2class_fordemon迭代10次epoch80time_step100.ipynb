{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#本代碼所涉及的所有函數庫\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout,LSTM\n",
    "from keras import backend\n",
    "from keras.optimizers import SGD\n",
    "from pandas import read_csv\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import operator\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import medfilt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.recurrent import GRU\n",
    "%matplotlib inline\n",
    "import os\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res(arr,x,y):\n",
    "    zeroarray=np.zeros((1,y))\n",
    "    #print(arr.shape)\n",
    "    k=120-x+1\n",
    "    if x<=120:\n",
    "        for i in range(1,k):\n",
    "            arr = np.vstack((arr,zeroarray))      #重設矩陣大小\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classdatapredeal(dirdata1,dirdata2,string):\n",
    "    \n",
    "#     df = pd.read_csv(filedir1)#\n",
    "#     #print(df)\n",
    "#     attribute=df.columns#獲取屬性值\n",
    "    attribute_set=[]\n",
    "    count_arribute=0#基因選擇後的屬性個數\n",
    "    #print(attribute)\n",
    "    i=0\n",
    "    for record in string: \n",
    "        if (record=='0'):\n",
    "            count_arribute+=1\n",
    "            attribute_set.append(i)\n",
    "        i=1+i\n",
    "    print(count_arribute)\n",
    "    \n",
    "    data1 = []\n",
    "    label1 = []\n",
    "    data2 = []\n",
    "    label2 = []\n",
    "    \n",
    "    for i in os.listdir(dirdata1):\n",
    "        npy_file = (dirdata1+i)\n",
    "        x=np.load(npy_file)\n",
    "        \n",
    "        #x=np.delete(x, [30,31,32,33,34,35,36,37,40,41,42,43,46,47,48,49], axis=1)\n",
    "        x=np.delete(x,attribute_set , axis=1)\n",
    "        a,b=x.shape\n",
    "        x=x.flatten('F')\n",
    "        x.resize(120*b)\n",
    "        x = np.array(x)\n",
    "        \n",
    "        \n",
    "        data1.append(x)\n",
    "        label1.append(0)\n",
    "    print(len(data1))\n",
    "\n",
    "    for i in os.listdir(dirdata2):\n",
    "        npy_file = (dirdata2+i)\n",
    "        x=np.load(npy_file)\n",
    "        #x=np.delete(x, [30,31,32,33,34,35,36,37,40,41,42,43,46,47,48,49], axis=1)\n",
    "        x=np.delete(x,attribute_set , axis=1)\n",
    "        a,b=x.shape\n",
    "        \n",
    "        x=x.flatten('F')\n",
    "        \n",
    "        x.resize(120*b)\n",
    "        x = np.array(x)\n",
    "        \n",
    "        data2.append(x)\n",
    "        label2.append(1)\n",
    "    print(len(data2))\n",
    "    \n",
    "    # print(data1)\n",
    "    data1 = np.array(data1)\n",
    "    label1 = np.array(label1)\n",
    "    print(data1)\n",
    "    data2 = np.array(data2)\n",
    "    label2 = np.array(label2)\n",
    "    \n",
    "    \n",
    "    print(label1.shape)\n",
    "    #print(label1)\n",
    "    \n",
    "    data1 = preprocessing.scale(data1)\n",
    "    data2 = preprocessing.scale(data2)\n",
    "   \n",
    "    #print(data1)\n",
    "    print(data1.shape)\n",
    "#     data1=medfilt(data1,3)\n",
    "#     data1=gaussian_filter1d(data1,1.2)\n",
    "#     data2=medfilt(data2,3)\n",
    "#     data2=gaussian_filter1d(data2,1.2)\n",
    "#     sc=MinMaxScaler(feature_range=(0,1))\n",
    "#     data1=sc.fit_transform(data1)\n",
    "#     data2=sc.fit_transform(data2)\n",
    "    return  data1,label1,data2,label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasplit(data,label):\n",
    "    train_X,test_X, train_y, test_y = train_test_split(data,\n",
    "                                                   label,\n",
    "                                                   test_size = 0.4,\n",
    "                                                   random_state = 77,shuffle=True)\n",
    "    return train_X,test_X, train_y, test_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasplit1(data,label):\n",
    "    train_X,test_X, train_y, test_y = train_test_split(data,\n",
    "                                                   label,\n",
    "                                                   test_size = 0.5,\n",
    "                                                   random_state = 42,shuffle=True)\n",
    "    return train_X,test_X, train_y, test_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分類數據重組\n",
    "def classdataReorganization(data1,label1,data2,label2,step):\n",
    "    re_train_data = []\n",
    "    re_train_label=[]\n",
    "    \n",
    "    data1 = np.array(data1)\n",
    "    data2 = np.array(data2)\n",
    "    \n",
    "    for i in range(0,data1.shape[0]):\n",
    "        re_train_data.append(data1[i])\n",
    "        re_train_label.append(label1[0])\n",
    "\n",
    "    for i in range(0,data2.shape[0]):\n",
    "        re_train_data.append(data2[i])\n",
    "        re_train_label.append(label2[0])\n",
    "    \n",
    "    \n",
    "    All_data = np.array(re_train_data)\n",
    "    All_label = np.array(re_train_label)\n",
    "    #print(All_data[0])\n",
    "     # Label Onehot-encoding \n",
    "    All_label = np_utils.to_categorical(All_label)\n",
    "    #print(All_data.shape[2])\n",
    "    #print(All_label.shape)\n",
    "    #print(All_label)\n",
    "    return All_data,All_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分類數據重組\n",
    "def classdataReorganization1(data1,label1,data2,label2,step):\n",
    "    re_train_data = []\n",
    "    re_train_label=[]\n",
    "    #print(data1.shape)\n",
    "    #print(label1)\n",
    "    for i in range(len(data1)-step):\n",
    "        re_train_data.append(data1[i:i+step])\n",
    "        re_train_label.append(label1[i+step])\n",
    "\n",
    "    for i in range(len(data2)-step):\n",
    "        re_train_data.append(data2[i:i+step])\n",
    "        re_train_label.append(label2[i+step])\n",
    "    \n",
    "    \n",
    "    All_data = np.array(re_train_data)\n",
    "    All_label = np.array(re_train_label)\n",
    "    #print(All_data.shape)\n",
    "     # Label Onehot-encoding \n",
    "    All_label = np_utils.to_categorical(All_label)\n",
    "    return All_data,All_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分類數據重組\n",
    "def classdataReorganization2(data1,label1,data2,label2,step):\n",
    "    re_train_data = []\n",
    "    re_train_label=[]\n",
    "    \n",
    "    data1 = np.array(data1)\n",
    "    data2 = np.array(data2)\n",
    "    #print(data1.shape)\n",
    "    #print(label1)\n",
    "    \n",
    "    for i in range(0,data1.shape[0]):\n",
    "        re_train_data.append(data1[i])\n",
    "        re_train_label.append(label1[i])\n",
    "\n",
    "    for i in range(0,data2.shape[0]):\n",
    "        re_train_data.append(data2[i])\n",
    "        re_train_label.append(label2[i])\n",
    "    \n",
    "    \n",
    "    All_data = np.array(re_train_data)\n",
    "    All_label = np.array(re_train_label)\n",
    "    #print(All_data.shape)\n",
    "    #print(All_data[0])\n",
    "     # Label Onehot-encoding \n",
    "    All_label = np_utils.to_categorical(All_label)\n",
    "    return All_data,All_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeModel(X,step):\n",
    "# 序列到序列堆叠式LSTM模型 \n",
    "    #temp=X.shape[2]\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(20,activation='relu',input_shape=(step,X.shape[2]),return_sequences=True))\n",
    "    model.add(LSTM(20,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(2,activation = 'sigmoid'))\n",
    "    model.compile(loss='mse', optimizer=\"Adam\", metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeModel1(X,step):\n",
    "# 序列到序列堆叠式LSTM模型 \n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(20,activation='relu',input_shape=(step,X.shape[2]),return_sequences=True))\n",
    "    model.add(LSTM(20,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(2,activation = 'sigmoid'))\n",
    "    model.compile(loss='mse', optimizer=\"Adam\", metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基因演算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GA():\n",
    "    def __init__(self, length, count):\n",
    "        # 染色體長度\n",
    "        self.length = length\n",
    "        # 種群中的染色體數量\n",
    "        self.count = count\n",
    "        # 隨機生成初始種群\n",
    "        self.population = self.gen_population(length, count)\n",
    "        for i in range(len(self.population)):\n",
    "            print(\"染色體：\")\n",
    "            print(i)\n",
    "            print (self.population[i])\n",
    "            print ('{0:b}'.format(self.population[i]))\n",
    "#         #數據文路徑\n",
    "#         self.filedir=filedir\n",
    "    def evolve(self, retain_rate=0.2, random_select_rate=0.5, mutation_rate=0.01):\n",
    "        \"\"\"\n",
    "        進化\n",
    "        對當前一代種群依次進行選擇、交叉並生成新一代種群，然後對新一代種群進行變異\n",
    "        \"\"\"\n",
    "        parents = self.selection(retain_rate, random_select_rate)\n",
    "        self.crossover(parents)\n",
    "        self.mutation(mutation_rate)\n",
    "    def gen_chromosome(self, length):\n",
    "        \"\"\"\n",
    "        隨機生成長度為length的染色體，每個基因的取值是0或1\n",
    "        這裡用一個bit表示一個基因\n",
    "        \"\"\"\n",
    "        chromosome = 0\n",
    "        for i in range(length):\n",
    "            # 這裡的或是整個二進位制比對的或|,比如10和1或下來的結果是11，  1001和101或的結果是1101，所以此處是個不斷隨機或出來的長度\n",
    "            chromosome |= (1 << i) * random.randint(0, 1)  # 這裡每次左移， 隨機生成一個0或者1的數字，這樣不斷左移生成給定長度的二進位制染色體\n",
    "\n",
    "        #print ('{0:b}'.format(chromosome))\n",
    "        print(\"gen_chromosome pass\")\n",
    "        return chromosome\n",
    "    def gen_population(self, length, count):\n",
    "        \"\"\"\n",
    "        獲取初始種群（一個含有count個長度為length的染色體的列表）\n",
    "        \"\"\"\n",
    "        po=[]\n",
    "        j=0\n",
    "        while j<=count:#保证染色体长度一致\n",
    "            chromosome=0\n",
    "            for i in range(length):\n",
    "                    # 這裡的或是整個二進位制比對的或|,比如10和1或下來的結果是11，  1001和101或的結果是1101，所以此處是個不斷隨機或出來的長度\n",
    "                    chromosome |= (1 << i) * random.randint(0, 1) \n",
    "                    #print('{0:b}'.format(chromosome))\n",
    "            string='{0:b}'.format(chromosome)\n",
    "            len_chromosome=len(string)\n",
    "            if len_chromosome==length:\n",
    "                po.append(chromosome)\n",
    "                j+=1\n",
    "\n",
    "            \n",
    "        print(\"gen_population pass\")\n",
    "        return po\n",
    "    def fitness(self, chromosome):\n",
    "            string='{0:b}'.format(chromosome)\n",
    "            print(\"所選擇的染色體：\")\n",
    "            print(string)\n",
    "            #檔案路徑\n",
    "            class_dirdata1='正手訓/'\n",
    "            class_dirdata2='反手訓/'\n",
    "            #特征篩選\n",
    "            class_data1,class_label1,class_data2,class_label2=classdatapredeal(class_dirdata1,class_dirdata2,string)\n",
    "            time_step=100#時間序列設置\n",
    "            #數據和標籤設定\n",
    "            class_All_data,class_All_label=classdataReorganization1(class_data1,class_label1,class_data2,class_label2,time_step)\n",
    "            #訓練集測試集分割\n",
    "            train_X,test_X, train_y, test_y=datasplit(class_All_data,class_All_label)\n",
    "            \n",
    "            print(train_X.shape)\n",
    "            \n",
    "            #print(train_X)\n",
    "            \n",
    "            #print(train_X[0][0])\n",
    "            \n",
    "            #print(train_X[0][0].shape)\n",
    "            \n",
    "            #模型訓練\n",
    "            timemodel=timeModel1(train_X,time_step)\n",
    "            history = timemodel.fit(train_X,train_y,epochs=50, validation_split=0.2,batch_size=50, verbose=1)\n",
    "            score = timemodel.evaluate(test_X, test_y, verbose=0)\n",
    "            \n",
    "            print(score[1])\n",
    "            print(\"fitness pass\")\n",
    "            return score[1]\n",
    "    def selection(self, retain_rate, random_select_rate):\n",
    "        \"\"\"\n",
    "        選擇\n",
    "        先對適應度從大到小排序，選出存活的染色體\n",
    "        再進行隨機選擇，選出適應度雖然小，但是倖存下來的個體\n",
    "        \"\"\"\n",
    "        # 對適應度從大到小進行排序\n",
    "        graded = [(self.fitness(chromosome), chromosome) for chromosome in self.population]  # 求出所有染色體的適應值列表\n",
    "        \n",
    "        print(graded)\n",
    "        graded = [x[1] for x in sorted(graded, reverse=True)]  # 從小到大排序，形成新列表\n",
    "        # 選出適應性強的染色體\n",
    "        retain_length = int(len(graded) * retain_rate)  # 根據比例值  找到前。個適應性強的染色體 作為下一代的父母親\n",
    "        parents = graded[:retain_length]\n",
    "        print(parents)\n",
    "        # 選出適應性不強，但是倖存的染色體        從後面中  隨機選取一比例   也放到父母親中\n",
    "        for chromosome in graded[retain_length:]:\n",
    "            if random.random() < random_select_rate:\n",
    "                parents.append(chromosome)\n",
    "        print(parents)\n",
    "        print(\"selection pass\")\n",
    "        return parents\n",
    "    def crossover(self, parents):\n",
    "        \"\"\"\n",
    "        染色體的交叉、繁殖，生成新一代的種群\n",
    "        \"\"\"\n",
    "        # 新出生的孩子，最終會被加入存活下來的父母之中，形成新一代的種群。\n",
    "        children = []\n",
    "        # 需要繁殖的孩子的量，差值，就是要交叉生成的目標數\n",
    "        target_count = len(self.population) - len(parents)\n",
    "        print(\"target_count:\")\n",
    "        print(target_count)\n",
    "        # 開始根據需要的量進行繁殖\n",
    "        while len(children) < target_count:\n",
    "            male = random.randint(0, len(parents) - 1)\n",
    "            female = random.randint(0, len(parents) - 1)\n",
    "            if male != female:  # 父母親序號不能相同\n",
    "                # 隨機選取交叉點\n",
    "                cross_pos = random.randint(0, self.length)\n",
    "                # 生成掩碼，方便位操作\n",
    "                mask = 0\n",
    "                for i in range(cross_pos):\n",
    "                    mask |= (1 << i)\n",
    "                male = parents[male]\n",
    "                female = parents[female]\n",
    "                # 孩子將獲得父親在交叉點前的基因和母親在交叉點後（包括交叉點）的基因\n",
    "                child = ((male & mask) | (female & ~mask)) & ((1 << self.length) - 1)\n",
    "                children.append(child)\n",
    "        # 經過繁殖後，孩子和父母的數量與原始種群數量相等，在這裡可以更新種群。\n",
    "        self.population = parents + children\n",
    "        for i in range(len(self.population)):\n",
    "            print(\"生成新一代的種群\")\n",
    "            print(\"染色體：\")\n",
    "            print(i)\n",
    "            print (self.population[i])\n",
    "            print ('{0:b}'.format(self.population[i]))\n",
    "        print(\"crossover pass\")\n",
    "    def mutation(self, rate):\n",
    "        \"\"\"\n",
    "        變異\n",
    "        對種群中的所有個體，隨機改變某個個體中的某個基因\n",
    "        \"\"\"\n",
    "        for i in range(len(self.population)):\n",
    "            if random.random() < rate:\n",
    "                j = random.randint(0, self.length - 1)\n",
    "                self.population[i] ^= 1 << j\n",
    "        for i in range(len(self.population)):\n",
    "            print(\"變異後的種群\")\n",
    "            print(\"染色體：\")\n",
    "            print(i)\n",
    "            print (self.population[i])\n",
    "            print ('{0:b}'.format(self.population[i]))\n",
    "        print(\"mutation pass\")\n",
    "    def decode(self, chromosome):\n",
    "            \"\"\"\n",
    "            解碼染色體，將二進位制轉化為屬於[0, 9]的實數\n",
    "            \"\"\"\n",
    "            print(\"decode pass\")\n",
    "            return chromosome * 9.0 / (2 ** self.length - 1)\n",
    "            \n",
    "    def result(self):\n",
    "        \"\"\"\n",
    "        獲得當前代的最優值，這裡取的是函式取最大值時x的值。\n",
    "        \"\"\"\n",
    "#         print (self.population[i])\n",
    "#         print ('{0:b}'.format(self.population[i]))\n",
    "        print(\"result pass\")\n",
    "        return '{0:b}'.format(self.population[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合併演算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_population pass\n",
      "染色體：\n",
      "0\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "染色體：\n",
      "1\n",
      "775310821526625\n",
      "10110000010010010000011110000110111000110001100001\n",
      "染色體：\n",
      "2\n",
      "921963755448778\n",
      "11010001101000010101101010001000111010100111001010\n",
      "染色體：\n",
      "3\n",
      "957257731078682\n",
      "11011001101001111011101111000001001111101000011010\n",
      "染色體：\n",
      "4\n",
      "1061734365432041\n",
      "11110001011010010001001011101100101000100011101001\n",
      "染色體：\n",
      "5\n",
      "675987511003229\n",
      "10011001101100111010011011011101110100100001011101\n",
      "染色體：\n",
      "6\n",
      "1019307627305479\n",
      "11100111110000111000001101000010101101101000000111\n",
      "染色體：\n",
      "7\n",
      "785501562696613\n",
      "10110010100110100011010101100111010111001110100101\n",
      "染色體：\n",
      "8\n",
      "714840212662246\n",
      "10100010100010010010110100111100100110011111100110\n",
      "染色體：\n",
      "9\n",
      "961137397134474\n",
      "11011010100010011000111101001000101111010010001010\n",
      "染色體：\n",
      "10\n",
      "1110258296291920\n",
      "11111100011100011000100111010111000000001001010000\n",
      "迭代次數： 0\n",
      "0\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111101010100000\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n",
      "(144, 100, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.2903 - accuracy: 0.5304 - val_loss: 0.2750 - val_accuracy: 0.7586\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2860 - accuracy: 0.6087 - val_loss: 0.2785 - val_accuracy: 0.5172\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2836 - accuracy: 0.6348 - val_loss: 0.2672 - val_accuracy: 0.6552\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2900 - accuracy: 0.5565 - val_loss: 0.2881 - val_accuracy: 0.6207\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.3069 - accuracy: 0.5217 - val_loss: 0.3505 - val_accuracy: 0.3448\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2906 - accuracy: 0.5652 - val_loss: 0.2935 - val_accuracy: 0.5862\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2945 - accuracy: 0.4957 - val_loss: 0.3974 - val_accuracy: 0.3448\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.3212 - accuracy: 0.4783 - val_loss: 0.2445 - val_accuracy: 0.3793\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2824 - accuracy: 0.4696 - val_loss: 0.2356 - val_accuracy: 0.4138\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2850 - accuracy: 0.4087 - val_loss: 0.2284 - val_accuracy: 0.4483\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.3022 - accuracy: 0.5478 - val_loss: 0.2934 - val_accuracy: 0.2759\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.3021 - accuracy: 0.5043 - val_loss: 0.2333 - val_accuracy: 0.4828\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2999 - accuracy: 0.5304 - val_loss: 0.2834 - val_accuracy: 0.3793\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2953 - accuracy: 0.5391 - val_loss: 0.2493 - val_accuracy: 0.4828\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2966 - accuracy: 0.5565 - val_loss: 0.2726 - val_accuracy: 0.3793\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2679 - accuracy: 0.6087 - val_loss: 0.2487 - val_accuracy: 0.4828\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2734 - accuracy: 0.6174 - val_loss: 0.2627 - val_accuracy: 0.3793\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2776 - accuracy: 0.5478 - val_loss: 0.2610 - val_accuracy: 0.3793\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2895 - accuracy: 0.5478 - val_loss: 0.2649 - val_accuracy: 0.3448\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2862 - accuracy: 0.5130 - val_loss: 0.2568 - val_accuracy: 0.4138\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2846 - accuracy: 0.5130 - val_loss: 0.2602 - val_accuracy: 0.3793\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2935 - accuracy: 0.5217 - val_loss: 0.2532 - val_accuracy: 0.3793\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2836 - accuracy: 0.5478 - val_loss: 0.2581 - val_accuracy: 0.4138\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2623 - accuracy: 0.5652 - val_loss: 0.2536 - val_accuracy: 0.4483\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2716 - accuracy: 0.6087 - val_loss: 0.2619 - val_accuracy: 0.4483\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2961 - accuracy: 0.5304 - val_loss: 0.2600 - val_accuracy: 0.3793\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2716 - accuracy: 0.6087 - val_loss: 0.2666 - val_accuracy: 0.3448\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2959 - accuracy: 0.5391 - val_loss: 0.2654 - val_accuracy: 0.3793\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2709 - accuracy: 0.5826 - val_loss: 0.2650 - val_accuracy: 0.3793\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2668 - accuracy: 0.5913 - val_loss: 0.2659 - val_accuracy: 0.3793\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2680 - accuracy: 0.5913 - val_loss: 0.2618 - val_accuracy: 0.3793\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2727 - accuracy: 0.5304 - val_loss: 0.2654 - val_accuracy: 0.3793\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2790 - accuracy: 0.6000 - val_loss: 0.2763 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2844 - accuracy: 0.5043 - val_loss: 0.2790 - val_accuracy: 0.4138\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2863 - accuracy: 0.5826 - val_loss: 0.2712 - val_accuracy: 0.3793\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2916 - accuracy: 0.5304 - val_loss: 0.2730 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.3074 - accuracy: 0.4870 - val_loss: 0.2769 - val_accuracy: 0.3448\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2862 - accuracy: 0.5217 - val_loss: 0.2760 - val_accuracy: 0.4483\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2696 - accuracy: 0.6000 - val_loss: 0.2674 - val_accuracy: 0.4483\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2774 - accuracy: 0.5391 - val_loss: 0.2649 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2846 - accuracy: 0.5391 - val_loss: 0.2642 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2792 - accuracy: 0.5739 - val_loss: 0.2667 - val_accuracy: 0.4138\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2608 - accuracy: 0.6696 - val_loss: 0.2679 - val_accuracy: 0.3793\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2606 - accuracy: 0.6087 - val_loss: 0.2690 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2551 - accuracy: 0.6174 - val_loss: 0.2785 - val_accuracy: 0.3793\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2702 - accuracy: 0.5478 - val_loss: 0.2739 - val_accuracy: 0.3793\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2672 - accuracy: 0.6000 - val_loss: 0.2669 - val_accuracy: 0.4483\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2382 - accuracy: 0.6783 - val_loss: 0.2683 - val_accuracy: 0.4483\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2362 - accuracy: 0.7043 - val_loss: 0.2671 - val_accuracy: 0.4483\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2457 - accuracy: 0.6783 - val_loss: 0.2627 - val_accuracy: 0.4483\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2515 - accuracy: 0.6696 - val_loss: 0.2661 - val_accuracy: 0.3793\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2467 - accuracy: 0.6609 - val_loss: 0.2687 - val_accuracy: 0.3793\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2460 - accuracy: 0.6348 - val_loss: 0.2693 - val_accuracy: 0.3793\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2430 - accuracy: 0.6435 - val_loss: 0.2728 - val_accuracy: 0.3448\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2344 - accuracy: 0.7043 - val_loss: 0.2749 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2312 - accuracy: 0.6609 - val_loss: 0.2717 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2274 - accuracy: 0.7043 - val_loss: 0.2758 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2310 - accuracy: 0.6435 - val_loss: 0.2714 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2293 - accuracy: 0.7130 - val_loss: 0.2724 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2370 - accuracy: 0.6696 - val_loss: 0.2720 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2344 - accuracy: 0.6783 - val_loss: 0.2663 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2282 - accuracy: 0.6609 - val_loss: 0.2710 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2383 - accuracy: 0.6087 - val_loss: 0.2695 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2361 - accuracy: 0.6261 - val_loss: 0.2741 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2353 - accuracy: 0.6348 - val_loss: 0.2736 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2411 - accuracy: 0.6435 - val_loss: 0.2809 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2421 - accuracy: 0.6261 - val_loss: 0.2707 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2259 - accuracy: 0.6783 - val_loss: 0.2703 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2393 - accuracy: 0.6261 - val_loss: 0.2757 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2577 - accuracy: 0.6000 - val_loss: 0.2769 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2754 - accuracy: 0.5478 - val_loss: 0.2750 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2686 - accuracy: 0.5913 - val_loss: 0.2763 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2886 - accuracy: 0.5391 - val_loss: 0.2804 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2671 - accuracy: 0.6174 - val_loss: 0.2758 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2607 - accuracy: 0.5826 - val_loss: 0.2816 - val_accuracy: 0.4483\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2400 - accuracy: 0.6435 - val_loss: 0.2797 - val_accuracy: 0.4483\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2614 - accuracy: 0.6000 - val_loss: 0.2795 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2551 - accuracy: 0.6522 - val_loss: 0.2783 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2427 - accuracy: 0.6261 - val_loss: 0.2786 - val_accuracy: 0.4483\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2436 - accuracy: 0.6087 - val_loss: 0.2804 - val_accuracy: 0.4483\n",
      "0.6145833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "10110000010010010000011110000110111000110001100001\n",
      "30\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 2400)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 100, 20)           193680    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 197,082\n",
      "Trainable params: 197,042\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.3189 - accuracy: 0.4870 - val_loss: 0.2258 - val_accuracy: 0.7586\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2454 - accuracy: 0.6870 - val_loss: 0.2628 - val_accuracy: 0.6207\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2750 - accuracy: 0.5217 - val_loss: 0.3341 - val_accuracy: 0.5172\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2988 - accuracy: 0.3826 - val_loss: 0.3099 - val_accuracy: 0.6552\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2613 - accuracy: 0.6087 - val_loss: 0.3090 - val_accuracy: 0.6552\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2634 - accuracy: 0.6348 - val_loss: 0.3272 - val_accuracy: 0.5517\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2559 - accuracy: 0.6174 - val_loss: 0.3587 - val_accuracy: 0.4828\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.2833 - accuracy: 0.5304 - val_loss: 0.3603 - val_accuracy: 0.5172\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.3049 - accuracy: 0.4870 - val_loss: 0.3543 - val_accuracy: 0.4828\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2809 - accuracy: 0.4783 - val_loss: 0.3647 - val_accuracy: 0.4828\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2705 - accuracy: 0.4522 - val_loss: 0.3547 - val_accuracy: 0.4828\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2721 - accuracy: 0.5217 - val_loss: 0.2824 - val_accuracy: 0.6552\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2619 - accuracy: 0.6609 - val_loss: 0.2646 - val_accuracy: 0.6552\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2565 - accuracy: 0.6783 - val_loss: 0.2672 - val_accuracy: 0.6897\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2695 - accuracy: 0.6435 - val_loss: 0.3094 - val_accuracy: 0.4828\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2560 - accuracy: 0.5130 - val_loss: 0.3678 - val_accuracy: 0.3448\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2685 - accuracy: 0.6435 - val_loss: 0.2763 - val_accuracy: 0.3448\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.3006 - accuracy: 0.4609 - val_loss: 0.2815 - val_accuracy: 0.3448\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2859 - accuracy: 0.4609 - val_loss: 0.3039 - val_accuracy: 0.2414\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2859 - accuracy: 0.4435 - val_loss: 0.2539 - val_accuracy: 0.3448\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.3268 - accuracy: 0.3913 - val_loss: 0.2622 - val_accuracy: 0.4828\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2999 - accuracy: 0.4957 - val_loss: 0.2883 - val_accuracy: 0.4828\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.3166 - accuracy: 0.5130 - val_loss: 0.3080 - val_accuracy: 0.3793\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2912 - accuracy: 0.5130 - val_loss: 0.3314 - val_accuracy: 0.4828\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2847 - accuracy: 0.6000 - val_loss: 0.2660 - val_accuracy: 0.4138\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.3083 - accuracy: 0.4870 - val_loss: 0.2939 - val_accuracy: 0.3448\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.3048 - accuracy: 0.5130 - val_loss: 0.2778 - val_accuracy: 0.4138\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2941 - accuracy: 0.5304 - val_loss: 0.2945 - val_accuracy: 0.3793\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2919 - accuracy: 0.5391 - val_loss: 0.2846 - val_accuracy: 0.4138\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2839 - accuracy: 0.6000 - val_loss: 0.2984 - val_accuracy: 0.4138\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2854 - accuracy: 0.5652 - val_loss: 0.2691 - val_accuracy: 0.4138\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2943 - accuracy: 0.5565 - val_loss: 0.2719 - val_accuracy: 0.4483\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.3076 - accuracy: 0.4783 - val_loss: 0.3006 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.3088 - accuracy: 0.4870 - val_loss: 0.2936 - val_accuracy: 0.4138\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.3150 - accuracy: 0.5478 - val_loss: 0.2774 - val_accuracy: 0.4138\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.3040 - accuracy: 0.5304 - val_loss: 0.2747 - val_accuracy: 0.4483\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.3037 - accuracy: 0.5043 - val_loss: 0.2791 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2796 - accuracy: 0.5478 - val_loss: 0.2766 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2743 - accuracy: 0.6000 - val_loss: 0.2645 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2804 - accuracy: 0.5826 - val_loss: 0.2717 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2683 - accuracy: 0.6261 - val_loss: 0.2815 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2734 - accuracy: 0.5913 - val_loss: 0.2700 - val_accuracy: 0.4483\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2729 - accuracy: 0.6435 - val_loss: 0.2630 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2714 - accuracy: 0.5739 - val_loss: 0.2775 - val_accuracy: 0.3793\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2694 - accuracy: 0.6261 - val_loss: 0.2793 - val_accuracy: 0.3793\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2763 - accuracy: 0.5913 - val_loss: 0.2781 - val_accuracy: 0.4483\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2785 - accuracy: 0.6609 - val_loss: 0.2754 - val_accuracy: 0.4483\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2915 - accuracy: 0.5913 - val_loss: 0.2752 - val_accuracy: 0.4483\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2903 - accuracy: 0.6783 - val_loss: 0.2721 - val_accuracy: 0.4483\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2895 - accuracy: 0.6000 - val_loss: 0.2700 - val_accuracy: 0.4483\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2778 - accuracy: 0.6348 - val_loss: 0.2642 - val_accuracy: 0.4828\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2814 - accuracy: 0.6087 - val_loss: 0.2690 - val_accuracy: 0.4483\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2598 - accuracy: 0.6522 - val_loss: 0.2672 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2707 - accuracy: 0.6696 - val_loss: 0.2648 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2651 - accuracy: 0.6609 - val_loss: 0.2714 - val_accuracy: 0.3793\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2849 - accuracy: 0.6261 - val_loss: 0.2686 - val_accuracy: 0.3793\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2856 - accuracy: 0.5739 - val_loss: 0.2831 - val_accuracy: 0.3448\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2617 - accuracy: 0.5826 - val_loss: 0.3113 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2540 - accuracy: 0.6783 - val_loss: 0.2990 - val_accuracy: 0.5172\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2665 - accuracy: 0.5826 - val_loss: 0.3108 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2622 - accuracy: 0.6174 - val_loss: 0.3085 - val_accuracy: 0.4483\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2715 - accuracy: 0.6087 - val_loss: 0.3493 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2516 - accuracy: 0.6261 - val_loss: 0.3046 - val_accuracy: 0.3793\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2636 - accuracy: 0.5739 - val_loss: 0.2955 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2483 - accuracy: 0.6696 - val_loss: 0.2808 - val_accuracy: 0.3793\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2510 - accuracy: 0.6261 - val_loss: 0.2893 - val_accuracy: 0.3793\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2564 - accuracy: 0.6261 - val_loss: 0.2850 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2647 - accuracy: 0.6087 - val_loss: 0.2870 - val_accuracy: 0.4483\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2851 - accuracy: 0.5565 - val_loss: 0.2994 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2531 - accuracy: 0.6348 - val_loss: 0.2836 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2610 - accuracy: 0.6087 - val_loss: 0.2961 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2605 - accuracy: 0.6000 - val_loss: 0.3164 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2642 - accuracy: 0.5826 - val_loss: 0.2783 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2708 - accuracy: 0.5565 - val_loss: 0.2749 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2695 - accuracy: 0.5652 - val_loss: 0.2914 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2460 - accuracy: 0.6348 - val_loss: 0.2857 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2596 - accuracy: 0.5913 - val_loss: 0.2865 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2569 - accuracy: 0.5739 - val_loss: 0.2859 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2421 - accuracy: 0.6609 - val_loss: 0.2761 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2490 - accuracy: 0.5739 - val_loss: 0.3000 - val_accuracy: 0.4138\n",
      "0.625\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001101000010101101010001000111010100111001010\n",
      "27\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2760)\n",
      "(144, 100, 2760)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 100, 20)           222480    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 225,882\n",
      "Trainable params: 225,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 0.2777 - accuracy: 0.5478 - val_loss: 0.5091 - val_accuracy: 0.4483\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.3159 - accuracy: 0.4609 - val_loss: 0.3198 - val_accuracy: 0.4828\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.3083 - accuracy: 0.3826 - val_loss: 0.4767 - val_accuracy: 0.3793\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.3323 - accuracy: 0.2609 - val_loss: 0.6482 - val_accuracy: 0.3448\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.3673 - accuracy: 0.1826 - val_loss: 0.5839 - val_accuracy: 0.3793\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.3638 - accuracy: 0.1478 - val_loss: 0.5072 - val_accuracy: 0.4138\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.3214 - accuracy: 0.2870 - val_loss: 0.4464 - val_accuracy: 0.4138\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.3018 - accuracy: 0.3565 - val_loss: 0.4677 - val_accuracy: 0.4138\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2919 - accuracy: 0.4261 - val_loss: 0.4530 - val_accuracy: 0.4138\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.3008 - accuracy: 0.3739 - val_loss: 0.4436 - val_accuracy: 0.4138\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.2941 - accuracy: 0.4522 - val_loss: 0.4343 - val_accuracy: 0.4138\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2873 - accuracy: 0.4609 - val_loss: 0.4234 - val_accuracy: 0.4138\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2865 - accuracy: 0.4870 - val_loss: 0.4023 - val_accuracy: 0.4138\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2823 - accuracy: 0.4696 - val_loss: 0.3928 - val_accuracy: 0.4138\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2601 - accuracy: 0.5217 - val_loss: 0.3717 - val_accuracy: 0.4483\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2609 - accuracy: 0.6261 - val_loss: 0.3736 - val_accuracy: 0.4138\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2750 - accuracy: 0.6000 - val_loss: 0.3630 - val_accuracy: 0.4138\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2633 - accuracy: 0.6435 - val_loss: 0.3596 - val_accuracy: 0.4138\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2518 - accuracy: 0.6696 - val_loss: 0.3544 - val_accuracy: 0.4138\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2440 - accuracy: 0.7304 - val_loss: 0.3351 - val_accuracy: 0.4138\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2471 - accuracy: 0.7391 - val_loss: 0.3230 - val_accuracy: 0.4138\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2323 - accuracy: 0.7478 - val_loss: 0.3102 - val_accuracy: 0.4138\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2452 - accuracy: 0.7478 - val_loss: 0.2980 - val_accuracy: 0.4138\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2399 - accuracy: 0.8261 - val_loss: 0.2987 - val_accuracy: 0.4138\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2403 - accuracy: 0.6957 - val_loss: 0.2945 - val_accuracy: 0.4138\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2325 - accuracy: 0.6870 - val_loss: 0.2921 - val_accuracy: 0.4138\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2422 - accuracy: 0.6435 - val_loss: 0.2859 - val_accuracy: 0.4138\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2232 - accuracy: 0.7913 - val_loss: 0.2849 - val_accuracy: 0.4138\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2193 - accuracy: 0.7391 - val_loss: 0.2833 - val_accuracy: 0.4138\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2203 - accuracy: 0.7304 - val_loss: 0.2805 - val_accuracy: 0.4138\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2178 - accuracy: 0.7565 - val_loss: 0.2758 - val_accuracy: 0.4138\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2132 - accuracy: 0.7913 - val_loss: 0.2764 - val_accuracy: 0.4138\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2081 - accuracy: 0.8261 - val_loss: 0.2658 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2038 - accuracy: 0.8000 - val_loss: 0.2532 - val_accuracy: 0.4483\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2053 - accuracy: 0.8087 - val_loss: 0.2470 - val_accuracy: 0.4483\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.1967 - accuracy: 0.8348 - val_loss: 0.2422 - val_accuracy: 0.4483\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1965 - accuracy: 0.8522 - val_loss: 0.2373 - val_accuracy: 0.4483\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1923 - accuracy: 0.8609 - val_loss: 0.2309 - val_accuracy: 0.4483\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.2004 - accuracy: 0.8609 - val_loss: 0.2263 - val_accuracy: 0.4483\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1900 - accuracy: 0.8696 - val_loss: 0.2288 - val_accuracy: 0.4483\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1917 - accuracy: 0.8609 - val_loss: 0.2198 - val_accuracy: 0.4483\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.1851 - accuracy: 0.8783 - val_loss: 0.2029 - val_accuracy: 0.4483\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.1900 - accuracy: 0.8783 - val_loss: 0.2008 - val_accuracy: 0.4483\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.1856 - accuracy: 0.8348 - val_loss: 0.2083 - val_accuracy: 0.4828\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1831 - accuracy: 0.8522 - val_loss: 0.2131 - val_accuracy: 0.5862\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1811 - accuracy: 0.8522 - val_loss: 0.2126 - val_accuracy: 0.6552\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1796 - accuracy: 0.8261 - val_loss: 0.2075 - val_accuracy: 0.6552\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1756 - accuracy: 0.8522 - val_loss: 0.2024 - val_accuracy: 0.5862\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1723 - accuracy: 0.8696 - val_loss: 0.2077 - val_accuracy: 0.5172\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1708 - accuracy: 0.8696 - val_loss: 0.2050 - val_accuracy: 0.7241\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.1650 - accuracy: 0.8957 - val_loss: 0.2056 - val_accuracy: 0.8276\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.1681 - accuracy: 0.8696 - val_loss: 0.2049 - val_accuracy: 0.8621\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1648 - accuracy: 0.8870 - val_loss: 0.2054 - val_accuracy: 0.7931\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1620 - accuracy: 0.8957 - val_loss: 0.2072 - val_accuracy: 0.7241\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1660 - accuracy: 0.8870 - val_loss: 0.2022 - val_accuracy: 0.8966\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1564 - accuracy: 0.8783 - val_loss: 0.2027 - val_accuracy: 0.8966\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1556 - accuracy: 0.8957 - val_loss: 0.2020 - val_accuracy: 0.8966\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1492 - accuracy: 0.9130 - val_loss: 0.2035 - val_accuracy: 0.8966\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.1502 - accuracy: 0.9130 - val_loss: 0.2032 - val_accuracy: 0.8621\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.1504 - accuracy: 0.9130 - val_loss: 0.2012 - val_accuracy: 0.8621\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.1437 - accuracy: 0.9130 - val_loss: 0.1999 - val_accuracy: 0.8621\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1450 - accuracy: 0.9043 - val_loss: 0.1988 - val_accuracy: 0.8621\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1416 - accuracy: 0.9130 - val_loss: 0.1977 - val_accuracy: 0.8621\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1423 - accuracy: 0.8957 - val_loss: 0.1962 - val_accuracy: 0.8621\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1399 - accuracy: 0.9043 - val_loss: 0.1949 - val_accuracy: 0.8621\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.1378 - accuracy: 0.9043 - val_loss: 0.1942 - val_accuracy: 0.8621\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1385 - accuracy: 0.9130 - val_loss: 0.2048 - val_accuracy: 0.8621\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1354 - accuracy: 0.9217 - val_loss: 0.2055 - val_accuracy: 0.8621\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.1407 - accuracy: 0.8870 - val_loss: 0.2044 - val_accuracy: 0.8621\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1331 - accuracy: 0.9217 - val_loss: 0.2035 - val_accuracy: 0.8621\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.1299 - accuracy: 0.9217 - val_loss: 0.2002 - val_accuracy: 0.8621\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1278 - accuracy: 0.9304 - val_loss: 0.1881 - val_accuracy: 0.8621\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1300 - accuracy: 0.8957 - val_loss: 0.1874 - val_accuracy: 0.8621\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1258 - accuracy: 0.9217 - val_loss: 0.1834 - val_accuracy: 0.8966\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1248 - accuracy: 0.9130 - val_loss: 0.1813 - val_accuracy: 0.8966\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.1217 - accuracy: 0.9304 - val_loss: 0.1799 - val_accuracy: 0.8966\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.1220 - accuracy: 0.9217 - val_loss: 0.1794 - val_accuracy: 0.8966\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1229 - accuracy: 0.9304 - val_loss: 0.1790 - val_accuracy: 0.8966\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.1203 - accuracy: 0.9217 - val_loss: 0.1777 - val_accuracy: 0.8966\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1198 - accuracy: 0.9304 - val_loss: 0.1772 - val_accuracy: 0.8966\n",
      "0.8958333134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101001111011101111000001001111101000011010\n",
      "22\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3360)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 100, 20)           270480    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 273,882\n",
      "Trainable params: 273,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 0.2989 - accuracy: 0.4609 - val_loss: 0.3159 - val_accuracy: 0.6552\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2419 - accuracy: 0.6261 - val_loss: 0.3057 - val_accuracy: 0.6897\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2181 - accuracy: 0.7217 - val_loss: 0.2856 - val_accuracy: 0.7241\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1841 - accuracy: 0.8522 - val_loss: 0.2553 - val_accuracy: 0.7241\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1616 - accuracy: 0.9478 - val_loss: 0.1808 - val_accuracy: 0.8621\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1465 - accuracy: 0.9217 - val_loss: 0.1928 - val_accuracy: 0.7586\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1378 - accuracy: 0.9304 - val_loss: 0.1809 - val_accuracy: 0.8276\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1230 - accuracy: 0.9565 - val_loss: 0.1511 - val_accuracy: 0.8966\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0987 - accuracy: 0.9652 - val_loss: 0.1292 - val_accuracy: 0.9310\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0894 - accuracy: 0.9826 - val_loss: 0.1236 - val_accuracy: 0.9310\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0737 - accuracy: 0.9826 - val_loss: 0.0900 - val_accuracy: 0.9655\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9655\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9655\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9310\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9655\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9655\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.0932 - val_accuracy: 0.9655\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9655\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9655\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "1.0\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11110001011010010001001011101100101000100011101001\n",
      "26\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2880)\n",
      "(144, 100, 2880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 100, 20)           232080    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 235,482\n",
      "Trainable params: 235,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.2570 - accuracy: 0.5391 - val_loss: 0.3385 - val_accuracy: 0.6552\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2331 - accuracy: 0.6087 - val_loss: 0.2957 - val_accuracy: 0.5172\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2497 - accuracy: 0.6348 - val_loss: 0.4130 - val_accuracy: 0.4483\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2976 - accuracy: 0.4957 - val_loss: 0.4423 - val_accuracy: 0.5517\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.3267 - accuracy: 0.4000 - val_loss: 0.4108 - val_accuracy: 0.5862\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.3207 - accuracy: 0.2261 - val_loss: 0.4375 - val_accuracy: 0.4138\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.3273 - accuracy: 0.3217 - val_loss: 0.4022 - val_accuracy: 0.4828\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2957 - accuracy: 0.5478 - val_loss: 0.3926 - val_accuracy: 0.4483\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.3038 - accuracy: 0.4783 - val_loss: 0.3453 - val_accuracy: 0.4828\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.3047 - accuracy: 0.4348 - val_loss: 0.4222 - val_accuracy: 0.3448\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2800 - accuracy: 0.5565 - val_loss: 0.3438 - val_accuracy: 0.3793\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2855 - accuracy: 0.4609 - val_loss: 0.3631 - val_accuracy: 0.3793\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2734 - accuracy: 0.5478 - val_loss: 0.2926 - val_accuracy: 0.5517\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2656 - accuracy: 0.5739 - val_loss: 0.3322 - val_accuracy: 0.4828\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2764 - accuracy: 0.5391 - val_loss: 0.3267 - val_accuracy: 0.4138\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2613 - accuracy: 0.5826 - val_loss: 0.3112 - val_accuracy: 0.4483\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2612 - accuracy: 0.6174 - val_loss: 0.2885 - val_accuracy: 0.4138\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2934 - accuracy: 0.4522 - val_loss: 0.2897 - val_accuracy: 0.4138\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2971 - accuracy: 0.4087 - val_loss: 0.3094 - val_accuracy: 0.4138\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2757 - accuracy: 0.6522 - val_loss: 0.3606 - val_accuracy: 0.3448\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2917 - accuracy: 0.4174 - val_loss: 0.3592 - val_accuracy: 0.3793\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2637 - accuracy: 0.4696 - val_loss: 0.3168 - val_accuracy: 0.4138\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2810 - accuracy: 0.4435 - val_loss: 0.3743 - val_accuracy: 0.3448\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2938 - accuracy: 0.4696 - val_loss: 0.3717 - val_accuracy: 0.4138\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.3045 - accuracy: 0.5304 - val_loss: 0.3171 - val_accuracy: 0.4138\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2845 - accuracy: 0.4870 - val_loss: 0.2626 - val_accuracy: 0.5172\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.3086 - accuracy: 0.5478 - val_loss: 0.2587 - val_accuracy: 0.5172\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.3060 - accuracy: 0.5043 - val_loss: 0.2666 - val_accuracy: 0.4828\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2942 - accuracy: 0.5478 - val_loss: 0.2606 - val_accuracy: 0.5172\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.3132 - accuracy: 0.5391 - val_loss: 0.2597 - val_accuracy: 0.4483\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.3078 - accuracy: 0.5043 - val_loss: 0.2619 - val_accuracy: 0.4483\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.3136 - accuracy: 0.4609 - val_loss: 0.2725 - val_accuracy: 0.4828\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.3256 - accuracy: 0.4348 - val_loss: 0.2808 - val_accuracy: 0.4828\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.3168 - accuracy: 0.4087 - val_loss: 0.2552 - val_accuracy: 0.4828\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2919 - accuracy: 0.4957 - val_loss: 0.2669 - val_accuracy: 0.4483\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2695 - accuracy: 0.5478 - val_loss: 0.2611 - val_accuracy: 0.4483\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2805 - accuracy: 0.5391 - val_loss: 0.2617 - val_accuracy: 0.4483\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2681 - accuracy: 0.5652 - val_loss: 0.2606 - val_accuracy: 0.4483\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2707 - accuracy: 0.5652 - val_loss: 0.2584 - val_accuracy: 0.4483\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2487 - accuracy: 0.6435 - val_loss: 0.2603 - val_accuracy: 0.4483\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2636 - accuracy: 0.6087 - val_loss: 0.2613 - val_accuracy: 0.4483\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2706 - accuracy: 0.5652 - val_loss: 0.2575 - val_accuracy: 0.4828\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2691 - accuracy: 0.5739 - val_loss: 0.2555 - val_accuracy: 0.4828\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2498 - accuracy: 0.6348 - val_loss: 0.2540 - val_accuracy: 0.4828\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2542 - accuracy: 0.6261 - val_loss: 0.2555 - val_accuracy: 0.4828\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2430 - accuracy: 0.6522 - val_loss: 0.2523 - val_accuracy: 0.4828\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2454 - accuracy: 0.6870 - val_loss: 0.2467 - val_accuracy: 0.5172\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2382 - accuracy: 0.6435 - val_loss: 0.2446 - val_accuracy: 0.5172\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2274 - accuracy: 0.6696 - val_loss: 0.2382 - val_accuracy: 0.5517\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2555 - accuracy: 0.6000 - val_loss: 0.2579 - val_accuracy: 0.4483\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2504 - accuracy: 0.6087 - val_loss: 0.2618 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2350 - accuracy: 0.7043 - val_loss: 0.2612 - val_accuracy: 0.4138\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2473 - accuracy: 0.6522 - val_loss: 0.2553 - val_accuracy: 0.4483\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2339 - accuracy: 0.6348 - val_loss: 0.2606 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2366 - accuracy: 0.7043 - val_loss: 0.2592 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2339 - accuracy: 0.6783 - val_loss: 0.2598 - val_accuracy: 0.4483\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2379 - accuracy: 0.6348 - val_loss: 0.2581 - val_accuracy: 0.4483\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2304 - accuracy: 0.6696 - val_loss: 0.2575 - val_accuracy: 0.4483\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2225 - accuracy: 0.7043 - val_loss: 0.2530 - val_accuracy: 0.4483\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2334 - accuracy: 0.6609 - val_loss: 0.2281 - val_accuracy: 0.5517\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2288 - accuracy: 0.6609 - val_loss: 0.2229 - val_accuracy: 0.5517\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2209 - accuracy: 0.7130 - val_loss: 0.2251 - val_accuracy: 0.5517\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2325 - accuracy: 0.6609 - val_loss: 0.2282 - val_accuracy: 0.5172\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2090 - accuracy: 0.7652 - val_loss: 0.2157 - val_accuracy: 0.5862\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2154 - accuracy: 0.7391 - val_loss: 0.2337 - val_accuracy: 0.5172\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2132 - accuracy: 0.7478 - val_loss: 0.2350 - val_accuracy: 0.5172\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2112 - accuracy: 0.7478 - val_loss: 0.2362 - val_accuracy: 0.5172\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2070 - accuracy: 0.7304 - val_loss: 0.2257 - val_accuracy: 0.5862\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2039 - accuracy: 0.7739 - val_loss: 0.2224 - val_accuracy: 0.5862\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2115 - accuracy: 0.8000 - val_loss: 0.2154 - val_accuracy: 0.5517\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2103 - accuracy: 0.7478 - val_loss: 0.2606 - val_accuracy: 0.4483\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2246 - accuracy: 0.7043 - val_loss: 0.2544 - val_accuracy: 0.4483\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2131 - accuracy: 0.7391 - val_loss: 0.2652 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2170 - accuracy: 0.7130 - val_loss: 0.2623 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2315 - accuracy: 0.6174 - val_loss: 0.2631 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2341 - accuracy: 0.6522 - val_loss: 0.2667 - val_accuracy: 0.4483\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2223 - accuracy: 0.6957 - val_loss: 0.2634 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.2300 - accuracy: 0.6870 - val_loss: 0.2709 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2328 - accuracy: 0.6609 - val_loss: 0.2688 - val_accuracy: 0.4483\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2471 - accuracy: 0.6783 - val_loss: 0.2681 - val_accuracy: 0.4483\n",
      "0.6770833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "10011001101100111010011011011101110100100001011101\n",
      "22\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3360)\n",
      "(144, 100, 3360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 100, 20)           270480    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 273,882\n",
      "Trainable params: 273,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.2749 - accuracy: 0.6261 - val_loss: 0.4004 - val_accuracy: 0.7586\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2544 - accuracy: 0.6435 - val_loss: 0.2682 - val_accuracy: 0.7586\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2586 - accuracy: 0.6000 - val_loss: 0.3435 - val_accuracy: 0.5172\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2722 - accuracy: 0.6174 - val_loss: 0.3512 - val_accuracy: 0.6552\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2966 - accuracy: 0.5217 - val_loss: 0.3890 - val_accuracy: 0.6207\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.3108 - accuracy: 0.4870 - val_loss: 0.3799 - val_accuracy: 0.4138\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3017 - accuracy: 0.5391 - val_loss: 0.3047 - val_accuracy: 0.5517\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2794 - accuracy: 0.5913 - val_loss: 0.3214 - val_accuracy: 0.5172\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2930 - accuracy: 0.5565 - val_loss: 0.3211 - val_accuracy: 0.4483\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2997 - accuracy: 0.5739 - val_loss: 0.3232 - val_accuracy: 0.4138\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2884 - accuracy: 0.5565 - val_loss: 0.3022 - val_accuracy: 0.4138\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2911 - accuracy: 0.5217 - val_loss: 0.3128 - val_accuracy: 0.5517\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.3011 - accuracy: 0.5217 - val_loss: 0.3030 - val_accuracy: 0.5172\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.3123 - accuracy: 0.5217 - val_loss: 0.3515 - val_accuracy: 0.5172\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2885 - accuracy: 0.5739 - val_loss: 0.3586 - val_accuracy: 0.4483\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2933 - accuracy: 0.5130 - val_loss: 0.3100 - val_accuracy: 0.5172\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2870 - accuracy: 0.5826 - val_loss: 0.3511 - val_accuracy: 0.4828\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2821 - accuracy: 0.6174 - val_loss: 0.3168 - val_accuracy: 0.4483\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2776 - accuracy: 0.6000 - val_loss: 0.3294 - val_accuracy: 0.5517\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2631 - accuracy: 0.6087 - val_loss: 0.3248 - val_accuracy: 0.5862\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2773 - accuracy: 0.5565 - val_loss: 0.3203 - val_accuracy: 0.4828\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2682 - accuracy: 0.5826 - val_loss: 0.3348 - val_accuracy: 0.3448\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2817 - accuracy: 0.4957 - val_loss: 0.3448 - val_accuracy: 0.4138\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2935 - accuracy: 0.4522 - val_loss: 0.3113 - val_accuracy: 0.3793\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2805 - accuracy: 0.5652 - val_loss: 0.2934 - val_accuracy: 0.4828\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2918 - accuracy: 0.5043 - val_loss: 0.3360 - val_accuracy: 0.3793\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3136 - accuracy: 0.4261 - val_loss: 0.3112 - val_accuracy: 0.3448\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2744 - accuracy: 0.5304 - val_loss: 0.2776 - val_accuracy: 0.4138\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2752 - accuracy: 0.5652 - val_loss: 0.2903 - val_accuracy: 0.4483\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2769 - accuracy: 0.5043 - val_loss: 0.2965 - val_accuracy: 0.4483\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2608 - accuracy: 0.5565 - val_loss: 0.2709 - val_accuracy: 0.5172\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2614 - accuracy: 0.5217 - val_loss: 0.2794 - val_accuracy: 0.3448\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2455 - accuracy: 0.6174 - val_loss: 0.2742 - val_accuracy: 0.4483\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2569 - accuracy: 0.6174 - val_loss: 0.3252 - val_accuracy: 0.3793\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2767 - accuracy: 0.5739 - val_loss: 0.2713 - val_accuracy: 0.4828\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2634 - accuracy: 0.6174 - val_loss: 0.2925 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2679 - accuracy: 0.6000 - val_loss: 0.2858 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2700 - accuracy: 0.5478 - val_loss: 0.3049 - val_accuracy: 0.4828\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2656 - accuracy: 0.6000 - val_loss: 0.2679 - val_accuracy: 0.4828\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2590 - accuracy: 0.6348 - val_loss: 0.2207 - val_accuracy: 0.6207\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2201 - accuracy: 0.7565 - val_loss: 0.2340 - val_accuracy: 0.6552\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2182 - accuracy: 0.7565 - val_loss: 0.1971 - val_accuracy: 0.6552\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2283 - accuracy: 0.6957 - val_loss: 0.2715 - val_accuracy: 0.5517\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2449 - accuracy: 0.6174 - val_loss: 0.2712 - val_accuracy: 0.4828\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2349 - accuracy: 0.6870 - val_loss: 0.2967 - val_accuracy: 0.4828\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2419 - accuracy: 0.7043 - val_loss: 0.3122 - val_accuracy: 0.4828\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2544 - accuracy: 0.6783 - val_loss: 0.2739 - val_accuracy: 0.5172\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2637 - accuracy: 0.5739 - val_loss: 0.2881 - val_accuracy: 0.4828\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2665 - accuracy: 0.5913 - val_loss: 0.3069 - val_accuracy: 0.4483\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2690 - accuracy: 0.5826 - val_loss: 0.3165 - val_accuracy: 0.4483\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2729 - accuracy: 0.5565 - val_loss: 0.2635 - val_accuracy: 0.5517\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2486 - accuracy: 0.6348 - val_loss: 0.2978 - val_accuracy: 0.4138\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2548 - accuracy: 0.6261 - val_loss: 0.2869 - val_accuracy: 0.4828\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2385 - accuracy: 0.6696 - val_loss: 0.2841 - val_accuracy: 0.5517\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2542 - accuracy: 0.6261 - val_loss: 0.2842 - val_accuracy: 0.5172\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2468 - accuracy: 0.6783 - val_loss: 0.3126 - val_accuracy: 0.4828\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2384 - accuracy: 0.6870 - val_loss: 0.3106 - val_accuracy: 0.4828\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2501 - accuracy: 0.6696 - val_loss: 0.3030 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2547 - accuracy: 0.6435 - val_loss: 0.2810 - val_accuracy: 0.5172\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2448 - accuracy: 0.7043 - val_loss: 0.2843 - val_accuracy: 0.4483\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2657 - accuracy: 0.6261 - val_loss: 0.3009 - val_accuracy: 0.4828\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2634 - accuracy: 0.6696 - val_loss: 0.3370 - val_accuracy: 0.4828\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2560 - accuracy: 0.6783 - val_loss: 0.3013 - val_accuracy: 0.5517\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2517 - accuracy: 0.6609 - val_loss: 0.3029 - val_accuracy: 0.5172\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2482 - accuracy: 0.6435 - val_loss: 0.3128 - val_accuracy: 0.5517\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2477 - accuracy: 0.6522 - val_loss: 0.3238 - val_accuracy: 0.5862\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2571 - accuracy: 0.6174 - val_loss: 0.3373 - val_accuracy: 0.4828\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2454 - accuracy: 0.6696 - val_loss: 0.3271 - val_accuracy: 0.5172\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2651 - accuracy: 0.6435 - val_loss: 0.3239 - val_accuracy: 0.5517\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2519 - accuracy: 0.6522 - val_loss: 0.3080 - val_accuracy: 0.5172\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2575 - accuracy: 0.6174 - val_loss: 0.3258 - val_accuracy: 0.5517\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2491 - accuracy: 0.6696 - val_loss: 0.3182 - val_accuracy: 0.5862\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2385 - accuracy: 0.6348 - val_loss: 0.2899 - val_accuracy: 0.5172\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2383 - accuracy: 0.6174 - val_loss: 0.2865 - val_accuracy: 0.5172\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2324 - accuracy: 0.6609 - val_loss: 0.2741 - val_accuracy: 0.5517\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2385 - accuracy: 0.6522 - val_loss: 0.2788 - val_accuracy: 0.4828\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2375 - accuracy: 0.6174 - val_loss: 0.3043 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2494 - accuracy: 0.6174 - val_loss: 0.3035 - val_accuracy: 0.4828\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2444 - accuracy: 0.6261 - val_loss: 0.2896 - val_accuracy: 0.5172\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2417 - accuracy: 0.6609 - val_loss: 0.2816 - val_accuracy: 0.5172\n",
      "0.65625\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11100111110000111000001101000010101101101000000111\n",
      "26\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 2880)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (None, 100, 20)           232080    \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 235,482\n",
      "Trainable params: 235,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.2446 - accuracy: 0.6261 - val_loss: 0.1961 - val_accuracy: 0.6897\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1750 - accuracy: 0.7913 - val_loss: 0.3980 - val_accuracy: 0.5172\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.3238 - accuracy: 0.4435 - val_loss: 0.1565 - val_accuracy: 0.7241\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1765 - accuracy: 0.7478 - val_loss: 0.1772 - val_accuracy: 0.7586\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2021 - accuracy: 0.7043 - val_loss: 0.1697 - val_accuracy: 0.8276\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1752 - accuracy: 0.7913 - val_loss: 0.1339 - val_accuracy: 0.8621\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1827 - accuracy: 0.8087 - val_loss: 0.2993 - val_accuracy: 0.6897\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2280 - accuracy: 0.7391 - val_loss: 0.2418 - val_accuracy: 0.7241\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2637 - accuracy: 0.6087 - val_loss: 0.2208 - val_accuracy: 0.6552\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.1964 - accuracy: 0.7130 - val_loss: 0.2577 - val_accuracy: 0.6207\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1753 - accuracy: 0.8174 - val_loss: 0.2144 - val_accuracy: 0.7241\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2367 - accuracy: 0.6870 - val_loss: 0.2726 - val_accuracy: 0.5517\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1846 - accuracy: 0.7478 - val_loss: 0.2353 - val_accuracy: 0.7586\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2301 - accuracy: 0.7391 - val_loss: 0.2287 - val_accuracy: 0.7241\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2635 - accuracy: 0.6000 - val_loss: 0.3353 - val_accuracy: 0.5862\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2451 - accuracy: 0.6087 - val_loss: 0.3017 - val_accuracy: 0.5172\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2898 - accuracy: 0.5391 - val_loss: 0.2385 - val_accuracy: 0.4483\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2173 - accuracy: 0.7565 - val_loss: 0.2066 - val_accuracy: 0.7241\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2238 - accuracy: 0.6609 - val_loss: 0.1775 - val_accuracy: 0.6897\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.1860 - accuracy: 0.7391 - val_loss: 0.2192 - val_accuracy: 0.6552\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2301 - accuracy: 0.6783 - val_loss: 0.2991 - val_accuracy: 0.5517\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2425 - accuracy: 0.6261 - val_loss: 0.2550 - val_accuracy: 0.6207\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1880 - accuracy: 0.7391 - val_loss: 0.2064 - val_accuracy: 0.7241\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.1705 - accuracy: 0.7913 - val_loss: 0.2024 - val_accuracy: 0.7241\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1820 - accuracy: 0.8174 - val_loss: 0.1960 - val_accuracy: 0.7241\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1877 - accuracy: 0.7043 - val_loss: 0.2572 - val_accuracy: 0.7241\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1897 - accuracy: 0.7826 - val_loss: 0.2038 - val_accuracy: 0.7241\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2038 - accuracy: 0.7043 - val_loss: 0.2299 - val_accuracy: 0.7241\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1999 - accuracy: 0.7565 - val_loss: 0.2163 - val_accuracy: 0.6552\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2312 - accuracy: 0.7304 - val_loss: 0.2200 - val_accuracy: 0.7586\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2078 - accuracy: 0.7565 - val_loss: 0.1720 - val_accuracy: 0.8621\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1580 - accuracy: 0.8174 - val_loss: 0.2038 - val_accuracy: 0.7931\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2226 - accuracy: 0.7304 - val_loss: 0.2169 - val_accuracy: 0.6552\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2280 - accuracy: 0.6348 - val_loss: 0.2939 - val_accuracy: 0.4828\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2621 - accuracy: 0.6087 - val_loss: 0.3262 - val_accuracy: 0.5172\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2546 - accuracy: 0.6783 - val_loss: 0.2470 - val_accuracy: 0.7241\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2610 - accuracy: 0.6174 - val_loss: 0.2846 - val_accuracy: 0.6552\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2488 - accuracy: 0.6783 - val_loss: 0.3060 - val_accuracy: 0.5517\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2319 - accuracy: 0.6957 - val_loss: 0.3161 - val_accuracy: 0.5172\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2401 - accuracy: 0.6696 - val_loss: 0.2743 - val_accuracy: 0.5862\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2164 - accuracy: 0.6783 - val_loss: 0.2998 - val_accuracy: 0.5172\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1558 - accuracy: 0.8087 - val_loss: 0.2425 - val_accuracy: 0.5862\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1712 - accuracy: 0.8261 - val_loss: 0.2900 - val_accuracy: 0.4828\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1651 - accuracy: 0.8435 - val_loss: 0.2973 - val_accuracy: 0.4483\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1626 - accuracy: 0.8174 - val_loss: 0.2786 - val_accuracy: 0.4138\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1936 - accuracy: 0.6957 - val_loss: 0.2677 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2129 - accuracy: 0.6348 - val_loss: 0.2656 - val_accuracy: 0.4483\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2009 - accuracy: 0.6783 - val_loss: 0.2598 - val_accuracy: 0.4483\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2104 - accuracy: 0.6174 - val_loss: 0.2585 - val_accuracy: 0.4483\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2012 - accuracy: 0.6609 - val_loss: 0.2588 - val_accuracy: 0.4483\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1985 - accuracy: 0.6696 - val_loss: 0.2585 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1909 - accuracy: 0.7217 - val_loss: 0.2535 - val_accuracy: 0.4483\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1537 - accuracy: 0.7652 - val_loss: 0.2519 - val_accuracy: 0.4483\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1228 - accuracy: 0.8261 - val_loss: 0.2508 - val_accuracy: 0.4483\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1197 - accuracy: 0.8522 - val_loss: 0.2486 - val_accuracy: 0.4483\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1449 - accuracy: 0.8348 - val_loss: 0.2465 - val_accuracy: 0.4483\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1475 - accuracy: 0.8261 - val_loss: 0.2452 - val_accuracy: 0.5517\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1503 - accuracy: 0.8261 - val_loss: 0.2444 - val_accuracy: 0.5862\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1454 - accuracy: 0.8261 - val_loss: 0.2435 - val_accuracy: 0.5862\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1329 - accuracy: 0.8696 - val_loss: 0.2434 - val_accuracy: 0.5862\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1371 - accuracy: 0.8000 - val_loss: 0.2471 - val_accuracy: 0.5517\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1825 - accuracy: 0.7217 - val_loss: 0.2478 - val_accuracy: 0.5517\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1675 - accuracy: 0.7391 - val_loss: 0.2475 - val_accuracy: 0.4483\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1634 - accuracy: 0.7565 - val_loss: 0.2474 - val_accuracy: 0.5172\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1755 - accuracy: 0.7217 - val_loss: 0.2471 - val_accuracy: 0.5172\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1757 - accuracy: 0.7652 - val_loss: 0.2471 - val_accuracy: 0.5172\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1699 - accuracy: 0.7565 - val_loss: 0.2469 - val_accuracy: 0.5172\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1782 - accuracy: 0.7391 - val_loss: 0.2465 - val_accuracy: 0.5172\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1732 - accuracy: 0.7130 - val_loss: 0.2462 - val_accuracy: 0.5517\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.1702 - accuracy: 0.7391 - val_loss: 0.2459 - val_accuracy: 0.5517\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1868 - accuracy: 0.7652 - val_loss: 0.2457 - val_accuracy: 0.5517\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1827 - accuracy: 0.7217 - val_loss: 0.2453 - val_accuracy: 0.5517\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1799 - accuracy: 0.7565 - val_loss: 0.2449 - val_accuracy: 0.5517\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1748 - accuracy: 0.7652 - val_loss: 0.2445 - val_accuracy: 0.5517\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1725 - accuracy: 0.8000 - val_loss: 0.2439 - val_accuracy: 0.5517\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1692 - accuracy: 0.7826 - val_loss: 0.2433 - val_accuracy: 0.5517\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1671 - accuracy: 0.7565 - val_loss: 0.2428 - val_accuracy: 0.5517\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.1675 - accuracy: 0.7739 - val_loss: 0.2424 - val_accuracy: 0.5517\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.1728 - accuracy: 0.7739 - val_loss: 0.2419 - val_accuracy: 0.5517\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1704 - accuracy: 0.7826 - val_loss: 0.2415 - val_accuracy: 0.5517\n",
      "0.5520833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "10110010100110100011010101100111010111001110100101\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n",
      "(144, 100, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.2585 - accuracy: 0.6087 - val_loss: 0.5294 - val_accuracy: 0.4138\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2656 - accuracy: 0.4870 - val_loss: 0.3076 - val_accuracy: 0.6207\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2457 - accuracy: 0.7217 - val_loss: 0.3536 - val_accuracy: 0.5862\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.3100 - accuracy: 0.3739 - val_loss: 0.3287 - val_accuracy: 0.5172\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2829 - accuracy: 0.4696 - val_loss: 0.2961 - val_accuracy: 0.6897\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2895 - accuracy: 0.6609 - val_loss: 0.3216 - val_accuracy: 0.6897\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2779 - accuracy: 0.5130 - val_loss: 0.3448 - val_accuracy: 0.6897\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2918 - accuracy: 0.6087 - val_loss: 0.2459 - val_accuracy: 0.6552\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2157 - accuracy: 0.7478 - val_loss: 0.2934 - val_accuracy: 0.5862\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2757 - accuracy: 0.5826 - val_loss: 0.2881 - val_accuracy: 0.5172\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2404 - accuracy: 0.5652 - val_loss: 0.2505 - val_accuracy: 0.5172\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2623 - accuracy: 0.5826 - val_loss: 0.3215 - val_accuracy: 0.5172\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2910 - accuracy: 0.5826 - val_loss: 0.2885 - val_accuracy: 0.4138\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.3689 - accuracy: 0.5043 - val_loss: 0.2354 - val_accuracy: 0.5172\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.3475 - accuracy: 0.4435 - val_loss: 0.2622 - val_accuracy: 0.5172\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.3098 - accuracy: 0.5304 - val_loss: 0.2605 - val_accuracy: 0.3448\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2768 - accuracy: 0.5739 - val_loss: 0.3191 - val_accuracy: 0.3448\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2270 - accuracy: 0.7304 - val_loss: 0.2911 - val_accuracy: 0.5862\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2691 - accuracy: 0.6087 - val_loss: 0.3167 - val_accuracy: 0.6207\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2222 - accuracy: 0.6957 - val_loss: 0.3051 - val_accuracy: 0.5862\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2270 - accuracy: 0.7043 - val_loss: 0.3246 - val_accuracy: 0.5517\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2372 - accuracy: 0.6348 - val_loss: 0.3529 - val_accuracy: 0.5862\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2521 - accuracy: 0.6435 - val_loss: 0.3169 - val_accuracy: 0.5862\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2502 - accuracy: 0.6435 - val_loss: 0.3273 - val_accuracy: 0.5517\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2416 - accuracy: 0.6609 - val_loss: 0.3072 - val_accuracy: 0.5862\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2727 - accuracy: 0.5652 - val_loss: 0.2798 - val_accuracy: 0.5862\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2349 - accuracy: 0.6609 - val_loss: 0.3111 - val_accuracy: 0.4138\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2725 - accuracy: 0.6087 - val_loss: 0.3114 - val_accuracy: 0.4138\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2692 - accuracy: 0.5826 - val_loss: 0.2830 - val_accuracy: 0.4138\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2567 - accuracy: 0.6435 - val_loss: 0.2951 - val_accuracy: 0.4138\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2779 - accuracy: 0.5826 - val_loss: 0.2596 - val_accuracy: 0.4828\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2492 - accuracy: 0.6000 - val_loss: 0.2754 - val_accuracy: 0.4138\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2421 - accuracy: 0.6783 - val_loss: 0.2781 - val_accuracy: 0.4828\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.1976 - accuracy: 0.7304 - val_loss: 0.3013 - val_accuracy: 0.4483\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2454 - accuracy: 0.6348 - val_loss: 0.2677 - val_accuracy: 0.4828\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2891 - accuracy: 0.6522 - val_loss: 0.3267 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2989 - accuracy: 0.5739 - val_loss: 0.2886 - val_accuracy: 0.4483\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.3018 - accuracy: 0.5217 - val_loss: 0.2827 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2803 - accuracy: 0.5826 - val_loss: 0.3033 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2422 - accuracy: 0.6087 - val_loss: 0.3076 - val_accuracy: 0.4828\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2608 - accuracy: 0.6522 - val_loss: 0.3199 - val_accuracy: 0.5517\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2510 - accuracy: 0.6696 - val_loss: 0.2412 - val_accuracy: 0.5172\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2788 - accuracy: 0.5130 - val_loss: 0.2895 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2830 - accuracy: 0.5391 - val_loss: 0.2890 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2649 - accuracy: 0.6348 - val_loss: 0.3180 - val_accuracy: 0.3448\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2640 - accuracy: 0.6609 - val_loss: 0.3591 - val_accuracy: 0.4828\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2729 - accuracy: 0.5826 - val_loss: 0.3619 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2322 - accuracy: 0.6870 - val_loss: 0.3937 - val_accuracy: 0.4483\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2320 - accuracy: 0.6348 - val_loss: 0.3264 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2507 - accuracy: 0.6348 - val_loss: 0.2693 - val_accuracy: 0.5517\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2456 - accuracy: 0.6870 - val_loss: 0.3576 - val_accuracy: 0.4828\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2473 - accuracy: 0.6696 - val_loss: 0.2997 - val_accuracy: 0.5862\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2195 - accuracy: 0.6957 - val_loss: 0.2845 - val_accuracy: 0.4828\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2384 - accuracy: 0.6696 - val_loss: 0.2696 - val_accuracy: 0.5172\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2236 - accuracy: 0.7304 - val_loss: 0.2199 - val_accuracy: 0.6552\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2194 - accuracy: 0.7304 - val_loss: 0.3310 - val_accuracy: 0.4828\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2318 - accuracy: 0.7130 - val_loss: 0.3594 - val_accuracy: 0.4483\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2377 - accuracy: 0.6870 - val_loss: 0.3061 - val_accuracy: 0.4483\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2384 - accuracy: 0.6609 - val_loss: 0.2798 - val_accuracy: 0.4483\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2351 - accuracy: 0.6696 - val_loss: 0.2937 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2295 - accuracy: 0.6696 - val_loss: 0.2920 - val_accuracy: 0.4483\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2469 - accuracy: 0.6696 - val_loss: 0.3014 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2369 - accuracy: 0.6783 - val_loss: 0.2864 - val_accuracy: 0.5172\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2386 - accuracy: 0.7043 - val_loss: 0.2842 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2148 - accuracy: 0.7043 - val_loss: 0.2703 - val_accuracy: 0.4483\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2371 - accuracy: 0.6783 - val_loss: 0.2914 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2239 - accuracy: 0.6957 - val_loss: 0.3076 - val_accuracy: 0.4483\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2046 - accuracy: 0.7130 - val_loss: 0.2680 - val_accuracy: 0.4483\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2508 - accuracy: 0.6696 - val_loss: 0.2995 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2203 - accuracy: 0.6696 - val_loss: 0.2760 - val_accuracy: 0.5172\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2027 - accuracy: 0.7217 - val_loss: 0.3033 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2347 - accuracy: 0.6783 - val_loss: 0.2848 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2057 - accuracy: 0.7043 - val_loss: 0.2814 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2364 - accuracy: 0.6609 - val_loss: 0.2781 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2241 - accuracy: 0.6783 - val_loss: 0.2664 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2315 - accuracy: 0.6783 - val_loss: 0.2864 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2195 - accuracy: 0.7217 - val_loss: 0.2793 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2140 - accuracy: 0.7130 - val_loss: 0.2564 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2280 - accuracy: 0.7130 - val_loss: 0.3190 - val_accuracy: 0.3793\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1989 - accuracy: 0.7739 - val_loss: 0.2929 - val_accuracy: 0.4138\n",
      "0.6458333134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "10100010100010010010110100111100100110011111100110\n",
      "25\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3000)\n",
      "(144, 100, 3000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (None, 100, 20)           241680    \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 245,082\n",
      "Trainable params: 245,042\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.3062 - accuracy: 0.5478 - val_loss: 0.2234 - val_accuracy: 0.6897\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2614 - accuracy: 0.6174 - val_loss: 0.5142 - val_accuracy: 0.3103\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2996 - accuracy: 0.5130 - val_loss: 0.3009 - val_accuracy: 0.6552\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2724 - accuracy: 0.5913 - val_loss: 0.3287 - val_accuracy: 0.5517\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2673 - accuracy: 0.5652 - val_loss: 0.3159 - val_accuracy: 0.4138\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2694 - accuracy: 0.5652 - val_loss: 0.3223 - val_accuracy: 0.4138\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2905 - accuracy: 0.5217 - val_loss: 0.3503 - val_accuracy: 0.3103\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2985 - accuracy: 0.5913 - val_loss: 0.3729 - val_accuracy: 0.3103\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.3077 - accuracy: 0.5217 - val_loss: 0.3566 - val_accuracy: 0.3793\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.3151 - accuracy: 0.4783 - val_loss: 0.3651 - val_accuracy: 0.4828\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.3240 - accuracy: 0.4174 - val_loss: 0.3856 - val_accuracy: 0.4138\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.3137 - accuracy: 0.5043 - val_loss: 0.3894 - val_accuracy: 0.4828\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2918 - accuracy: 0.5304 - val_loss: 0.3978 - val_accuracy: 0.5517\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2760 - accuracy: 0.6348 - val_loss: 0.3707 - val_accuracy: 0.6552\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2676 - accuracy: 0.6348 - val_loss: 0.3410 - val_accuracy: 0.6897\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2733 - accuracy: 0.6261 - val_loss: 0.3500 - val_accuracy: 0.6552\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2690 - accuracy: 0.6174 - val_loss: 0.3428 - val_accuracy: 0.6897\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2575 - accuracy: 0.6522 - val_loss: 0.2957 - val_accuracy: 0.7241\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2691 - accuracy: 0.6087 - val_loss: 0.2883 - val_accuracy: 0.6207\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2616 - accuracy: 0.6609 - val_loss: 0.2824 - val_accuracy: 0.6207\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2582 - accuracy: 0.6261 - val_loss: 0.3071 - val_accuracy: 0.6552\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2511 - accuracy: 0.6174 - val_loss: 0.3322 - val_accuracy: 0.5862\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2708 - accuracy: 0.6000 - val_loss: 0.2837 - val_accuracy: 0.6207\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2509 - accuracy: 0.7304 - val_loss: 0.3123 - val_accuracy: 0.5517\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2716 - accuracy: 0.6783 - val_loss: 0.3082 - val_accuracy: 0.6552\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2564 - accuracy: 0.7043 - val_loss: 0.2716 - val_accuracy: 0.8276\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2554 - accuracy: 0.6870 - val_loss: 0.2743 - val_accuracy: 0.7586\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2388 - accuracy: 0.7391 - val_loss: 0.3133 - val_accuracy: 0.7241\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2446 - accuracy: 0.6696 - val_loss: 0.2922 - val_accuracy: 0.7241\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2313 - accuracy: 0.7391 - val_loss: 0.2910 - val_accuracy: 0.6897\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2488 - accuracy: 0.7043 - val_loss: 0.2962 - val_accuracy: 0.6897\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2367 - accuracy: 0.7043 - val_loss: 0.3269 - val_accuracy: 0.6207\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2240 - accuracy: 0.7652 - val_loss: 0.3090 - val_accuracy: 0.6897\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2221 - accuracy: 0.7826 - val_loss: 0.3172 - val_accuracy: 0.6552\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2239 - accuracy: 0.8000 - val_loss: 0.3141 - val_accuracy: 0.6552\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2211 - accuracy: 0.7304 - val_loss: 0.3047 - val_accuracy: 0.6552\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2240 - accuracy: 0.7478 - val_loss: 0.3041 - val_accuracy: 0.5862\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2303 - accuracy: 0.7565 - val_loss: 0.3037 - val_accuracy: 0.6207\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2176 - accuracy: 0.7826 - val_loss: 0.3079 - val_accuracy: 0.6207\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2108 - accuracy: 0.8087 - val_loss: 0.2753 - val_accuracy: 0.5862\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2256 - accuracy: 0.7913 - val_loss: 0.3044 - val_accuracy: 0.5862\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2197 - accuracy: 0.7826 - val_loss: 0.2756 - val_accuracy: 0.6552\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2142 - accuracy: 0.8087 - val_loss: 0.2820 - val_accuracy: 0.6552\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2077 - accuracy: 0.8087 - val_loss: 0.2736 - val_accuracy: 0.6552\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2084 - accuracy: 0.8609 - val_loss: 0.2708 - val_accuracy: 0.5862\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2189 - accuracy: 0.8000 - val_loss: 0.2468 - val_accuracy: 0.6897\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2199 - accuracy: 0.7913 - val_loss: 0.2433 - val_accuracy: 0.6897\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2156 - accuracy: 0.7478 - val_loss: 0.2723 - val_accuracy: 0.6897\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2087 - accuracy: 0.7739 - val_loss: 0.2376 - val_accuracy: 0.7586\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2145 - accuracy: 0.8087 - val_loss: 0.2655 - val_accuracy: 0.7241\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2052 - accuracy: 0.8000 - val_loss: 0.2634 - val_accuracy: 0.6552\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2123 - accuracy: 0.7826 - val_loss: 0.2665 - val_accuracy: 0.6897\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2085 - accuracy: 0.7739 - val_loss: 0.2656 - val_accuracy: 0.6897\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2103 - accuracy: 0.7739 - val_loss: 0.2693 - val_accuracy: 0.6207\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2015 - accuracy: 0.8087 - val_loss: 0.2641 - val_accuracy: 0.6897\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2075 - accuracy: 0.8000 - val_loss: 0.2718 - val_accuracy: 0.6552\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1998 - accuracy: 0.8000 - val_loss: 0.2676 - val_accuracy: 0.6897\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.1937 - accuracy: 0.8261 - val_loss: 0.2311 - val_accuracy: 0.7931\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1980 - accuracy: 0.7913 - val_loss: 0.2438 - val_accuracy: 0.6897\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1998 - accuracy: 0.7913 - val_loss: 0.2422 - val_accuracy: 0.7586\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1904 - accuracy: 0.8087 - val_loss: 0.2252 - val_accuracy: 0.7586\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1874 - accuracy: 0.8174 - val_loss: 0.2448 - val_accuracy: 0.7241\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1936 - accuracy: 0.7739 - val_loss: 0.2290 - val_accuracy: 0.7586\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1965 - accuracy: 0.8000 - val_loss: 0.2423 - val_accuracy: 0.7586\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.1795 - accuracy: 0.8000 - val_loss: 0.2422 - val_accuracy: 0.7241\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1947 - accuracy: 0.7913 - val_loss: 0.2430 - val_accuracy: 0.6897\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1869 - accuracy: 0.8087 - val_loss: 0.2530 - val_accuracy: 0.6552\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1916 - accuracy: 0.7913 - val_loss: 0.2452 - val_accuracy: 0.6552\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.1961 - accuracy: 0.8087 - val_loss: 0.2443 - val_accuracy: 0.6552\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1895 - accuracy: 0.8000 - val_loss: 0.2425 - val_accuracy: 0.6207\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1901 - accuracy: 0.7739 - val_loss: 0.2384 - val_accuracy: 0.6552\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1972 - accuracy: 0.7739 - val_loss: 0.2364 - val_accuracy: 0.6552\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1882 - accuracy: 0.7478 - val_loss: 0.2375 - val_accuracy: 0.6207\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1947 - accuracy: 0.7739 - val_loss: 0.2413 - val_accuracy: 0.6207\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1932 - accuracy: 0.7565 - val_loss: 0.2396 - val_accuracy: 0.6552\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1924 - accuracy: 0.7565 - val_loss: 0.2408 - val_accuracy: 0.6552\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1836 - accuracy: 0.7565 - val_loss: 0.2384 - val_accuracy: 0.6207\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1844 - accuracy: 0.8000 - val_loss: 0.2339 - val_accuracy: 0.6207\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1788 - accuracy: 0.8087 - val_loss: 0.2343 - val_accuracy: 0.6552\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1705 - accuracy: 0.8000 - val_loss: 0.2315 - val_accuracy: 0.6897\n",
      "0.8125\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011010100010011000111101001000101111010010001010\n",
      "26\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2880)\n",
      "(144, 100, 2880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (None, 100, 20)           232080    \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 235,482\n",
      "Trainable params: 235,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.2617 - accuracy: 0.6087 - val_loss: 0.4192 - val_accuracy: 0.4828\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1982 - accuracy: 0.7304 - val_loss: 0.3345 - val_accuracy: 0.6207\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2455 - accuracy: 0.6783 - val_loss: 0.3628 - val_accuracy: 0.5517\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.3378 - accuracy: 0.4870 - val_loss: 0.3630 - val_accuracy: 0.3793\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.3289 - accuracy: 0.4174 - val_loss: 0.5241 - val_accuracy: 0.2414\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.3259 - accuracy: 0.3826 - val_loss: 0.3257 - val_accuracy: 0.3793\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.3253 - accuracy: 0.3652 - val_loss: 0.3707 - val_accuracy: 0.5172\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.3132 - accuracy: 0.5043 - val_loss: 0.3366 - val_accuracy: 0.5172\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2689 - accuracy: 0.6000 - val_loss: 0.4230 - val_accuracy: 0.3793\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.3001 - accuracy: 0.4348 - val_loss: 0.3063 - val_accuracy: 0.4828\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2645 - accuracy: 0.5739 - val_loss: 0.3255 - val_accuracy: 0.5172\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2656 - accuracy: 0.6000 - val_loss: 0.3566 - val_accuracy: 0.3448\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2797 - accuracy: 0.4609 - val_loss: 0.3320 - val_accuracy: 0.5172\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2612 - accuracy: 0.5565 - val_loss: 0.3275 - val_accuracy: 0.4483\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2637 - accuracy: 0.5478 - val_loss: 0.4009 - val_accuracy: 0.3448\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2719 - accuracy: 0.5217 - val_loss: 0.4314 - val_accuracy: 0.3448\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2862 - accuracy: 0.4522 - val_loss: 0.3557 - val_accuracy: 0.4138\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2573 - accuracy: 0.5913 - val_loss: 0.3088 - val_accuracy: 0.5517\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2628 - accuracy: 0.5652 - val_loss: 0.2872 - val_accuracy: 0.5172\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2477 - accuracy: 0.6087 - val_loss: 0.2830 - val_accuracy: 0.5517\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2778 - accuracy: 0.5043 - val_loss: 0.3054 - val_accuracy: 0.5862\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2464 - accuracy: 0.6261 - val_loss: 0.2023 - val_accuracy: 0.7586\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2388 - accuracy: 0.6435 - val_loss: 0.2596 - val_accuracy: 0.5862\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2583 - accuracy: 0.5913 - val_loss: 0.3451 - val_accuracy: 0.5517\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2860 - accuracy: 0.5826 - val_loss: 0.3124 - val_accuracy: 0.5862\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2606 - accuracy: 0.5826 - val_loss: 0.2967 - val_accuracy: 0.6207\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2250 - accuracy: 0.7304 - val_loss: 0.1929 - val_accuracy: 0.8621\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2241 - accuracy: 0.6696 - val_loss: 0.2699 - val_accuracy: 0.5517\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2241 - accuracy: 0.7130 - val_loss: 0.2217 - val_accuracy: 0.6207\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2214 - accuracy: 0.7130 - val_loss: 0.2905 - val_accuracy: 0.5517\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2542 - accuracy: 0.6435 - val_loss: 0.2687 - val_accuracy: 0.5862\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2491 - accuracy: 0.6522 - val_loss: 0.3041 - val_accuracy: 0.5862\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2451 - accuracy: 0.7217 - val_loss: 0.2736 - val_accuracy: 0.5172\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2301 - accuracy: 0.6783 - val_loss: 0.2974 - val_accuracy: 0.5862\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2220 - accuracy: 0.6783 - val_loss: 0.2673 - val_accuracy: 0.5517\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2411 - accuracy: 0.6783 - val_loss: 0.3084 - val_accuracy: 0.4483\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2247 - accuracy: 0.7043 - val_loss: 0.2110 - val_accuracy: 0.5517\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2196 - accuracy: 0.7043 - val_loss: 0.2681 - val_accuracy: 0.4828\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2765 - accuracy: 0.5391 - val_loss: 0.2942 - val_accuracy: 0.4483\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2657 - accuracy: 0.5043 - val_loss: 0.3268 - val_accuracy: 0.4828\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2490 - accuracy: 0.6348 - val_loss: 0.3317 - val_accuracy: 0.5172\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2558 - accuracy: 0.5304 - val_loss: 0.3981 - val_accuracy: 0.4483\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2745 - accuracy: 0.5304 - val_loss: 0.3224 - val_accuracy: 0.4483\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2714 - accuracy: 0.6000 - val_loss: 0.3592 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2792 - accuracy: 0.5130 - val_loss: 0.3391 - val_accuracy: 0.3793\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2941 - accuracy: 0.4957 - val_loss: 0.3348 - val_accuracy: 0.3793\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2894 - accuracy: 0.4870 - val_loss: 0.3634 - val_accuracy: 0.4483\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.3081 - accuracy: 0.5043 - val_loss: 0.4625 - val_accuracy: 0.4138\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2949 - accuracy: 0.6261 - val_loss: 0.3466 - val_accuracy: 0.5172\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2792 - accuracy: 0.6087 - val_loss: 0.3715 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2975 - accuracy: 0.6174 - val_loss: 0.3378 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2912 - accuracy: 0.6000 - val_loss: 0.3231 - val_accuracy: 0.4138\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2977 - accuracy: 0.5913 - val_loss: 0.2906 - val_accuracy: 0.5862\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2938 - accuracy: 0.6087 - val_loss: 0.3451 - val_accuracy: 0.3448\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2857 - accuracy: 0.5826 - val_loss: 0.3537 - val_accuracy: 0.3793\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2778 - accuracy: 0.5565 - val_loss: 0.3769 - val_accuracy: 0.3793\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2747 - accuracy: 0.6000 - val_loss: 0.3509 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2797 - accuracy: 0.6087 - val_loss: 0.3335 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2820 - accuracy: 0.5565 - val_loss: 0.2915 - val_accuracy: 0.5172\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2761 - accuracy: 0.5739 - val_loss: 0.3194 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2741 - accuracy: 0.6435 - val_loss: 0.3365 - val_accuracy: 0.3793\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2892 - accuracy: 0.5304 - val_loss: 0.3619 - val_accuracy: 0.3448\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2973 - accuracy: 0.5304 - val_loss: 0.2760 - val_accuracy: 0.5517\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2967 - accuracy: 0.5739 - val_loss: 0.2853 - val_accuracy: 0.4828\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2793 - accuracy: 0.5565 - val_loss: 0.3175 - val_accuracy: 0.4483\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2948 - accuracy: 0.5391 - val_loss: 0.3325 - val_accuracy: 0.4483\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2767 - accuracy: 0.6087 - val_loss: 0.3370 - val_accuracy: 0.4483\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2728 - accuracy: 0.6348 - val_loss: 0.3758 - val_accuracy: 0.3448\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2748 - accuracy: 0.6696 - val_loss: 0.3920 - val_accuracy: 0.3448\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2877 - accuracy: 0.6087 - val_loss: 0.3364 - val_accuracy: 0.4828\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2639 - accuracy: 0.6087 - val_loss: 0.3186 - val_accuracy: 0.5172\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2444 - accuracy: 0.6783 - val_loss: 0.3318 - val_accuracy: 0.5172\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2636 - accuracy: 0.6174 - val_loss: 0.3375 - val_accuracy: 0.4483\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2876 - accuracy: 0.5478 - val_loss: 0.3654 - val_accuracy: 0.4483\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2591 - accuracy: 0.6000 - val_loss: 0.2988 - val_accuracy: 0.5172\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2570 - accuracy: 0.6522 - val_loss: 0.3010 - val_accuracy: 0.5172\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2570 - accuracy: 0.6261 - val_loss: 0.2910 - val_accuracy: 0.4828\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2610 - accuracy: 0.6522 - val_loss: 0.2894 - val_accuracy: 0.5172\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2469 - accuracy: 0.6348 - val_loss: 0.2755 - val_accuracy: 0.4828\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2762 - accuracy: 0.4957 - val_loss: 0.2905 - val_accuracy: 0.4828\n",
      "0.6458333134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11111100011100011000100111010111000000001001010000\n",
      "28\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2640)\n",
      "(144, 100, 2640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_20 (LSTM)               (None, 100, 20)           212880    \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 216,282\n",
      "Trainable params: 216,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.1919 - accuracy: 0.8348 - val_loss: 0.2048 - val_accuracy: 0.9310\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.1546 - accuracy: 0.8870 - val_loss: 0.1383 - val_accuracy: 0.9310\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1824 - accuracy: 0.8348 - val_loss: 0.2270 - val_accuracy: 0.6552\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2433 - accuracy: 0.6435 - val_loss: 0.2611 - val_accuracy: 0.6207\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.2427 - accuracy: 0.6696 - val_loss: 0.2130 - val_accuracy: 0.7931\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2145 - accuracy: 0.8435 - val_loss: 0.2468 - val_accuracy: 0.9310\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2351 - accuracy: 0.7652 - val_loss: 0.2034 - val_accuracy: 0.9655\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.2322 - accuracy: 0.7304 - val_loss: 0.2860 - val_accuracy: 0.7931\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.2310 - accuracy: 0.7217 - val_loss: 0.2942 - val_accuracy: 0.5517\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.2652 - accuracy: 0.6435 - val_loss: 0.3047 - val_accuracy: 0.5517\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2656 - accuracy: 0.6348 - val_loss: 0.2553 - val_accuracy: 0.8276\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.2493 - accuracy: 0.6522 - val_loss: 0.2802 - val_accuracy: 0.8276\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2494 - accuracy: 0.6696 - val_loss: 0.3221 - val_accuracy: 0.6897\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2412 - accuracy: 0.7217 - val_loss: 0.2592 - val_accuracy: 0.8276\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2396 - accuracy: 0.7304 - val_loss: 0.3459 - val_accuracy: 0.5862\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.2645 - accuracy: 0.5826 - val_loss: 0.2763 - val_accuracy: 0.6207\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2352 - accuracy: 0.6957 - val_loss: 0.2477 - val_accuracy: 0.8966\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.2503 - accuracy: 0.6783 - val_loss: 0.2662 - val_accuracy: 0.7586\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2691 - accuracy: 0.6174 - val_loss: 0.3761 - val_accuracy: 0.4138\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2939 - accuracy: 0.5304 - val_loss: 0.3033 - val_accuracy: 0.5517\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.3068 - accuracy: 0.5217 - val_loss: 0.3491 - val_accuracy: 0.4828\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.3150 - accuracy: 0.4174 - val_loss: 0.3409 - val_accuracy: 0.5172\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2847 - accuracy: 0.5304 - val_loss: 0.2849 - val_accuracy: 0.7931\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2878 - accuracy: 0.5565 - val_loss: 0.2964 - val_accuracy: 0.7931\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2699 - accuracy: 0.6087 - val_loss: 0.3612 - val_accuracy: 0.5862\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.2814 - accuracy: 0.5652 - val_loss: 0.4514 - val_accuracy: 0.4828\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.3167 - accuracy: 0.5043 - val_loss: 0.3511 - val_accuracy: 0.7241\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2475 - accuracy: 0.6348 - val_loss: 0.2673 - val_accuracy: 0.6207\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2659 - accuracy: 0.6870 - val_loss: 0.3212 - val_accuracy: 0.5517\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2730 - accuracy: 0.5739 - val_loss: 0.3653 - val_accuracy: 0.4828\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2571 - accuracy: 0.6348 - val_loss: 0.3302 - val_accuracy: 0.5517\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2648 - accuracy: 0.6696 - val_loss: 0.2604 - val_accuracy: 0.7586\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2550 - accuracy: 0.7913 - val_loss: 0.2793 - val_accuracy: 0.6207\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.2597 - accuracy: 0.6957 - val_loss: 0.2618 - val_accuracy: 0.6552\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2376 - accuracy: 0.7478 - val_loss: 0.2591 - val_accuracy: 0.5862\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2657 - accuracy: 0.6087 - val_loss: 0.2529 - val_accuracy: 0.5172\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2777 - accuracy: 0.6087 - val_loss: 0.2574 - val_accuracy: 0.4828\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2775 - accuracy: 0.5913 - val_loss: 0.2573 - val_accuracy: 0.4828\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2750 - accuracy: 0.6000 - val_loss: 0.2543 - val_accuracy: 0.4828\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2626 - accuracy: 0.6435 - val_loss: 0.2523 - val_accuracy: 0.5172\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.2753 - accuracy: 0.6087 - val_loss: 0.2502 - val_accuracy: 0.5172\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.2683 - accuracy: 0.6348 - val_loss: 0.2485 - val_accuracy: 0.5517\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2490 - accuracy: 0.6174 - val_loss: 0.2471 - val_accuracy: 0.5517\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2588 - accuracy: 0.6261 - val_loss: 0.2452 - val_accuracy: 0.5517\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2544 - accuracy: 0.6348 - val_loss: 0.2421 - val_accuracy: 0.5517\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2347 - accuracy: 0.7043 - val_loss: 0.2332 - val_accuracy: 0.6207\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2234 - accuracy: 0.7217 - val_loss: 0.2314 - val_accuracy: 0.6207\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2141 - accuracy: 0.7391 - val_loss: 0.2304 - val_accuracy: 0.6207\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2167 - accuracy: 0.7739 - val_loss: 0.2291 - val_accuracy: 0.6207\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2180 - accuracy: 0.7391 - val_loss: 0.2275 - val_accuracy: 0.6207\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.2097 - accuracy: 0.7565 - val_loss: 0.2261 - val_accuracy: 0.6207\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2061 - accuracy: 0.7739 - val_loss: 0.2246 - val_accuracy: 0.6207\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2043 - accuracy: 0.7565 - val_loss: 0.2229 - val_accuracy: 0.6207\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2022 - accuracy: 0.7652 - val_loss: 0.2212 - val_accuracy: 0.6207\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.1921 - accuracy: 0.8348 - val_loss: 0.2197 - val_accuracy: 0.6552\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1967 - accuracy: 0.7826 - val_loss: 0.2181 - val_accuracy: 0.6552\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.1989 - accuracy: 0.7739 - val_loss: 0.2164 - val_accuracy: 0.6552\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1914 - accuracy: 0.8000 - val_loss: 0.2147 - val_accuracy: 0.6897\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.1866 - accuracy: 0.8261 - val_loss: 0.2129 - val_accuracy: 0.7241\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.1807 - accuracy: 0.8261 - val_loss: 0.2114 - val_accuracy: 0.7241\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.1796 - accuracy: 0.8174 - val_loss: 0.2102 - val_accuracy: 0.7241\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.1792 - accuracy: 0.8000 - val_loss: 0.2091 - val_accuracy: 0.7241\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.1737 - accuracy: 0.8000 - val_loss: 0.2080 - val_accuracy: 0.7241\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.1781 - accuracy: 0.8087 - val_loss: 0.2067 - val_accuracy: 0.7586\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.1656 - accuracy: 0.8435 - val_loss: 0.2054 - val_accuracy: 0.7586\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.1625 - accuracy: 0.8348 - val_loss: 0.2038 - val_accuracy: 0.7586\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.1638 - accuracy: 0.8348 - val_loss: 0.2022 - val_accuracy: 0.7586\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.1644 - accuracy: 0.8174 - val_loss: 0.2007 - val_accuracy: 0.7586\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1599 - accuracy: 0.8522 - val_loss: 0.1996 - val_accuracy: 0.7586\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1546 - accuracy: 0.8522 - val_loss: 0.1983 - val_accuracy: 0.7586\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1551 - accuracy: 0.8348 - val_loss: 0.1969 - val_accuracy: 0.7586\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1432 - accuracy: 0.8696 - val_loss: 0.1957 - val_accuracy: 0.7586\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.1467 - accuracy: 0.8522 - val_loss: 0.1941 - val_accuracy: 0.7586\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1453 - accuracy: 0.8522 - val_loss: 0.1927 - val_accuracy: 0.7586\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1444 - accuracy: 0.8435 - val_loss: 0.1916 - val_accuracy: 0.7586\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1441 - accuracy: 0.8435 - val_loss: 0.1906 - val_accuracy: 0.7586\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.1407 - accuracy: 0.8609 - val_loss: 0.1893 - val_accuracy: 0.7586\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.1331 - accuracy: 0.8696 - val_loss: 0.1881 - val_accuracy: 0.7586\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.1343 - accuracy: 0.8609 - val_loss: 0.1871 - val_accuracy: 0.7586\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.1317 - accuracy: 0.8609 - val_loss: 0.1865 - val_accuracy: 0.7586\n",
      "0.8541666865348816\n",
      "fitness pass\n",
      "[(0.6145833134651184, 923441258232480), (0.625, 775310821526625), (0.8958333134651184, 921963755448778), (1.0, 957257731078682), (0.6770833134651184, 1061734365432041), (0.65625, 675987511003229), (0.5520833134651184, 1019307627305479), (0.6458333134651184, 785501562696613), (0.8125, 714840212662246), (0.6458333134651184, 961137397134474), (0.8541666865348816, 1110258296291920)]\n",
      "[957257731078682, 921963755448778]\n",
      "[957257731078682, 921963755448778, 714840212662246, 1061734365432041, 675987511003229, 923441258232480, 1019307627305479]\n",
      "selection pass\n",
      "target_count:\n",
      "4\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "0\n",
      "957257731078682\n",
      "11011001101001111011101111000001001111101000011010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "1\n",
      "921963755448778\n",
      "11010001101000010101101010001000111010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "2\n",
      "714840212662246\n",
      "10100010100010010010110100111100100110011111100110\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "3\n",
      "1061734365432041\n",
      "11110001011010010001001011101100101000100011101001\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "4\n",
      "675987511003229\n",
      "10011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "5\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "6\n",
      "1019307627305479\n",
      "11100111110000111000001101000010101101101000000111\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "7\n",
      "957257731078682\n",
      "11011001101001111011101111000001001111101000011010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "8\n",
      "1019308115470794\n",
      "11100111110000111000101010001000111010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "9\n",
      "714840212744650\n",
      "10100010100010010010110100111100111010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "10\n",
      "923375237782023\n",
      "11010001111100111000001101000010101101101000000111\n",
      "crossover pass\n",
      "變異後的種群\n",
      "染色體：\n",
      "0\n",
      "957257731078682\n",
      "11011001101001111011101111000001001111101000011010\n",
      "變異後的種群\n",
      "染色體：\n",
      "1\n",
      "921963755448778\n",
      "11010001101000010101101010001000111010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "2\n",
      "714840212662246\n",
      "10100010100010010010110100111100100110011111100110\n",
      "變異後的種群\n",
      "染色體：\n",
      "3\n",
      "1061734365432041\n",
      "11110001011010010001001011101100101000100011101001\n",
      "變異後的種群\n",
      "染色體：\n",
      "4\n",
      "675987511003229\n",
      "10011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "5\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "變異後的種群\n",
      "染色體：\n",
      "6\n",
      "1019307627305479\n",
      "11100111110000111000001101000010101101101000000111\n",
      "變異後的種群\n",
      "染色體：\n",
      "7\n",
      "957257731078682\n",
      "11011001101001111011101111000001001111101000011010\n",
      "變異後的種群\n",
      "染色體：\n",
      "8\n",
      "1019308115470794\n",
      "11100111110000111000101010001000111010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "9\n",
      "714840212744650\n",
      "10100010100010010010110100111100111010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "10\n",
      "923375237782023\n",
      "11010001111100111000001101000010101101101000000111\n",
      "mutation pass\n",
      "迭代次數： 1\n",
      "1\n",
      "所選擇的染色體：\n",
      "11011001101001111011101111000001001111101000011010\n",
      "22\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3360)\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_22 (LSTM)               (None, 100, 20)           270480    \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 273,882\n",
      "Trainable params: 273,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.3009 - accuracy: 0.4174 - val_loss: 0.3549 - val_accuracy: 0.6552\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2460 - accuracy: 0.6087 - val_loss: 0.3104 - val_accuracy: 0.7241\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2459 - accuracy: 0.6783 - val_loss: 0.3193 - val_accuracy: 0.6552\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2218 - accuracy: 0.7478 - val_loss: 0.2536 - val_accuracy: 0.7241\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2391 - accuracy: 0.7739 - val_loss: 0.2306 - val_accuracy: 0.7931\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1971 - accuracy: 0.8696 - val_loss: 0.2620 - val_accuracy: 0.7586\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2250 - accuracy: 0.7739 - val_loss: 0.2288 - val_accuracy: 0.7931\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2670 - accuracy: 0.6261 - val_loss: 0.2503 - val_accuracy: 0.7586\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2446 - accuracy: 0.6696 - val_loss: 0.3456 - val_accuracy: 0.7586\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2420 - accuracy: 0.7130 - val_loss: 0.2305 - val_accuracy: 0.7586\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2515 - accuracy: 0.7043 - val_loss: 0.2856 - val_accuracy: 0.6897\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2594 - accuracy: 0.6870 - val_loss: 0.2515 - val_accuracy: 0.8276\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2639 - accuracy: 0.6696 - val_loss: 0.2516 - val_accuracy: 0.7241\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2680 - accuracy: 0.6783 - val_loss: 0.2225 - val_accuracy: 0.7586\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2527 - accuracy: 0.7130 - val_loss: 0.2258 - val_accuracy: 0.7931\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2715 - accuracy: 0.5826 - val_loss: 0.2378 - val_accuracy: 0.7241\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2830 - accuracy: 0.5217 - val_loss: 0.2413 - val_accuracy: 0.6897\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2898 - accuracy: 0.5913 - val_loss: 0.2240 - val_accuracy: 0.6897\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2423 - accuracy: 0.7565 - val_loss: 0.3208 - val_accuracy: 0.3793\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2944 - accuracy: 0.6000 - val_loss: 0.3017 - val_accuracy: 0.4138\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3325 - accuracy: 0.4348 - val_loss: 0.2969 - val_accuracy: 0.4138\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3126 - accuracy: 0.5391 - val_loss: 0.2652 - val_accuracy: 0.5172\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2725 - accuracy: 0.6174 - val_loss: 0.2711 - val_accuracy: 0.4828\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2933 - accuracy: 0.5826 - val_loss: 0.2699 - val_accuracy: 0.4138\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2793 - accuracy: 0.6609 - val_loss: 0.2667 - val_accuracy: 0.4483\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2795 - accuracy: 0.6000 - val_loss: 0.2626 - val_accuracy: 0.4828\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2864 - accuracy: 0.6087 - val_loss: 0.2617 - val_accuracy: 0.4828\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2437 - accuracy: 0.7304 - val_loss: 0.2761 - val_accuracy: 0.5172\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2448 - accuracy: 0.7130 - val_loss: 0.2848 - val_accuracy: 0.4483\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2592 - accuracy: 0.6348 - val_loss: 0.2859 - val_accuracy: 0.4828\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3031 - accuracy: 0.5565 - val_loss: 0.2777 - val_accuracy: 0.4138\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3339 - accuracy: 0.4957 - val_loss: 0.2796 - val_accuracy: 0.4138\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.3601 - accuracy: 0.4522 - val_loss: 0.2805 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.3495 - accuracy: 0.4696 - val_loss: 0.2815 - val_accuracy: 0.4138\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.3585 - accuracy: 0.4609 - val_loss: 0.2837 - val_accuracy: 0.4138\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3450 - accuracy: 0.4957 - val_loss: 0.2832 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3347 - accuracy: 0.4609 - val_loss: 0.2843 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3403 - accuracy: 0.4783 - val_loss: 0.2848 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3372 - accuracy: 0.5043 - val_loss: 0.2844 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.3327 - accuracy: 0.5043 - val_loss: 0.2845 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.3144 - accuracy: 0.5391 - val_loss: 0.2851 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.3197 - accuracy: 0.4957 - val_loss: 0.2870 - val_accuracy: 0.4483\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3180 - accuracy: 0.5478 - val_loss: 0.2835 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.3033 - accuracy: 0.5913 - val_loss: 0.3044 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.3081 - accuracy: 0.5391 - val_loss: 0.2861 - val_accuracy: 0.4138\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.3133 - accuracy: 0.5739 - val_loss: 0.2859 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3187 - accuracy: 0.5043 - val_loss: 0.2888 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.3251 - accuracy: 0.5217 - val_loss: 0.2887 - val_accuracy: 0.4138\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3012 - accuracy: 0.5565 - val_loss: 0.2902 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2904 - accuracy: 0.5826 - val_loss: 0.2910 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2851 - accuracy: 0.5913 - val_loss: 0.2914 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2862 - accuracy: 0.5739 - val_loss: 0.2916 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2899 - accuracy: 0.5826 - val_loss: 0.2919 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2891 - accuracy: 0.5739 - val_loss: 0.2922 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2782 - accuracy: 0.5478 - val_loss: 0.2924 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2757 - accuracy: 0.5826 - val_loss: 0.2925 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2648 - accuracy: 0.5739 - val_loss: 0.2925 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2679 - accuracy: 0.6000 - val_loss: 0.2926 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2634 - accuracy: 0.5739 - val_loss: 0.2926 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2589 - accuracy: 0.5913 - val_loss: 0.2927 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2593 - accuracy: 0.6348 - val_loss: 0.2927 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2498 - accuracy: 0.6174 - val_loss: 0.2927 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2561 - accuracy: 0.6174 - val_loss: 0.2927 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2469 - accuracy: 0.6435 - val_loss: 0.2928 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2396 - accuracy: 0.6348 - val_loss: 0.2927 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2382 - accuracy: 0.6609 - val_loss: 0.2926 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2420 - accuracy: 0.6174 - val_loss: 0.2925 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2250 - accuracy: 0.6696 - val_loss: 0.2925 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2290 - accuracy: 0.6348 - val_loss: 0.2924 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2223 - accuracy: 0.6696 - val_loss: 0.2922 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2131 - accuracy: 0.7130 - val_loss: 0.2920 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2154 - accuracy: 0.6696 - val_loss: 0.2918 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2127 - accuracy: 0.7043 - val_loss: 0.2915 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2146 - accuracy: 0.7043 - val_loss: 0.2912 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2076 - accuracy: 0.7304 - val_loss: 0.2908 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2108 - accuracy: 0.7130 - val_loss: 0.2903 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2050 - accuracy: 0.7304 - val_loss: 0.2899 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2010 - accuracy: 0.7652 - val_loss: 0.2896 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1972 - accuracy: 0.7739 - val_loss: 0.2893 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2095 - accuracy: 0.7739 - val_loss: 0.2890 - val_accuracy: 0.4138\n",
      "0.6145833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001101000010101101010001000111010100111001010\n",
      "27\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2760)\n",
      "(144, 100, 2760)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_24 (LSTM)               (None, 100, 20)           222480    \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 225,882\n",
      "Trainable params: 225,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.2691 - accuracy: 0.5739 - val_loss: 0.1726 - val_accuracy: 0.7241\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2140 - accuracy: 0.7043 - val_loss: 0.3650 - val_accuracy: 0.5517\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2852 - accuracy: 0.6000 - val_loss: 0.5124 - val_accuracy: 0.3448\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.3232 - accuracy: 0.5043 - val_loss: 0.6126 - val_accuracy: 0.2414\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.3025 - accuracy: 0.5478 - val_loss: 0.4487 - val_accuracy: 0.2759\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2746 - accuracy: 0.5826 - val_loss: 0.3595 - val_accuracy: 0.2069\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2375 - accuracy: 0.6087 - val_loss: 0.3466 - val_accuracy: 0.4138\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2480 - accuracy: 0.7130 - val_loss: 0.3129 - val_accuracy: 0.5172\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2196 - accuracy: 0.7304 - val_loss: 0.3290 - val_accuracy: 0.4138\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2252 - accuracy: 0.7478 - val_loss: 0.3722 - val_accuracy: 0.4828\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2348 - accuracy: 0.7826 - val_loss: 0.3281 - val_accuracy: 0.5172\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2597 - accuracy: 0.6435 - val_loss: 0.3354 - val_accuracy: 0.5862\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2339 - accuracy: 0.6957 - val_loss: 0.3416 - val_accuracy: 0.5172\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2212 - accuracy: 0.6957 - val_loss: 0.2815 - val_accuracy: 0.5172\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1834 - accuracy: 0.7652 - val_loss: 0.2356 - val_accuracy: 0.6207\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1932 - accuracy: 0.7478 - val_loss: 0.2356 - val_accuracy: 0.6897\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1996 - accuracy: 0.7217 - val_loss: 0.2472 - val_accuracy: 0.6552\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1995 - accuracy: 0.7739 - val_loss: 0.2702 - val_accuracy: 0.5862\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2040 - accuracy: 0.7478 - val_loss: 0.2092 - val_accuracy: 0.7586\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.1646 - accuracy: 0.8174 - val_loss: 0.2565 - val_accuracy: 0.5862\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1794 - accuracy: 0.8435 - val_loss: 0.2661 - val_accuracy: 0.5862\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2135 - accuracy: 0.7478 - val_loss: 0.2705 - val_accuracy: 0.5517\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1601 - accuracy: 0.8174 - val_loss: 0.2632 - val_accuracy: 0.5862\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1864 - accuracy: 0.7478 - val_loss: 0.3051 - val_accuracy: 0.5862\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.1914 - accuracy: 0.7565 - val_loss: 0.2274 - val_accuracy: 0.5862\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2156 - accuracy: 0.7130 - val_loss: 0.3200 - val_accuracy: 0.4483\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2151 - accuracy: 0.7043 - val_loss: 0.3276 - val_accuracy: 0.5862\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2278 - accuracy: 0.6783 - val_loss: 0.4082 - val_accuracy: 0.4828\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2738 - accuracy: 0.5652 - val_loss: 0.4955 - val_accuracy: 0.4138\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.3351 - accuracy: 0.4261 - val_loss: 0.4258 - val_accuracy: 0.4138\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.3291 - accuracy: 0.5130 - val_loss: 0.4363 - val_accuracy: 0.2759\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.3898 - accuracy: 0.3826 - val_loss: 0.4119 - val_accuracy: 0.4138\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.3352 - accuracy: 0.4348 - val_loss: 0.4715 - val_accuracy: 0.3793\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.4040 - accuracy: 0.3391 - val_loss: 0.4889 - val_accuracy: 0.3793\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.3347 - accuracy: 0.4783 - val_loss: 0.3865 - val_accuracy: 0.4138\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.3261 - accuracy: 0.5130 - val_loss: 0.4128 - val_accuracy: 0.3793\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.3760 - accuracy: 0.4000 - val_loss: 0.4170 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.3353 - accuracy: 0.4435 - val_loss: 0.3934 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.3295 - accuracy: 0.4435 - val_loss: 0.4173 - val_accuracy: 0.3448\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.3593 - accuracy: 0.4000 - val_loss: 0.3969 - val_accuracy: 0.3793\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.3257 - accuracy: 0.4696 - val_loss: 0.3763 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.3373 - accuracy: 0.4522 - val_loss: 0.3635 - val_accuracy: 0.4828\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.3204 - accuracy: 0.4435 - val_loss: 0.3640 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.3163 - accuracy: 0.4783 - val_loss: 0.3756 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.3333 - accuracy: 0.4348 - val_loss: 0.3771 - val_accuracy: 0.4138\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.3205 - accuracy: 0.4435 - val_loss: 0.3715 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.3328 - accuracy: 0.4174 - val_loss: 0.3441 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.3157 - accuracy: 0.4783 - val_loss: 0.3394 - val_accuracy: 0.4483\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.3192 - accuracy: 0.4174 - val_loss: 0.3464 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.3175 - accuracy: 0.4435 - val_loss: 0.3417 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.3126 - accuracy: 0.4522 - val_loss: 0.3402 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2996 - accuracy: 0.4696 - val_loss: 0.3347 - val_accuracy: 0.4138\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.3024 - accuracy: 0.4957 - val_loss: 0.3308 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.3012 - accuracy: 0.4783 - val_loss: 0.3260 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2998 - accuracy: 0.4870 - val_loss: 0.3193 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.3031 - accuracy: 0.4783 - val_loss: 0.3153 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.3029 - accuracy: 0.4348 - val_loss: 0.3122 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2837 - accuracy: 0.4870 - val_loss: 0.3094 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2851 - accuracy: 0.4783 - val_loss: 0.3072 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2746 - accuracy: 0.4957 - val_loss: 0.3066 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2754 - accuracy: 0.5043 - val_loss: 0.3051 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2743 - accuracy: 0.5130 - val_loss: 0.2958 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2711 - accuracy: 0.5043 - val_loss: 0.2921 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2650 - accuracy: 0.5217 - val_loss: 0.2903 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2667 - accuracy: 0.5043 - val_loss: 0.2869 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2588 - accuracy: 0.5043 - val_loss: 0.2839 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2551 - accuracy: 0.5391 - val_loss: 0.2809 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2609 - accuracy: 0.4957 - val_loss: 0.2808 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2496 - accuracy: 0.5913 - val_loss: 0.2828 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2482 - accuracy: 0.5739 - val_loss: 0.2770 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2532 - accuracy: 0.5652 - val_loss: 0.2780 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2437 - accuracy: 0.5478 - val_loss: 0.2762 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2414 - accuracy: 0.5739 - val_loss: 0.2690 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2236 - accuracy: 0.6174 - val_loss: 0.2667 - val_accuracy: 0.4483\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2181 - accuracy: 0.6087 - val_loss: 0.2653 - val_accuracy: 0.4483\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2173 - accuracy: 0.6522 - val_loss: 0.2637 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2145 - accuracy: 0.6435 - val_loss: 0.2624 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2098 - accuracy: 0.6870 - val_loss: 0.2610 - val_accuracy: 0.4828\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2075 - accuracy: 0.6522 - val_loss: 0.2595 - val_accuracy: 0.4828\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2111 - accuracy: 0.6522 - val_loss: 0.2580 - val_accuracy: 0.4828\n",
      "0.625\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "10100010100010010010110100111100100110011111100110\n",
      "25\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3000)\n",
      "(144, 100, 3000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_26 (LSTM)               (None, 100, 20)           241680    \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 245,082\n",
      "Trainable params: 245,042\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.2447 - accuracy: 0.6957 - val_loss: 0.4708 - val_accuracy: 0.3448\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.3098 - accuracy: 0.4087 - val_loss: 0.3089 - val_accuracy: 0.5172\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2726 - accuracy: 0.6087 - val_loss: 0.2172 - val_accuracy: 0.6897\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2755 - accuracy: 0.6522 - val_loss: 0.2817 - val_accuracy: 0.5172\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2844 - accuracy: 0.5652 - val_loss: 0.3095 - val_accuracy: 0.6552\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2825 - accuracy: 0.5913 - val_loss: 0.3661 - val_accuracy: 0.3103\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.3105 - accuracy: 0.4522 - val_loss: 0.3079 - val_accuracy: 0.6207\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2940 - accuracy: 0.4957 - val_loss: 0.2540 - val_accuracy: 0.7586\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2748 - accuracy: 0.5826 - val_loss: 0.2381 - val_accuracy: 0.7241\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2374 - accuracy: 0.6348 - val_loss: 0.2899 - val_accuracy: 0.4138\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2853 - accuracy: 0.4348 - val_loss: 0.2755 - val_accuracy: 0.4828\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2461 - accuracy: 0.5913 - val_loss: 0.2563 - val_accuracy: 0.5862\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2377 - accuracy: 0.5826 - val_loss: 0.2528 - val_accuracy: 0.5517\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2433 - accuracy: 0.6087 - val_loss: 0.2554 - val_accuracy: 0.5862\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2488 - accuracy: 0.6087 - val_loss: 0.2486 - val_accuracy: 0.5172\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2246 - accuracy: 0.6870 - val_loss: 0.2482 - val_accuracy: 0.6552\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2447 - accuracy: 0.6174 - val_loss: 0.2404 - val_accuracy: 0.6897\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2215 - accuracy: 0.6522 - val_loss: 0.2444 - val_accuracy: 0.6552\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2161 - accuracy: 0.6522 - val_loss: 0.2443 - val_accuracy: 0.6207\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2283 - accuracy: 0.6696 - val_loss: 0.2433 - val_accuracy: 0.5862\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2281 - accuracy: 0.6696 - val_loss: 0.2417 - val_accuracy: 0.5517\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2175 - accuracy: 0.6870 - val_loss: 0.2408 - val_accuracy: 0.5517\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2117 - accuracy: 0.7130 - val_loss: 0.2393 - val_accuracy: 0.5517\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1861 - accuracy: 0.7217 - val_loss: 0.2460 - val_accuracy: 0.5517\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1830 - accuracy: 0.7391 - val_loss: 0.2398 - val_accuracy: 0.5862\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.1775 - accuracy: 0.7391 - val_loss: 0.2699 - val_accuracy: 0.5517\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1807 - accuracy: 0.7304 - val_loss: 0.2477 - val_accuracy: 0.5862\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.1813 - accuracy: 0.7130 - val_loss: 0.2379 - val_accuracy: 0.5517\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1681 - accuracy: 0.7391 - val_loss: 0.2317 - val_accuracy: 0.6552\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1862 - accuracy: 0.6609 - val_loss: 0.2342 - val_accuracy: 0.5862\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1860 - accuracy: 0.6957 - val_loss: 0.2479 - val_accuracy: 0.5862\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2300 - accuracy: 0.6522 - val_loss: 0.2332 - val_accuracy: 0.6207\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2007 - accuracy: 0.6348 - val_loss: 0.2343 - val_accuracy: 0.5862\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2103 - accuracy: 0.6957 - val_loss: 0.2372 - val_accuracy: 0.5862\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1928 - accuracy: 0.7565 - val_loss: 0.2364 - val_accuracy: 0.5862\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1920 - accuracy: 0.7739 - val_loss: 0.2411 - val_accuracy: 0.5517\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1845 - accuracy: 0.7739 - val_loss: 0.2409 - val_accuracy: 0.5517\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1889 - accuracy: 0.7652 - val_loss: 0.2396 - val_accuracy: 0.5517\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1776 - accuracy: 0.7826 - val_loss: 0.2387 - val_accuracy: 0.5517\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1711 - accuracy: 0.7739 - val_loss: 0.2382 - val_accuracy: 0.5517\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1682 - accuracy: 0.8000 - val_loss: 0.2355 - val_accuracy: 0.5517\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1636 - accuracy: 0.8087 - val_loss: 0.2313 - val_accuracy: 0.5517\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1705 - accuracy: 0.7739 - val_loss: 0.2274 - val_accuracy: 0.6207\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.1694 - accuracy: 0.8087 - val_loss: 0.2258 - val_accuracy: 0.6207\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1536 - accuracy: 0.8087 - val_loss: 0.2260 - val_accuracy: 0.5862\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.1574 - accuracy: 0.8174 - val_loss: 0.2274 - val_accuracy: 0.5862\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1472 - accuracy: 0.8261 - val_loss: 0.2306 - val_accuracy: 0.5172\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1476 - accuracy: 0.8174 - val_loss: 0.2329 - val_accuracy: 0.5172\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1314 - accuracy: 0.8783 - val_loss: 0.2347 - val_accuracy: 0.5172\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1279 - accuracy: 0.8609 - val_loss: 0.2310 - val_accuracy: 0.5172\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1342 - accuracy: 0.8522 - val_loss: 0.2215 - val_accuracy: 0.5862\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1327 - accuracy: 0.8609 - val_loss: 0.2335 - val_accuracy: 0.5862\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1497 - accuracy: 0.8000 - val_loss: 0.2228 - val_accuracy: 0.5862\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1740 - accuracy: 0.7478 - val_loss: 0.2298 - val_accuracy: 0.5517\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1661 - accuracy: 0.8087 - val_loss: 0.2199 - val_accuracy: 0.5517\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1677 - accuracy: 0.7652 - val_loss: 0.2292 - val_accuracy: 0.5517\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2233 - accuracy: 0.6870 - val_loss: 0.1768 - val_accuracy: 0.6897\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.3102 - accuracy: 0.6174 - val_loss: 0.2284 - val_accuracy: 0.6552\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2853 - accuracy: 0.6522 - val_loss: 0.2300 - val_accuracy: 0.5517\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2715 - accuracy: 0.5565 - val_loss: 0.2913 - val_accuracy: 0.4483\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.3256 - accuracy: 0.4957 - val_loss: 0.3666 - val_accuracy: 0.3793\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2981 - accuracy: 0.5826 - val_loss: 0.3938 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2813 - accuracy: 0.5565 - val_loss: 0.3647 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.3130 - accuracy: 0.5130 - val_loss: 0.3408 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.3371 - accuracy: 0.4609 - val_loss: 0.3099 - val_accuracy: 0.3448\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2611 - accuracy: 0.6261 - val_loss: 0.3315 - val_accuracy: 0.3793\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.3098 - accuracy: 0.5304 - val_loss: 0.4199 - val_accuracy: 0.2414\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.3419 - accuracy: 0.5391 - val_loss: 0.4846 - val_accuracy: 0.1724\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.3296 - accuracy: 0.5304 - val_loss: 0.3918 - val_accuracy: 0.3103\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2883 - accuracy: 0.5739 - val_loss: 0.4927 - val_accuracy: 0.2414\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2865 - accuracy: 0.5565 - val_loss: 0.4703 - val_accuracy: 0.2069\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.3331 - accuracy: 0.4522 - val_loss: 0.3962 - val_accuracy: 0.2759\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2895 - accuracy: 0.5391 - val_loss: 0.3692 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.3377 - accuracy: 0.5043 - val_loss: 0.3937 - val_accuracy: 0.3448\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.3181 - accuracy: 0.4783 - val_loss: 0.4543 - val_accuracy: 0.2759\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.3155 - accuracy: 0.4870 - val_loss: 0.3922 - val_accuracy: 0.2759\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2976 - accuracy: 0.5217 - val_loss: 0.3854 - val_accuracy: 0.3793\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.3029 - accuracy: 0.5304 - val_loss: 0.3676 - val_accuracy: 0.3793\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2749 - accuracy: 0.5391 - val_loss: 0.3820 - val_accuracy: 0.3448\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2728 - accuracy: 0.5826 - val_loss: 0.3477 - val_accuracy: 0.3793\n",
      "0.5\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11110001011010010001001011101100101000100011101001\n",
      "26\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2880)\n",
      "(144, 100, 2880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_28 (LSTM)               (None, 100, 20)           232080    \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 235,482\n",
      "Trainable params: 235,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.3834 - accuracy: 0.2696 - val_loss: 0.6327 - val_accuracy: 0.3103\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.3415 - accuracy: 0.4261 - val_loss: 0.3852 - val_accuracy: 0.4483\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2774 - accuracy: 0.4870 - val_loss: 0.3824 - val_accuracy: 0.3793\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2788 - accuracy: 0.5043 - val_loss: 0.3546 - val_accuracy: 0.4138\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2896 - accuracy: 0.4435 - val_loss: 0.3063 - val_accuracy: 0.5862\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2681 - accuracy: 0.4696 - val_loss: 0.3206 - val_accuracy: 0.4483\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2957 - accuracy: 0.5913 - val_loss: 0.3126 - val_accuracy: 0.4483\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.3196 - accuracy: 0.4696 - val_loss: 0.3292 - val_accuracy: 0.4138\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2767 - accuracy: 0.5478 - val_loss: 0.2812 - val_accuracy: 0.6207\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2501 - accuracy: 0.6870 - val_loss: 0.3029 - val_accuracy: 0.5517\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2289 - accuracy: 0.7217 - val_loss: 0.3200 - val_accuracy: 0.5517\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2765 - accuracy: 0.6435 - val_loss: 0.4414 - val_accuracy: 0.2069\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2692 - accuracy: 0.5739 - val_loss: 0.2238 - val_accuracy: 0.5862\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2310 - accuracy: 0.6261 - val_loss: 0.2507 - val_accuracy: 0.5172\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2625 - accuracy: 0.6174 - val_loss: 0.3104 - val_accuracy: 0.2414\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.3599 - accuracy: 0.3565 - val_loss: 0.3219 - val_accuracy: 0.3103\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.3787 - accuracy: 0.2870 - val_loss: 0.3338 - val_accuracy: 0.3793\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.3316 - accuracy: 0.3913 - val_loss: 0.3228 - val_accuracy: 0.4138\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.3254 - accuracy: 0.4000 - val_loss: 0.2869 - val_accuracy: 0.4138\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2838 - accuracy: 0.4261 - val_loss: 0.2946 - val_accuracy: 0.3103\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2993 - accuracy: 0.4348 - val_loss: 0.2903 - val_accuracy: 0.3448\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.3102 - accuracy: 0.3826 - val_loss: 0.2769 - val_accuracy: 0.4138\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2951 - accuracy: 0.4696 - val_loss: 0.2936 - val_accuracy: 0.3448\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2869 - accuracy: 0.4348 - val_loss: 0.2899 - val_accuracy: 0.3793\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2800 - accuracy: 0.4783 - val_loss: 0.2938 - val_accuracy: 0.3103\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2866 - accuracy: 0.4783 - val_loss: 0.2924 - val_accuracy: 0.3793\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.3040 - accuracy: 0.4348 - val_loss: 0.2903 - val_accuracy: 0.3793\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2772 - accuracy: 0.4957 - val_loss: 0.2827 - val_accuracy: 0.3793\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2878 - accuracy: 0.5391 - val_loss: 0.2803 - val_accuracy: 0.3793\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2883 - accuracy: 0.5478 - val_loss: 0.2834 - val_accuracy: 0.3793\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2815 - accuracy: 0.5565 - val_loss: 0.2821 - val_accuracy: 0.3793\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2877 - accuracy: 0.5478 - val_loss: 0.2810 - val_accuracy: 0.3793\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2803 - accuracy: 0.5739 - val_loss: 0.2802 - val_accuracy: 0.3793\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2763 - accuracy: 0.5739 - val_loss: 0.2789 - val_accuracy: 0.3793\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2822 - accuracy: 0.5913 - val_loss: 0.2772 - val_accuracy: 0.3793\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2792 - accuracy: 0.5652 - val_loss: 0.2776 - val_accuracy: 0.3793\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2714 - accuracy: 0.5739 - val_loss: 0.2771 - val_accuracy: 0.3793\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2714 - accuracy: 0.6087 - val_loss: 0.2760 - val_accuracy: 0.3793\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2795 - accuracy: 0.5652 - val_loss: 0.2748 - val_accuracy: 0.3793\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2702 - accuracy: 0.5913 - val_loss: 0.2740 - val_accuracy: 0.3793\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2647 - accuracy: 0.6000 - val_loss: 0.2734 - val_accuracy: 0.3793\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2674 - accuracy: 0.6000 - val_loss: 0.2733 - val_accuracy: 0.3793\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2651 - accuracy: 0.5913 - val_loss: 0.2734 - val_accuracy: 0.3793\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2624 - accuracy: 0.6174 - val_loss: 0.2727 - val_accuracy: 0.3793\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2651 - accuracy: 0.5739 - val_loss: 0.2714 - val_accuracy: 0.3793\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2581 - accuracy: 0.6261 - val_loss: 0.2707 - val_accuracy: 0.3793\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2641 - accuracy: 0.5739 - val_loss: 0.2701 - val_accuracy: 0.3793\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2573 - accuracy: 0.6174 - val_loss: 0.2696 - val_accuracy: 0.3793\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2554 - accuracy: 0.5826 - val_loss: 0.2689 - val_accuracy: 0.3793\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2530 - accuracy: 0.6261 - val_loss: 0.2683 - val_accuracy: 0.3793\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2593 - accuracy: 0.6261 - val_loss: 0.2676 - val_accuracy: 0.3793\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2478 - accuracy: 0.6435 - val_loss: 0.2670 - val_accuracy: 0.3793\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2505 - accuracy: 0.6435 - val_loss: 0.2665 - val_accuracy: 0.3793\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2445 - accuracy: 0.6348 - val_loss: 0.2661 - val_accuracy: 0.3793\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2481 - accuracy: 0.6348 - val_loss: 0.2657 - val_accuracy: 0.3793\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2417 - accuracy: 0.6522 - val_loss: 0.2655 - val_accuracy: 0.3793\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2406 - accuracy: 0.6435 - val_loss: 0.2650 - val_accuracy: 0.3793\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2477 - accuracy: 0.6348 - val_loss: 0.2647 - val_accuracy: 0.3793\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2432 - accuracy: 0.6348 - val_loss: 0.2642 - val_accuracy: 0.3793\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2378 - accuracy: 0.6522 - val_loss: 0.2638 - val_accuracy: 0.3793\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2397 - accuracy: 0.6261 - val_loss: 0.2634 - val_accuracy: 0.3793\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2358 - accuracy: 0.6522 - val_loss: 0.2631 - val_accuracy: 0.3793\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2395 - accuracy: 0.6522 - val_loss: 0.2629 - val_accuracy: 0.3793\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2353 - accuracy: 0.6609 - val_loss: 0.2627 - val_accuracy: 0.3793\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2363 - accuracy: 0.6783 - val_loss: 0.2623 - val_accuracy: 0.3793\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2383 - accuracy: 0.6174 - val_loss: 0.2620 - val_accuracy: 0.3793\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2294 - accuracy: 0.6696 - val_loss: 0.2617 - val_accuracy: 0.3793\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2325 - accuracy: 0.6609 - val_loss: 0.2614 - val_accuracy: 0.3793\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2347 - accuracy: 0.6696 - val_loss: 0.2610 - val_accuracy: 0.3793\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2261 - accuracy: 0.6870 - val_loss: 0.2605 - val_accuracy: 0.3793\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2302 - accuracy: 0.6696 - val_loss: 0.2601 - val_accuracy: 0.3793\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2193 - accuracy: 0.7043 - val_loss: 0.2596 - val_accuracy: 0.3793\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2216 - accuracy: 0.6870 - val_loss: 0.2592 - val_accuracy: 0.3793\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2232 - accuracy: 0.7043 - val_loss: 0.2587 - val_accuracy: 0.3793\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2234 - accuracy: 0.6957 - val_loss: 0.2583 - val_accuracy: 0.3793\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2220 - accuracy: 0.6870 - val_loss: 0.2576 - val_accuracy: 0.3793\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2182 - accuracy: 0.7043 - val_loss: 0.2568 - val_accuracy: 0.3793\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2222 - accuracy: 0.6870 - val_loss: 0.2560 - val_accuracy: 0.3793\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2207 - accuracy: 0.6957 - val_loss: 0.2555 - val_accuracy: 0.3793\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2173 - accuracy: 0.6696 - val_loss: 0.2549 - val_accuracy: 0.3793\n",
      "0.4895833432674408\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "10011001101100111010011011011101110100100001011101\n",
      "22\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3360)\n",
      "(144, 100, 3360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_30 (LSTM)               (None, 100, 20)           270480    \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 273,882\n",
      "Trainable params: 273,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 0.2516 - accuracy: 0.6522 - val_loss: 0.2887 - val_accuracy: 0.5517\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2811 - accuracy: 0.5478 - val_loss: 0.2721 - val_accuracy: 0.5172\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2770 - accuracy: 0.4783 - val_loss: 0.3134 - val_accuracy: 0.3448\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2742 - accuracy: 0.4957 - val_loss: 0.2385 - val_accuracy: 0.4138\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2369 - accuracy: 0.8000 - val_loss: 0.2524 - val_accuracy: 0.3793\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2324 - accuracy: 0.7739 - val_loss: 0.2429 - val_accuracy: 0.4138\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2227 - accuracy: 0.7826 - val_loss: 0.2433 - val_accuracy: 0.4138\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2236 - accuracy: 0.8000 - val_loss: 0.2566 - val_accuracy: 0.4138\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2202 - accuracy: 0.7913 - val_loss: 0.2494 - val_accuracy: 0.4138\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2055 - accuracy: 0.8522 - val_loss: 0.2411 - val_accuracy: 0.4138\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1959 - accuracy: 0.9043 - val_loss: 0.2432 - val_accuracy: 0.4138\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2018 - accuracy: 0.8696 - val_loss: 0.2379 - val_accuracy: 0.4138\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1976 - accuracy: 0.8435 - val_loss: 0.2369 - val_accuracy: 0.4138\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1982 - accuracy: 0.8957 - val_loss: 0.2267 - val_accuracy: 0.4138\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1908 - accuracy: 0.8783 - val_loss: 0.2209 - val_accuracy: 0.4138\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1886 - accuracy: 0.8870 - val_loss: 0.2187 - val_accuracy: 0.4138\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1861 - accuracy: 0.9043 - val_loss: 0.2167 - val_accuracy: 0.4138\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1804 - accuracy: 0.8783 - val_loss: 0.2158 - val_accuracy: 0.4138\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1783 - accuracy: 0.8870 - val_loss: 0.2149 - val_accuracy: 0.4138\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1770 - accuracy: 0.9217 - val_loss: 0.2135 - val_accuracy: 0.4138\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1732 - accuracy: 0.9043 - val_loss: 0.2114 - val_accuracy: 0.4138\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1662 - accuracy: 0.9217 - val_loss: 0.2093 - val_accuracy: 0.4138\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1609 - accuracy: 0.9217 - val_loss: 0.2072 - val_accuracy: 0.4138\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1571 - accuracy: 0.9391 - val_loss: 0.2051 - val_accuracy: 0.4138\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1486 - accuracy: 0.9130 - val_loss: 0.2028 - val_accuracy: 0.4138\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1489 - accuracy: 0.9304 - val_loss: 0.2003 - val_accuracy: 0.4138\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1433 - accuracy: 0.9217 - val_loss: 0.1975 - val_accuracy: 0.4483\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1437 - accuracy: 0.9304 - val_loss: 0.1948 - val_accuracy: 0.4483\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1369 - accuracy: 0.9304 - val_loss: 0.1925 - val_accuracy: 0.4828\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1362 - accuracy: 0.9304 - val_loss: 0.1903 - val_accuracy: 0.7931\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1325 - accuracy: 0.9478 - val_loss: 0.1877 - val_accuracy: 0.8621\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1287 - accuracy: 0.9304 - val_loss: 0.1849 - val_accuracy: 0.8621\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1249 - accuracy: 0.9217 - val_loss: 0.1821 - val_accuracy: 0.8621\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1226 - accuracy: 0.9565 - val_loss: 0.1795 - val_accuracy: 0.8621\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1264 - accuracy: 0.9130 - val_loss: 0.1768 - val_accuracy: 0.8621\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1193 - accuracy: 0.9391 - val_loss: 0.1742 - val_accuracy: 0.8621\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1151 - accuracy: 0.9565 - val_loss: 0.1711 - val_accuracy: 0.8621\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1143 - accuracy: 0.9565 - val_loss: 0.1686 - val_accuracy: 0.8966\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1158 - accuracy: 0.9391 - val_loss: 0.1694 - val_accuracy: 0.8966\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1119 - accuracy: 0.9565 - val_loss: 0.1663 - val_accuracy: 0.8966\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1102 - accuracy: 0.9478 - val_loss: 0.1634 - val_accuracy: 0.8966\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1134 - accuracy: 0.9043 - val_loss: 0.1606 - val_accuracy: 0.8966\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1057 - accuracy: 0.9391 - val_loss: 0.1553 - val_accuracy: 0.8966\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1036 - accuracy: 0.9478 - val_loss: 0.1530 - val_accuracy: 0.8966\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1047 - accuracy: 0.9478 - val_loss: 0.1504 - val_accuracy: 0.8966\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1015 - accuracy: 0.9652 - val_loss: 0.1478 - val_accuracy: 0.8966\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0973 - accuracy: 0.9565 - val_loss: 0.1454 - val_accuracy: 0.8966\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0986 - accuracy: 0.9391 - val_loss: 0.1429 - val_accuracy: 0.8966\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0939 - accuracy: 0.9565 - val_loss: 0.1409 - val_accuracy: 0.8966\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0934 - accuracy: 0.9565 - val_loss: 0.1390 - val_accuracy: 0.8966\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0913 - accuracy: 0.9565 - val_loss: 0.1369 - val_accuracy: 0.8966\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0941 - accuracy: 0.9652 - val_loss: 0.1347 - val_accuracy: 0.8966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0893 - accuracy: 0.9565 - val_loss: 0.1330 - val_accuracy: 0.8966\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0874 - accuracy: 0.9565 - val_loss: 0.1309 - val_accuracy: 0.8966\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0857 - accuracy: 0.9739 - val_loss: 0.1290 - val_accuracy: 0.8966\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0851 - accuracy: 0.9652 - val_loss: 0.1273 - val_accuracy: 0.8966\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0834 - accuracy: 0.9565 - val_loss: 0.1282 - val_accuracy: 0.8966\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0837 - accuracy: 0.9565 - val_loss: 0.1264 - val_accuracy: 0.8966\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0806 - accuracy: 0.9565 - val_loss: 0.1247 - val_accuracy: 0.8966\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0818 - accuracy: 0.9739 - val_loss: 0.1228 - val_accuracy: 0.8966\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0820 - accuracy: 0.9478 - val_loss: 0.1209 - val_accuracy: 0.8966\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0792 - accuracy: 0.9739 - val_loss: 0.1191 - val_accuracy: 0.8966\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0758 - accuracy: 0.9565 - val_loss: 0.1172 - val_accuracy: 0.8966\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0768 - accuracy: 0.9652 - val_loss: 0.1156 - val_accuracy: 0.8966\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0736 - accuracy: 0.9565 - val_loss: 0.1140 - val_accuracy: 0.8966\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0732 - accuracy: 0.9565 - val_loss: 0.1126 - val_accuracy: 0.8966\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0717 - accuracy: 0.9565 - val_loss: 0.1112 - val_accuracy: 0.8966\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0718 - accuracy: 0.9652 - val_loss: 0.1095 - val_accuracy: 0.8966\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0774 - accuracy: 0.9652 - val_loss: 0.1071 - val_accuracy: 0.8966\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0728 - accuracy: 0.9478 - val_loss: 0.1050 - val_accuracy: 0.8966\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0691 - accuracy: 0.9565 - val_loss: 0.1034 - val_accuracy: 0.8966\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0747 - accuracy: 0.9652 - val_loss: 0.1020 - val_accuracy: 0.8966\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0698 - accuracy: 0.9565 - val_loss: 0.1013 - val_accuracy: 0.8966\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0646 - accuracy: 0.9565 - val_loss: 0.1006 - val_accuracy: 0.8966\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0665 - accuracy: 0.9391 - val_loss: 0.0994 - val_accuracy: 0.8966\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0645 - accuracy: 0.9565 - val_loss: 0.0983 - val_accuracy: 0.8966\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0681 - accuracy: 0.9565 - val_loss: 0.0973 - val_accuracy: 0.8966\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0629 - accuracy: 0.9652 - val_loss: 0.0964 - val_accuracy: 0.8966\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0614 - accuracy: 0.9565 - val_loss: 0.0955 - val_accuracy: 0.8966\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0610 - accuracy: 0.9565 - val_loss: 0.0945 - val_accuracy: 0.8966\n",
      "0.90625\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111101010100000\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3240)\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_32 (LSTM)               (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.2878 - accuracy: 0.4696 - val_loss: 0.3887 - val_accuracy: 0.4828\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2715 - accuracy: 0.6261 - val_loss: 0.3663 - val_accuracy: 0.7931\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2858 - accuracy: 0.6348 - val_loss: 0.3860 - val_accuracy: 0.3448\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2632 - accuracy: 0.5739 - val_loss: 0.3266 - val_accuracy: 0.5172\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2665 - accuracy: 0.6435 - val_loss: 0.4168 - val_accuracy: 0.5517\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2940 - accuracy: 0.6435 - val_loss: 0.4764 - val_accuracy: 0.3448\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2946 - accuracy: 0.5304 - val_loss: 0.3884 - val_accuracy: 0.4138\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.3038 - accuracy: 0.5043 - val_loss: 0.3028 - val_accuracy: 0.5172\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2895 - accuracy: 0.5304 - val_loss: 0.3208 - val_accuracy: 0.5172\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2557 - accuracy: 0.6870 - val_loss: 0.3355 - val_accuracy: 0.7931\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2251 - accuracy: 0.8087 - val_loss: 0.3404 - val_accuracy: 0.7931\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2186 - accuracy: 0.8870 - val_loss: 0.3297 - val_accuracy: 0.8276\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2090 - accuracy: 0.8957 - val_loss: 0.3183 - val_accuracy: 0.7931\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2248 - accuracy: 0.8087 - val_loss: 0.2897 - val_accuracy: 0.7241\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2012 - accuracy: 0.8261 - val_loss: 0.2874 - val_accuracy: 0.7586\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2518 - accuracy: 0.6957 - val_loss: 0.2885 - val_accuracy: 0.5172\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2724 - accuracy: 0.6174 - val_loss: 0.3289 - val_accuracy: 0.4138\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2925 - accuracy: 0.4522 - val_loss: 0.2613 - val_accuracy: 0.5862\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2880 - accuracy: 0.5391 - val_loss: 0.3086 - val_accuracy: 0.5172\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2960 - accuracy: 0.5478 - val_loss: 0.3105 - val_accuracy: 0.5172\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2892 - accuracy: 0.5217 - val_loss: 0.2912 - val_accuracy: 0.4483\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2667 - accuracy: 0.5565 - val_loss: 0.3226 - val_accuracy: 0.6207\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.3028 - accuracy: 0.5043 - val_loss: 0.3182 - val_accuracy: 0.5862\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.3059 - accuracy: 0.5304 - val_loss: 0.2695 - val_accuracy: 0.6207\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.3117 - accuracy: 0.4609 - val_loss: 0.2950 - val_accuracy: 0.4483\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.3123 - accuracy: 0.4348 - val_loss: 0.2892 - val_accuracy: 0.5172\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.3109 - accuracy: 0.5565 - val_loss: 0.3416 - val_accuracy: 0.4828\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.3274 - accuracy: 0.4174 - val_loss: 0.3157 - val_accuracy: 0.4483\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.3178 - accuracy: 0.4174 - val_loss: 0.3862 - val_accuracy: 0.4138\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.3321 - accuracy: 0.4783 - val_loss: 0.2927 - val_accuracy: 0.4828\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.3074 - accuracy: 0.4609 - val_loss: 0.2979 - val_accuracy: 0.5862\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.3094 - accuracy: 0.4870 - val_loss: 0.2727 - val_accuracy: 0.5172\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2966 - accuracy: 0.5652 - val_loss: 0.2770 - val_accuracy: 0.5862\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2614 - accuracy: 0.6348 - val_loss: 0.2616 - val_accuracy: 0.5517\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2687 - accuracy: 0.6087 - val_loss: 0.2722 - val_accuracy: 0.4483\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2750 - accuracy: 0.5391 - val_loss: 0.2625 - val_accuracy: 0.4828\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2548 - accuracy: 0.6522 - val_loss: 0.2708 - val_accuracy: 0.4828\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2902 - accuracy: 0.5826 - val_loss: 0.2657 - val_accuracy: 0.4483\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2861 - accuracy: 0.5565 - val_loss: 0.2642 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2813 - accuracy: 0.5565 - val_loss: 0.2733 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2710 - accuracy: 0.5565 - val_loss: 0.2635 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2702 - accuracy: 0.6000 - val_loss: 0.2609 - val_accuracy: 0.4138\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2884 - accuracy: 0.5565 - val_loss: 0.2898 - val_accuracy: 0.3448\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2778 - accuracy: 0.5043 - val_loss: 0.2851 - val_accuracy: 0.3448\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2943 - accuracy: 0.5043 - val_loss: 0.2800 - val_accuracy: 0.3448\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2934 - accuracy: 0.5043 - val_loss: 0.2783 - val_accuracy: 0.3448\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2882 - accuracy: 0.4348 - val_loss: 0.2827 - val_accuracy: 0.3448\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2793 - accuracy: 0.5304 - val_loss: 0.2790 - val_accuracy: 0.3448\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2956 - accuracy: 0.4609 - val_loss: 0.2723 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2955 - accuracy: 0.4609 - val_loss: 0.2832 - val_accuracy: 0.3448\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2867 - accuracy: 0.5391 - val_loss: 0.2864 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2969 - accuracy: 0.5391 - val_loss: 0.3046 - val_accuracy: 0.3793\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2923 - accuracy: 0.5739 - val_loss: 0.2739 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.3188 - accuracy: 0.5043 - val_loss: 0.2866 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.3020 - accuracy: 0.5130 - val_loss: 0.2836 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.3009 - accuracy: 0.5130 - val_loss: 0.2784 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2981 - accuracy: 0.5391 - val_loss: 0.2762 - val_accuracy: 0.4828\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2964 - accuracy: 0.4870 - val_loss: 0.2815 - val_accuracy: 0.4483\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2871 - accuracy: 0.5304 - val_loss: 0.2721 - val_accuracy: 0.4483\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2665 - accuracy: 0.6000 - val_loss: 0.2615 - val_accuracy: 0.4828\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2577 - accuracy: 0.5739 - val_loss: 0.2717 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2484 - accuracy: 0.6348 - val_loss: 0.2704 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2508 - accuracy: 0.6000 - val_loss: 0.2690 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2549 - accuracy: 0.6000 - val_loss: 0.2681 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2480 - accuracy: 0.6174 - val_loss: 0.2674 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2589 - accuracy: 0.5739 - val_loss: 0.2620 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2555 - accuracy: 0.5913 - val_loss: 0.2626 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2652 - accuracy: 0.5826 - val_loss: 0.2664 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2543 - accuracy: 0.5739 - val_loss: 0.2761 - val_accuracy: 0.3793\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2528 - accuracy: 0.5913 - val_loss: 0.2758 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2589 - accuracy: 0.6000 - val_loss: 0.2752 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2634 - accuracy: 0.6174 - val_loss: 0.2750 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2671 - accuracy: 0.5565 - val_loss: 0.2746 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2604 - accuracy: 0.5478 - val_loss: 0.2741 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2549 - accuracy: 0.6174 - val_loss: 0.2736 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2528 - accuracy: 0.6087 - val_loss: 0.2732 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2554 - accuracy: 0.5826 - val_loss: 0.2727 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2413 - accuracy: 0.6435 - val_loss: 0.2626 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2351 - accuracy: 0.6261 - val_loss: 0.2611 - val_accuracy: 0.4483\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2322 - accuracy: 0.6348 - val_loss: 0.2694 - val_accuracy: 0.4483\n",
      "0.6041666865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11100111110000111000001101000010101101101000000111\n",
      "26\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2880)\n",
      "(144, 100, 2880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_34 (LSTM)               (None, 100, 20)           232080    \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 235,482\n",
      "Trainable params: 235,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.2324 - accuracy: 0.6870 - val_loss: 0.2948 - val_accuracy: 0.6552\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.3264 - accuracy: 0.4174 - val_loss: 0.3548 - val_accuracy: 0.7241\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2685 - accuracy: 0.6174 - val_loss: 0.2978 - val_accuracy: 0.6207\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2722 - accuracy: 0.5304 - val_loss: 0.3680 - val_accuracy: 0.6207\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.3371 - accuracy: 0.4522 - val_loss: 0.4095 - val_accuracy: 0.1034\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.3094 - accuracy: 0.4783 - val_loss: 0.3826 - val_accuracy: 0.4828\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2746 - accuracy: 0.6435 - val_loss: 0.3338 - val_accuracy: 0.4828\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2797 - accuracy: 0.6087 - val_loss: 0.3324 - val_accuracy: 0.5862\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2748 - accuracy: 0.6696 - val_loss: 0.2817 - val_accuracy: 0.6207\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2844 - accuracy: 0.6261 - val_loss: 0.2840 - val_accuracy: 0.6552\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2811 - accuracy: 0.6348 - val_loss: 0.2838 - val_accuracy: 0.6207\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2629 - accuracy: 0.6435 - val_loss: 0.2652 - val_accuracy: 0.5862\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2580 - accuracy: 0.7130 - val_loss: 0.2855 - val_accuracy: 0.5517\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2703 - accuracy: 0.5913 - val_loss: 0.2610 - val_accuracy: 0.6897\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2587 - accuracy: 0.6000 - val_loss: 0.3283 - val_accuracy: 0.5172\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2806 - accuracy: 0.5652 - val_loss: 0.3352 - val_accuracy: 0.5172\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2531 - accuracy: 0.6174 - val_loss: 0.2561 - val_accuracy: 0.5862\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2533 - accuracy: 0.6609 - val_loss: 0.2330 - val_accuracy: 0.6552\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2542 - accuracy: 0.6087 - val_loss: 0.2556 - val_accuracy: 0.6552\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2628 - accuracy: 0.6261 - val_loss: 0.2642 - val_accuracy: 0.6207\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2719 - accuracy: 0.5739 - val_loss: 0.2761 - val_accuracy: 0.5862\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2650 - accuracy: 0.6261 - val_loss: 0.3108 - val_accuracy: 0.5862\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2522 - accuracy: 0.5913 - val_loss: 0.3025 - val_accuracy: 0.6207\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2531 - accuracy: 0.6261 - val_loss: 0.3151 - val_accuracy: 0.6552\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2460 - accuracy: 0.6087 - val_loss: 0.2823 - val_accuracy: 0.6207\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2383 - accuracy: 0.6609 - val_loss: 0.2400 - val_accuracy: 0.6207\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2794 - accuracy: 0.5565 - val_loss: 0.2539 - val_accuracy: 0.6207\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2773 - accuracy: 0.5826 - val_loss: 0.2680 - val_accuracy: 0.6552\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2726 - accuracy: 0.5478 - val_loss: 0.2549 - val_accuracy: 0.6207\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2566 - accuracy: 0.5565 - val_loss: 0.2597 - val_accuracy: 0.6552\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2618 - accuracy: 0.5826 - val_loss: 0.3155 - val_accuracy: 0.6207\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.2637 - accuracy: 0.6696 - val_loss: 0.2481 - val_accuracy: 0.6552\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2571 - accuracy: 0.5826 - val_loss: 0.2679 - val_accuracy: 0.6552\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2414 - accuracy: 0.6609 - val_loss: 0.2780 - val_accuracy: 0.5517\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2514 - accuracy: 0.6348 - val_loss: 0.2864 - val_accuracy: 0.6207\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2524 - accuracy: 0.6783 - val_loss: 0.2988 - val_accuracy: 0.5862\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2723 - accuracy: 0.5565 - val_loss: 0.2917 - val_accuracy: 0.6207\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2570 - accuracy: 0.6348 - val_loss: 0.2296 - val_accuracy: 0.6897\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2321 - accuracy: 0.6696 - val_loss: 0.2676 - val_accuracy: 0.5862\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2700 - accuracy: 0.5826 - val_loss: 0.3002 - val_accuracy: 0.5862\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2626 - accuracy: 0.6174 - val_loss: 0.3122 - val_accuracy: 0.5517\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2616 - accuracy: 0.5826 - val_loss: 0.2473 - val_accuracy: 0.5862\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2441 - accuracy: 0.5913 - val_loss: 0.2605 - val_accuracy: 0.5862\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2450 - accuracy: 0.6174 - val_loss: 0.2793 - val_accuracy: 0.6207\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2367 - accuracy: 0.6174 - val_loss: 0.2710 - val_accuracy: 0.5862\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2575 - accuracy: 0.6435 - val_loss: 0.2878 - val_accuracy: 0.5862\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2282 - accuracy: 0.6609 - val_loss: 0.2765 - val_accuracy: 0.6207\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2445 - accuracy: 0.6174 - val_loss: 0.2980 - val_accuracy: 0.5862\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2346 - accuracy: 0.6957 - val_loss: 0.2865 - val_accuracy: 0.6207\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2408 - accuracy: 0.6696 - val_loss: 0.2748 - val_accuracy: 0.6552\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2487 - accuracy: 0.6261 - val_loss: 0.2739 - val_accuracy: 0.6552\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2392 - accuracy: 0.5913 - val_loss: 0.2825 - val_accuracy: 0.6207\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2318 - accuracy: 0.6696 - val_loss: 0.3039 - val_accuracy: 0.6207\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2252 - accuracy: 0.6348 - val_loss: 0.2770 - val_accuracy: 0.6552\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2310 - accuracy: 0.6870 - val_loss: 0.2878 - val_accuracy: 0.6552\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2361 - accuracy: 0.6957 - val_loss: 0.2937 - val_accuracy: 0.6552\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2512 - accuracy: 0.6348 - val_loss: 0.3059 - val_accuracy: 0.6552\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2278 - accuracy: 0.6522 - val_loss: 0.2576 - val_accuracy: 0.6552\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2341 - accuracy: 0.6870 - val_loss: 0.2716 - val_accuracy: 0.6552\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2340 - accuracy: 0.6348 - val_loss: 0.2744 - val_accuracy: 0.6552\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2364 - accuracy: 0.6435 - val_loss: 0.2722 - val_accuracy: 0.6552\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2345 - accuracy: 0.6435 - val_loss: 0.2680 - val_accuracy: 0.6207\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2456 - accuracy: 0.6870 - val_loss: 0.2628 - val_accuracy: 0.6207\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2283 - accuracy: 0.7130 - val_loss: 0.2761 - val_accuracy: 0.6207\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2400 - accuracy: 0.6957 - val_loss: 0.2677 - val_accuracy: 0.6207\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2469 - accuracy: 0.6696 - val_loss: 0.2809 - val_accuracy: 0.6207\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2389 - accuracy: 0.6435 - val_loss: 0.2823 - val_accuracy: 0.6207\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2161 - accuracy: 0.6870 - val_loss: 0.2992 - val_accuracy: 0.5517\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2277 - accuracy: 0.6783 - val_loss: 0.2521 - val_accuracy: 0.5862\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2389 - accuracy: 0.6609 - val_loss: 0.2633 - val_accuracy: 0.5862\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2373 - accuracy: 0.6957 - val_loss: 0.2950 - val_accuracy: 0.5862\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2177 - accuracy: 0.7217 - val_loss: 0.2860 - val_accuracy: 0.5862\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2210 - accuracy: 0.7043 - val_loss: 0.2863 - val_accuracy: 0.5862\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2172 - accuracy: 0.7130 - val_loss: 0.2837 - val_accuracy: 0.6207\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2206 - accuracy: 0.6957 - val_loss: 0.2949 - val_accuracy: 0.5862\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2211 - accuracy: 0.7043 - val_loss: 0.2946 - val_accuracy: 0.5862\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2200 - accuracy: 0.6783 - val_loss: 0.2988 - val_accuracy: 0.5862\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2107 - accuracy: 0.6870 - val_loss: 0.2972 - val_accuracy: 0.5862\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2146 - accuracy: 0.7217 - val_loss: 0.3060 - val_accuracy: 0.5517\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2079 - accuracy: 0.6957 - val_loss: 0.3021 - val_accuracy: 0.5862\n",
      "0.6979166865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101001111011101111000001001111101000011010\n",
      "22\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3360)\n",
      "(144, 100, 3360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_36 (LSTM)               (None, 100, 20)           270480    \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 273,882\n",
      "Trainable params: 273,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 0.2729 - accuracy: 0.5217 - val_loss: 0.4356 - val_accuracy: 0.2759\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.3126 - accuracy: 0.4174 - val_loss: 0.3884 - val_accuracy: 0.4483\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.3058 - accuracy: 0.4696 - val_loss: 0.3039 - val_accuracy: 0.5172\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2979 - accuracy: 0.5043 - val_loss: 0.2931 - val_accuracy: 0.6207\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3047 - accuracy: 0.4696 - val_loss: 0.3565 - val_accuracy: 0.4828\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2890 - accuracy: 0.4522 - val_loss: 0.4194 - val_accuracy: 0.3448\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2769 - accuracy: 0.5304 - val_loss: 0.3209 - val_accuracy: 0.3103\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2531 - accuracy: 0.5826 - val_loss: 0.3195 - val_accuracy: 0.3793\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2708 - accuracy: 0.5826 - val_loss: 0.4502 - val_accuracy: 0.3103\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2783 - accuracy: 0.5130 - val_loss: 0.4016 - val_accuracy: 0.2759\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2978 - accuracy: 0.3826 - val_loss: 0.4232 - val_accuracy: 0.2414\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2710 - accuracy: 0.5565 - val_loss: 0.3082 - val_accuracy: 0.4138\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2869 - accuracy: 0.4435 - val_loss: 0.3378 - val_accuracy: 0.3103\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2678 - accuracy: 0.5391 - val_loss: 0.2841 - val_accuracy: 0.5172\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2649 - accuracy: 0.6087 - val_loss: 0.2583 - val_accuracy: 0.5517\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2661 - accuracy: 0.5826 - val_loss: 0.2320 - val_accuracy: 0.5862\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2638 - accuracy: 0.6000 - val_loss: 0.2463 - val_accuracy: 0.5517\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2486 - accuracy: 0.6261 - val_loss: 0.2383 - val_accuracy: 0.6552\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2559 - accuracy: 0.5652 - val_loss: 0.2426 - val_accuracy: 0.6897\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2621 - accuracy: 0.5826 - val_loss: 0.2087 - val_accuracy: 0.7241\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2563 - accuracy: 0.6000 - val_loss: 0.2532 - val_accuracy: 0.6207\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2428 - accuracy: 0.6087 - val_loss: 0.2440 - val_accuracy: 0.6207\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2465 - accuracy: 0.6174 - val_loss: 0.2257 - val_accuracy: 0.6897\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2483 - accuracy: 0.6261 - val_loss: 0.2208 - val_accuracy: 0.7241\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2472 - accuracy: 0.6087 - val_loss: 0.2201 - val_accuracy: 0.6207\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2440 - accuracy: 0.6174 - val_loss: 0.2417 - val_accuracy: 0.5862\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2259 - accuracy: 0.6957 - val_loss: 0.2481 - val_accuracy: 0.5517\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2319 - accuracy: 0.6522 - val_loss: 0.2263 - val_accuracy: 0.6207\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2483 - accuracy: 0.5826 - val_loss: 0.2655 - val_accuracy: 0.5517\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2530 - accuracy: 0.5826 - val_loss: 0.2860 - val_accuracy: 0.5517\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2577 - accuracy: 0.5826 - val_loss: 0.2801 - val_accuracy: 0.4138\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2229 - accuracy: 0.6783 - val_loss: 0.2768 - val_accuracy: 0.4138\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2308 - accuracy: 0.6783 - val_loss: 0.2772 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2602 - accuracy: 0.6000 - val_loss: 0.2800 - val_accuracy: 0.4138\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2635 - accuracy: 0.5652 - val_loss: 0.2729 - val_accuracy: 0.4138\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2690 - accuracy: 0.5217 - val_loss: 0.2748 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2812 - accuracy: 0.4696 - val_loss: 0.2763 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2578 - accuracy: 0.4870 - val_loss: 0.2727 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2227 - accuracy: 0.6783 - val_loss: 0.2662 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2450 - accuracy: 0.5913 - val_loss: 0.2512 - val_accuracy: 0.4483\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2199 - accuracy: 0.7043 - val_loss: 0.2306 - val_accuracy: 0.6552\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2363 - accuracy: 0.6261 - val_loss: 0.2529 - val_accuracy: 0.4483\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2197 - accuracy: 0.6435 - val_loss: 0.2378 - val_accuracy: 0.5862\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2078 - accuracy: 0.6609 - val_loss: 0.2816 - val_accuracy: 0.4828\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2224 - accuracy: 0.6870 - val_loss: 0.2127 - val_accuracy: 0.6897\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2210 - accuracy: 0.6696 - val_loss: 0.2091 - val_accuracy: 0.7241\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2048 - accuracy: 0.7130 - val_loss: 0.1887 - val_accuracy: 0.7931\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2278 - accuracy: 0.6087 - val_loss: 0.1838 - val_accuracy: 0.7931\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2591 - accuracy: 0.5478 - val_loss: 0.1797 - val_accuracy: 0.7931\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2563 - accuracy: 0.5826 - val_loss: 0.1781 - val_accuracy: 0.7931\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2516 - accuracy: 0.6435 - val_loss: 0.1851 - val_accuracy: 0.7586\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2344 - accuracy: 0.6696 - val_loss: 0.1931 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2223 - accuracy: 0.6609 - val_loss: 0.1839 - val_accuracy: 0.7586\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2143 - accuracy: 0.6435 - val_loss: 0.1828 - val_accuracy: 0.7586\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2123 - accuracy: 0.6870 - val_loss: 0.1807 - val_accuracy: 0.7586\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1961 - accuracy: 0.7739 - val_loss: 0.1775 - val_accuracy: 0.7931\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1962 - accuracy: 0.7652 - val_loss: 0.1703 - val_accuracy: 0.7931\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2113 - accuracy: 0.7565 - val_loss: 0.1670 - val_accuracy: 0.8276\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2049 - accuracy: 0.7130 - val_loss: 0.1680 - val_accuracy: 0.7931\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1968 - accuracy: 0.7739 - val_loss: 0.1612 - val_accuracy: 0.8276\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1905 - accuracy: 0.7739 - val_loss: 0.1677 - val_accuracy: 0.7931\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1858 - accuracy: 0.7391 - val_loss: 0.1674 - val_accuracy: 0.7931\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1932 - accuracy: 0.7739 - val_loss: 0.1710 - val_accuracy: 0.7931\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2137 - accuracy: 0.7391 - val_loss: 0.1696 - val_accuracy: 0.7931\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2010 - accuracy: 0.7565 - val_loss: 0.1707 - val_accuracy: 0.7931\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1916 - accuracy: 0.7478 - val_loss: 0.1684 - val_accuracy: 0.7931\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1879 - accuracy: 0.7565 - val_loss: 0.1688 - val_accuracy: 0.7931\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1881 - accuracy: 0.7478 - val_loss: 0.1684 - val_accuracy: 0.7931\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1856 - accuracy: 0.7565 - val_loss: 0.1672 - val_accuracy: 0.7931\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1785 - accuracy: 0.7391 - val_loss: 0.1665 - val_accuracy: 0.7931\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1806 - accuracy: 0.7652 - val_loss: 0.1669 - val_accuracy: 0.7586\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1810 - accuracy: 0.7565 - val_loss: 0.1685 - val_accuracy: 0.7586\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1793 - accuracy: 0.7652 - val_loss: 0.1695 - val_accuracy: 0.7586\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1855 - accuracy: 0.7304 - val_loss: 0.1741 - val_accuracy: 0.7586\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1799 - accuracy: 0.7652 - val_loss: 0.1743 - val_accuracy: 0.7241\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1759 - accuracy: 0.7478 - val_loss: 0.1740 - val_accuracy: 0.7241\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1819 - accuracy: 0.7391 - val_loss: 0.1736 - val_accuracy: 0.7586\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1796 - accuracy: 0.7478 - val_loss: 0.1681 - val_accuracy: 0.7586\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1718 - accuracy: 0.7652 - val_loss: 0.1679 - val_accuracy: 0.7586\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1696 - accuracy: 0.7652 - val_loss: 0.1676 - val_accuracy: 0.7586\n",
      "0.8020833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11100111110000111000101010001000111010100111001010\n",
      "25\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3000)\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_38 (LSTM)               (None, 100, 20)           241680    \n",
      "_________________________________________________________________\n",
      "lstm_39 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 245,082\n",
      "Trainable params: 245,042\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.2508 - accuracy: 0.6609 - val_loss: 0.3353 - val_accuracy: 0.5517\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.3399 - accuracy: 0.4000 - val_loss: 0.1952 - val_accuracy: 0.6552\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2681 - accuracy: 0.6696 - val_loss: 0.4008 - val_accuracy: 0.6207\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.3170 - accuracy: 0.5739 - val_loss: 0.2414 - val_accuracy: 0.6897\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2314 - accuracy: 0.7217 - val_loss: 0.2217 - val_accuracy: 0.7586\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2266 - accuracy: 0.6957 - val_loss: 0.2329 - val_accuracy: 0.7241\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2184 - accuracy: 0.7130 - val_loss: 0.2336 - val_accuracy: 0.7241\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2137 - accuracy: 0.7304 - val_loss: 0.2025 - val_accuracy: 0.7586\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2010 - accuracy: 0.7652 - val_loss: 0.2696 - val_accuracy: 0.6897\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2016 - accuracy: 0.8000 - val_loss: 0.2323 - val_accuracy: 0.7586\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1930 - accuracy: 0.7739 - val_loss: 0.2528 - val_accuracy: 0.6897\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1922 - accuracy: 0.7565 - val_loss: 0.2355 - val_accuracy: 0.7586\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1782 - accuracy: 0.7739 - val_loss: 0.2432 - val_accuracy: 0.6897\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.1422 - accuracy: 0.8609 - val_loss: 0.1965 - val_accuracy: 0.7586\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.1533 - accuracy: 0.8783 - val_loss: 0.2306 - val_accuracy: 0.6207\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1578 - accuracy: 0.8435 - val_loss: 0.2631 - val_accuracy: 0.6207\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1843 - accuracy: 0.7739 - val_loss: 0.2662 - val_accuracy: 0.6897\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1838 - accuracy: 0.8000 - val_loss: 0.2065 - val_accuracy: 0.6897\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1712 - accuracy: 0.8435 - val_loss: 0.1920 - val_accuracy: 0.6897\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1852 - accuracy: 0.7739 - val_loss: 0.2328 - val_accuracy: 0.6207\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.1782 - accuracy: 0.7739 - val_loss: 0.2772 - val_accuracy: 0.6552\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2500 - accuracy: 0.6348 - val_loss: 0.3325 - val_accuracy: 0.5172\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2533 - accuracy: 0.6522 - val_loss: 0.3395 - val_accuracy: 0.5172\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2925 - accuracy: 0.5739 - val_loss: 0.4562 - val_accuracy: 0.3793\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2499 - accuracy: 0.6783 - val_loss: 0.4647 - val_accuracy: 0.4138\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2909 - accuracy: 0.5652 - val_loss: 0.3964 - val_accuracy: 0.4138\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2464 - accuracy: 0.6522 - val_loss: 0.3188 - val_accuracy: 0.6207\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1539 - accuracy: 0.8261 - val_loss: 0.2535 - val_accuracy: 0.6552\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1474 - accuracy: 0.8435 - val_loss: 0.2487 - val_accuracy: 0.6897\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1630 - accuracy: 0.8261 - val_loss: 0.2455 - val_accuracy: 0.6897\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1572 - accuracy: 0.8348 - val_loss: 0.2043 - val_accuracy: 0.7241\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1507 - accuracy: 0.8522 - val_loss: 0.1817 - val_accuracy: 0.6552\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1753 - accuracy: 0.8261 - val_loss: 0.1666 - val_accuracy: 0.6897\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2034 - accuracy: 0.6957 - val_loss: 0.1440 - val_accuracy: 0.7241\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1230 - accuracy: 0.8522 - val_loss: 0.1591 - val_accuracy: 0.7931\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.1093 - accuracy: 0.8609 - val_loss: 0.1753 - val_accuracy: 0.6897\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1164 - accuracy: 0.8522 - val_loss: 0.1632 - val_accuracy: 0.7586\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1456 - accuracy: 0.8087 - val_loss: 0.2228 - val_accuracy: 0.7241\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.1506 - accuracy: 0.8087 - val_loss: 0.2278 - val_accuracy: 0.7586\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2358 - accuracy: 0.6435 - val_loss: 0.4075 - val_accuracy: 0.4828\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2779 - accuracy: 0.5565 - val_loss: 0.4148 - val_accuracy: 0.3448\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.3438 - accuracy: 0.4261 - val_loss: 0.4252 - val_accuracy: 0.2759\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2874 - accuracy: 0.4957 - val_loss: 0.3928 - val_accuracy: 0.3448\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1844 - accuracy: 0.7565 - val_loss: 0.1985 - val_accuracy: 0.7586\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1316 - accuracy: 0.8783 - val_loss: 0.1310 - val_accuracy: 0.8966\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1411 - accuracy: 0.8609 - val_loss: 0.1670 - val_accuracy: 0.7931\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1247 - accuracy: 0.8696 - val_loss: 0.1657 - val_accuracy: 0.7931\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1403 - accuracy: 0.8696 - val_loss: 0.1550 - val_accuracy: 0.7586\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1353 - accuracy: 0.8870 - val_loss: 0.1284 - val_accuracy: 0.7931\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1245 - accuracy: 0.8783 - val_loss: 0.1411 - val_accuracy: 0.7931\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1256 - accuracy: 0.8696 - val_loss: 0.1766 - val_accuracy: 0.7586\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1090 - accuracy: 0.9043 - val_loss: 0.1361 - val_accuracy: 0.8276\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1157 - accuracy: 0.8957 - val_loss: 0.2458 - val_accuracy: 0.6207\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1943 - accuracy: 0.7304 - val_loss: 0.2396 - val_accuracy: 0.6207\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1918 - accuracy: 0.7478 - val_loss: 0.2422 - val_accuracy: 0.6207\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1956 - accuracy: 0.7652 - val_loss: 0.2492 - val_accuracy: 0.6207\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2080 - accuracy: 0.7304 - val_loss: 0.2572 - val_accuracy: 0.6207\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.1918 - accuracy: 0.7565 - val_loss: 0.2487 - val_accuracy: 0.5862\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2009 - accuracy: 0.7217 - val_loss: 0.2618 - val_accuracy: 0.5862\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2319 - accuracy: 0.6696 - val_loss: 0.2998 - val_accuracy: 0.4483\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2328 - accuracy: 0.6435 - val_loss: 0.2636 - val_accuracy: 0.5517\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2245 - accuracy: 0.6609 - val_loss: 0.2621 - val_accuracy: 0.5862\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1906 - accuracy: 0.7565 - val_loss: 0.2358 - val_accuracy: 0.6552\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2068 - accuracy: 0.6696 - val_loss: 0.2853 - val_accuracy: 0.5517\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2397 - accuracy: 0.6261 - val_loss: 0.2664 - val_accuracy: 0.5862\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2239 - accuracy: 0.6696 - val_loss: 0.2774 - val_accuracy: 0.5172\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2645 - accuracy: 0.6174 - val_loss: 0.2705 - val_accuracy: 0.5172\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2696 - accuracy: 0.6174 - val_loss: 0.2823 - val_accuracy: 0.5517\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2409 - accuracy: 0.6348 - val_loss: 0.2189 - val_accuracy: 0.6552\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2325 - accuracy: 0.6348 - val_loss: 0.2126 - val_accuracy: 0.6897\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2096 - accuracy: 0.6957 - val_loss: 0.2194 - val_accuracy: 0.6552\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2095 - accuracy: 0.6783 - val_loss: 0.2026 - val_accuracy: 0.6552\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2078 - accuracy: 0.6870 - val_loss: 0.2568 - val_accuracy: 0.5172\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1733 - accuracy: 0.7478 - val_loss: 0.1690 - val_accuracy: 0.7586\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2101 - accuracy: 0.6870 - val_loss: 0.2833 - val_accuracy: 0.5172\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2351 - accuracy: 0.5826 - val_loss: 0.3281 - val_accuracy: 0.4483\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2937 - accuracy: 0.5043 - val_loss: 0.3323 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2597 - accuracy: 0.5304 - val_loss: 0.3373 - val_accuracy: 0.4828\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2853 - accuracy: 0.5130 - val_loss: 0.3412 - val_accuracy: 0.4828\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2681 - accuracy: 0.5217 - val_loss: 0.3498 - val_accuracy: 0.4483\n",
      "0.625\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "10100010100010010010110100111100111010100111001010\n",
      "26\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2880)\n",
      "(144, 100, 2880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_40 (LSTM)               (None, 100, 20)           232080    \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 235,482\n",
      "Trainable params: 235,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.2868 - accuracy: 0.4435 - val_loss: 0.3757 - val_accuracy: 0.4483\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2967 - accuracy: 0.5130 - val_loss: 0.3925 - val_accuracy: 0.3448\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2766 - accuracy: 0.4957 - val_loss: 0.3708 - val_accuracy: 0.3448\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2727 - accuracy: 0.5130 - val_loss: 0.3252 - val_accuracy: 0.3793\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2753 - accuracy: 0.5217 - val_loss: 0.3114 - val_accuracy: 0.3793\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2700 - accuracy: 0.5130 - val_loss: 0.3262 - val_accuracy: 0.3448\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2630 - accuracy: 0.5565 - val_loss: 0.2797 - val_accuracy: 0.4483\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2539 - accuracy: 0.5391 - val_loss: 0.2854 - val_accuracy: 0.5862\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2409 - accuracy: 0.5565 - val_loss: 0.2942 - val_accuracy: 0.5517\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2419 - accuracy: 0.5913 - val_loss: 0.3128 - val_accuracy: 0.6207\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2427 - accuracy: 0.6261 - val_loss: 0.2735 - val_accuracy: 0.5862\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2392 - accuracy: 0.6522 - val_loss: 0.2742 - val_accuracy: 0.6897\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2340 - accuracy: 0.6261 - val_loss: 0.2750 - val_accuracy: 0.7241\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2276 - accuracy: 0.6783 - val_loss: 0.2577 - val_accuracy: 0.6552\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2295 - accuracy: 0.6522 - val_loss: 0.2383 - val_accuracy: 0.6897\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2252 - accuracy: 0.6522 - val_loss: 0.2472 - val_accuracy: 0.7241\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2261 - accuracy: 0.6435 - val_loss: 0.2580 - val_accuracy: 0.7241\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2187 - accuracy: 0.6435 - val_loss: 0.2349 - val_accuracy: 0.7241\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2231 - accuracy: 0.6696 - val_loss: 0.2376 - val_accuracy: 0.7241\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2230 - accuracy: 0.6870 - val_loss: 0.2299 - val_accuracy: 0.7241\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2210 - accuracy: 0.7043 - val_loss: 0.2378 - val_accuracy: 0.7586\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2197 - accuracy: 0.7217 - val_loss: 0.2391 - val_accuracy: 0.7241\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2188 - accuracy: 0.7478 - val_loss: 0.2324 - val_accuracy: 0.7586\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2172 - accuracy: 0.7130 - val_loss: 0.2271 - val_accuracy: 0.7241\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2105 - accuracy: 0.7391 - val_loss: 0.2255 - val_accuracy: 0.7241\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2134 - accuracy: 0.7739 - val_loss: 0.2260 - val_accuracy: 0.7586\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2094 - accuracy: 0.7478 - val_loss: 0.2307 - val_accuracy: 0.7241\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2068 - accuracy: 0.7913 - val_loss: 0.2326 - val_accuracy: 0.7241\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2066 - accuracy: 0.7913 - val_loss: 0.2328 - val_accuracy: 0.6897\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2088 - accuracy: 0.6783 - val_loss: 0.2393 - val_accuracy: 0.6897\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2044 - accuracy: 0.7304 - val_loss: 0.2530 - val_accuracy: 0.6897\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2034 - accuracy: 0.7217 - val_loss: 0.2395 - val_accuracy: 0.7241\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2045 - accuracy: 0.7043 - val_loss: 0.2423 - val_accuracy: 0.7241\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2026 - accuracy: 0.7652 - val_loss: 0.2357 - val_accuracy: 0.6897\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2066 - accuracy: 0.7391 - val_loss: 0.2250 - val_accuracy: 0.6552\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2012 - accuracy: 0.7478 - val_loss: 0.2356 - val_accuracy: 0.7241\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2321 - accuracy: 0.7826 - val_loss: 0.2775 - val_accuracy: 0.5172\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2529 - accuracy: 0.6348 - val_loss: 0.3060 - val_accuracy: 0.4828\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2455 - accuracy: 0.6348 - val_loss: 0.2923 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2553 - accuracy: 0.5565 - val_loss: 0.3092 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2543 - accuracy: 0.5478 - val_loss: 0.3172 - val_accuracy: 0.3448\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2506 - accuracy: 0.6000 - val_loss: 0.3005 - val_accuracy: 0.3448\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2420 - accuracy: 0.5913 - val_loss: 0.2921 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2576 - accuracy: 0.5130 - val_loss: 0.2870 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2633 - accuracy: 0.4522 - val_loss: 0.2912 - val_accuracy: 0.4138\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2628 - accuracy: 0.4087 - val_loss: 0.2993 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2585 - accuracy: 0.4609 - val_loss: 0.3009 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2399 - accuracy: 0.4957 - val_loss: 0.2960 - val_accuracy: 0.4138\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2480 - accuracy: 0.4696 - val_loss: 0.3008 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2424 - accuracy: 0.4957 - val_loss: 0.3038 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2461 - accuracy: 0.5043 - val_loss: 0.3062 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2413 - accuracy: 0.5130 - val_loss: 0.3025 - val_accuracy: 0.4138\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2403 - accuracy: 0.5478 - val_loss: 0.2975 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2427 - accuracy: 0.5043 - val_loss: 0.2989 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2412 - accuracy: 0.4870 - val_loss: 0.2973 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2421 - accuracy: 0.4783 - val_loss: 0.2956 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2376 - accuracy: 0.5130 - val_loss: 0.2936 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2365 - accuracy: 0.5304 - val_loss: 0.2949 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2381 - accuracy: 0.5043 - val_loss: 0.2959 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2356 - accuracy: 0.4522 - val_loss: 0.2951 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2337 - accuracy: 0.5043 - val_loss: 0.2943 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2343 - accuracy: 0.4522 - val_loss: 0.2938 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2373 - accuracy: 0.4696 - val_loss: 0.2920 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2319 - accuracy: 0.5391 - val_loss: 0.2916 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2348 - accuracy: 0.5043 - val_loss: 0.2934 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2372 - accuracy: 0.5043 - val_loss: 0.2909 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2329 - accuracy: 0.5130 - val_loss: 0.2902 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2327 - accuracy: 0.5304 - val_loss: 0.2918 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2317 - accuracy: 0.5565 - val_loss: 0.2912 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2313 - accuracy: 0.5130 - val_loss: 0.2892 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2288 - accuracy: 0.5652 - val_loss: 0.2860 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2320 - accuracy: 0.5478 - val_loss: 0.2876 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2282 - accuracy: 0.5478 - val_loss: 0.2894 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2270 - accuracy: 0.5826 - val_loss: 0.2909 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2276 - accuracy: 0.6174 - val_loss: 0.2898 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2228 - accuracy: 0.6174 - val_loss: 0.2892 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2241 - accuracy: 0.6087 - val_loss: 0.2865 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2251 - accuracy: 0.5739 - val_loss: 0.2872 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2253 - accuracy: 0.6087 - val_loss: 0.2830 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2275 - accuracy: 0.5391 - val_loss: 0.2826 - val_accuracy: 0.4138\n",
      "0.6145833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111100111000001101000010101101101000000111\n",
      "26\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2880)\n",
      "(144, 100, 2880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_42 (LSTM)               (None, 100, 20)           232080    \n",
      "_________________________________________________________________\n",
      "lstm_43 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 235,482\n",
      "Trainable params: 235,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.2273 - accuracy: 0.6261 - val_loss: 0.4721 - val_accuracy: 0.5862\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2622 - accuracy: 0.6000 - val_loss: 0.2842 - val_accuracy: 0.6552\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2983 - accuracy: 0.4870 - val_loss: 0.2597 - val_accuracy: 0.7241\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2638 - accuracy: 0.6000 - val_loss: 0.2585 - val_accuracy: 0.6552\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2601 - accuracy: 0.5739 - val_loss: 0.2469 - val_accuracy: 0.7586\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2569 - accuracy: 0.6435 - val_loss: 0.2578 - val_accuracy: 0.7586\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2820 - accuracy: 0.5391 - val_loss: 0.3124 - val_accuracy: 0.5862\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2838 - accuracy: 0.5304 - val_loss: 0.2643 - val_accuracy: 0.6897\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2585 - accuracy: 0.6609 - val_loss: 0.2680 - val_accuracy: 0.6207\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2621 - accuracy: 0.6696 - val_loss: 0.2130 - val_accuracy: 0.8276\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2293 - accuracy: 0.7652 - val_loss: 0.1409 - val_accuracy: 0.9310\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2261 - accuracy: 0.7739 - val_loss: 0.1524 - val_accuracy: 0.9655\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2360 - accuracy: 0.7391 - val_loss: 0.1383 - val_accuracy: 0.9310\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2324 - accuracy: 0.7652 - val_loss: 0.1884 - val_accuracy: 0.8966\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2373 - accuracy: 0.7130 - val_loss: 0.1681 - val_accuracy: 0.9310\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2363 - accuracy: 0.6870 - val_loss: 0.2758 - val_accuracy: 0.5862\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2380 - accuracy: 0.7304 - val_loss: 0.2412 - val_accuracy: 0.6552\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2410 - accuracy: 0.6696 - val_loss: 0.2800 - val_accuracy: 0.6552\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2410 - accuracy: 0.7043 - val_loss: 0.2904 - val_accuracy: 0.4138\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2532 - accuracy: 0.6087 - val_loss: 0.3679 - val_accuracy: 0.5517\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2931 - accuracy: 0.6000 - val_loss: 0.3441 - val_accuracy: 0.4828\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2874 - accuracy: 0.5739 - val_loss: 0.2442 - val_accuracy: 0.6207\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2399 - accuracy: 0.6870 - val_loss: 0.2649 - val_accuracy: 0.7241\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2172 - accuracy: 0.7391 - val_loss: 0.2643 - val_accuracy: 0.6552\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2325 - accuracy: 0.6957 - val_loss: 0.2475 - val_accuracy: 0.7586\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2202 - accuracy: 0.7391 - val_loss: 0.2457 - val_accuracy: 0.6897\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2233 - accuracy: 0.7217 - val_loss: 0.2384 - val_accuracy: 0.6897\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2343 - accuracy: 0.7130 - val_loss: 0.2348 - val_accuracy: 0.6897\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2176 - accuracy: 0.7652 - val_loss: 0.2333 - val_accuracy: 0.6897\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2073 - accuracy: 0.7913 - val_loss: 0.2370 - val_accuracy: 0.6897\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2655 - accuracy: 0.6261 - val_loss: 0.2301 - val_accuracy: 0.7241\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2715 - accuracy: 0.6087 - val_loss: 0.2301 - val_accuracy: 0.7241\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2757 - accuracy: 0.6174 - val_loss: 0.2275 - val_accuracy: 0.7241\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2436 - accuracy: 0.6348 - val_loss: 0.2269 - val_accuracy: 0.7586\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2054 - accuracy: 0.7739 - val_loss: 0.2236 - val_accuracy: 0.6897\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2216 - accuracy: 0.6957 - val_loss: 0.2611 - val_accuracy: 0.5517\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1945 - accuracy: 0.7652 - val_loss: 0.2551 - val_accuracy: 0.5862\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2259 - accuracy: 0.7391 - val_loss: 0.2023 - val_accuracy: 0.7241\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2352 - accuracy: 0.6609 - val_loss: 0.2043 - val_accuracy: 0.6897\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2019 - accuracy: 0.7739 - val_loss: 0.2310 - val_accuracy: 0.6552\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2189 - accuracy: 0.6522 - val_loss: 0.2540 - val_accuracy: 0.5517\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2094 - accuracy: 0.7130 - val_loss: 0.2623 - val_accuracy: 0.6207\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2769 - accuracy: 0.4957 - val_loss: 0.2081 - val_accuracy: 0.6897\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2468 - accuracy: 0.6000 - val_loss: 0.1979 - val_accuracy: 0.6897\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2338 - accuracy: 0.6870 - val_loss: 0.2323 - val_accuracy: 0.6207\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2550 - accuracy: 0.6435 - val_loss: 0.2683 - val_accuracy: 0.6897\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2527 - accuracy: 0.6261 - val_loss: 0.3183 - val_accuracy: 0.6207\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2197 - accuracy: 0.6783 - val_loss: 0.2843 - val_accuracy: 0.5517\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2826 - accuracy: 0.5565 - val_loss: 0.3878 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.3299 - accuracy: 0.4609 - val_loss: 0.5023 - val_accuracy: 0.2759\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.3275 - accuracy: 0.4522 - val_loss: 0.3615 - val_accuracy: 0.4828\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.3058 - accuracy: 0.5043 - val_loss: 0.3750 - val_accuracy: 0.3793\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2741 - accuracy: 0.5652 - val_loss: 0.3407 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2859 - accuracy: 0.4783 - val_loss: 0.3132 - val_accuracy: 0.4828\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2934 - accuracy: 0.4348 - val_loss: 0.3228 - val_accuracy: 0.3793\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2820 - accuracy: 0.4783 - val_loss: 0.3230 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2911 - accuracy: 0.4957 - val_loss: 0.3848 - val_accuracy: 0.2759\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2911 - accuracy: 0.5130 - val_loss: 0.3669 - val_accuracy: 0.3448\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2740 - accuracy: 0.5652 - val_loss: 0.3125 - val_accuracy: 0.3103\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2841 - accuracy: 0.5304 - val_loss: 0.3160 - val_accuracy: 0.4483\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2596 - accuracy: 0.6000 - val_loss: 0.3134 - val_accuracy: 0.3448\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2518 - accuracy: 0.6261 - val_loss: 0.3539 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2457 - accuracy: 0.6174 - val_loss: 0.3029 - val_accuracy: 0.4483\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2593 - accuracy: 0.5652 - val_loss: 0.2722 - val_accuracy: 0.4483\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2824 - accuracy: 0.5652 - val_loss: 0.2667 - val_accuracy: 0.4828\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2663 - accuracy: 0.5913 - val_loss: 0.3096 - val_accuracy: 0.3448\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2657 - accuracy: 0.5913 - val_loss: 0.2614 - val_accuracy: 0.4483\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2483 - accuracy: 0.6174 - val_loss: 0.3107 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2360 - accuracy: 0.6522 - val_loss: 0.3134 - val_accuracy: 0.4828\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2487 - accuracy: 0.6522 - val_loss: 0.3093 - val_accuracy: 0.4828\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2501 - accuracy: 0.6087 - val_loss: 0.3093 - val_accuracy: 0.3793\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2421 - accuracy: 0.6174 - val_loss: 0.2610 - val_accuracy: 0.5517\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2445 - accuracy: 0.6174 - val_loss: 0.2856 - val_accuracy: 0.5517\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2451 - accuracy: 0.6174 - val_loss: 0.2789 - val_accuracy: 0.4483\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2489 - accuracy: 0.6087 - val_loss: 0.2642 - val_accuracy: 0.4483\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2733 - accuracy: 0.5391 - val_loss: 0.2689 - val_accuracy: 0.4828\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2860 - accuracy: 0.5478 - val_loss: 0.2724 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2835 - accuracy: 0.5826 - val_loss: 0.3083 - val_accuracy: 0.4828\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2755 - accuracy: 0.5652 - val_loss: 0.2936 - val_accuracy: 0.4483\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2834 - accuracy: 0.5130 - val_loss: 0.3122 - val_accuracy: 0.4138\n",
      "0.5520833134651184\n",
      "fitness pass\n",
      "[(0.6145833134651184, 957257731078682), (0.625, 921963755448778), (0.5, 714840212662246), (0.4895833432674408, 1061734365432041), (0.90625, 675987511003229), (0.6041666865348816, 923441258232480), (0.6979166865348816, 1019307627305479), (0.8020833134651184, 957257731078682), (0.625, 1019308115470794), (0.6145833134651184, 714840212744650), (0.5520833134651184, 923375237782023)]\n",
      "[675987511003229, 957257731078682]\n",
      "[675987511003229, 957257731078682, 921963755448778, 923441258232480]\n",
      "selection pass\n",
      "target_count:\n",
      "7\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "0\n",
      "675987511003229\n",
      "10011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "1\n",
      "957257731078682\n",
      "11011001101001111011101111000001001111101000011010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "2\n",
      "921963755448778\n",
      "11010001101000010101101010001000111010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "3\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "4\n",
      "675987570620954\n",
      "10011001101100111010011111000001001111101000011010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "5\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "6\n",
      "921963789482656\n",
      "11010001101000010101101100001010101111101010100000\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "7\n",
      "957257731074506\n",
      "11011001101001111011101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "8\n",
      "957257731078816\n",
      "11011001101001111011101111000001001111101010100000\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "9\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "10\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "crossover pass\n",
      "變異後的種群\n",
      "染色體：\n",
      "0\n",
      "675987511003229\n",
      "10011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "1\n",
      "957257731078682\n",
      "11011001101001111011101111000001001111101000011010\n",
      "變異後的種群\n",
      "染色體：\n",
      "2\n",
      "921963755448778\n",
      "11010001101000010101101010001000111010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "3\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "變異後的種群\n",
      "染色體：\n",
      "4\n",
      "675987570620954\n",
      "10011001101100111010011111000001001111101000011010\n",
      "變異後的種群\n",
      "染色體：\n",
      "5\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "變異後的種群\n",
      "染色體：\n",
      "6\n",
      "921963789482656\n",
      "11010001101000010101101100001010101111101010100000\n",
      "變異後的種群\n",
      "染色體：\n",
      "7\n",
      "957257731074506\n",
      "11011001101001111011101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "8\n",
      "957257731078816\n",
      "11011001101001111011101111000001001111101010100000\n",
      "變異後的種群\n",
      "染色體：\n",
      "9\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "10\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "mutation pass\n",
      "迭代次數： 2\n",
      "2\n",
      "所選擇的染色體：\n",
      "10011001101100111010011011011101110100100001011101\n",
      "22\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3360)\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_44 (LSTM)               (None, 100, 20)           270480    \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 273,882\n",
      "Trainable params: 273,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.2226 - accuracy: 0.7652 - val_loss: 0.2759 - val_accuracy: 0.6552\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2562 - accuracy: 0.6261 - val_loss: 0.3379 - val_accuracy: 0.5172\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2706 - accuracy: 0.6000 - val_loss: 0.3573 - val_accuracy: 0.5172\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2661 - accuracy: 0.6087 - val_loss: 0.2996 - val_accuracy: 0.4483\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2429 - accuracy: 0.6261 - val_loss: 0.3136 - val_accuracy: 0.5172\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2622 - accuracy: 0.6522 - val_loss: 0.3514 - val_accuracy: 0.5862\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2676 - accuracy: 0.5739 - val_loss: 0.2783 - val_accuracy: 0.5517\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2769 - accuracy: 0.5826 - val_loss: 0.2236 - val_accuracy: 0.6552\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2835 - accuracy: 0.5652 - val_loss: 0.3259 - val_accuracy: 0.5862\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2394 - accuracy: 0.6609 - val_loss: 0.3406 - val_accuracy: 0.5517\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2661 - accuracy: 0.6696 - val_loss: 0.2924 - val_accuracy: 0.5517\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2378 - accuracy: 0.7130 - val_loss: 0.2971 - val_accuracy: 0.5862\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2469 - accuracy: 0.6609 - val_loss: 0.2739 - val_accuracy: 0.6207\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2574 - accuracy: 0.6348 - val_loss: 0.3609 - val_accuracy: 0.4483\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.3133 - accuracy: 0.4609 - val_loss: 0.3620 - val_accuracy: 0.4828\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2820 - accuracy: 0.5478 - val_loss: 0.2855 - val_accuracy: 0.5517\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.3191 - accuracy: 0.4348 - val_loss: 0.3452 - val_accuracy: 0.5172\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2988 - accuracy: 0.4957 - val_loss: 0.3286 - val_accuracy: 0.6207\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2925 - accuracy: 0.5391 - val_loss: 0.3196 - val_accuracy: 0.4828\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3389 - accuracy: 0.4435 - val_loss: 0.2581 - val_accuracy: 0.5862\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2797 - accuracy: 0.5913 - val_loss: 0.3503 - val_accuracy: 0.5172\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2567 - accuracy: 0.6261 - val_loss: 0.3248 - val_accuracy: 0.4138\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2813 - accuracy: 0.5304 - val_loss: 0.2832 - val_accuracy: 0.4828\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2884 - accuracy: 0.5739 - val_loss: 0.3024 - val_accuracy: 0.4828\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2798 - accuracy: 0.5913 - val_loss: 0.3531 - val_accuracy: 0.4138\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2925 - accuracy: 0.5217 - val_loss: 0.4105 - val_accuracy: 0.3448\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2869 - accuracy: 0.5130 - val_loss: 0.3312 - val_accuracy: 0.2414\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3119 - accuracy: 0.4783 - val_loss: 0.3119 - val_accuracy: 0.3793\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3117 - accuracy: 0.4957 - val_loss: 0.3116 - val_accuracy: 0.3103\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3376 - accuracy: 0.5130 - val_loss: 0.3306 - val_accuracy: 0.2759\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3157 - accuracy: 0.4348 - val_loss: 0.3247 - val_accuracy: 0.3103\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2903 - accuracy: 0.5739 - val_loss: 0.3233 - val_accuracy: 0.3103\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2835 - accuracy: 0.5130 - val_loss: 0.2556 - val_accuracy: 0.5862\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2845 - accuracy: 0.6000 - val_loss: 0.2887 - val_accuracy: 0.3793\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2787 - accuracy: 0.5652 - val_loss: 0.3085 - val_accuracy: 0.3448\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2628 - accuracy: 0.6348 - val_loss: 0.2640 - val_accuracy: 0.4483\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2269 - accuracy: 0.7478 - val_loss: 0.2608 - val_accuracy: 0.5172\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2151 - accuracy: 0.7565 - val_loss: 0.2278 - val_accuracy: 0.6897\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2407 - accuracy: 0.7391 - val_loss: 0.2404 - val_accuracy: 0.5517\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2284 - accuracy: 0.7826 - val_loss: 0.2293 - val_accuracy: 0.5862\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2159 - accuracy: 0.7565 - val_loss: 0.2136 - val_accuracy: 0.6552\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2256 - accuracy: 0.6870 - val_loss: 0.2162 - val_accuracy: 0.6207\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2421 - accuracy: 0.7043 - val_loss: 0.2116 - val_accuracy: 0.6552\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2428 - accuracy: 0.6957 - val_loss: 0.2274 - val_accuracy: 0.5862\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2434 - accuracy: 0.6957 - val_loss: 0.2205 - val_accuracy: 0.6207\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2256 - accuracy: 0.7478 - val_loss: 0.2213 - val_accuracy: 0.5862\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2505 - accuracy: 0.6522 - val_loss: 0.2369 - val_accuracy: 0.5517\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2297 - accuracy: 0.7391 - val_loss: 0.2182 - val_accuracy: 0.6897\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2408 - accuracy: 0.7130 - val_loss: 0.2423 - val_accuracy: 0.6207\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2385 - accuracy: 0.7304 - val_loss: 0.2553 - val_accuracy: 0.4828\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2431 - accuracy: 0.6609 - val_loss: 0.2149 - val_accuracy: 0.6207\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2371 - accuracy: 0.7217 - val_loss: 0.2282 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2192 - accuracy: 0.7304 - val_loss: 0.1757 - val_accuracy: 0.7586\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2029 - accuracy: 0.7826 - val_loss: 0.1997 - val_accuracy: 0.6552\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2133 - accuracy: 0.7652 - val_loss: 0.1981 - val_accuracy: 0.6552\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2015 - accuracy: 0.7913 - val_loss: 0.2060 - val_accuracy: 0.6207\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2152 - accuracy: 0.7565 - val_loss: 0.2362 - val_accuracy: 0.5862\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2205 - accuracy: 0.7130 - val_loss: 0.2429 - val_accuracy: 0.5517\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2047 - accuracy: 0.8348 - val_loss: 0.2315 - val_accuracy: 0.6207\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2419 - accuracy: 0.6957 - val_loss: 0.2451 - val_accuracy: 0.6207\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2205 - accuracy: 0.7304 - val_loss: 0.2277 - val_accuracy: 0.6207\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2103 - accuracy: 0.7043 - val_loss: 0.2495 - val_accuracy: 0.5517\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2325 - accuracy: 0.7130 - val_loss: 0.2587 - val_accuracy: 0.5172\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2353 - accuracy: 0.6609 - val_loss: 0.2655 - val_accuracy: 0.5172\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2254 - accuracy: 0.7043 - val_loss: 0.2824 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2488 - accuracy: 0.6609 - val_loss: 0.2812 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2528 - accuracy: 0.6609 - val_loss: 0.2846 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2432 - accuracy: 0.6783 - val_loss: 0.2834 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2398 - accuracy: 0.6870 - val_loss: 0.2682 - val_accuracy: 0.4828\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2385 - accuracy: 0.6522 - val_loss: 0.2554 - val_accuracy: 0.5517\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2253 - accuracy: 0.7217 - val_loss: 0.2671 - val_accuracy: 0.5172\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2016 - accuracy: 0.7217 - val_loss: 0.2700 - val_accuracy: 0.4828\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2258 - accuracy: 0.6783 - val_loss: 0.2706 - val_accuracy: 0.4828\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2232 - accuracy: 0.6957 - val_loss: 0.2670 - val_accuracy: 0.4828\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2108 - accuracy: 0.7043 - val_loss: 0.2917 - val_accuracy: 0.4828\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1999 - accuracy: 0.7304 - val_loss: 0.2733 - val_accuracy: 0.5172\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1996 - accuracy: 0.7391 - val_loss: 0.2713 - val_accuracy: 0.5172\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2118 - accuracy: 0.7130 - val_loss: 0.2706 - val_accuracy: 0.5172\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2087 - accuracy: 0.6957 - val_loss: 0.2762 - val_accuracy: 0.5172\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2060 - accuracy: 0.6957 - val_loss: 0.2712 - val_accuracy: 0.5517\n",
      "0.7083333134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101001111011101111000001001111101000011010\n",
      "22\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3360)\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_46 (LSTM)               (None, 100, 20)           270480    \n",
      "_________________________________________________________________\n",
      "lstm_47 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 273,882\n",
      "Trainable params: 273,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.2901 - accuracy: 0.5565 - val_loss: 0.2843 - val_accuracy: 0.6207\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1249 - accuracy: 0.9043 - val_loss: 0.3045 - val_accuracy: 0.6207\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2169 - accuracy: 0.6522 - val_loss: 0.3397 - val_accuracy: 0.5862\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2246 - accuracy: 0.5217 - val_loss: 0.2698 - val_accuracy: 0.5172\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2320 - accuracy: 0.5739 - val_loss: 0.1887 - val_accuracy: 0.6207\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2076 - accuracy: 0.6609 - val_loss: 0.2842 - val_accuracy: 0.5172\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2012 - accuracy: 0.7130 - val_loss: 0.2158 - val_accuracy: 0.6552\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2472 - accuracy: 0.5739 - val_loss: 0.3130 - val_accuracy: 0.5172\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2654 - accuracy: 0.5652 - val_loss: 0.2425 - val_accuracy: 0.6897\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2854 - accuracy: 0.5043 - val_loss: 0.2213 - val_accuracy: 0.5517\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2763 - accuracy: 0.5217 - val_loss: 0.2396 - val_accuracy: 0.5862\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2765 - accuracy: 0.5652 - val_loss: 0.2204 - val_accuracy: 0.5862\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2380 - accuracy: 0.6522 - val_loss: 0.2995 - val_accuracy: 0.4828\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2561 - accuracy: 0.6348 - val_loss: 0.2409 - val_accuracy: 0.6207\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2368 - accuracy: 0.6522 - val_loss: 0.2408 - val_accuracy: 0.5172\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2519 - accuracy: 0.6261 - val_loss: 0.2476 - val_accuracy: 0.6207\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2626 - accuracy: 0.6261 - val_loss: 0.2510 - val_accuracy: 0.5862\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2553 - accuracy: 0.6087 - val_loss: 0.2799 - val_accuracy: 0.5517\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2596 - accuracy: 0.6000 - val_loss: 0.1741 - val_accuracy: 0.8966\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2880 - accuracy: 0.5217 - val_loss: 0.3052 - val_accuracy: 0.4828\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3089 - accuracy: 0.5478 - val_loss: 0.3006 - val_accuracy: 0.4138\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2901 - accuracy: 0.5478 - val_loss: 0.3358 - val_accuracy: 0.3793\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2649 - accuracy: 0.6261 - val_loss: 0.3070 - val_accuracy: 0.4483\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2611 - accuracy: 0.6174 - val_loss: 0.3452 - val_accuracy: 0.3448\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2814 - accuracy: 0.5478 - val_loss: 0.3120 - val_accuracy: 0.4138\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2701 - accuracy: 0.5565 - val_loss: 0.3108 - val_accuracy: 0.3793\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2759 - accuracy: 0.5739 - val_loss: 0.3252 - val_accuracy: 0.3793\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2869 - accuracy: 0.5565 - val_loss: 0.2862 - val_accuracy: 0.4138\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3022 - accuracy: 0.5304 - val_loss: 0.2649 - val_accuracy: 0.4828\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2979 - accuracy: 0.4957 - val_loss: 0.2760 - val_accuracy: 0.4483\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2887 - accuracy: 0.5391 - val_loss: 0.2734 - val_accuracy: 0.5172\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3052 - accuracy: 0.5478 - val_loss: 0.3283 - val_accuracy: 0.3103\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2828 - accuracy: 0.5391 - val_loss: 0.3100 - val_accuracy: 0.5172\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2604 - accuracy: 0.5652 - val_loss: 0.2599 - val_accuracy: 0.4828\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2673 - accuracy: 0.5565 - val_loss: 0.2750 - val_accuracy: 0.4138\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2697 - accuracy: 0.5739 - val_loss: 0.2768 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2672 - accuracy: 0.5739 - val_loss: 0.2809 - val_accuracy: 0.4483\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2650 - accuracy: 0.5652 - val_loss: 0.2577 - val_accuracy: 0.5172\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2531 - accuracy: 0.6087 - val_loss: 0.2655 - val_accuracy: 0.5517\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2654 - accuracy: 0.6087 - val_loss: 0.2430 - val_accuracy: 0.6207\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2638 - accuracy: 0.6435 - val_loss: 0.2326 - val_accuracy: 0.5862\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2713 - accuracy: 0.5565 - val_loss: 0.2555 - val_accuracy: 0.5172\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2522 - accuracy: 0.6174 - val_loss: 0.2820 - val_accuracy: 0.5862\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2380 - accuracy: 0.6348 - val_loss: 0.2705 - val_accuracy: 0.5172\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2709 - accuracy: 0.5130 - val_loss: 0.2661 - val_accuracy: 0.5172\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2720 - accuracy: 0.5391 - val_loss: 0.2073 - val_accuracy: 0.5862\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2657 - accuracy: 0.5739 - val_loss: 0.2139 - val_accuracy: 0.6552\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2485 - accuracy: 0.6087 - val_loss: 0.2314 - val_accuracy: 0.5862\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2592 - accuracy: 0.6174 - val_loss: 0.2317 - val_accuracy: 0.5862\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2304 - accuracy: 0.6609 - val_loss: 0.2330 - val_accuracy: 0.5517\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2332 - accuracy: 0.6174 - val_loss: 0.2496 - val_accuracy: 0.5862\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2238 - accuracy: 0.6870 - val_loss: 0.2353 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2768 - accuracy: 0.5565 - val_loss: 0.2656 - val_accuracy: 0.4828\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2565 - accuracy: 0.5913 - val_loss: 0.2472 - val_accuracy: 0.5172\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2631 - accuracy: 0.5826 - val_loss: 0.2505 - val_accuracy: 0.5517\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2632 - accuracy: 0.5391 - val_loss: 0.2535 - val_accuracy: 0.5172\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2423 - accuracy: 0.6261 - val_loss: 0.2577 - val_accuracy: 0.5172\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2435 - accuracy: 0.6261 - val_loss: 0.2380 - val_accuracy: 0.5172\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2694 - accuracy: 0.6087 - val_loss: 0.2560 - val_accuracy: 0.4828\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2597 - accuracy: 0.5913 - val_loss: 0.2285 - val_accuracy: 0.5862\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2629 - accuracy: 0.6087 - val_loss: 0.2579 - val_accuracy: 0.4828\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2481 - accuracy: 0.6087 - val_loss: 0.2495 - val_accuracy: 0.4828\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2528 - accuracy: 0.5652 - val_loss: 0.2527 - val_accuracy: 0.4828\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2624 - accuracy: 0.5826 - val_loss: 0.2477 - val_accuracy: 0.5172\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2537 - accuracy: 0.5826 - val_loss: 0.2714 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2505 - accuracy: 0.6087 - val_loss: 0.2753 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2544 - accuracy: 0.6087 - val_loss: 0.2788 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2624 - accuracy: 0.5478 - val_loss: 0.2754 - val_accuracy: 0.4483\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2582 - accuracy: 0.5565 - val_loss: 0.2673 - val_accuracy: 0.4483\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2662 - accuracy: 0.5565 - val_loss: 0.2718 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2534 - accuracy: 0.5739 - val_loss: 0.2575 - val_accuracy: 0.4828\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2655 - accuracy: 0.5391 - val_loss: 0.2754 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2675 - accuracy: 0.5652 - val_loss: 0.2505 - val_accuracy: 0.4828\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2607 - accuracy: 0.5565 - val_loss: 0.2644 - val_accuracy: 0.4483\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2662 - accuracy: 0.5739 - val_loss: 0.2521 - val_accuracy: 0.4828\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2521 - accuracy: 0.5913 - val_loss: 0.2736 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2557 - accuracy: 0.5739 - val_loss: 0.2755 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2534 - accuracy: 0.5565 - val_loss: 0.2700 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2467 - accuracy: 0.6000 - val_loss: 0.2679 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2462 - accuracy: 0.5739 - val_loss: 0.2573 - val_accuracy: 0.4483\n",
      "0.6354166865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001101000010101101010001000111010100111001010\n",
      "27\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2760)\n",
      "(144, 100, 2760)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_48 (LSTM)               (None, 100, 20)           222480    \n",
      "_________________________________________________________________\n",
      "lstm_49 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 225,882\n",
      "Trainable params: 225,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.2564 - accuracy: 0.7043 - val_loss: 0.3114 - val_accuracy: 0.5862\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2666 - accuracy: 0.5913 - val_loss: 0.3416 - val_accuracy: 0.5172\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2621 - accuracy: 0.5565 - val_loss: 0.3250 - val_accuracy: 0.6552\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2621 - accuracy: 0.5217 - val_loss: 0.3842 - val_accuracy: 0.3448\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2936 - accuracy: 0.4783 - val_loss: 0.3791 - val_accuracy: 0.2069\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2794 - accuracy: 0.5043 - val_loss: 0.3697 - val_accuracy: 0.3793\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2786 - accuracy: 0.4957 - val_loss: 0.3160 - val_accuracy: 0.4483\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2765 - accuracy: 0.5217 - val_loss: 0.2947 - val_accuracy: 0.3793\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2665 - accuracy: 0.5304 - val_loss: 0.3474 - val_accuracy: 0.3793\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2765 - accuracy: 0.5391 - val_loss: 0.3550 - val_accuracy: 0.3448\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2785 - accuracy: 0.4696 - val_loss: 0.3222 - val_accuracy: 0.4138\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2702 - accuracy: 0.5478 - val_loss: 0.3266 - val_accuracy: 0.3448\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2506 - accuracy: 0.6000 - val_loss: 0.3243 - val_accuracy: 0.3448\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2520 - accuracy: 0.5478 - val_loss: 0.3032 - val_accuracy: 0.4828\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2504 - accuracy: 0.6000 - val_loss: 0.3051 - val_accuracy: 0.4828\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2544 - accuracy: 0.5913 - val_loss: 0.2964 - val_accuracy: 0.4483\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2796 - accuracy: 0.4870 - val_loss: 0.4254 - val_accuracy: 0.3448\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.3019 - accuracy: 0.4261 - val_loss: 0.4633 - val_accuracy: 0.2759\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.3104 - accuracy: 0.4261 - val_loss: 0.3668 - val_accuracy: 0.3793\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2658 - accuracy: 0.5739 - val_loss: 0.2966 - val_accuracy: 0.4828\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2539 - accuracy: 0.6261 - val_loss: 0.3331 - val_accuracy: 0.4138\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2604 - accuracy: 0.6087 - val_loss: 0.3762 - val_accuracy: 0.3448\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2499 - accuracy: 0.6261 - val_loss: 0.3806 - val_accuracy: 0.3448\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2400 - accuracy: 0.6522 - val_loss: 0.3710 - val_accuracy: 0.3448\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2400 - accuracy: 0.6522 - val_loss: 0.3653 - val_accuracy: 0.3448\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2371 - accuracy: 0.6522 - val_loss: 0.3648 - val_accuracy: 0.3448\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2376 - accuracy: 0.6522 - val_loss: 0.3655 - val_accuracy: 0.3448\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2381 - accuracy: 0.6522 - val_loss: 0.3636 - val_accuracy: 0.3448\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2368 - accuracy: 0.6696 - val_loss: 0.3607 - val_accuracy: 0.3448\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2349 - accuracy: 0.6522 - val_loss: 0.3527 - val_accuracy: 0.3793\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2317 - accuracy: 0.6696 - val_loss: 0.3383 - val_accuracy: 0.3793\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2299 - accuracy: 0.6696 - val_loss: 0.3380 - val_accuracy: 0.3793\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2312 - accuracy: 0.6435 - val_loss: 0.3946 - val_accuracy: 0.2759\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2622 - accuracy: 0.5217 - val_loss: 0.2723 - val_accuracy: 0.4483\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2278 - accuracy: 0.6348 - val_loss: 0.2673 - val_accuracy: 0.4483\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2415 - accuracy: 0.6087 - val_loss: 0.2916 - val_accuracy: 0.3448\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2267 - accuracy: 0.6435 - val_loss: 0.2796 - val_accuracy: 0.3793\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2239 - accuracy: 0.6435 - val_loss: 0.2809 - val_accuracy: 0.3793\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2174 - accuracy: 0.6348 - val_loss: 0.2922 - val_accuracy: 0.3103\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.2256 - accuracy: 0.6174 - val_loss: 0.2905 - val_accuracy: 0.3793\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2265 - accuracy: 0.6348 - val_loss: 0.2896 - val_accuracy: 0.3793\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2223 - accuracy: 0.6609 - val_loss: 0.3088 - val_accuracy: 0.3448\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2159 - accuracy: 0.6522 - val_loss: 0.2853 - val_accuracy: 0.4828\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2194 - accuracy: 0.6609 - val_loss: 0.2871 - val_accuracy: 0.4483\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2236 - accuracy: 0.6261 - val_loss: 0.2842 - val_accuracy: 0.4483\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2182 - accuracy: 0.6783 - val_loss: 0.2702 - val_accuracy: 0.4483\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2155 - accuracy: 0.6870 - val_loss: 0.2763 - val_accuracy: 0.4483\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.2091 - accuracy: 0.6522 - val_loss: 0.2754 - val_accuracy: 0.4483\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2079 - accuracy: 0.6957 - val_loss: 0.3312 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2309 - accuracy: 0.6435 - val_loss: 0.2682 - val_accuracy: 0.4828\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2374 - accuracy: 0.5913 - val_loss: 0.3180 - val_accuracy: 0.3448\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2321 - accuracy: 0.6261 - val_loss: 0.3406 - val_accuracy: 0.2414\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2264 - accuracy: 0.6435 - val_loss: 0.3330 - val_accuracy: 0.2759\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2296 - accuracy: 0.6087 - val_loss: 0.3187 - val_accuracy: 0.3103\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2319 - accuracy: 0.5826 - val_loss: 0.3266 - val_accuracy: 0.3103\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2347 - accuracy: 0.6087 - val_loss: 0.3247 - val_accuracy: 0.2759\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2285 - accuracy: 0.6087 - val_loss: 0.3238 - val_accuracy: 0.2759\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2343 - accuracy: 0.6087 - val_loss: 0.3288 - val_accuracy: 0.2414\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2324 - accuracy: 0.6000 - val_loss: 0.3299 - val_accuracy: 0.2414\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2267 - accuracy: 0.6174 - val_loss: 0.3211 - val_accuracy: 0.2759\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2329 - accuracy: 0.6000 - val_loss: 0.3131 - val_accuracy: 0.2759\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2149 - accuracy: 0.6783 - val_loss: 0.2919 - val_accuracy: 0.3103\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2116 - accuracy: 0.6696 - val_loss: 0.2919 - val_accuracy: 0.3448\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2150 - accuracy: 0.6783 - val_loss: 0.2930 - val_accuracy: 0.3448\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2168 - accuracy: 0.6696 - val_loss: 0.3119 - val_accuracy: 0.3793\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2141 - accuracy: 0.6870 - val_loss: 0.3172 - val_accuracy: 0.3793\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2085 - accuracy: 0.6957 - val_loss: 0.3182 - val_accuracy: 0.3448\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2113 - accuracy: 0.6609 - val_loss: 0.2787 - val_accuracy: 0.4483\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2099 - accuracy: 0.7043 - val_loss: 0.2749 - val_accuracy: 0.4483\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2126 - accuracy: 0.6957 - val_loss: 0.2754 - val_accuracy: 0.4483\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2145 - accuracy: 0.7043 - val_loss: 0.2722 - val_accuracy: 0.4483\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2099 - accuracy: 0.6870 - val_loss: 0.2729 - val_accuracy: 0.4483\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2128 - accuracy: 0.6609 - val_loss: 0.2735 - val_accuracy: 0.4483\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2122 - accuracy: 0.7043 - val_loss: 0.2705 - val_accuracy: 0.4828\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2138 - accuracy: 0.6696 - val_loss: 0.2689 - val_accuracy: 0.4483\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2112 - accuracy: 0.6957 - val_loss: 0.2879 - val_accuracy: 0.3793\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2124 - accuracy: 0.6696 - val_loss: 0.2888 - val_accuracy: 0.3793\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2095 - accuracy: 0.6696 - val_loss: 0.2731 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2104 - accuracy: 0.6783 - val_loss: 0.2682 - val_accuracy: 0.4483\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2098 - accuracy: 0.6696 - val_loss: 0.2691 - val_accuracy: 0.4483\n",
      "0.6354166865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111101010100000\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3240)\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_50 (LSTM)               (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_51 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.2461 - accuracy: 0.6348 - val_loss: 0.1795 - val_accuracy: 0.8966\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1994 - accuracy: 0.8783 - val_loss: 0.2505 - val_accuracy: 0.7241\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1889 - accuracy: 0.8783 - val_loss: 0.2916 - val_accuracy: 0.7241\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1765 - accuracy: 0.8261 - val_loss: 0.2457 - val_accuracy: 0.7586\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2024 - accuracy: 0.7652 - val_loss: 0.2260 - val_accuracy: 0.8276\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1849 - accuracy: 0.8174 - val_loss: 0.2052 - val_accuracy: 0.8276\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1579 - accuracy: 0.8609 - val_loss: 0.1814 - val_accuracy: 0.8276\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1681 - accuracy: 0.8435 - val_loss: 0.1889 - val_accuracy: 0.8966\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1445 - accuracy: 0.8957 - val_loss: 0.1602 - val_accuracy: 0.9310\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1223 - accuracy: 0.9304 - val_loss: 0.1512 - val_accuracy: 0.8966\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1137 - accuracy: 0.9304 - val_loss: 0.1494 - val_accuracy: 0.8966\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1088 - accuracy: 0.9391 - val_loss: 0.1682 - val_accuracy: 0.8966\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1099 - accuracy: 0.9217 - val_loss: 0.1393 - val_accuracy: 0.8621\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0916 - accuracy: 0.9826 - val_loss: 0.1270 - val_accuracy: 0.8621\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0871 - accuracy: 0.9739 - val_loss: 0.1256 - val_accuracy: 0.8621\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0849 - accuracy: 0.9913 - val_loss: 0.1318 - val_accuracy: 0.8276\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0754 - accuracy: 0.9826 - val_loss: 0.1511 - val_accuracy: 0.8621\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0968 - accuracy: 0.9652 - val_loss: 0.1272 - val_accuracy: 0.8621\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0859 - accuracy: 0.9826 - val_loss: 0.1131 - val_accuracy: 0.8621\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0805 - accuracy: 0.9739 - val_loss: 0.0995 - val_accuracy: 0.8966\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0659 - accuracy: 0.9913 - val_loss: 0.0973 - val_accuracy: 0.8966\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0707 - accuracy: 0.9826 - val_loss: 0.0875 - val_accuracy: 0.8966\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.8966\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.8966\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9310\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9310\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 0.9310\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9310\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0359 - accuracy: 0.9913 - val_loss: 0.0688 - val_accuracy: 0.9310\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9310\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9310\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9310\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.0671 - val_accuracy: 0.9310\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 0.9310\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9310\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.0601 - val_accuracy: 0.9310\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9655\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 0.9655\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 0.9655\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9655\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9655\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0447 - accuracy: 0.9913 - val_loss: 0.1111 - val_accuracy: 0.9310\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9310\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9655\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9655\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9655\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 0.9655\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 0.0655 - val_accuracy: 0.9655\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0564 - val_accuracy: 0.9655\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9655\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9655\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9655\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9655\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9655\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9655\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9655\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9655\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9655\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9655\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9655\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9655\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9655\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9655\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9655\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9655\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9655\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9655\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9655\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 0.9655\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9655\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9655\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9655\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9655\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9655\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9655\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9655\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9655\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9655\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9655\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 0.9655\n",
      "1.0\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "10011001101100111010011111000001001111101000011010\n",
      "24\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3120)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3120)\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_52 (LSTM)               (None, 100, 20)           251280    \n",
      "_________________________________________________________________\n",
      "lstm_53 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 254,682\n",
      "Trainable params: 254,642\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.3048 - accuracy: 0.4609 - val_loss: 0.5472 - val_accuracy: 0.4138\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2603 - accuracy: 0.5565 - val_loss: 0.3674 - val_accuracy: 0.4828\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2407 - accuracy: 0.7130 - val_loss: 0.3129 - val_accuracy: 0.6207\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2606 - accuracy: 0.6348 - val_loss: 0.3530 - val_accuracy: 0.6897\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2692 - accuracy: 0.5826 - val_loss: 0.4479 - val_accuracy: 0.3448\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2259 - accuracy: 0.6957 - val_loss: 0.3011 - val_accuracy: 0.5517\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2524 - accuracy: 0.5913 - val_loss: 0.2707 - val_accuracy: 0.6552\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2862 - accuracy: 0.4870 - val_loss: 0.3234 - val_accuracy: 0.6207\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2772 - accuracy: 0.6087 - val_loss: 0.3316 - val_accuracy: 0.5862\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2723 - accuracy: 0.5913 - val_loss: 0.3140 - val_accuracy: 0.5862\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2714 - accuracy: 0.6087 - val_loss: 0.3379 - val_accuracy: 0.5517\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2700 - accuracy: 0.6000 - val_loss: 0.3326 - val_accuracy: 0.5517\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2829 - accuracy: 0.5913 - val_loss: 0.3149 - val_accuracy: 0.5172\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2827 - accuracy: 0.4696 - val_loss: 0.3859 - val_accuracy: 0.4138\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2909 - accuracy: 0.5826 - val_loss: 0.2933 - val_accuracy: 0.5172\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2914 - accuracy: 0.4348 - val_loss: 0.2921 - val_accuracy: 0.5172\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2440 - accuracy: 0.6348 - val_loss: 0.3174 - val_accuracy: 0.5517\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2563 - accuracy: 0.5826 - val_loss: 0.3326 - val_accuracy: 0.5862\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2638 - accuracy: 0.5652 - val_loss: 0.2639 - val_accuracy: 0.5172\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2659 - accuracy: 0.5565 - val_loss: 0.2465 - val_accuracy: 0.6897\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2426 - accuracy: 0.6609 - val_loss: 0.2692 - val_accuracy: 0.5862\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2378 - accuracy: 0.6435 - val_loss: 0.2810 - val_accuracy: 0.5517\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2426 - accuracy: 0.6783 - val_loss: 0.2497 - val_accuracy: 0.6207\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2482 - accuracy: 0.6261 - val_loss: 0.2734 - val_accuracy: 0.5517\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2412 - accuracy: 0.6522 - val_loss: 0.2196 - val_accuracy: 0.6897\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2403 - accuracy: 0.6348 - val_loss: 0.2469 - val_accuracy: 0.6207\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2442 - accuracy: 0.6522 - val_loss: 0.2467 - val_accuracy: 0.5862\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2291 - accuracy: 0.6870 - val_loss: 0.2530 - val_accuracy: 0.5517\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2202 - accuracy: 0.7043 - val_loss: 0.2611 - val_accuracy: 0.5172\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2262 - accuracy: 0.7130 - val_loss: 0.2628 - val_accuracy: 0.5517\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2170 - accuracy: 0.7652 - val_loss: 0.2600 - val_accuracy: 0.5517\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2214 - accuracy: 0.7304 - val_loss: 0.2433 - val_accuracy: 0.6207\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2194 - accuracy: 0.7304 - val_loss: 0.2346 - val_accuracy: 0.6552\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2104 - accuracy: 0.8000 - val_loss: 0.2298 - val_accuracy: 0.6897\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2088 - accuracy: 0.7913 - val_loss: 0.2315 - val_accuracy: 0.6897\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2101 - accuracy: 0.7739 - val_loss: 0.2335 - val_accuracy: 0.6897\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2056 - accuracy: 0.7739 - val_loss: 0.2352 - val_accuracy: 0.6552\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2014 - accuracy: 0.8174 - val_loss: 0.2384 - val_accuracy: 0.6207\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2094 - accuracy: 0.7652 - val_loss: 0.2268 - val_accuracy: 0.6552\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1962 - accuracy: 0.8000 - val_loss: 0.2361 - val_accuracy: 0.5862\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1906 - accuracy: 0.8087 - val_loss: 0.2075 - val_accuracy: 0.6897\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1908 - accuracy: 0.8261 - val_loss: 0.2082 - val_accuracy: 0.6897\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1876 - accuracy: 0.8174 - val_loss: 0.2146 - val_accuracy: 0.6207\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1724 - accuracy: 0.9043 - val_loss: 0.2382 - val_accuracy: 0.5517\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1960 - accuracy: 0.7826 - val_loss: 0.2377 - val_accuracy: 0.6207\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.1874 - accuracy: 0.7913 - val_loss: 0.2191 - val_accuracy: 0.5517\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1896 - accuracy: 0.7913 - val_loss: 0.2045 - val_accuracy: 0.6552\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1924 - accuracy: 0.7652 - val_loss: 0.2280 - val_accuracy: 0.5862\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1883 - accuracy: 0.7391 - val_loss: 0.2139 - val_accuracy: 0.6207\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1878 - accuracy: 0.8000 - val_loss: 0.1956 - val_accuracy: 0.6897\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1932 - accuracy: 0.7217 - val_loss: 0.2133 - val_accuracy: 0.6552\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1831 - accuracy: 0.7913 - val_loss: 0.1964 - val_accuracy: 0.6897\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1866 - accuracy: 0.8000 - val_loss: 0.1944 - val_accuracy: 0.6897\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1912 - accuracy: 0.7391 - val_loss: 0.1855 - val_accuracy: 0.7586\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1807 - accuracy: 0.8261 - val_loss: 0.1901 - val_accuracy: 0.7586\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1796 - accuracy: 0.7739 - val_loss: 0.1977 - val_accuracy: 0.6897\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1810 - accuracy: 0.7913 - val_loss: 0.1983 - val_accuracy: 0.6897\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1764 - accuracy: 0.7913 - val_loss: 0.1896 - val_accuracy: 0.7241\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1810 - accuracy: 0.7826 - val_loss: 0.1864 - val_accuracy: 0.7586\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1756 - accuracy: 0.7826 - val_loss: 0.1924 - val_accuracy: 0.6897\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1731 - accuracy: 0.8000 - val_loss: 0.1902 - val_accuracy: 0.6897\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1866 - accuracy: 0.7304 - val_loss: 0.1957 - val_accuracy: 0.6897\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1880 - accuracy: 0.7304 - val_loss: 0.2462 - val_accuracy: 0.5862\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2117 - accuracy: 0.6174 - val_loss: 0.2360 - val_accuracy: 0.5172\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2141 - accuracy: 0.6348 - val_loss: 0.2435 - val_accuracy: 0.5172\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2143 - accuracy: 0.6696 - val_loss: 0.2504 - val_accuracy: 0.6552\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2108 - accuracy: 0.6783 - val_loss: 0.2231 - val_accuracy: 0.6207\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2165 - accuracy: 0.6348 - val_loss: 0.2466 - val_accuracy: 0.6897\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2214 - accuracy: 0.6348 - val_loss: 0.2529 - val_accuracy: 0.7241\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2228 - accuracy: 0.6261 - val_loss: 0.2296 - val_accuracy: 0.7241\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2209 - accuracy: 0.6348 - val_loss: 0.2597 - val_accuracy: 0.7241\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2326 - accuracy: 0.6261 - val_loss: 0.2486 - val_accuracy: 0.6207\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2320 - accuracy: 0.6087 - val_loss: 0.2410 - val_accuracy: 0.6897\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2282 - accuracy: 0.6261 - val_loss: 0.2592 - val_accuracy: 0.5862\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2280 - accuracy: 0.6435 - val_loss: 0.2723 - val_accuracy: 0.6552\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2327 - accuracy: 0.6174 - val_loss: 0.2926 - val_accuracy: 0.5862\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2262 - accuracy: 0.6087 - val_loss: 0.2738 - val_accuracy: 0.5517\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2414 - accuracy: 0.5826 - val_loss: 0.2616 - val_accuracy: 0.5862\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2165 - accuracy: 0.6522 - val_loss: 0.2736 - val_accuracy: 0.5517\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2175 - accuracy: 0.6435 - val_loss: 0.2548 - val_accuracy: 0.5172\n",
      "0.5833333134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111101010100000\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n",
      "(144, 100, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_54 (LSTM)               (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_55 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.2369 - accuracy: 0.6522 - val_loss: 0.1466 - val_accuracy: 0.6207\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1617 - accuracy: 0.8696 - val_loss: 0.1097 - val_accuracy: 0.7931\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1581 - accuracy: 0.8957 - val_loss: 0.3910 - val_accuracy: 0.3448\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.3045 - accuracy: 0.3478 - val_loss: 0.4742 - val_accuracy: 0.3448\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2726 - accuracy: 0.4000 - val_loss: 0.3219 - val_accuracy: 0.5172\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2878 - accuracy: 0.3652 - val_loss: 0.3171 - val_accuracy: 0.5172\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2756 - accuracy: 0.4174 - val_loss: 0.2721 - val_accuracy: 0.6207\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2670 - accuracy: 0.5739 - val_loss: 0.2518 - val_accuracy: 0.6207\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2600 - accuracy: 0.5826 - val_loss: 0.2901 - val_accuracy: 0.6207\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2574 - accuracy: 0.6261 - val_loss: 0.2583 - val_accuracy: 0.6897\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2440 - accuracy: 0.6261 - val_loss: 0.2858 - val_accuracy: 0.6207\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2319 - accuracy: 0.6957 - val_loss: 0.2721 - val_accuracy: 0.5862\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2127 - accuracy: 0.8000 - val_loss: 0.2582 - val_accuracy: 0.5862\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1803 - accuracy: 0.8261 - val_loss: 0.1955 - val_accuracy: 0.7241\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1445 - accuracy: 0.9043 - val_loss: 0.1140 - val_accuracy: 0.8966\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1239 - accuracy: 0.9565 - val_loss: 0.1247 - val_accuracy: 0.8966\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1155 - accuracy: 0.9652 - val_loss: 0.1207 - val_accuracy: 0.8966\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1249 - accuracy: 0.9217 - val_loss: 0.1248 - val_accuracy: 0.8966\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1265 - accuracy: 0.9391 - val_loss: 0.1279 - val_accuracy: 0.8966\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1064 - accuracy: 0.9739 - val_loss: 0.1267 - val_accuracy: 0.9310\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1095 - accuracy: 0.9652 - val_loss: 0.1272 - val_accuracy: 0.9310\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0987 - accuracy: 0.9739 - val_loss: 0.1251 - val_accuracy: 0.9310\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1034 - accuracy: 0.9739 - val_loss: 0.1175 - val_accuracy: 0.9310\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1115 - accuracy: 0.9391 - val_loss: 0.1173 - val_accuracy: 0.9310\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1466 - accuracy: 0.8957 - val_loss: 0.1520 - val_accuracy: 0.8276\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1527 - accuracy: 0.8783 - val_loss: 0.1281 - val_accuracy: 0.8621\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1218 - accuracy: 0.9217 - val_loss: 0.0978 - val_accuracy: 0.8966\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1212 - accuracy: 0.8783 - val_loss: 0.1696 - val_accuracy: 0.7241\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1624 - accuracy: 0.7652 - val_loss: 0.1926 - val_accuracy: 0.6207\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1932 - accuracy: 0.7391 - val_loss: 0.2212 - val_accuracy: 0.6207\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1957 - accuracy: 0.7565 - val_loss: 0.2491 - val_accuracy: 0.5862\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2114 - accuracy: 0.7217 - val_loss: 0.2663 - val_accuracy: 0.5172\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2108 - accuracy: 0.7043 - val_loss: 0.3175 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2196 - accuracy: 0.7043 - val_loss: 0.3253 - val_accuracy: 0.5172\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2075 - accuracy: 0.6870 - val_loss: 0.3177 - val_accuracy: 0.4828\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2206 - accuracy: 0.6696 - val_loss: 0.2735 - val_accuracy: 0.5172\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2102 - accuracy: 0.6870 - val_loss: 0.2894 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1961 - accuracy: 0.7043 - val_loss: 0.3709 - val_accuracy: 0.4828\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2186 - accuracy: 0.7043 - val_loss: 0.4226 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2228 - accuracy: 0.7130 - val_loss: 0.2622 - val_accuracy: 0.5517\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2042 - accuracy: 0.7304 - val_loss: 0.3454 - val_accuracy: 0.4483\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2347 - accuracy: 0.6174 - val_loss: 0.3441 - val_accuracy: 0.4483\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2719 - accuracy: 0.5478 - val_loss: 0.3813 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2532 - accuracy: 0.5913 - val_loss: 0.3205 - val_accuracy: 0.3793\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2632 - accuracy: 0.5478 - val_loss: 0.3008 - val_accuracy: 0.3793\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2851 - accuracy: 0.5130 - val_loss: 0.3025 - val_accuracy: 0.3448\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2967 - accuracy: 0.5565 - val_loss: 0.2678 - val_accuracy: 0.4483\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2769 - accuracy: 0.5826 - val_loss: 0.3014 - val_accuracy: 0.4828\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2618 - accuracy: 0.5913 - val_loss: 0.2992 - val_accuracy: 0.3793\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2560 - accuracy: 0.5652 - val_loss: 0.2874 - val_accuracy: 0.5517\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2594 - accuracy: 0.5478 - val_loss: 0.2825 - val_accuracy: 0.4828\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2623 - accuracy: 0.5478 - val_loss: 0.2594 - val_accuracy: 0.5862\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2574 - accuracy: 0.6000 - val_loss: 0.2664 - val_accuracy: 0.4828\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2520 - accuracy: 0.5652 - val_loss: 0.2598 - val_accuracy: 0.6207\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2573 - accuracy: 0.5478 - val_loss: 0.2162 - val_accuracy: 0.6897\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2542 - accuracy: 0.5565 - val_loss: 0.2788 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2525 - accuracy: 0.5913 - val_loss: 0.2552 - val_accuracy: 0.5172\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2545 - accuracy: 0.6174 - val_loss: 0.3046 - val_accuracy: 0.4483\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2746 - accuracy: 0.5739 - val_loss: 0.3065 - val_accuracy: 0.4828\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2758 - accuracy: 0.5739 - val_loss: 0.2798 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2395 - accuracy: 0.5913 - val_loss: 0.2586 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2596 - accuracy: 0.5739 - val_loss: 0.3028 - val_accuracy: 0.4828\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2471 - accuracy: 0.6609 - val_loss: 0.3315 - val_accuracy: 0.4483\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2286 - accuracy: 0.6522 - val_loss: 0.2646 - val_accuracy: 0.5172\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2190 - accuracy: 0.6783 - val_loss: 0.2547 - val_accuracy: 0.4483\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2136 - accuracy: 0.6783 - val_loss: 0.2562 - val_accuracy: 0.4483\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2137 - accuracy: 0.6348 - val_loss: 0.3001 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2255 - accuracy: 0.6696 - val_loss: 0.2732 - val_accuracy: 0.5517\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2206 - accuracy: 0.7304 - val_loss: 0.2220 - val_accuracy: 0.6897\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1932 - accuracy: 0.8087 - val_loss: 0.2316 - val_accuracy: 0.7241\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1895 - accuracy: 0.7652 - val_loss: 0.2014 - val_accuracy: 0.7586\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1930 - accuracy: 0.7565 - val_loss: 0.2054 - val_accuracy: 0.7931\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1908 - accuracy: 0.7565 - val_loss: 0.2798 - val_accuracy: 0.6207\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2151 - accuracy: 0.7391 - val_loss: 0.3207 - val_accuracy: 0.4483\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2292 - accuracy: 0.6609 - val_loss: 0.2305 - val_accuracy: 0.7241\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1793 - accuracy: 0.8174 - val_loss: 0.2272 - val_accuracy: 0.7931\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1868 - accuracy: 0.8348 - val_loss: 0.2339 - val_accuracy: 0.7931\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2256 - accuracy: 0.6522 - val_loss: 0.2666 - val_accuracy: 0.7586\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2289 - accuracy: 0.7565 - val_loss: 0.2170 - val_accuracy: 0.8276\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2184 - accuracy: 0.7391 - val_loss: 0.2120 - val_accuracy: 0.8621\n",
      "0.8541666865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001101000010101101100001010101111101010100000\n",
      "27\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2760)\n",
      "(144, 100, 2760)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_56 (LSTM)               (None, 100, 20)           222480    \n",
      "_________________________________________________________________\n",
      "lstm_57 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 225,882\n",
      "Trainable params: 225,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.1835 - accuracy: 0.8000 - val_loss: 0.2716 - val_accuracy: 0.6207\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2082 - accuracy: 0.7565 - val_loss: 0.2235 - val_accuracy: 0.6552\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2035 - accuracy: 0.7478 - val_loss: 0.2780 - val_accuracy: 0.5862\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1997 - accuracy: 0.8000 - val_loss: 0.2075 - val_accuracy: 0.6552\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2430 - accuracy: 0.7217 - val_loss: 0.2064 - val_accuracy: 0.6552\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2119 - accuracy: 0.8000 - val_loss: 0.2395 - val_accuracy: 0.4828\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2106 - accuracy: 0.7913 - val_loss: 0.1827 - val_accuracy: 0.5862\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2470 - accuracy: 0.5739 - val_loss: 0.2446 - val_accuracy: 0.5517\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2371 - accuracy: 0.6348 - val_loss: 0.3309 - val_accuracy: 0.4483\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2578 - accuracy: 0.6435 - val_loss: 0.3577 - val_accuracy: 0.4138\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2906 - accuracy: 0.5652 - val_loss: 0.2894 - val_accuracy: 0.4138\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2840 - accuracy: 0.5652 - val_loss: 0.3050 - val_accuracy: 0.5172\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2688 - accuracy: 0.5826 - val_loss: 0.2764 - val_accuracy: 0.4828\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2806 - accuracy: 0.5565 - val_loss: 0.2599 - val_accuracy: 0.5862\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.3038 - accuracy: 0.5043 - val_loss: 0.2614 - val_accuracy: 0.5862\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2757 - accuracy: 0.5130 - val_loss: 0.2618 - val_accuracy: 0.7241\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2703 - accuracy: 0.5565 - val_loss: 0.2523 - val_accuracy: 0.6207\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2874 - accuracy: 0.6087 - val_loss: 0.3147 - val_accuracy: 0.4483\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2774 - accuracy: 0.5478 - val_loss: 0.3097 - val_accuracy: 0.5517\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2896 - accuracy: 0.4957 - val_loss: 0.2871 - val_accuracy: 0.5517\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2609 - accuracy: 0.5826 - val_loss: 0.3034 - val_accuracy: 0.4828\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2805 - accuracy: 0.5826 - val_loss: 0.3169 - val_accuracy: 0.4138\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2720 - accuracy: 0.5652 - val_loss: 0.3054 - val_accuracy: 0.4138\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2684 - accuracy: 0.5652 - val_loss: 0.2863 - val_accuracy: 0.4828\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2694 - accuracy: 0.6087 - val_loss: 0.2881 - val_accuracy: 0.4483\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2629 - accuracy: 0.6435 - val_loss: 0.2938 - val_accuracy: 0.4483\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2593 - accuracy: 0.6783 - val_loss: 0.2978 - val_accuracy: 0.4138\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2713 - accuracy: 0.6348 - val_loss: 0.2987 - val_accuracy: 0.4483\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2792 - accuracy: 0.5913 - val_loss: 0.2919 - val_accuracy: 0.4828\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2725 - accuracy: 0.6261 - val_loss: 0.2943 - val_accuracy: 0.4828\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2742 - accuracy: 0.6174 - val_loss: 0.2956 - val_accuracy: 0.4483\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2637 - accuracy: 0.6348 - val_loss: 0.2966 - val_accuracy: 0.4138\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2651 - accuracy: 0.6261 - val_loss: 0.2970 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2722 - accuracy: 0.6261 - val_loss: 0.2970 - val_accuracy: 0.4138\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2598 - accuracy: 0.6609 - val_loss: 0.2965 - val_accuracy: 0.4138\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2527 - accuracy: 0.6261 - val_loss: 0.2965 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2558 - accuracy: 0.6957 - val_loss: 0.2970 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2503 - accuracy: 0.6783 - val_loss: 0.2980 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2540 - accuracy: 0.6870 - val_loss: 0.2999 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2455 - accuracy: 0.7130 - val_loss: 0.3010 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2425 - accuracy: 0.7043 - val_loss: 0.3020 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2353 - accuracy: 0.6609 - val_loss: 0.3026 - val_accuracy: 0.4138\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2451 - accuracy: 0.6696 - val_loss: 0.3031 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2409 - accuracy: 0.7304 - val_loss: 0.3037 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2320 - accuracy: 0.7043 - val_loss: 0.3040 - val_accuracy: 0.4138\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2351 - accuracy: 0.7217 - val_loss: 0.3047 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2374 - accuracy: 0.7217 - val_loss: 0.3053 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2319 - accuracy: 0.7130 - val_loss: 0.3058 - val_accuracy: 0.4138\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2342 - accuracy: 0.7304 - val_loss: 0.3061 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2248 - accuracy: 0.6870 - val_loss: 0.3065 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2261 - accuracy: 0.6957 - val_loss: 0.3068 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2225 - accuracy: 0.7391 - val_loss: 0.3068 - val_accuracy: 0.4483\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2363 - accuracy: 0.6783 - val_loss: 0.3068 - val_accuracy: 0.4483\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2300 - accuracy: 0.7391 - val_loss: 0.3068 - val_accuracy: 0.4483\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2195 - accuracy: 0.7304 - val_loss: 0.3069 - val_accuracy: 0.4483\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2241 - accuracy: 0.7478 - val_loss: 0.3062 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2292 - accuracy: 0.7304 - val_loss: 0.3070 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2215 - accuracy: 0.7478 - val_loss: 0.3088 - val_accuracy: 0.4483\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2257 - accuracy: 0.7304 - val_loss: 0.3104 - val_accuracy: 0.4483\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2216 - accuracy: 0.7304 - val_loss: 0.3105 - val_accuracy: 0.4483\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2231 - accuracy: 0.7304 - val_loss: 0.3106 - val_accuracy: 0.4483\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2249 - accuracy: 0.7304 - val_loss: 0.3109 - val_accuracy: 0.4483\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2176 - accuracy: 0.7217 - val_loss: 0.3111 - val_accuracy: 0.4483\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2105 - accuracy: 0.7565 - val_loss: 0.3116 - val_accuracy: 0.4483\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2137 - accuracy: 0.7478 - val_loss: 0.3120 - val_accuracy: 0.4483\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2073 - accuracy: 0.7217 - val_loss: 0.3123 - val_accuracy: 0.4483\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2130 - accuracy: 0.7478 - val_loss: 0.3124 - val_accuracy: 0.4483\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2024 - accuracy: 0.7478 - val_loss: 0.3126 - val_accuracy: 0.4483\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2051 - accuracy: 0.7652 - val_loss: 0.3134 - val_accuracy: 0.4483\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.1964 - accuracy: 0.7478 - val_loss: 0.3142 - val_accuracy: 0.4483\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2043 - accuracy: 0.7652 - val_loss: 0.3146 - val_accuracy: 0.4483\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2065 - accuracy: 0.7652 - val_loss: 0.3149 - val_accuracy: 0.4483\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2026 - accuracy: 0.7391 - val_loss: 0.3151 - val_accuracy: 0.4483\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.2023 - accuracy: 0.7478 - val_loss: 0.3154 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2005 - accuracy: 0.7739 - val_loss: 0.3155 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1985 - accuracy: 0.7739 - val_loss: 0.3153 - val_accuracy: 0.4483\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1901 - accuracy: 0.7826 - val_loss: 0.3153 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.1969 - accuracy: 0.7652 - val_loss: 0.3156 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1948 - accuracy: 0.7478 - val_loss: 0.3151 - val_accuracy: 0.4483\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1941 - accuracy: 0.7565 - val_loss: 0.3151 - val_accuracy: 0.4483\n",
      "0.6666666865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101001111011101111000001001110100111001010\n",
      "22\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3360)\n",
      "(144, 100, 3360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_58 (LSTM)               (None, 100, 20)           270480    \n",
      "_________________________________________________________________\n",
      "lstm_59 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 273,882\n",
      "Trainable params: 273,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.2933 - accuracy: 0.5130 - val_loss: 0.4238 - val_accuracy: 0.4828\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2795 - accuracy: 0.6087 - val_loss: 0.3255 - val_accuracy: 0.5517\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2865 - accuracy: 0.5565 - val_loss: 0.3398 - val_accuracy: 0.5517\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3115 - accuracy: 0.5913 - val_loss: 0.2881 - val_accuracy: 0.8966\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2875 - accuracy: 0.6957 - val_loss: 0.3375 - val_accuracy: 0.6207\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2838 - accuracy: 0.6261 - val_loss: 0.2969 - val_accuracy: 0.6552\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2769 - accuracy: 0.5913 - val_loss: 0.2877 - val_accuracy: 0.5517\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.3156 - accuracy: 0.4696 - val_loss: 0.3578 - val_accuracy: 0.2759\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.3132 - accuracy: 0.5304 - val_loss: 0.2810 - val_accuracy: 0.7241\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.3071 - accuracy: 0.5652 - val_loss: 0.3244 - val_accuracy: 0.5862\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2741 - accuracy: 0.7043 - val_loss: 0.2915 - val_accuracy: 0.6897\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2777 - accuracy: 0.6174 - val_loss: 0.2889 - val_accuracy: 0.6207\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3059 - accuracy: 0.4957 - val_loss: 0.3153 - val_accuracy: 0.6897\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2706 - accuracy: 0.6870 - val_loss: 0.3066 - val_accuracy: 0.8276\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2825 - accuracy: 0.6348 - val_loss: 0.2888 - val_accuracy: 0.8621\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2706 - accuracy: 0.6261 - val_loss: 0.2565 - val_accuracy: 0.7586\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2767 - accuracy: 0.5826 - val_loss: 0.2617 - val_accuracy: 0.7241\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2550 - accuracy: 0.6696 - val_loss: 0.3130 - val_accuracy: 0.6897\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2776 - accuracy: 0.5913 - val_loss: 0.3249 - val_accuracy: 0.6897\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2607 - accuracy: 0.5913 - val_loss: 0.2943 - val_accuracy: 0.7241\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2474 - accuracy: 0.6261 - val_loss: 0.2746 - val_accuracy: 0.6897\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2475 - accuracy: 0.7043 - val_loss: 0.3144 - val_accuracy: 0.6897\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2386 - accuracy: 0.7565 - val_loss: 0.2816 - val_accuracy: 0.6897\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2606 - accuracy: 0.6087 - val_loss: 0.2723 - val_accuracy: 0.5517\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2460 - accuracy: 0.6696 - val_loss: 0.2824 - val_accuracy: 0.6552\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2193 - accuracy: 0.7826 - val_loss: 0.2900 - val_accuracy: 0.7241\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2432 - accuracy: 0.7043 - val_loss: 0.2965 - val_accuracy: 0.5517\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2276 - accuracy: 0.7217 - val_loss: 0.2779 - val_accuracy: 0.6207\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2433 - accuracy: 0.6696 - val_loss: 0.2448 - val_accuracy: 0.6552\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2244 - accuracy: 0.7043 - val_loss: 0.2706 - val_accuracy: 0.5862\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2161 - accuracy: 0.7391 - val_loss: 0.2405 - val_accuracy: 0.5862\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2231 - accuracy: 0.7217 - val_loss: 0.2663 - val_accuracy: 0.6552\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2016 - accuracy: 0.7913 - val_loss: 0.2094 - val_accuracy: 0.6552\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2162 - accuracy: 0.7565 - val_loss: 0.2412 - val_accuracy: 0.6897\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2257 - accuracy: 0.7391 - val_loss: 0.2754 - val_accuracy: 0.7241\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2306 - accuracy: 0.7304 - val_loss: 0.2213 - val_accuracy: 0.7241\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2297 - accuracy: 0.6783 - val_loss: 0.2324 - val_accuracy: 0.7586\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2318 - accuracy: 0.7043 - val_loss: 0.2420 - val_accuracy: 0.6552\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2299 - accuracy: 0.7304 - val_loss: 0.2269 - val_accuracy: 0.6897\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2176 - accuracy: 0.7478 - val_loss: 0.2427 - val_accuracy: 0.6207\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2167 - accuracy: 0.7565 - val_loss: 0.2269 - val_accuracy: 0.6897\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1960 - accuracy: 0.7652 - val_loss: 0.2230 - val_accuracy: 0.6552\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2138 - accuracy: 0.7739 - val_loss: 0.2368 - val_accuracy: 0.6552\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2099 - accuracy: 0.8000 - val_loss: 0.2213 - val_accuracy: 0.6897\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1963 - accuracy: 0.8000 - val_loss: 0.2029 - val_accuracy: 0.7586\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2044 - accuracy: 0.8000 - val_loss: 0.2504 - val_accuracy: 0.6207\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2052 - accuracy: 0.7652 - val_loss: 0.2399 - val_accuracy: 0.6207\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2080 - accuracy: 0.7826 - val_loss: 0.2034 - val_accuracy: 0.6897\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2201 - accuracy: 0.7304 - val_loss: 0.1921 - val_accuracy: 0.7241\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2057 - accuracy: 0.7652 - val_loss: 0.2042 - val_accuracy: 0.7241\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2029 - accuracy: 0.7826 - val_loss: 0.2155 - val_accuracy: 0.7241\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2085 - accuracy: 0.7652 - val_loss: 0.1815 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2178 - accuracy: 0.7391 - val_loss: 0.2010 - val_accuracy: 0.6207\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2059 - accuracy: 0.7652 - val_loss: 0.1989 - val_accuracy: 0.6552\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2030 - accuracy: 0.7478 - val_loss: 0.2124 - val_accuracy: 0.6552\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2005 - accuracy: 0.7913 - val_loss: 0.2377 - val_accuracy: 0.6552\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1753 - accuracy: 0.7826 - val_loss: 0.2068 - val_accuracy: 0.6552\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2028 - accuracy: 0.7826 - val_loss: 0.2041 - val_accuracy: 0.6552\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2067 - accuracy: 0.7304 - val_loss: 0.2170 - val_accuracy: 0.6207\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1943 - accuracy: 0.7913 - val_loss: 0.2041 - val_accuracy: 0.6552\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2021 - accuracy: 0.7565 - val_loss: 0.2171 - val_accuracy: 0.6552\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2060 - accuracy: 0.7391 - val_loss: 0.2121 - val_accuracy: 0.7241\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2157 - accuracy: 0.7130 - val_loss: 0.1983 - val_accuracy: 0.6897\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1996 - accuracy: 0.7652 - val_loss: 0.1816 - val_accuracy: 0.6897\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1928 - accuracy: 0.7478 - val_loss: 0.1799 - val_accuracy: 0.7241\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2000 - accuracy: 0.7043 - val_loss: 0.1965 - val_accuracy: 0.6897\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1910 - accuracy: 0.7565 - val_loss: 0.1810 - val_accuracy: 0.7241\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2086 - accuracy: 0.7304 - val_loss: 0.1849 - val_accuracy: 0.6897\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2036 - accuracy: 0.7391 - val_loss: 0.1895 - val_accuracy: 0.6897\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2004 - accuracy: 0.7478 - val_loss: 0.1878 - val_accuracy: 0.6897\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1918 - accuracy: 0.7565 - val_loss: 0.2353 - val_accuracy: 0.5862\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1781 - accuracy: 0.7478 - val_loss: 0.2237 - val_accuracy: 0.5862\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1620 - accuracy: 0.8696 - val_loss: 0.2399 - val_accuracy: 0.5517\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1966 - accuracy: 0.8087 - val_loss: 0.2287 - val_accuracy: 0.5862\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1653 - accuracy: 0.8087 - val_loss: 0.2463 - val_accuracy: 0.5517\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1850 - accuracy: 0.7826 - val_loss: 0.2319 - val_accuracy: 0.5862\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1833 - accuracy: 0.7304 - val_loss: 0.2607 - val_accuracy: 0.5172\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1636 - accuracy: 0.8696 - val_loss: 0.2488 - val_accuracy: 0.5862\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1517 - accuracy: 0.8696 - val_loss: 0.2378 - val_accuracy: 0.5517\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1454 - accuracy: 0.8522 - val_loss: 0.2310 - val_accuracy: 0.5862\n",
      "0.7291666865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101001111011101111000001001111101010100000\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3240)\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_60 (LSTM)               (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_61 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.3299 - accuracy: 0.3478 - val_loss: 0.3963 - val_accuracy: 0.5172\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2879 - accuracy: 0.4870 - val_loss: 0.3935 - val_accuracy: 0.3103\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2870 - accuracy: 0.3826 - val_loss: 0.3819 - val_accuracy: 0.5517\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2882 - accuracy: 0.4174 - val_loss: 0.3572 - val_accuracy: 0.4138\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2908 - accuracy: 0.4174 - val_loss: 0.3933 - val_accuracy: 0.3448\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.3206 - accuracy: 0.2696 - val_loss: 0.3365 - val_accuracy: 0.4483\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.3166 - accuracy: 0.3130 - val_loss: 0.3959 - val_accuracy: 0.3103\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2990 - accuracy: 0.3391 - val_loss: 0.2656 - val_accuracy: 0.4828\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.3096 - accuracy: 0.3217 - val_loss: 0.3266 - val_accuracy: 0.3793\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.3239 - accuracy: 0.3130 - val_loss: 0.3030 - val_accuracy: 0.3448\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.3114 - accuracy: 0.3652 - val_loss: 0.3082 - val_accuracy: 0.3793\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3395 - accuracy: 0.2783 - val_loss: 0.2531 - val_accuracy: 0.4138\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3451 - accuracy: 0.3043 - val_loss: 0.2755 - val_accuracy: 0.4483\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.3263 - accuracy: 0.3478 - val_loss: 0.3074 - val_accuracy: 0.4483\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2800 - accuracy: 0.4348 - val_loss: 0.2730 - val_accuracy: 0.3793\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2902 - accuracy: 0.3565 - val_loss: 0.2653 - val_accuracy: 0.4483\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.3166 - accuracy: 0.3130 - val_loss: 0.2748 - val_accuracy: 0.4828\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2858 - accuracy: 0.3130 - val_loss: 0.2618 - val_accuracy: 0.5172\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2959 - accuracy: 0.4000 - val_loss: 0.3079 - val_accuracy: 0.3103\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2807 - accuracy: 0.5130 - val_loss: 0.2451 - val_accuracy: 0.3793\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2673 - accuracy: 0.5130 - val_loss: 0.2639 - val_accuracy: 0.3793\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2502 - accuracy: 0.6000 - val_loss: 0.2567 - val_accuracy: 0.4483\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2384 - accuracy: 0.6696 - val_loss: 0.2813 - val_accuracy: 0.3448\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2771 - accuracy: 0.4870 - val_loss: 0.3080 - val_accuracy: 0.3103\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2279 - accuracy: 0.6957 - val_loss: 0.3378 - val_accuracy: 0.3103\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2370 - accuracy: 0.7130 - val_loss: 0.2858 - val_accuracy: 0.3103\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2440 - accuracy: 0.5913 - val_loss: 0.2984 - val_accuracy: 0.2414\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2479 - accuracy: 0.6348 - val_loss: 0.2716 - val_accuracy: 0.3103\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2501 - accuracy: 0.6000 - val_loss: 0.3085 - val_accuracy: 0.3103\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2497 - accuracy: 0.6522 - val_loss: 0.2897 - val_accuracy: 0.3448\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2532 - accuracy: 0.6435 - val_loss: 0.2600 - val_accuracy: 0.3793\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2540 - accuracy: 0.5043 - val_loss: 0.2607 - val_accuracy: 0.4483\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2524 - accuracy: 0.5478 - val_loss: 0.2577 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2636 - accuracy: 0.5391 - val_loss: 0.2566 - val_accuracy: 0.4138\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2583 - accuracy: 0.5478 - val_loss: 0.2918 - val_accuracy: 0.3103\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1996 - accuracy: 0.7826 - val_loss: 0.2765 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2583 - accuracy: 0.5913 - val_loss: 0.2928 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2505 - accuracy: 0.6000 - val_loss: 0.3178 - val_accuracy: 0.3793\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2289 - accuracy: 0.6000 - val_loss: 0.3248 - val_accuracy: 0.3793\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2503 - accuracy: 0.5826 - val_loss: 0.3052 - val_accuracy: 0.3448\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2401 - accuracy: 0.5826 - val_loss: 0.2840 - val_accuracy: 0.3793\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2144 - accuracy: 0.6000 - val_loss: 0.2866 - val_accuracy: 0.3793\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1992 - accuracy: 0.8609 - val_loss: 0.2912 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2038 - accuracy: 0.8261 - val_loss: 0.2747 - val_accuracy: 0.4483\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2129 - accuracy: 0.7565 - val_loss: 0.2811 - val_accuracy: 0.4483\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2018 - accuracy: 0.7565 - val_loss: 0.2619 - val_accuracy: 0.4483\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2327 - accuracy: 0.6696 - val_loss: 0.2612 - val_accuracy: 0.4483\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2185 - accuracy: 0.7304 - val_loss: 0.2552 - val_accuracy: 0.4483\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2137 - accuracy: 0.7304 - val_loss: 0.2510 - val_accuracy: 0.4483\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1984 - accuracy: 0.8087 - val_loss: 0.2566 - val_accuracy: 0.4483\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2037 - accuracy: 0.7565 - val_loss: 0.2578 - val_accuracy: 0.4483\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2447 - accuracy: 0.6261 - val_loss: 0.2582 - val_accuracy: 0.4483\n",
      "Epoch 53/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2136 - accuracy: 0.7304 - val_loss: 0.2526 - val_accuracy: 0.4483\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2264 - accuracy: 0.7130 - val_loss: 0.2474 - val_accuracy: 0.4483\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2453 - accuracy: 0.6957 - val_loss: 0.2811 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2554 - accuracy: 0.6522 - val_loss: 0.2840 - val_accuracy: 0.3793\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2675 - accuracy: 0.5478 - val_loss: 0.3030 - val_accuracy: 0.3793\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2687 - accuracy: 0.6000 - val_loss: 0.3150 - val_accuracy: 0.3793\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2908 - accuracy: 0.5913 - val_loss: 0.3101 - val_accuracy: 0.3793\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2571 - accuracy: 0.6000 - val_loss: 0.3050 - val_accuracy: 0.3103\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2652 - accuracy: 0.6261 - val_loss: 0.3011 - val_accuracy: 0.3103\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2907 - accuracy: 0.5565 - val_loss: 0.3073 - val_accuracy: 0.3103\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2697 - accuracy: 0.5826 - val_loss: 0.2957 - val_accuracy: 0.3448\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2791 - accuracy: 0.6000 - val_loss: 0.3049 - val_accuracy: 0.3103\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2508 - accuracy: 0.6000 - val_loss: 0.2969 - val_accuracy: 0.3103\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2602 - accuracy: 0.6261 - val_loss: 0.3140 - val_accuracy: 0.3448\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2659 - accuracy: 0.5739 - val_loss: 0.3071 - val_accuracy: 0.3793\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2650 - accuracy: 0.6174 - val_loss: 0.2929 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2622 - accuracy: 0.6522 - val_loss: 0.2678 - val_accuracy: 0.3793\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2548 - accuracy: 0.6609 - val_loss: 0.2708 - val_accuracy: 0.3793\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2509 - accuracy: 0.6696 - val_loss: 0.2737 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2332 - accuracy: 0.6522 - val_loss: 0.2698 - val_accuracy: 0.3793\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2706 - accuracy: 0.6087 - val_loss: 0.2877 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2709 - accuracy: 0.6348 - val_loss: 0.2719 - val_accuracy: 0.3448\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2580 - accuracy: 0.6435 - val_loss: 0.2753 - val_accuracy: 0.3448\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2669 - accuracy: 0.6174 - val_loss: 0.2866 - val_accuracy: 0.3793\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2690 - accuracy: 0.6000 - val_loss: 0.2769 - val_accuracy: 0.5172\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2502 - accuracy: 0.6261 - val_loss: 0.2796 - val_accuracy: 0.4828\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2549 - accuracy: 0.6087 - val_loss: 0.2789 - val_accuracy: 0.4828\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2932 - accuracy: 0.5739 - val_loss: 0.2962 - val_accuracy: 0.4483\n",
      "0.5625\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101000010101101010001000111010100111001010\n",
      "26\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2880)\n",
      "(144, 100, 2880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_62 (LSTM)               (None, 100, 20)           232080    \n",
      "_________________________________________________________________\n",
      "lstm_63 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 235,482\n",
      "Trainable params: 235,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.2785 - accuracy: 0.5739 - val_loss: 0.2981 - val_accuracy: 0.7241\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2900 - accuracy: 0.5826 - val_loss: 0.2679 - val_accuracy: 0.7241\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2636 - accuracy: 0.5565 - val_loss: 0.2726 - val_accuracy: 0.6552\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2595 - accuracy: 0.6870 - val_loss: 0.2942 - val_accuracy: 0.6552\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2988 - accuracy: 0.6087 - val_loss: 0.2795 - val_accuracy: 0.7586\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.3058 - accuracy: 0.5739 - val_loss: 0.2450 - val_accuracy: 0.7241\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2973 - accuracy: 0.5478 - val_loss: 0.2857 - val_accuracy: 0.4828\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2869 - accuracy: 0.5739 - val_loss: 0.3227 - val_accuracy: 0.4483\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2953 - accuracy: 0.5217 - val_loss: 0.3557 - val_accuracy: 0.4138\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2999 - accuracy: 0.5391 - val_loss: 0.3553 - val_accuracy: 0.4138\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2859 - accuracy: 0.5565 - val_loss: 0.3498 - val_accuracy: 0.4138\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2799 - accuracy: 0.5478 - val_loss: 0.3469 - val_accuracy: 0.4138\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2718 - accuracy: 0.6087 - val_loss: 0.3312 - val_accuracy: 0.4138\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2618 - accuracy: 0.6087 - val_loss: 0.3179 - val_accuracy: 0.4138\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2502 - accuracy: 0.6783 - val_loss: 0.3073 - val_accuracy: 0.4828\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.2499 - accuracy: 0.7130 - val_loss: 0.3120 - val_accuracy: 0.4828\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2353 - accuracy: 0.7130 - val_loss: 0.3072 - val_accuracy: 0.5172\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.2352 - accuracy: 0.6957 - val_loss: 0.3027 - val_accuracy: 0.5862\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2348 - accuracy: 0.6609 - val_loss: 0.2965 - val_accuracy: 0.6552\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2239 - accuracy: 0.7043 - val_loss: 0.2934 - val_accuracy: 0.5517\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2111 - accuracy: 0.7217 - val_loss: 0.2883 - val_accuracy: 0.5862\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2124 - accuracy: 0.7217 - val_loss: 0.2819 - val_accuracy: 0.6207\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2025 - accuracy: 0.7478 - val_loss: 0.2735 - val_accuracy: 0.6552\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.1984 - accuracy: 0.7304 - val_loss: 0.2642 - val_accuracy: 0.7241\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1963 - accuracy: 0.7739 - val_loss: 0.2518 - val_accuracy: 0.7586\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1854 - accuracy: 0.8000 - val_loss: 0.2382 - val_accuracy: 0.7586\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1757 - accuracy: 0.8174 - val_loss: 0.2276 - val_accuracy: 0.7586\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1681 - accuracy: 0.8000 - val_loss: 0.2197 - val_accuracy: 0.7586\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1682 - accuracy: 0.8261 - val_loss: 0.2139 - val_accuracy: 0.7931\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1547 - accuracy: 0.8522 - val_loss: 0.2082 - val_accuracy: 0.7931\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1563 - accuracy: 0.8261 - val_loss: 0.2022 - val_accuracy: 0.7931\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.1482 - accuracy: 0.8348 - val_loss: 0.1962 - val_accuracy: 0.8276\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1381 - accuracy: 0.8783 - val_loss: 0.1707 - val_accuracy: 0.8276\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1471 - accuracy: 0.8783 - val_loss: 0.1655 - val_accuracy: 0.8276\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1426 - accuracy: 0.8522 - val_loss: 0.1636 - val_accuracy: 0.8276\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1334 - accuracy: 0.8783 - val_loss: 0.1632 - val_accuracy: 0.8276\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1355 - accuracy: 0.8870 - val_loss: 0.1640 - val_accuracy: 0.8276\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1189 - accuracy: 0.9130 - val_loss: 0.1650 - val_accuracy: 0.7931\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1157 - accuracy: 0.9043 - val_loss: 0.1664 - val_accuracy: 0.8276\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.1068 - accuracy: 0.9217 - val_loss: 0.1665 - val_accuracy: 0.8621\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1030 - accuracy: 0.8957 - val_loss: 0.1640 - val_accuracy: 0.8621\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1016 - accuracy: 0.9043 - val_loss: 0.1584 - val_accuracy: 0.8621\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0885 - accuracy: 0.9478 - val_loss: 0.1530 - val_accuracy: 0.8621\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0871 - accuracy: 0.9478 - val_loss: 0.1482 - val_accuracy: 0.8621\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0844 - accuracy: 0.9652 - val_loss: 0.1425 - val_accuracy: 0.8966\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0822 - accuracy: 0.9478 - val_loss: 0.1350 - val_accuracy: 0.8966\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0925 - accuracy: 0.9652 - val_loss: 0.1354 - val_accuracy: 0.8966\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0711 - accuracy: 0.9913 - val_loss: 0.1286 - val_accuracy: 0.9310\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0718 - accuracy: 0.9739 - val_loss: 0.1217 - val_accuracy: 0.9655\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0736 - accuracy: 0.9652 - val_loss: 0.1183 - val_accuracy: 0.9655\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0719 - accuracy: 0.9739 - val_loss: 0.1153 - val_accuracy: 0.9655\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0654 - accuracy: 0.9739 - val_loss: 0.1133 - val_accuracy: 0.9655\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0670 - accuracy: 0.9826 - val_loss: 0.1105 - val_accuracy: 0.9655\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0645 - accuracy: 0.9826 - val_loss: 0.1067 - val_accuracy: 0.9655\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0667 - accuracy: 0.9652 - val_loss: 0.1037 - val_accuracy: 0.9655\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0587 - accuracy: 0.9826 - val_loss: 0.1023 - val_accuracy: 0.9655\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0559 - accuracy: 0.9739 - val_loss: 0.0990 - val_accuracy: 0.9655\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0519 - accuracy: 0.9826 - val_loss: 0.0946 - val_accuracy: 0.9655\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0495 - accuracy: 0.9826 - val_loss: 0.0921 - val_accuracy: 0.9655\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0496 - accuracy: 0.9826 - val_loss: 0.0926 - val_accuracy: 0.9655\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0468 - accuracy: 0.9913 - val_loss: 0.0908 - val_accuracy: 0.9655\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0545 - accuracy: 0.9652 - val_loss: 0.0882 - val_accuracy: 0.9655\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0441 - accuracy: 0.9826 - val_loss: 0.0859 - val_accuracy: 0.9655\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0417 - accuracy: 0.9826 - val_loss: 0.0833 - val_accuracy: 0.9655\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0429 - accuracy: 0.9826 - val_loss: 0.0827 - val_accuracy: 0.9655\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0459 - accuracy: 0.9826 - val_loss: 0.0797 - val_accuracy: 0.9655\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0378 - accuracy: 0.9826 - val_loss: 0.0766 - val_accuracy: 0.9655\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0467 - accuracy: 0.9739 - val_loss: 0.0723 - val_accuracy: 0.9655\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0356 - accuracy: 0.9913 - val_loss: 0.0708 - val_accuracy: 0.9655\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0372 - accuracy: 0.9913 - val_loss: 0.0713 - val_accuracy: 0.9655\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0317 - accuracy: 0.9913 - val_loss: 0.0689 - val_accuracy: 0.9655\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0319 - accuracy: 0.9826 - val_loss: 0.0658 - val_accuracy: 0.9655\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 0.9655\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0303 - accuracy: 0.9913 - val_loss: 0.0605 - val_accuracy: 0.9655\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0307 - accuracy: 0.9826 - val_loss: 0.0588 - val_accuracy: 0.9655\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0322 - accuracy: 0.9826 - val_loss: 0.0538 - val_accuracy: 0.9655\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0264 - accuracy: 0.9913 - val_loss: 0.0495 - val_accuracy: 0.9655\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0283 - accuracy: 0.9913 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0197 - accuracy: 0.9913 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
      "1.0\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101100111010011011011101110100100001011101\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_64 (LSTM)               (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_65 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 0.2323 - accuracy: 0.7739 - val_loss: 0.2130 - val_accuracy: 0.6897\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2419 - accuracy: 0.6000 - val_loss: 0.3019 - val_accuracy: 0.6552\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2504 - accuracy: 0.5217 - val_loss: 0.2717 - val_accuracy: 0.6552\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2302 - accuracy: 0.6348 - val_loss: 0.2395 - val_accuracy: 0.7586\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2494 - accuracy: 0.5826 - val_loss: 0.2395 - val_accuracy: 0.7241\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2807 - accuracy: 0.4609 - val_loss: 0.2534 - val_accuracy: 0.7241\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2255 - accuracy: 0.6435 - val_loss: 0.2420 - val_accuracy: 0.5517\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2492 - accuracy: 0.5478 - val_loss: 0.2440 - val_accuracy: 0.5172\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2879 - accuracy: 0.4174 - val_loss: 0.2644 - val_accuracy: 0.5517\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2367 - accuracy: 0.6174 - val_loss: 0.1533 - val_accuracy: 0.9310\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2118 - accuracy: 0.7391 - val_loss: 0.2099 - val_accuracy: 0.7241\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2465 - accuracy: 0.5478 - val_loss: 0.1991 - val_accuracy: 0.7931\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2445 - accuracy: 0.5478 - val_loss: 0.2191 - val_accuracy: 0.7586\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2547 - accuracy: 0.5043 - val_loss: 0.2430 - val_accuracy: 0.6897\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2877 - accuracy: 0.4870 - val_loss: 0.2889 - val_accuracy: 0.5517\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3041 - accuracy: 0.4261 - val_loss: 0.2746 - val_accuracy: 0.6552\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2788 - accuracy: 0.5130 - val_loss: 0.2876 - val_accuracy: 0.6552\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2858 - accuracy: 0.4957 - val_loss: 0.2845 - val_accuracy: 0.5517\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2728 - accuracy: 0.5217 - val_loss: 0.2620 - val_accuracy: 0.5862\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2672 - accuracy: 0.5652 - val_loss: 0.2731 - val_accuracy: 0.5172\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2545 - accuracy: 0.5826 - val_loss: 0.2786 - val_accuracy: 0.4483\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2518 - accuracy: 0.5739 - val_loss: 0.2750 - val_accuracy: 0.4483\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2430 - accuracy: 0.6348 - val_loss: 0.2828 - val_accuracy: 0.4483\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2473 - accuracy: 0.6348 - val_loss: 0.2722 - val_accuracy: 0.4828\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2772 - accuracy: 0.5130 - val_loss: 0.2665 - val_accuracy: 0.5172\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2741 - accuracy: 0.5739 - val_loss: 0.2657 - val_accuracy: 0.4828\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2366 - accuracy: 0.6609 - val_loss: 0.2658 - val_accuracy: 0.4828\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2311 - accuracy: 0.6783 - val_loss: 0.2779 - val_accuracy: 0.4138\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2275 - accuracy: 0.6783 - val_loss: 0.2790 - val_accuracy: 0.4138\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2384 - accuracy: 0.6696 - val_loss: 0.2791 - val_accuracy: 0.4483\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2205 - accuracy: 0.7043 - val_loss: 0.2789 - val_accuracy: 0.5172\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2153 - accuracy: 0.7217 - val_loss: 0.2813 - val_accuracy: 0.4828\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2173 - accuracy: 0.6957 - val_loss: 0.2683 - val_accuracy: 0.4828\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2193 - accuracy: 0.6783 - val_loss: 0.2735 - val_accuracy: 0.5172\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2161 - accuracy: 0.7652 - val_loss: 0.2727 - val_accuracy: 0.5172\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2008 - accuracy: 0.7304 - val_loss: 0.2345 - val_accuracy: 0.6207\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1847 - accuracy: 0.8261 - val_loss: 0.2096 - val_accuracy: 0.6552\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1868 - accuracy: 0.8000 - val_loss: 0.2066 - val_accuracy: 0.6897\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1766 - accuracy: 0.8435 - val_loss: 0.2045 - val_accuracy: 0.6897\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1755 - accuracy: 0.8348 - val_loss: 0.2022 - val_accuracy: 0.6897\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1690 - accuracy: 0.8609 - val_loss: 0.2006 - val_accuracy: 0.6897\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1776 - accuracy: 0.8522 - val_loss: 0.2013 - val_accuracy: 0.6552\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1688 - accuracy: 0.8783 - val_loss: 0.2018 - val_accuracy: 0.6552\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1644 - accuracy: 0.8609 - val_loss: 0.2017 - val_accuracy: 0.6552\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1599 - accuracy: 0.9043 - val_loss: 0.2008 - val_accuracy: 0.6552\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1599 - accuracy: 0.8957 - val_loss: 0.1974 - val_accuracy: 0.6552\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1532 - accuracy: 0.9130 - val_loss: 0.1948 - val_accuracy: 0.6207\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1536 - accuracy: 0.8870 - val_loss: 0.1745 - val_accuracy: 0.7241\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1600 - accuracy: 0.8609 - val_loss: 0.1829 - val_accuracy: 0.7241\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1577 - accuracy: 0.8957 - val_loss: 0.1755 - val_accuracy: 0.7586\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1533 - accuracy: 0.9304 - val_loss: 0.1766 - val_accuracy: 0.7586\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1543 - accuracy: 0.8783 - val_loss: 0.1780 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1466 - accuracy: 0.9304 - val_loss: 0.1788 - val_accuracy: 0.7241\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1374 - accuracy: 0.9565 - val_loss: 0.1779 - val_accuracy: 0.7241\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1373 - accuracy: 0.9391 - val_loss: 0.1767 - val_accuracy: 0.7241\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1424 - accuracy: 0.9130 - val_loss: 0.1796 - val_accuracy: 0.6897\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1371 - accuracy: 0.9391 - val_loss: 0.1706 - val_accuracy: 0.7241\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1351 - accuracy: 0.9565 - val_loss: 0.1705 - val_accuracy: 0.7241\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1262 - accuracy: 0.9565 - val_loss: 0.1786 - val_accuracy: 0.6552\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1303 - accuracy: 0.9304 - val_loss: 0.1751 - val_accuracy: 0.6897\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1277 - accuracy: 0.9478 - val_loss: 0.1743 - val_accuracy: 0.6897\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1284 - accuracy: 0.9565 - val_loss: 0.1734 - val_accuracy: 0.6897\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1293 - accuracy: 0.9391 - val_loss: 0.1720 - val_accuracy: 0.6897\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1197 - accuracy: 0.9565 - val_loss: 0.1705 - val_accuracy: 0.6897\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1173 - accuracy: 0.9565 - val_loss: 0.1676 - val_accuracy: 0.6897\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1180 - accuracy: 0.9652 - val_loss: 0.1691 - val_accuracy: 0.6897\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1157 - accuracy: 0.9478 - val_loss: 0.1661 - val_accuracy: 0.6897\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1155 - accuracy: 0.9565 - val_loss: 0.1665 - val_accuracy: 0.6897\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1123 - accuracy: 0.9478 - val_loss: 0.1612 - val_accuracy: 0.6897\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1157 - accuracy: 0.9652 - val_loss: 0.1568 - val_accuracy: 0.7241\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1030 - accuracy: 0.9652 - val_loss: 0.1575 - val_accuracy: 0.7241\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1059 - accuracy: 0.9826 - val_loss: 0.1516 - val_accuracy: 0.7241\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1097 - accuracy: 0.9478 - val_loss: 0.1489 - val_accuracy: 0.7586\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1069 - accuracy: 0.9565 - val_loss: 0.1655 - val_accuracy: 0.6552\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1258 - accuracy: 0.8957 - val_loss: 0.1655 - val_accuracy: 0.6552\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1221 - accuracy: 0.8870 - val_loss: 0.1750 - val_accuracy: 0.6552\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1129 - accuracy: 0.9217 - val_loss: 0.1507 - val_accuracy: 0.6897\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1075 - accuracy: 0.9391 - val_loss: 0.1533 - val_accuracy: 0.6897\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1115 - accuracy: 0.9217 - val_loss: 0.1470 - val_accuracy: 0.6897\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1116 - accuracy: 0.9478 - val_loss: 0.1487 - val_accuracy: 0.6897\n",
      "0.75\n",
      "fitness pass\n",
      "[(0.7083333134651184, 675987511003229), (0.6354166865348816, 957257731078682), (0.6354166865348816, 921963755448778), (1.0, 923441258232480), (0.5833333134651184, 675987570620954), (0.8541666865348816, 923441258232480), (0.6666666865348816, 921963789482656), (0.7291666865348816, 957257731074506), (0.5625, 957257731078816), (1.0, 957148127537610), (0.75, 957462487713885)]\n",
      "[957148127537610, 923441258232480]\n",
      "[957148127537610, 923441258232480, 923441258232480, 957462487713885, 957257731074506]\n",
      "selection pass\n",
      "target_count:\n",
      "6\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "0\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "1\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "2\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "3\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "4\n",
      "957257731074506\n",
      "11011001101001111011101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "5\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "6\n",
      "923441258211786\n",
      "11010001111101110101101100001010101010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "7\n",
      "923441258232266\n",
      "11010001111101110101101100001010101111100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "8\n",
      "923441306069450\n",
      "11010001111101110101101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "9\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "10\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "crossover pass\n",
      "變異後的種群\n",
      "染色體：\n",
      "0\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "1\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "變異後的種群\n",
      "染色體：\n",
      "2\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "變異後的種群\n",
      "染色體：\n",
      "3\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "4\n",
      "957257731074506\n",
      "11011001101001111011101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "5\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "變異後的種群\n",
      "染色體：\n",
      "6\n",
      "923441258211786\n",
      "11010001111101110101101100001010101010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "7\n",
      "923441258232266\n",
      "11010001111101110101101100001010101111100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "8\n",
      "923441306069450\n",
      "11010001111101110101101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "9\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "10\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "mutation pass\n",
      "迭代次數： 3\n",
      "3\n",
      "所選擇的染色體：\n",
      "11011001101000010101101010001000111010100111001010\n",
      "26\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 2880)\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_66 (LSTM)               (None, 100, 20)           232080    \n",
      "_________________________________________________________________\n",
      "lstm_67 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 235,482\n",
      "Trainable params: 235,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.2905 - accuracy: 0.5565 - val_loss: 0.4202 - val_accuracy: 0.4483\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2946 - accuracy: 0.5739 - val_loss: 0.3482 - val_accuracy: 0.6552\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2900 - accuracy: 0.5043 - val_loss: 0.2277 - val_accuracy: 0.8966\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2537 - accuracy: 0.6870 - val_loss: 0.2727 - val_accuracy: 0.6552\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2487 - accuracy: 0.8000 - val_loss: 0.2725 - val_accuracy: 0.6552\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2642 - accuracy: 0.5652 - val_loss: 0.3481 - val_accuracy: 0.6552\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.3306 - accuracy: 0.3913 - val_loss: 0.3588 - val_accuracy: 0.7931\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2877 - accuracy: 0.4348 - val_loss: 0.3716 - val_accuracy: 0.5172\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.3209 - accuracy: 0.4696 - val_loss: 0.3295 - val_accuracy: 0.5517\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.3226 - accuracy: 0.5043 - val_loss: 0.2975 - val_accuracy: 0.4828\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2687 - accuracy: 0.6000 - val_loss: 0.2542 - val_accuracy: 0.5862\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2713 - accuracy: 0.6087 - val_loss: 0.2808 - val_accuracy: 0.3103\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.3246 - accuracy: 0.4000 - val_loss: 0.2846 - val_accuracy: 0.4138\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2984 - accuracy: 0.4696 - val_loss: 0.2607 - val_accuracy: 0.5862\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2625 - accuracy: 0.6957 - val_loss: 0.2879 - val_accuracy: 0.4483\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2860 - accuracy: 0.5739 - val_loss: 0.2486 - val_accuracy: 0.6897\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2714 - accuracy: 0.6435 - val_loss: 0.2642 - val_accuracy: 0.6552\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2804 - accuracy: 0.6522 - val_loss: 0.2447 - val_accuracy: 0.6897\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2654 - accuracy: 0.6174 - val_loss: 0.2351 - val_accuracy: 0.6552\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2628 - accuracy: 0.7130 - val_loss: 0.2416 - val_accuracy: 0.6897\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2525 - accuracy: 0.7043 - val_loss: 0.2658 - val_accuracy: 0.5517\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2371 - accuracy: 0.7304 - val_loss: 0.2908 - val_accuracy: 0.2759\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2664 - accuracy: 0.6348 - val_loss: 0.2708 - val_accuracy: 0.3793\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2948 - accuracy: 0.5130 - val_loss: 0.2786 - val_accuracy: 0.4828\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2837 - accuracy: 0.5304 - val_loss: 0.3735 - val_accuracy: 0.4828\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.3019 - accuracy: 0.6087 - val_loss: 0.2950 - val_accuracy: 0.6207\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2432 - accuracy: 0.6783 - val_loss: 0.2860 - val_accuracy: 0.5862\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2722 - accuracy: 0.5739 - val_loss: 0.2710 - val_accuracy: 0.5172\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2641 - accuracy: 0.6000 - val_loss: 0.2624 - val_accuracy: 0.4483\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2619 - accuracy: 0.5913 - val_loss: 0.3071 - val_accuracy: 0.4483\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2791 - accuracy: 0.5739 - val_loss: 0.3225 - val_accuracy: 0.4483\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2776 - accuracy: 0.6087 - val_loss: 0.3039 - val_accuracy: 0.4828\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2762 - accuracy: 0.6174 - val_loss: 0.2944 - val_accuracy: 0.5862\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2790 - accuracy: 0.6261 - val_loss: 0.2963 - val_accuracy: 0.5517\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2648 - accuracy: 0.5739 - val_loss: 0.3093 - val_accuracy: 0.5862\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2880 - accuracy: 0.4957 - val_loss: 0.3027 - val_accuracy: 0.6207\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2698 - accuracy: 0.5826 - val_loss: 0.2643 - val_accuracy: 0.6552\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2480 - accuracy: 0.6000 - val_loss: 0.2506 - val_accuracy: 0.6897\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2439 - accuracy: 0.6696 - val_loss: 0.2465 - val_accuracy: 0.6552\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2482 - accuracy: 0.6348 - val_loss: 0.2368 - val_accuracy: 0.6552\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2489 - accuracy: 0.6783 - val_loss: 0.2631 - val_accuracy: 0.7241\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2594 - accuracy: 0.7391 - val_loss: 0.3162 - val_accuracy: 0.5862\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2755 - accuracy: 0.5913 - val_loss: 0.2897 - val_accuracy: 0.7241\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2635 - accuracy: 0.5130 - val_loss: 0.2910 - val_accuracy: 0.6897\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2702 - accuracy: 0.5043 - val_loss: 0.2151 - val_accuracy: 0.7931\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2316 - accuracy: 0.6000 - val_loss: 0.2252 - val_accuracy: 0.7586\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2578 - accuracy: 0.7391 - val_loss: 0.2498 - val_accuracy: 0.6897\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2484 - accuracy: 0.7130 - val_loss: 0.2185 - val_accuracy: 0.6207\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2331 - accuracy: 0.7565 - val_loss: 0.2378 - val_accuracy: 0.4483\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2517 - accuracy: 0.6435 - val_loss: 0.2645 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2866 - accuracy: 0.5739 - val_loss: 0.2713 - val_accuracy: 0.4483\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2749 - accuracy: 0.5652 - val_loss: 0.2851 - val_accuracy: 0.5172\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2800 - accuracy: 0.5652 - val_loss: 0.3185 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2867 - accuracy: 0.5565 - val_loss: 0.3216 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2858 - accuracy: 0.5826 - val_loss: 0.3166 - val_accuracy: 0.4483\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2871 - accuracy: 0.5565 - val_loss: 0.2717 - val_accuracy: 0.5517\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2773 - accuracy: 0.6087 - val_loss: 0.2650 - val_accuracy: 0.5172\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2569 - accuracy: 0.6783 - val_loss: 0.2679 - val_accuracy: 0.5172\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2570 - accuracy: 0.5478 - val_loss: 0.2656 - val_accuracy: 0.5172\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2514 - accuracy: 0.6870 - val_loss: 0.2601 - val_accuracy: 0.5172\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2234 - accuracy: 0.7304 - val_loss: 0.2339 - val_accuracy: 0.7241\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2144 - accuracy: 0.7739 - val_loss: 0.2258 - val_accuracy: 0.7586\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2161 - accuracy: 0.7391 - val_loss: 0.2281 - val_accuracy: 0.7586\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2121 - accuracy: 0.7739 - val_loss: 0.2275 - val_accuracy: 0.7586\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2014 - accuracy: 0.7739 - val_loss: 0.2260 - val_accuracy: 0.7586\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2077 - accuracy: 0.7826 - val_loss: 0.2246 - val_accuracy: 0.7241\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2111 - accuracy: 0.7739 - val_loss: 0.2232 - val_accuracy: 0.7241\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2014 - accuracy: 0.8261 - val_loss: 0.2218 - val_accuracy: 0.7241\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2030 - accuracy: 0.8000 - val_loss: 0.2204 - val_accuracy: 0.7241\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1947 - accuracy: 0.8000 - val_loss: 0.2185 - val_accuracy: 0.7241\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1902 - accuracy: 0.8435 - val_loss: 0.2168 - val_accuracy: 0.7241\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1896 - accuracy: 0.8261 - val_loss: 0.2160 - val_accuracy: 0.7241\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1832 - accuracy: 0.8696 - val_loss: 0.2144 - val_accuracy: 0.7241\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1840 - accuracy: 0.8609 - val_loss: 0.2127 - val_accuracy: 0.7241\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1783 - accuracy: 0.8696 - val_loss: 0.2111 - val_accuracy: 0.7241\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1742 - accuracy: 0.8696 - val_loss: 0.2093 - val_accuracy: 0.7241\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1689 - accuracy: 0.8783 - val_loss: 0.2078 - val_accuracy: 0.7241\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1706 - accuracy: 0.8783 - val_loss: 0.2062 - val_accuracy: 0.7241\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1698 - accuracy: 0.8522 - val_loss: 0.2048 - val_accuracy: 0.7241\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1646 - accuracy: 0.8870 - val_loss: 0.2032 - val_accuracy: 0.7586\n",
      "0.8333333134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111101010100000\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3240)\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_68 (LSTM)               (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_69 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.2295 - accuracy: 0.6696 - val_loss: 0.3964 - val_accuracy: 0.6552\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2451 - accuracy: 0.5739 - val_loss: 0.2934 - val_accuracy: 0.6207\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2687 - accuracy: 0.6174 - val_loss: 0.4645 - val_accuracy: 0.3448\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3519 - accuracy: 0.4174 - val_loss: 0.3024 - val_accuracy: 0.5862\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2861 - accuracy: 0.5391 - val_loss: 0.1939 - val_accuracy: 0.8966\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2246 - accuracy: 0.7478 - val_loss: 0.1968 - val_accuracy: 0.8621\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2151 - accuracy: 0.7913 - val_loss: 0.5482 - val_accuracy: 0.3793\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2696 - accuracy: 0.6261 - val_loss: 0.5639 - val_accuracy: 0.4828\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.3061 - accuracy: 0.3304 - val_loss: 0.3913 - val_accuracy: 0.5517\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2815 - accuracy: 0.5217 - val_loss: 0.3774 - val_accuracy: 0.5517\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2748 - accuracy: 0.5217 - val_loss: 0.4241 - val_accuracy: 0.4483\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2848 - accuracy: 0.4522 - val_loss: 0.3320 - val_accuracy: 0.5172\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2698 - accuracy: 0.5565 - val_loss: 0.3789 - val_accuracy: 0.4483\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3253 - accuracy: 0.3130 - val_loss: 0.3900 - val_accuracy: 0.5172\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2977 - accuracy: 0.3913 - val_loss: 0.3342 - val_accuracy: 0.4138\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2704 - accuracy: 0.4174 - val_loss: 0.3619 - val_accuracy: 0.5517\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.3145 - accuracy: 0.3826 - val_loss: 0.2982 - val_accuracy: 0.6207\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2854 - accuracy: 0.4174 - val_loss: 0.3183 - val_accuracy: 0.6552\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3023 - accuracy: 0.3913 - val_loss: 0.4192 - val_accuracy: 0.5172\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3047 - accuracy: 0.4087 - val_loss: 0.3002 - val_accuracy: 0.5172\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2888 - accuracy: 0.4609 - val_loss: 0.3958 - val_accuracy: 0.4138\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2829 - accuracy: 0.4696 - val_loss: 0.4068 - val_accuracy: 0.5862\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2734 - accuracy: 0.6783 - val_loss: 0.4092 - val_accuracy: 0.5517\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2706 - accuracy: 0.6696 - val_loss: 0.3292 - val_accuracy: 0.6207\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2381 - accuracy: 0.7217 - val_loss: 0.3446 - val_accuracy: 0.5172\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2562 - accuracy: 0.7304 - val_loss: 0.3162 - val_accuracy: 0.5172\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2260 - accuracy: 0.7913 - val_loss: 0.2886 - val_accuracy: 0.6897\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2163 - accuracy: 0.8000 - val_loss: 0.2798 - val_accuracy: 0.7241\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2271 - accuracy: 0.8000 - val_loss: 0.2989 - val_accuracy: 0.4483\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2494 - accuracy: 0.6435 - val_loss: 0.3117 - val_accuracy: 0.5172\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2503 - accuracy: 0.6609 - val_loss: 0.2974 - val_accuracy: 0.4828\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2606 - accuracy: 0.6348 - val_loss: 0.2818 - val_accuracy: 0.5862\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2376 - accuracy: 0.7130 - val_loss: 0.2808 - val_accuracy: 0.4483\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2260 - accuracy: 0.6696 - val_loss: 0.2704 - val_accuracy: 0.6897\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2207 - accuracy: 0.7043 - val_loss: 0.3028 - val_accuracy: 0.4138\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2320 - accuracy: 0.6174 - val_loss: 0.2925 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2208 - accuracy: 0.6783 - val_loss: 0.2996 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2429 - accuracy: 0.6174 - val_loss: 0.3096 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2358 - accuracy: 0.6522 - val_loss: 0.2881 - val_accuracy: 0.5517\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2354 - accuracy: 0.7043 - val_loss: 0.2912 - val_accuracy: 0.6207\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1901 - accuracy: 0.7739 - val_loss: 0.2678 - val_accuracy: 0.6897\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2038 - accuracy: 0.7739 - val_loss: 0.2580 - val_accuracy: 0.7241\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2000 - accuracy: 0.7913 - val_loss: 0.2400 - val_accuracy: 0.7586\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2023 - accuracy: 0.7913 - val_loss: 0.2147 - val_accuracy: 0.7241\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2138 - accuracy: 0.7217 - val_loss: 0.2402 - val_accuracy: 0.7241\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2122 - accuracy: 0.7739 - val_loss: 0.2300 - val_accuracy: 0.7241\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1989 - accuracy: 0.7652 - val_loss: 0.2239 - val_accuracy: 0.7241\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2206 - accuracy: 0.7130 - val_loss: 0.3372 - val_accuracy: 0.4828\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2510 - accuracy: 0.6174 - val_loss: 0.2609 - val_accuracy: 0.4828\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2553 - accuracy: 0.6609 - val_loss: 0.2998 - val_accuracy: 0.3448\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2291 - accuracy: 0.7130 - val_loss: 0.2675 - val_accuracy: 0.5517\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2000 - accuracy: 0.7478 - val_loss: 0.2428 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2054 - accuracy: 0.7739 - val_loss: 0.3195 - val_accuracy: 0.4483\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2473 - accuracy: 0.6348 - val_loss: 0.2615 - val_accuracy: 0.4483\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2643 - accuracy: 0.5304 - val_loss: 0.2652 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2769 - accuracy: 0.4783 - val_loss: 0.3877 - val_accuracy: 0.3793\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.3051 - accuracy: 0.4957 - val_loss: 0.3255 - val_accuracy: 0.3793\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.3248 - accuracy: 0.4348 - val_loss: 0.2849 - val_accuracy: 0.3448\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.3056 - accuracy: 0.4696 - val_loss: 0.2823 - val_accuracy: 0.3793\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2710 - accuracy: 0.5565 - val_loss: 0.2706 - val_accuracy: 0.3793\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2922 - accuracy: 0.4870 - val_loss: 0.2563 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2816 - accuracy: 0.4609 - val_loss: 0.2854 - val_accuracy: 0.4828\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3235 - accuracy: 0.4522 - val_loss: 0.3359 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.3262 - accuracy: 0.4783 - val_loss: 0.3889 - val_accuracy: 0.4828\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.3385 - accuracy: 0.4261 - val_loss: 0.5278 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.3377 - accuracy: 0.4348 - val_loss: 0.4798 - val_accuracy: 0.3793\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3432 - accuracy: 0.4348 - val_loss: 0.4415 - val_accuracy: 0.3448\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.3095 - accuracy: 0.5217 - val_loss: 0.4159 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3033 - accuracy: 0.4870 - val_loss: 0.4497 - val_accuracy: 0.3448\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3007 - accuracy: 0.5130 - val_loss: 0.4265 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3025 - accuracy: 0.4870 - val_loss: 0.3445 - val_accuracy: 0.5172\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2886 - accuracy: 0.5217 - val_loss: 0.2917 - val_accuracy: 0.5517\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3090 - accuracy: 0.4957 - val_loss: 0.3715 - val_accuracy: 0.3103\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2816 - accuracy: 0.5739 - val_loss: 0.2518 - val_accuracy: 0.5517\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2462 - accuracy: 0.5826 - val_loss: 0.2333 - val_accuracy: 0.5172\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2774 - accuracy: 0.6435 - val_loss: 0.2721 - val_accuracy: 0.4483\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2796 - accuracy: 0.5043 - val_loss: 0.2643 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2753 - accuracy: 0.4783 - val_loss: 0.2880 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2782 - accuracy: 0.5391 - val_loss: 0.2606 - val_accuracy: 0.4828\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2400 - accuracy: 0.6783 - val_loss: 0.2611 - val_accuracy: 0.5172\n",
      "0.4583333432674408\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111101010100000\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n",
      "(144, 100, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_70 (LSTM)               (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_71 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.1874 - accuracy: 0.7739 - val_loss: 0.2166 - val_accuracy: 0.7931\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1527 - accuracy: 0.8435 - val_loss: 0.1757 - val_accuracy: 0.8276\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1850 - accuracy: 0.8261 - val_loss: 0.2371 - val_accuracy: 0.6552\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2485 - accuracy: 0.5652 - val_loss: 0.2224 - val_accuracy: 0.6897\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1905 - accuracy: 0.8087 - val_loss: 0.1483 - val_accuracy: 0.6897\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1712 - accuracy: 0.8957 - val_loss: 0.1321 - val_accuracy: 0.8276\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1657 - accuracy: 0.8957 - val_loss: 0.1204 - val_accuracy: 0.8276\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1653 - accuracy: 0.8783 - val_loss: 0.1153 - val_accuracy: 0.8966\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1589 - accuracy: 0.8870 - val_loss: 0.1325 - val_accuracy: 0.7586\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1588 - accuracy: 0.8348 - val_loss: 0.1578 - val_accuracy: 0.7586\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1497 - accuracy: 0.8174 - val_loss: 0.1498 - val_accuracy: 0.6897\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1545 - accuracy: 0.8435 - val_loss: 0.1410 - val_accuracy: 0.7241\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1455 - accuracy: 0.9304 - val_loss: 0.1284 - val_accuracy: 0.7241\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1528 - accuracy: 0.8957 - val_loss: 0.1356 - val_accuracy: 0.8621\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1750 - accuracy: 0.8348 - val_loss: 0.1584 - val_accuracy: 0.8276\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2320 - accuracy: 0.6870 - val_loss: 0.3457 - val_accuracy: 0.5172\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2602 - accuracy: 0.6000 - val_loss: 0.2799 - val_accuracy: 0.6207\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2379 - accuracy: 0.6087 - val_loss: 0.2615 - val_accuracy: 0.6207\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2296 - accuracy: 0.6522 - val_loss: 0.2279 - val_accuracy: 0.7241\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2165 - accuracy: 0.6609 - val_loss: 0.2112 - val_accuracy: 0.8276\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2243 - accuracy: 0.6870 - val_loss: 0.1956 - val_accuracy: 0.7586\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1818 - accuracy: 0.7391 - val_loss: 0.1776 - val_accuracy: 0.7931\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1778 - accuracy: 0.7478 - val_loss: 0.1657 - val_accuracy: 0.8276\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1534 - accuracy: 0.8261 - val_loss: 0.1639 - val_accuracy: 0.8621\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1575 - accuracy: 0.8435 - val_loss: 0.1567 - val_accuracy: 0.8276\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1511 - accuracy: 0.8435 - val_loss: 0.1750 - val_accuracy: 0.7931\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1714 - accuracy: 0.7565 - val_loss: 0.1417 - val_accuracy: 0.8621\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1625 - accuracy: 0.7913 - val_loss: 0.1950 - val_accuracy: 0.7586\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1571 - accuracy: 0.7913 - val_loss: 0.1962 - val_accuracy: 0.7586\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1661 - accuracy: 0.8000 - val_loss: 0.1975 - val_accuracy: 0.7241\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1513 - accuracy: 0.7826 - val_loss: 0.1850 - val_accuracy: 0.7586\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1540 - accuracy: 0.7826 - val_loss: 0.2053 - val_accuracy: 0.6552\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1570 - accuracy: 0.8000 - val_loss: 0.1814 - val_accuracy: 0.7931\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1337 - accuracy: 0.8522 - val_loss: 0.1766 - val_accuracy: 0.7931\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1322 - accuracy: 0.8870 - val_loss: 0.1695 - val_accuracy: 0.7586\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1407 - accuracy: 0.8435 - val_loss: 0.1761 - val_accuracy: 0.7931\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1325 - accuracy: 0.8870 - val_loss: 0.2137 - val_accuracy: 0.7241\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1197 - accuracy: 0.8783 - val_loss: 0.2179 - val_accuracy: 0.6897\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1360 - accuracy: 0.8522 - val_loss: 0.3253 - val_accuracy: 0.5862\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1652 - accuracy: 0.8261 - val_loss: 0.3119 - val_accuracy: 0.5862\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1207 - accuracy: 0.9130 - val_loss: 0.2184 - val_accuracy: 0.6207\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1240 - accuracy: 0.9130 - val_loss: 0.2502 - val_accuracy: 0.5517\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1585 - accuracy: 0.8261 - val_loss: 0.2823 - val_accuracy: 0.5862\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1441 - accuracy: 0.8609 - val_loss: 0.2729 - val_accuracy: 0.6207\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1772 - accuracy: 0.8087 - val_loss: 0.2490 - val_accuracy: 0.5862\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1552 - accuracy: 0.8000 - val_loss: 0.2440 - val_accuracy: 0.6552\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1657 - accuracy: 0.8348 - val_loss: 0.2855 - val_accuracy: 0.5517\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1614 - accuracy: 0.7913 - val_loss: 0.2594 - val_accuracy: 0.5862\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1714 - accuracy: 0.7913 - val_loss: 0.2848 - val_accuracy: 0.5517\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1997 - accuracy: 0.7391 - val_loss: 0.3230 - val_accuracy: 0.5517\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2386 - accuracy: 0.6870 - val_loss: 0.3078 - val_accuracy: 0.5517\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2098 - accuracy: 0.7304 - val_loss: 0.3102 - val_accuracy: 0.5172\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2656 - accuracy: 0.6174 - val_loss: 0.3490 - val_accuracy: 0.5172\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3006 - accuracy: 0.6435 - val_loss: 0.3444 - val_accuracy: 0.5172\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2529 - accuracy: 0.6696 - val_loss: 0.3337 - val_accuracy: 0.5862\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2403 - accuracy: 0.6783 - val_loss: 0.3002 - val_accuracy: 0.6552\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2404 - accuracy: 0.7130 - val_loss: 0.2780 - val_accuracy: 0.6552\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2170 - accuracy: 0.7217 - val_loss: 0.3489 - val_accuracy: 0.4828\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1745 - accuracy: 0.7826 - val_loss: 0.4077 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1672 - accuracy: 0.8348 - val_loss: 0.4566 - val_accuracy: 0.3793\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2301 - accuracy: 0.6957 - val_loss: 0.4354 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2194 - accuracy: 0.7043 - val_loss: 0.4385 - val_accuracy: 0.4483\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2145 - accuracy: 0.7478 - val_loss: 0.4414 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1774 - accuracy: 0.7913 - val_loss: 0.3897 - val_accuracy: 0.4828\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1461 - accuracy: 0.8783 - val_loss: 0.3809 - val_accuracy: 0.4828\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1450 - accuracy: 0.8609 - val_loss: 0.3739 - val_accuracy: 0.5172\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1529 - accuracy: 0.8087 - val_loss: 0.3545 - val_accuracy: 0.5172\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1426 - accuracy: 0.9043 - val_loss: 0.4189 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1725 - accuracy: 0.8435 - val_loss: 0.3657 - val_accuracy: 0.4828\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1745 - accuracy: 0.8174 - val_loss: 0.3888 - val_accuracy: 0.4483\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1634 - accuracy: 0.8261 - val_loss: 0.3167 - val_accuracy: 0.5172\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1595 - accuracy: 0.8174 - val_loss: 0.3284 - val_accuracy: 0.4483\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1568 - accuracy: 0.8174 - val_loss: 0.3262 - val_accuracy: 0.4483\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1479 - accuracy: 0.8522 - val_loss: 0.3332 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1422 - accuracy: 0.8609 - val_loss: 0.3379 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1441 - accuracy: 0.8609 - val_loss: 0.3252 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1376 - accuracy: 0.8609 - val_loss: 0.3147 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1388 - accuracy: 0.8522 - val_loss: 0.2974 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1368 - accuracy: 0.8609 - val_loss: 0.2856 - val_accuracy: 0.6207\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1257 - accuracy: 0.8783 - val_loss: 0.2776 - val_accuracy: 0.5862\n",
      "0.7291666865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101100111010011011011101110100100001011101\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_72 (LSTM)               (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_73 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 0.1995 - accuracy: 0.8609 - val_loss: 0.2872 - val_accuracy: 0.8621\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1586 - accuracy: 0.8957 - val_loss: 0.1620 - val_accuracy: 0.7241\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2220 - accuracy: 0.6957 - val_loss: 0.1804 - val_accuracy: 0.7241\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2190 - accuracy: 0.6957 - val_loss: 0.1725 - val_accuracy: 0.8966\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1623 - accuracy: 0.8609 - val_loss: 0.1909 - val_accuracy: 0.8966\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1800 - accuracy: 0.7913 - val_loss: 0.2224 - val_accuracy: 0.7931\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1893 - accuracy: 0.7739 - val_loss: 0.2103 - val_accuracy: 0.7931\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1945 - accuracy: 0.7739 - val_loss: 0.2624 - val_accuracy: 0.6552\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2043 - accuracy: 0.7565 - val_loss: 0.2492 - val_accuracy: 0.4483\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2188 - accuracy: 0.7478 - val_loss: 0.3219 - val_accuracy: 0.5517\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2800 - accuracy: 0.5130 - val_loss: 0.3585 - val_accuracy: 0.4138\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3340 - accuracy: 0.3565 - val_loss: 0.3411 - val_accuracy: 0.4138\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2999 - accuracy: 0.4261 - val_loss: 0.3051 - val_accuracy: 0.4483\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2811 - accuracy: 0.6000 - val_loss: 0.2924 - val_accuracy: 0.4138\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2328 - accuracy: 0.6261 - val_loss: 0.2921 - val_accuracy: 0.4138\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2196 - accuracy: 0.6348 - val_loss: 0.2752 - val_accuracy: 0.5172\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1829 - accuracy: 0.8522 - val_loss: 0.2903 - val_accuracy: 0.6207\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2440 - accuracy: 0.5739 - val_loss: 0.2958 - val_accuracy: 0.4138\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2561 - accuracy: 0.5565 - val_loss: 0.2744 - val_accuracy: 0.4138\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2200 - accuracy: 0.6696 - val_loss: 0.2685 - val_accuracy: 0.4138\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2082 - accuracy: 0.7478 - val_loss: 0.2668 - val_accuracy: 0.4138\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2146 - accuracy: 0.7304 - val_loss: 0.2739 - val_accuracy: 0.4138\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2153 - accuracy: 0.7565 - val_loss: 0.2689 - val_accuracy: 0.4138\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2036 - accuracy: 0.7739 - val_loss: 0.2702 - val_accuracy: 0.4138\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2085 - accuracy: 0.7217 - val_loss: 0.2651 - val_accuracy: 0.4138\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1856 - accuracy: 0.8435 - val_loss: 0.2653 - val_accuracy: 0.4483\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2251 - accuracy: 0.6522 - val_loss: 0.2705 - val_accuracy: 0.4138\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2142 - accuracy: 0.6696 - val_loss: 0.2719 - val_accuracy: 0.4483\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2385 - accuracy: 0.5739 - val_loss: 0.2596 - val_accuracy: 0.4483\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2184 - accuracy: 0.6783 - val_loss: 0.2578 - val_accuracy: 0.4828\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2355 - accuracy: 0.6087 - val_loss: 0.2565 - val_accuracy: 0.4828\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2300 - accuracy: 0.5913 - val_loss: 0.2314 - val_accuracy: 0.5517\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2112 - accuracy: 0.6261 - val_loss: 0.2431 - val_accuracy: 0.4828\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2173 - accuracy: 0.6348 - val_loss: 0.2438 - val_accuracy: 0.4828\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2304 - accuracy: 0.5913 - val_loss: 0.2379 - val_accuracy: 0.5172\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2453 - accuracy: 0.5130 - val_loss: 0.2540 - val_accuracy: 0.4483\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2314 - accuracy: 0.5826 - val_loss: 0.2625 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2107 - accuracy: 0.6522 - val_loss: 0.2634 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1797 - accuracy: 0.8000 - val_loss: 0.2627 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1735 - accuracy: 0.8348 - val_loss: 0.2636 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1691 - accuracy: 0.8696 - val_loss: 0.2643 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1685 - accuracy: 0.8609 - val_loss: 0.2646 - val_accuracy: 0.4138\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1642 - accuracy: 0.8783 - val_loss: 0.2657 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1605 - accuracy: 0.8957 - val_loss: 0.2664 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1659 - accuracy: 0.8783 - val_loss: 0.2668 - val_accuracy: 0.4138\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1592 - accuracy: 0.8783 - val_loss: 0.2672 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1578 - accuracy: 0.8870 - val_loss: 0.2676 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1540 - accuracy: 0.9043 - val_loss: 0.2680 - val_accuracy: 0.4138\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1458 - accuracy: 0.9217 - val_loss: 0.2683 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1385 - accuracy: 0.9217 - val_loss: 0.2684 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1387 - accuracy: 0.8957 - val_loss: 0.2685 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1389 - accuracy: 0.9217 - val_loss: 0.2684 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1331 - accuracy: 0.9304 - val_loss: 0.2684 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1279 - accuracy: 0.9304 - val_loss: 0.2684 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1243 - accuracy: 0.9217 - val_loss: 0.2683 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1248 - accuracy: 0.9391 - val_loss: 0.2682 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1197 - accuracy: 0.9304 - val_loss: 0.2681 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1214 - accuracy: 0.9217 - val_loss: 0.2680 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1158 - accuracy: 0.9478 - val_loss: 0.2679 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1110 - accuracy: 0.9304 - val_loss: 0.2675 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1086 - accuracy: 0.9565 - val_loss: 0.2671 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1100 - accuracy: 0.9304 - val_loss: 0.2667 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1061 - accuracy: 0.9478 - val_loss: 0.2667 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0984 - accuracy: 0.9478 - val_loss: 0.2667 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1110 - accuracy: 0.9304 - val_loss: 0.2665 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0988 - accuracy: 0.9391 - val_loss: 0.2658 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1007 - accuracy: 0.9391 - val_loss: 0.2649 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0974 - accuracy: 0.9565 - val_loss: 0.2727 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0938 - accuracy: 0.9304 - val_loss: 0.2713 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0969 - accuracy: 0.9304 - val_loss: 0.2735 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0916 - accuracy: 0.9391 - val_loss: 0.2813 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0888 - accuracy: 0.9478 - val_loss: 0.2811 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0875 - accuracy: 0.9391 - val_loss: 0.2666 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0881 - accuracy: 0.9478 - val_loss: 0.2672 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0887 - accuracy: 0.9565 - val_loss: 0.2665 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0922 - accuracy: 0.9391 - val_loss: 0.2649 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0834 - accuracy: 0.9478 - val_loss: 0.2651 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0846 - accuracy: 0.9565 - val_loss: 0.2656 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0774 - accuracy: 0.9565 - val_loss: 0.2661 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0769 - accuracy: 0.9565 - val_loss: 0.2655 - val_accuracy: 0.4138\n",
      "0.6145833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101001111011101111000001001110100111001010\n",
      "22\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3360)\n",
      "(144, 100, 3360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_74 (LSTM)               (None, 100, 20)           270480    \n",
      "_________________________________________________________________\n",
      "lstm_75 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 273,882\n",
      "Trainable params: 273,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 0.2421 - accuracy: 0.5913 - val_loss: 0.1450 - val_accuracy: 0.9310\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2069 - accuracy: 0.7739 - val_loss: 0.3213 - val_accuracy: 0.6207\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2453 - accuracy: 0.7130 - val_loss: 0.3542 - val_accuracy: 0.6207\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2496 - accuracy: 0.6000 - val_loss: 0.3612 - val_accuracy: 0.6207\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2763 - accuracy: 0.6087 - val_loss: 0.3894 - val_accuracy: 0.5172\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3009 - accuracy: 0.5652 - val_loss: 0.4680 - val_accuracy: 0.5517\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.3245 - accuracy: 0.4957 - val_loss: 0.5215 - val_accuracy: 0.3448\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3274 - accuracy: 0.3913 - val_loss: 0.4791 - val_accuracy: 0.3793\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3197 - accuracy: 0.4000 - val_loss: 0.4611 - val_accuracy: 0.4138\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.3381 - accuracy: 0.3304 - val_loss: 0.3524 - val_accuracy: 0.2759\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.3261 - accuracy: 0.4783 - val_loss: 0.2750 - val_accuracy: 0.4828\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.3287 - accuracy: 0.5652 - val_loss: 0.2946 - val_accuracy: 0.5517\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2872 - accuracy: 0.5913 - val_loss: 0.3101 - val_accuracy: 0.4483\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2727 - accuracy: 0.6087 - val_loss: 0.3245 - val_accuracy: 0.5517\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2403 - accuracy: 0.7043 - val_loss: 0.2629 - val_accuracy: 0.6207\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2333 - accuracy: 0.7130 - val_loss: 0.2765 - val_accuracy: 0.4828\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2160 - accuracy: 0.7130 - val_loss: 0.2386 - val_accuracy: 0.6207\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2294 - accuracy: 0.7043 - val_loss: 0.3206 - val_accuracy: 0.5517\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2512 - accuracy: 0.6783 - val_loss: 0.2589 - val_accuracy: 0.6552\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2538 - accuracy: 0.6870 - val_loss: 0.2243 - val_accuracy: 0.5862\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2405 - accuracy: 0.7217 - val_loss: 0.2415 - val_accuracy: 0.6207\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2535 - accuracy: 0.6870 - val_loss: 0.2577 - val_accuracy: 0.5517\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2570 - accuracy: 0.6696 - val_loss: 0.2128 - val_accuracy: 0.6552\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2711 - accuracy: 0.5913 - val_loss: 0.2241 - val_accuracy: 0.6207\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2630 - accuracy: 0.6261 - val_loss: 0.2281 - val_accuracy: 0.6552\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2793 - accuracy: 0.5826 - val_loss: 0.2434 - val_accuracy: 0.5517\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2735 - accuracy: 0.6087 - val_loss: 0.2470 - val_accuracy: 0.5517\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2808 - accuracy: 0.5913 - val_loss: 0.2438 - val_accuracy: 0.6552\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2950 - accuracy: 0.5652 - val_loss: 0.2796 - val_accuracy: 0.5517\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3151 - accuracy: 0.5217 - val_loss: 0.2844 - val_accuracy: 0.5862\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.3138 - accuracy: 0.5304 - val_loss: 0.2893 - val_accuracy: 0.4483\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3089 - accuracy: 0.5217 - val_loss: 0.3078 - val_accuracy: 0.4138\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2978 - accuracy: 0.5304 - val_loss: 0.2988 - val_accuracy: 0.4483\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.3048 - accuracy: 0.5565 - val_loss: 0.2772 - val_accuracy: 0.5862\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.3028 - accuracy: 0.5478 - val_loss: 0.2767 - val_accuracy: 0.5517\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2972 - accuracy: 0.5217 - val_loss: 0.2811 - val_accuracy: 0.5172\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2974 - accuracy: 0.5826 - val_loss: 0.2480 - val_accuracy: 0.6207\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2807 - accuracy: 0.5913 - val_loss: 0.2756 - val_accuracy: 0.5517\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2721 - accuracy: 0.6348 - val_loss: 0.2783 - val_accuracy: 0.5172\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2549 - accuracy: 0.6348 - val_loss: 0.2860 - val_accuracy: 0.4483\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2642 - accuracy: 0.6087 - val_loss: 0.2854 - val_accuracy: 0.4483\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2417 - accuracy: 0.6609 - val_loss: 0.2818 - val_accuracy: 0.4828\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2359 - accuracy: 0.6522 - val_loss: 0.2587 - val_accuracy: 0.5517\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2316 - accuracy: 0.6522 - val_loss: 0.2490 - val_accuracy: 0.5517\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2242 - accuracy: 0.6870 - val_loss: 0.2839 - val_accuracy: 0.4828\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2584 - accuracy: 0.6348 - val_loss: 0.2599 - val_accuracy: 0.6207\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2967 - accuracy: 0.5565 - val_loss: 0.2754 - val_accuracy: 0.4828\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2772 - accuracy: 0.5913 - val_loss: 0.2735 - val_accuracy: 0.4828\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2662 - accuracy: 0.6435 - val_loss: 0.2477 - val_accuracy: 0.5862\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2588 - accuracy: 0.6087 - val_loss: 0.2463 - val_accuracy: 0.5172\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2418 - accuracy: 0.6696 - val_loss: 0.2517 - val_accuracy: 0.5172\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2429 - accuracy: 0.6783 - val_loss: 0.2447 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2521 - accuracy: 0.6174 - val_loss: 0.2379 - val_accuracy: 0.6552\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2494 - accuracy: 0.6348 - val_loss: 0.2321 - val_accuracy: 0.6552\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2313 - accuracy: 0.6348 - val_loss: 0.2236 - val_accuracy: 0.6552\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2200 - accuracy: 0.6957 - val_loss: 0.2359 - val_accuracy: 0.5517\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2240 - accuracy: 0.6783 - val_loss: 0.2329 - val_accuracy: 0.5517\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2208 - accuracy: 0.6783 - val_loss: 0.2288 - val_accuracy: 0.5517\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2185 - accuracy: 0.6870 - val_loss: 0.2261 - val_accuracy: 0.6207\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2195 - accuracy: 0.6522 - val_loss: 0.2240 - val_accuracy: 0.6207\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2039 - accuracy: 0.6696 - val_loss: 0.2225 - val_accuracy: 0.6552\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2034 - accuracy: 0.6783 - val_loss: 0.2213 - val_accuracy: 0.6552\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2028 - accuracy: 0.6957 - val_loss: 0.2202 - val_accuracy: 0.6897\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1905 - accuracy: 0.7217 - val_loss: 0.2188 - val_accuracy: 0.6897\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1881 - accuracy: 0.7304 - val_loss: 0.2169 - val_accuracy: 0.6897\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1796 - accuracy: 0.7217 - val_loss: 0.2147 - val_accuracy: 0.6897\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1759 - accuracy: 0.7391 - val_loss: 0.2123 - val_accuracy: 0.6897\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1705 - accuracy: 0.7304 - val_loss: 0.2100 - val_accuracy: 0.6897\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1686 - accuracy: 0.7391 - val_loss: 0.2076 - val_accuracy: 0.6897\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1687 - accuracy: 0.7217 - val_loss: 0.2054 - val_accuracy: 0.6897\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1672 - accuracy: 0.7304 - val_loss: 0.2026 - val_accuracy: 0.7241\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1595 - accuracy: 0.7739 - val_loss: 0.2000 - val_accuracy: 0.7241\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1576 - accuracy: 0.7565 - val_loss: 0.1969 - val_accuracy: 0.7241\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1569 - accuracy: 0.7739 - val_loss: 0.1941 - val_accuracy: 0.7241\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1503 - accuracy: 0.8261 - val_loss: 0.1915 - val_accuracy: 0.7241\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1479 - accuracy: 0.8087 - val_loss: 0.1885 - val_accuracy: 0.7586\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1464 - accuracy: 0.8087 - val_loss: 0.1855 - val_accuracy: 0.7586\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1439 - accuracy: 0.8174 - val_loss: 0.1825 - val_accuracy: 0.7586\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1535 - accuracy: 0.7913 - val_loss: 0.1795 - val_accuracy: 0.7586\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1312 - accuracy: 0.8696 - val_loss: 0.1768 - val_accuracy: 0.7586\n",
      "0.7708333134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111101010100000\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3240)\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_76 (LSTM)               (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_77 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.1880 - accuracy: 0.8348 - val_loss: 0.4300 - val_accuracy: 0.5862\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2792 - accuracy: 0.5304 - val_loss: 0.2590 - val_accuracy: 0.5172\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.3104 - accuracy: 0.5217 - val_loss: 0.2784 - val_accuracy: 0.5862\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.3231 - accuracy: 0.3478 - val_loss: 0.2695 - val_accuracy: 0.6207\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.3111 - accuracy: 0.4783 - val_loss: 0.3186 - val_accuracy: 0.5172\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2897 - accuracy: 0.5130 - val_loss: 0.2665 - val_accuracy: 0.5862\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2620 - accuracy: 0.6000 - val_loss: 0.2324 - val_accuracy: 0.6207\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2551 - accuracy: 0.6435 - val_loss: 0.2684 - val_accuracy: 0.5517\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2460 - accuracy: 0.6870 - val_loss: 0.2448 - val_accuracy: 0.5517\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2268 - accuracy: 0.6957 - val_loss: 0.2498 - val_accuracy: 0.4828\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2370 - accuracy: 0.6087 - val_loss: 0.2579 - val_accuracy: 0.4138\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2548 - accuracy: 0.6261 - val_loss: 0.2722 - val_accuracy: 0.4828\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2561 - accuracy: 0.6087 - val_loss: 0.2587 - val_accuracy: 0.4483\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2526 - accuracy: 0.6696 - val_loss: 0.2559 - val_accuracy: 0.6552\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2393 - accuracy: 0.6870 - val_loss: 0.2531 - val_accuracy: 0.4483\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2748 - accuracy: 0.5826 - val_loss: 0.2517 - val_accuracy: 0.5172\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2630 - accuracy: 0.5652 - val_loss: 0.2733 - val_accuracy: 0.5172\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2264 - accuracy: 0.7391 - val_loss: 0.2516 - val_accuracy: 0.5862\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2466 - accuracy: 0.6696 - val_loss: 0.2561 - val_accuracy: 0.5517\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2172 - accuracy: 0.7391 - val_loss: 0.3109 - val_accuracy: 0.4138\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2130 - accuracy: 0.6870 - val_loss: 0.2420 - val_accuracy: 0.5517\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2541 - accuracy: 0.6522 - val_loss: 0.2438 - val_accuracy: 0.5172\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2349 - accuracy: 0.6696 - val_loss: 0.2127 - val_accuracy: 0.5862\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2172 - accuracy: 0.7565 - val_loss: 0.2738 - val_accuracy: 0.4828\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2427 - accuracy: 0.7391 - val_loss: 0.2434 - val_accuracy: 0.5862\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2207 - accuracy: 0.7304 - val_loss: 0.2482 - val_accuracy: 0.5172\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2258 - accuracy: 0.7304 - val_loss: 0.2394 - val_accuracy: 0.5172\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2054 - accuracy: 0.7304 - val_loss: 0.2592 - val_accuracy: 0.4828\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2438 - accuracy: 0.6522 - val_loss: 0.2526 - val_accuracy: 0.4483\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2284 - accuracy: 0.6957 - val_loss: 0.2352 - val_accuracy: 0.5172\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2148 - accuracy: 0.6783 - val_loss: 0.2305 - val_accuracy: 0.5862\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1954 - accuracy: 0.7478 - val_loss: 0.2184 - val_accuracy: 0.6207\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2120 - accuracy: 0.7217 - val_loss: 0.2332 - val_accuracy: 0.5862\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2078 - accuracy: 0.7130 - val_loss: 0.2384 - val_accuracy: 0.5862\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2072 - accuracy: 0.6870 - val_loss: 0.2399 - val_accuracy: 0.4828\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2179 - accuracy: 0.7043 - val_loss: 0.2684 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2216 - accuracy: 0.6696 - val_loss: 0.2560 - val_accuracy: 0.4483\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2084 - accuracy: 0.6696 - val_loss: 0.2468 - val_accuracy: 0.5172\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2175 - accuracy: 0.6870 - val_loss: 0.2347 - val_accuracy: 0.5517\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2274 - accuracy: 0.6435 - val_loss: 0.2404 - val_accuracy: 0.5172\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2250 - accuracy: 0.6609 - val_loss: 0.2300 - val_accuracy: 0.5172\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2206 - accuracy: 0.6522 - val_loss: 0.2374 - val_accuracy: 0.5172\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2386 - accuracy: 0.6435 - val_loss: 0.2470 - val_accuracy: 0.5172\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2433 - accuracy: 0.6261 - val_loss: 0.2414 - val_accuracy: 0.5517\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2240 - accuracy: 0.6609 - val_loss: 0.2526 - val_accuracy: 0.5172\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2388 - accuracy: 0.6522 - val_loss: 0.2249 - val_accuracy: 0.5862\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2182 - accuracy: 0.6783 - val_loss: 0.2514 - val_accuracy: 0.5172\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2276 - accuracy: 0.6261 - val_loss: 0.2188 - val_accuracy: 0.5862\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2122 - accuracy: 0.6609 - val_loss: 0.2201 - val_accuracy: 0.5862\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2178 - accuracy: 0.7130 - val_loss: 0.2407 - val_accuracy: 0.5172\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2085 - accuracy: 0.7130 - val_loss: 0.2288 - val_accuracy: 0.4828\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2345 - accuracy: 0.6435 - val_loss: 0.2300 - val_accuracy: 0.5172\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2172 - accuracy: 0.7478 - val_loss: 0.2195 - val_accuracy: 0.6207\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2222 - accuracy: 0.6870 - val_loss: 0.2389 - val_accuracy: 0.4828\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2040 - accuracy: 0.7826 - val_loss: 0.2445 - val_accuracy: 0.5172\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2104 - accuracy: 0.7217 - val_loss: 0.2282 - val_accuracy: 0.5517\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2309 - accuracy: 0.6435 - val_loss: 0.2301 - val_accuracy: 0.5172\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1955 - accuracy: 0.7478 - val_loss: 0.2428 - val_accuracy: 0.5517\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2166 - accuracy: 0.7130 - val_loss: 0.2319 - val_accuracy: 0.5517\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2054 - accuracy: 0.6696 - val_loss: 0.2817 - val_accuracy: 0.3793\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2153 - accuracy: 0.7217 - val_loss: 0.2683 - val_accuracy: 0.5172\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2436 - accuracy: 0.6696 - val_loss: 0.2739 - val_accuracy: 0.4483\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2827 - accuracy: 0.5826 - val_loss: 0.2809 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2467 - accuracy: 0.6435 - val_loss: 0.2598 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2282 - accuracy: 0.6783 - val_loss: 0.2741 - val_accuracy: 0.4483\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2253 - accuracy: 0.7130 - val_loss: 0.2797 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2444 - accuracy: 0.6435 - val_loss: 0.2659 - val_accuracy: 0.4483\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2690 - accuracy: 0.6261 - val_loss: 0.2552 - val_accuracy: 0.4828\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2261 - accuracy: 0.6783 - val_loss: 0.2437 - val_accuracy: 0.4828\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2342 - accuracy: 0.6870 - val_loss: 0.2544 - val_accuracy: 0.4483\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2280 - accuracy: 0.7043 - val_loss: 0.2715 - val_accuracy: 0.4483\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2562 - accuracy: 0.6174 - val_loss: 0.2647 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2396 - accuracy: 0.6870 - val_loss: 0.2623 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2339 - accuracy: 0.6957 - val_loss: 0.2606 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2425 - accuracy: 0.6522 - val_loss: 0.2529 - val_accuracy: 0.5172\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2125 - accuracy: 0.7043 - val_loss: 0.2626 - val_accuracy: 0.5172\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2078 - accuracy: 0.6609 - val_loss: 0.2481 - val_accuracy: 0.5172\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2101 - accuracy: 0.7043 - val_loss: 0.2564 - val_accuracy: 0.5172\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2188 - accuracy: 0.6870 - val_loss: 0.2649 - val_accuracy: 0.4828\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2072 - accuracy: 0.7391 - val_loss: 0.2569 - val_accuracy: 0.4483\n",
      "0.6458333134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101010100111001010\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3240)\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_78 (LSTM)               (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_79 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.2878 - accuracy: 0.4957 - val_loss: 0.2720 - val_accuracy: 0.7241\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.3026 - accuracy: 0.4522 - val_loss: 0.4775 - val_accuracy: 0.4138\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.3098 - accuracy: 0.4870 - val_loss: 0.4603 - val_accuracy: 0.3793\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3291 - accuracy: 0.4522 - val_loss: 0.4813 - val_accuracy: 0.3103\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2882 - accuracy: 0.5565 - val_loss: 0.3292 - val_accuracy: 0.4828\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2487 - accuracy: 0.6261 - val_loss: 0.3110 - val_accuracy: 0.3793\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2423 - accuracy: 0.7043 - val_loss: 0.2540 - val_accuracy: 0.5517\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2342 - accuracy: 0.6957 - val_loss: 0.2490 - val_accuracy: 0.5862\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2435 - accuracy: 0.6957 - val_loss: 0.2359 - val_accuracy: 0.6552\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2389 - accuracy: 0.6957 - val_loss: 0.2828 - val_accuracy: 0.6552\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2555 - accuracy: 0.5739 - val_loss: 0.2403 - val_accuracy: 0.5862\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2428 - accuracy: 0.6957 - val_loss: 0.2569 - val_accuracy: 0.4138\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2681 - accuracy: 0.6348 - val_loss: 0.2596 - val_accuracy: 0.4138\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2477 - accuracy: 0.6435 - val_loss: 0.2561 - val_accuracy: 0.4138\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2411 - accuracy: 0.7217 - val_loss: 0.2562 - val_accuracy: 0.4138\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2469 - accuracy: 0.7304 - val_loss: 0.2602 - val_accuracy: 0.4138\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2288 - accuracy: 0.7652 - val_loss: 0.2544 - val_accuracy: 0.4138\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2224 - accuracy: 0.7826 - val_loss: 0.2606 - val_accuracy: 0.4138\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2249 - accuracy: 0.7217 - val_loss: 0.2705 - val_accuracy: 0.4138\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2266 - accuracy: 0.7652 - val_loss: 0.2694 - val_accuracy: 0.4138\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2100 - accuracy: 0.7913 - val_loss: 0.2640 - val_accuracy: 0.4138\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1999 - accuracy: 0.8087 - val_loss: 0.2620 - val_accuracy: 0.4138\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1934 - accuracy: 0.8087 - val_loss: 0.2647 - val_accuracy: 0.4138\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1704 - accuracy: 0.8609 - val_loss: 0.2669 - val_accuracy: 0.4138\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1764 - accuracy: 0.8609 - val_loss: 0.2658 - val_accuracy: 0.4138\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1691 - accuracy: 0.8957 - val_loss: 0.2640 - val_accuracy: 0.4138\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1599 - accuracy: 0.8957 - val_loss: 0.2656 - val_accuracy: 0.4138\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2086 - accuracy: 0.7826 - val_loss: 0.2731 - val_accuracy: 0.4138\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2549 - accuracy: 0.7217 - val_loss: 0.2575 - val_accuracy: 0.4483\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2168 - accuracy: 0.7913 - val_loss: 0.4191 - val_accuracy: 0.4138\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2632 - accuracy: 0.7391 - val_loss: 0.2650 - val_accuracy: 0.4483\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2515 - accuracy: 0.6957 - val_loss: 0.2812 - val_accuracy: 0.4138\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2363 - accuracy: 0.7826 - val_loss: 0.2685 - val_accuracy: 0.4483\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2211 - accuracy: 0.7739 - val_loss: 0.2676 - val_accuracy: 0.4483\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2109 - accuracy: 0.7739 - val_loss: 0.2734 - val_accuracy: 0.4138\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2108 - accuracy: 0.7391 - val_loss: 0.2722 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2007 - accuracy: 0.7217 - val_loss: 0.2754 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2238 - accuracy: 0.7913 - val_loss: 0.2747 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2609 - accuracy: 0.6000 - val_loss: 0.2709 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2398 - accuracy: 0.7478 - val_loss: 0.3087 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2429 - accuracy: 0.6957 - val_loss: 0.2762 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2157 - accuracy: 0.7130 - val_loss: 0.2763 - val_accuracy: 0.4138\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2235 - accuracy: 0.7391 - val_loss: 0.2734 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1979 - accuracy: 0.7478 - val_loss: 0.2656 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2035 - accuracy: 0.7304 - val_loss: 0.2771 - val_accuracy: 0.4138\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1980 - accuracy: 0.7913 - val_loss: 0.2818 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1924 - accuracy: 0.7565 - val_loss: 0.3050 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1878 - accuracy: 0.7739 - val_loss: 0.2991 - val_accuracy: 0.4138\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1825 - accuracy: 0.7913 - val_loss: 0.3143 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2150 - accuracy: 0.6348 - val_loss: 0.2949 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2083 - accuracy: 0.6783 - val_loss: 0.2998 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2310 - accuracy: 0.6870 - val_loss: 0.2769 - val_accuracy: 0.4138\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2181 - accuracy: 0.6522 - val_loss: 0.2746 - val_accuracy: 0.4483\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2484 - accuracy: 0.5304 - val_loss: 0.2930 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2587 - accuracy: 0.5652 - val_loss: 0.2799 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2373 - accuracy: 0.6174 - val_loss: 0.2774 - val_accuracy: 0.4483\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2272 - accuracy: 0.6174 - val_loss: 0.2810 - val_accuracy: 0.4483\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2332 - accuracy: 0.5652 - val_loss: 0.2837 - val_accuracy: 0.4483\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2348 - accuracy: 0.5652 - val_loss: 0.2759 - val_accuracy: 0.4483\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2099 - accuracy: 0.6348 - val_loss: 0.2792 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2140 - accuracy: 0.6087 - val_loss: 0.2790 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2258 - accuracy: 0.6261 - val_loss: 0.2725 - val_accuracy: 0.4483\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2169 - accuracy: 0.6261 - val_loss: 0.2842 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1928 - accuracy: 0.6783 - val_loss: 0.2899 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1814 - accuracy: 0.7565 - val_loss: 0.2986 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1953 - accuracy: 0.8261 - val_loss: 0.2816 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1711 - accuracy: 0.7652 - val_loss: 0.2722 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1717 - accuracy: 0.8348 - val_loss: 0.2673 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1581 - accuracy: 0.8348 - val_loss: 0.2450 - val_accuracy: 0.4828\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1547 - accuracy: 0.8696 - val_loss: 0.2514 - val_accuracy: 0.4483\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1550 - accuracy: 0.8957 - val_loss: 0.2581 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1751 - accuracy: 0.8609 - val_loss: 0.2628 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1776 - accuracy: 0.8696 - val_loss: 0.2618 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1838 - accuracy: 0.8522 - val_loss: 0.2547 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2014 - accuracy: 0.7739 - val_loss: 0.2374 - val_accuracy: 0.4483\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1926 - accuracy: 0.8000 - val_loss: 0.2306 - val_accuracy: 0.4483\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1719 - accuracy: 0.8522 - val_loss: 0.2320 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1936 - accuracy: 0.7913 - val_loss: 0.2417 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1975 - accuracy: 0.7739 - val_loss: 0.2418 - val_accuracy: 0.4483\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1530 - accuracy: 0.8522 - val_loss: 0.2509 - val_accuracy: 0.4138\n",
      "0.6354166865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_80 (LSTM)               (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_81 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 184ms/step - loss: 0.2775 - accuracy: 0.5739 - val_loss: 0.2990 - val_accuracy: 0.3448\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3486 - accuracy: 0.3304 - val_loss: 0.2361 - val_accuracy: 0.5172\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3068 - accuracy: 0.4783 - val_loss: 0.3255 - val_accuracy: 0.4483\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3355 - accuracy: 0.4696 - val_loss: 0.3242 - val_accuracy: 0.4138\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.3082 - accuracy: 0.4435 - val_loss: 0.3307 - val_accuracy: 0.3448\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2777 - accuracy: 0.5304 - val_loss: 0.2931 - val_accuracy: 0.5862\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2558 - accuracy: 0.5826 - val_loss: 0.3152 - val_accuracy: 0.4828\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2787 - accuracy: 0.5130 - val_loss: 0.3076 - val_accuracy: 0.4138\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2558 - accuracy: 0.5913 - val_loss: 0.3315 - val_accuracy: 0.5517\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2930 - accuracy: 0.5391 - val_loss: 0.3308 - val_accuracy: 0.5172\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2705 - accuracy: 0.6348 - val_loss: 0.3170 - val_accuracy: 0.5517\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2450 - accuracy: 0.6348 - val_loss: 0.3329 - val_accuracy: 0.4828\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2618 - accuracy: 0.5217 - val_loss: 0.2832 - val_accuracy: 0.5517\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2531 - accuracy: 0.6348 - val_loss: 0.3618 - val_accuracy: 0.5172\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2512 - accuracy: 0.5739 - val_loss: 0.4096 - val_accuracy: 0.5862\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2548 - accuracy: 0.6087 - val_loss: 0.3848 - val_accuracy: 0.5517\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3049 - accuracy: 0.5217 - val_loss: 0.4493 - val_accuracy: 0.3448\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3265 - accuracy: 0.4261 - val_loss: 0.4291 - val_accuracy: 0.5172\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2976 - accuracy: 0.5478 - val_loss: 0.3214 - val_accuracy: 0.6207\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2591 - accuracy: 0.5913 - val_loss: 0.3619 - val_accuracy: 0.5517\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.3027 - accuracy: 0.4957 - val_loss: 0.3357 - val_accuracy: 0.5172\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2997 - accuracy: 0.4783 - val_loss: 0.3127 - val_accuracy: 0.6552\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2626 - accuracy: 0.6174 - val_loss: 0.2916 - val_accuracy: 0.5517\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2958 - accuracy: 0.4522 - val_loss: 0.2560 - val_accuracy: 0.4828\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2778 - accuracy: 0.5565 - val_loss: 0.2934 - val_accuracy: 0.4828\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2680 - accuracy: 0.5478 - val_loss: 0.3150 - val_accuracy: 0.4828\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3037 - accuracy: 0.5391 - val_loss: 0.2498 - val_accuracy: 0.6897\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2798 - accuracy: 0.5304 - val_loss: 0.3878 - val_accuracy: 0.4138\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2814 - accuracy: 0.5739 - val_loss: 0.3008 - val_accuracy: 0.4138\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2884 - accuracy: 0.5130 - val_loss: 0.3828 - val_accuracy: 0.3103\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.3099 - accuracy: 0.4870 - val_loss: 0.3629 - val_accuracy: 0.4138\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2951 - accuracy: 0.4435 - val_loss: 0.3831 - val_accuracy: 0.4828\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2775 - accuracy: 0.5739 - val_loss: 0.3328 - val_accuracy: 0.5862\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2891 - accuracy: 0.5130 - val_loss: 0.3187 - val_accuracy: 0.4828\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2706 - accuracy: 0.5913 - val_loss: 0.3157 - val_accuracy: 0.5172\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2790 - accuracy: 0.5391 - val_loss: 0.3412 - val_accuracy: 0.3448\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.3000 - accuracy: 0.4957 - val_loss: 0.3819 - val_accuracy: 0.4483\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2966 - accuracy: 0.5043 - val_loss: 0.2666 - val_accuracy: 0.4828\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2962 - accuracy: 0.5043 - val_loss: 0.3191 - val_accuracy: 0.3793\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.3003 - accuracy: 0.4783 - val_loss: 0.3192 - val_accuracy: 0.3103\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2916 - accuracy: 0.4870 - val_loss: 0.2743 - val_accuracy: 0.4483\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2944 - accuracy: 0.5130 - val_loss: 0.3377 - val_accuracy: 0.2759\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2787 - accuracy: 0.5652 - val_loss: 0.3061 - val_accuracy: 0.3793\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2806 - accuracy: 0.5565 - val_loss: 0.3002 - val_accuracy: 0.3793\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2779 - accuracy: 0.5739 - val_loss: 0.2917 - val_accuracy: 0.5862\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2779 - accuracy: 0.5652 - val_loss: 0.2977 - val_accuracy: 0.4828\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2808 - accuracy: 0.5739 - val_loss: 0.3111 - val_accuracy: 0.3793\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2767 - accuracy: 0.5565 - val_loss: 0.3239 - val_accuracy: 0.4483\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2980 - accuracy: 0.5217 - val_loss: 0.3176 - val_accuracy: 0.3793\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3074 - accuracy: 0.5043 - val_loss: 0.3164 - val_accuracy: 0.3793\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2703 - accuracy: 0.5217 - val_loss: 0.2855 - val_accuracy: 0.4828\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2944 - accuracy: 0.5304 - val_loss: 0.2770 - val_accuracy: 0.4483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2901 - accuracy: 0.5391 - val_loss: 0.3091 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2897 - accuracy: 0.5217 - val_loss: 0.3131 - val_accuracy: 0.3793\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3068 - accuracy: 0.4696 - val_loss: 0.2910 - val_accuracy: 0.4483\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.3007 - accuracy: 0.5304 - val_loss: 0.3426 - val_accuracy: 0.3793\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2943 - accuracy: 0.5130 - val_loss: 0.3139 - val_accuracy: 0.4483\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2869 - accuracy: 0.5652 - val_loss: 0.3059 - val_accuracy: 0.4483\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2795 - accuracy: 0.5565 - val_loss: 0.3177 - val_accuracy: 0.3793\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3005 - accuracy: 0.5043 - val_loss: 0.3087 - val_accuracy: 0.4828\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2922 - accuracy: 0.5304 - val_loss: 0.3240 - val_accuracy: 0.4483\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2761 - accuracy: 0.5913 - val_loss: 0.2937 - val_accuracy: 0.4483\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2580 - accuracy: 0.6435 - val_loss: 0.3401 - val_accuracy: 0.3793\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2689 - accuracy: 0.5913 - val_loss: 0.3044 - val_accuracy: 0.3793\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2850 - accuracy: 0.5652 - val_loss: 0.2999 - val_accuracy: 0.4483\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2858 - accuracy: 0.5565 - val_loss: 0.3114 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2574 - accuracy: 0.6348 - val_loss: 0.3084 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2636 - accuracy: 0.6261 - val_loss: 0.3056 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3094 - accuracy: 0.5043 - val_loss: 0.3421 - val_accuracy: 0.3793\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2760 - accuracy: 0.5913 - val_loss: 0.3272 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2654 - accuracy: 0.5826 - val_loss: 0.2998 - val_accuracy: 0.4483\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2810 - accuracy: 0.5826 - val_loss: 0.2816 - val_accuracy: 0.5172\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2670 - accuracy: 0.6261 - val_loss: 0.2861 - val_accuracy: 0.4483\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2579 - accuracy: 0.6348 - val_loss: 0.3133 - val_accuracy: 0.3793\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2813 - accuracy: 0.5739 - val_loss: 0.2891 - val_accuracy: 0.4828\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2727 - accuracy: 0.6174 - val_loss: 0.2965 - val_accuracy: 0.4483\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3000 - accuracy: 0.5304 - val_loss: 0.3070 - val_accuracy: 0.3793\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2977 - accuracy: 0.5043 - val_loss: 0.3161 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2553 - accuracy: 0.6261 - val_loss: 0.3294 - val_accuracy: 0.3448\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2675 - accuracy: 0.5826 - val_loss: 0.3288 - val_accuracy: 0.4138\n",
      "0.59375\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101111000001001110100111001010\n",
      "22\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3360)\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_82 (LSTM)               (None, 100, 20)           270480    \n",
      "_________________________________________________________________\n",
      "lstm_83 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 273,882\n",
      "Trainable params: 273,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 0.3292 - accuracy: 0.3217 - val_loss: 0.4313 - val_accuracy: 0.2414\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2977 - accuracy: 0.4435 - val_loss: 0.3344 - val_accuracy: 0.4828\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3115 - accuracy: 0.2870 - val_loss: 0.3298 - val_accuracy: 0.5862\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3064 - accuracy: 0.3739 - val_loss: 0.3225 - val_accuracy: 0.4483\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.3257 - accuracy: 0.4696 - val_loss: 0.2578 - val_accuracy: 0.4483\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.3027 - accuracy: 0.4435 - val_loss: 0.2519 - val_accuracy: 0.4828\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2987 - accuracy: 0.4957 - val_loss: 0.2577 - val_accuracy: 0.4828\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.3286 - accuracy: 0.4783 - val_loss: 0.2666 - val_accuracy: 0.4483\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2989 - accuracy: 0.4435 - val_loss: 0.3310 - val_accuracy: 0.3448\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.3295 - accuracy: 0.4609 - val_loss: 0.3152 - val_accuracy: 0.3448\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3009 - accuracy: 0.5304 - val_loss: 0.3063 - val_accuracy: 0.3793\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3155 - accuracy: 0.5130 - val_loss: 0.3101 - val_accuracy: 0.4483\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2880 - accuracy: 0.5565 - val_loss: 0.2773 - val_accuracy: 0.5172\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2496 - accuracy: 0.6348 - val_loss: 0.3045 - val_accuracy: 0.4138\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2575 - accuracy: 0.6087 - val_loss: 0.3086 - val_accuracy: 0.4138\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2274 - accuracy: 0.6783 - val_loss: 0.2860 - val_accuracy: 0.5517\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2604 - accuracy: 0.6522 - val_loss: 0.3077 - val_accuracy: 0.4483\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2350 - accuracy: 0.6957 - val_loss: 0.3014 - val_accuracy: 0.3793\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3154 - accuracy: 0.5652 - val_loss: 0.4048 - val_accuracy: 0.4138\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3103 - accuracy: 0.5826 - val_loss: 0.3141 - val_accuracy: 0.4483\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2787 - accuracy: 0.5913 - val_loss: 0.2819 - val_accuracy: 0.4138\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3234 - accuracy: 0.4870 - val_loss: 0.3130 - val_accuracy: 0.4138\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3048 - accuracy: 0.5739 - val_loss: 0.3114 - val_accuracy: 0.4138\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2587 - accuracy: 0.6435 - val_loss: 0.2898 - val_accuracy: 0.4483\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2804 - accuracy: 0.6087 - val_loss: 0.2817 - val_accuracy: 0.4138\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2777 - accuracy: 0.5913 - val_loss: 0.2838 - val_accuracy: 0.4138\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2534 - accuracy: 0.6087 - val_loss: 0.2927 - val_accuracy: 0.4138\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2868 - accuracy: 0.5565 - val_loss: 0.2694 - val_accuracy: 0.4138\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3025 - accuracy: 0.5304 - val_loss: 0.2821 - val_accuracy: 0.4138\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2827 - accuracy: 0.5391 - val_loss: 0.3046 - val_accuracy: 0.4138\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3053 - accuracy: 0.5130 - val_loss: 0.2923 - val_accuracy: 0.4138\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2888 - accuracy: 0.5130 - val_loss: 0.3252 - val_accuracy: 0.3793\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2965 - accuracy: 0.5391 - val_loss: 0.2857 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2770 - accuracy: 0.5826 - val_loss: 0.2740 - val_accuracy: 0.4483\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2707 - accuracy: 0.5739 - val_loss: 0.2850 - val_accuracy: 0.4483\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2751 - accuracy: 0.5913 - val_loss: 0.2919 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2674 - accuracy: 0.6087 - val_loss: 0.2761 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2730 - accuracy: 0.5826 - val_loss: 0.2760 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2714 - accuracy: 0.5826 - val_loss: 0.2839 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2760 - accuracy: 0.5652 - val_loss: 0.2830 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2679 - accuracy: 0.5304 - val_loss: 0.2760 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2685 - accuracy: 0.5652 - val_loss: 0.2843 - val_accuracy: 0.4138\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2472 - accuracy: 0.6174 - val_loss: 0.3020 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2438 - accuracy: 0.6261 - val_loss: 0.2882 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2396 - accuracy: 0.6435 - val_loss: 0.2866 - val_accuracy: 0.4138\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2271 - accuracy: 0.6435 - val_loss: 0.2817 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2481 - accuracy: 0.6174 - val_loss: 0.3010 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2602 - accuracy: 0.6261 - val_loss: 0.2797 - val_accuracy: 0.4138\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2678 - accuracy: 0.5826 - val_loss: 0.2950 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2761 - accuracy: 0.6000 - val_loss: 0.3065 - val_accuracy: 0.3793\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2660 - accuracy: 0.6174 - val_loss: 0.2941 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2723 - accuracy: 0.5826 - val_loss: 0.2918 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2545 - accuracy: 0.5913 - val_loss: 0.2905 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2622 - accuracy: 0.5652 - val_loss: 0.2893 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2737 - accuracy: 0.5913 - val_loss: 0.2870 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2679 - accuracy: 0.5652 - val_loss: 0.2903 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2716 - accuracy: 0.5478 - val_loss: 0.2893 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2450 - accuracy: 0.6087 - val_loss: 0.2987 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2527 - accuracy: 0.5739 - val_loss: 0.2971 - val_accuracy: 0.3793\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2553 - accuracy: 0.5826 - val_loss: 0.2981 - val_accuracy: 0.3793\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2598 - accuracy: 0.5826 - val_loss: 0.2964 - val_accuracy: 0.3793\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2639 - accuracy: 0.5826 - val_loss: 0.3034 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2566 - accuracy: 0.5565 - val_loss: 0.2949 - val_accuracy: 0.4483\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2763 - accuracy: 0.5565 - val_loss: 0.2938 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2693 - accuracy: 0.5826 - val_loss: 0.2888 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2650 - accuracy: 0.5652 - val_loss: 0.2807 - val_accuracy: 0.4483\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2553 - accuracy: 0.6087 - val_loss: 0.2827 - val_accuracy: 0.4483\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2691 - accuracy: 0.6000 - val_loss: 0.2993 - val_accuracy: 0.4483\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2641 - accuracy: 0.5826 - val_loss: 0.2902 - val_accuracy: 0.4483\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2687 - accuracy: 0.5739 - val_loss: 0.2849 - val_accuracy: 0.4483\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2586 - accuracy: 0.6000 - val_loss: 0.2852 - val_accuracy: 0.4483\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2511 - accuracy: 0.6261 - val_loss: 0.2840 - val_accuracy: 0.4483\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2407 - accuracy: 0.6348 - val_loss: 0.2859 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2560 - accuracy: 0.5913 - val_loss: 0.2912 - val_accuracy: 0.4483\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2763 - accuracy: 0.5739 - val_loss: 0.2992 - val_accuracy: 0.4483\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2453 - accuracy: 0.6348 - val_loss: 0.3017 - val_accuracy: 0.4483\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2525 - accuracy: 0.6348 - val_loss: 0.2826 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2153 - accuracy: 0.6870 - val_loss: 0.2807 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2299 - accuracy: 0.6435 - val_loss: 0.2981 - val_accuracy: 0.4483\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2501 - accuracy: 0.6348 - val_loss: 0.3117 - val_accuracy: 0.4483\n",
      "0.6041666865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101100111010011011011101110100100001011101\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n",
      "(144, 100, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_84 (LSTM)               (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_85 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 0.2336 - accuracy: 0.6522 - val_loss: 0.2834 - val_accuracy: 0.8621\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1471 - accuracy: 0.9217 - val_loss: 0.1584 - val_accuracy: 0.8966\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1851 - accuracy: 0.8435 - val_loss: 0.2359 - val_accuracy: 0.8966\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2534 - accuracy: 0.7652 - val_loss: 0.2005 - val_accuracy: 0.8621\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2238 - accuracy: 0.7565 - val_loss: 0.1952 - val_accuracy: 0.8276\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2327 - accuracy: 0.7739 - val_loss: 0.2748 - val_accuracy: 0.7586\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2487 - accuracy: 0.7565 - val_loss: 0.2440 - val_accuracy: 0.7586\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2254 - accuracy: 0.7304 - val_loss: 0.1952 - val_accuracy: 0.8621\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2168 - accuracy: 0.7217 - val_loss: 0.2632 - val_accuracy: 0.6897\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2766 - accuracy: 0.6087 - val_loss: 0.2829 - val_accuracy: 0.5862\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2654 - accuracy: 0.6435 - val_loss: 0.2755 - val_accuracy: 0.6207\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3071 - accuracy: 0.5478 - val_loss: 0.2645 - val_accuracy: 0.6552\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2623 - accuracy: 0.6957 - val_loss: 0.2516 - val_accuracy: 0.6207\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2630 - accuracy: 0.6348 - val_loss: 0.2665 - val_accuracy: 0.6552\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2747 - accuracy: 0.6174 - val_loss: 0.2552 - val_accuracy: 0.6207\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2695 - accuracy: 0.6000 - val_loss: 0.2979 - val_accuracy: 0.5862\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2626 - accuracy: 0.6174 - val_loss: 0.2614 - val_accuracy: 0.5862\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2590 - accuracy: 0.6087 - val_loss: 0.2678 - val_accuracy: 0.5862\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2425 - accuracy: 0.6870 - val_loss: 0.2537 - val_accuracy: 0.5862\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2271 - accuracy: 0.6870 - val_loss: 0.2545 - val_accuracy: 0.6207\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2364 - accuracy: 0.6000 - val_loss: 0.2378 - val_accuracy: 0.5862\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2330 - accuracy: 0.6957 - val_loss: 0.2344 - val_accuracy: 0.5862\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2411 - accuracy: 0.7043 - val_loss: 0.2388 - val_accuracy: 0.5862\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2125 - accuracy: 0.7478 - val_loss: 0.2316 - val_accuracy: 0.6207\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2264 - accuracy: 0.6957 - val_loss: 0.2455 - val_accuracy: 0.5517\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2173 - accuracy: 0.6957 - val_loss: 0.2401 - val_accuracy: 0.5517\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2090 - accuracy: 0.7043 - val_loss: 0.2373 - val_accuracy: 0.5517\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2085 - accuracy: 0.7304 - val_loss: 0.2342 - val_accuracy: 0.5862\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2069 - accuracy: 0.7217 - val_loss: 0.2332 - val_accuracy: 0.5862\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2085 - accuracy: 0.7217 - val_loss: 0.2331 - val_accuracy: 0.5862\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1979 - accuracy: 0.7652 - val_loss: 0.2325 - val_accuracy: 0.5862\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1931 - accuracy: 0.7652 - val_loss: 0.2315 - val_accuracy: 0.5517\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1870 - accuracy: 0.7739 - val_loss: 0.2302 - val_accuracy: 0.5517\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1899 - accuracy: 0.7478 - val_loss: 0.2288 - val_accuracy: 0.5862\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1883 - accuracy: 0.7739 - val_loss: 0.2280 - val_accuracy: 0.5862\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1886 - accuracy: 0.7565 - val_loss: 0.2271 - val_accuracy: 0.5862\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1744 - accuracy: 0.7913 - val_loss: 0.2262 - val_accuracy: 0.5862\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1736 - accuracy: 0.8087 - val_loss: 0.2250 - val_accuracy: 0.5862\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1778 - accuracy: 0.8000 - val_loss: 0.2236 - val_accuracy: 0.5862\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1790 - accuracy: 0.7913 - val_loss: 0.2222 - val_accuracy: 0.6207\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1663 - accuracy: 0.7913 - val_loss: 0.2207 - val_accuracy: 0.6207\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1621 - accuracy: 0.8087 - val_loss: 0.2193 - val_accuracy: 0.6207\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1574 - accuracy: 0.8261 - val_loss: 0.2179 - val_accuracy: 0.6207\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1567 - accuracy: 0.8000 - val_loss: 0.2166 - val_accuracy: 0.6552\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1554 - accuracy: 0.8348 - val_loss: 0.2153 - val_accuracy: 0.6552\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1564 - accuracy: 0.8087 - val_loss: 0.2143 - val_accuracy: 0.6552\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1561 - accuracy: 0.8348 - val_loss: 0.2130 - val_accuracy: 0.6552\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1598 - accuracy: 0.8348 - val_loss: 0.2106 - val_accuracy: 0.6552\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1433 - accuracy: 0.8435 - val_loss: 0.2076 - val_accuracy: 0.6552\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1415 - accuracy: 0.8522 - val_loss: 0.2058 - val_accuracy: 0.6552\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1552 - accuracy: 0.8348 - val_loss: 0.2043 - val_accuracy: 0.6897\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1466 - accuracy: 0.8261 - val_loss: 0.2030 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1374 - accuracy: 0.8609 - val_loss: 0.2017 - val_accuracy: 0.6897\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1399 - accuracy: 0.8609 - val_loss: 0.2003 - val_accuracy: 0.6897\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1342 - accuracy: 0.8609 - val_loss: 0.1990 - val_accuracy: 0.6897\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1355 - accuracy: 0.8435 - val_loss: 0.1983 - val_accuracy: 0.7241\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1365 - accuracy: 0.8609 - val_loss: 0.1967 - val_accuracy: 0.7586\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1264 - accuracy: 0.8696 - val_loss: 0.1954 - val_accuracy: 0.7586\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1245 - accuracy: 0.8957 - val_loss: 0.1942 - val_accuracy: 0.7586\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1250 - accuracy: 0.8696 - val_loss: 0.1928 - val_accuracy: 0.7586\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1246 - accuracy: 0.8609 - val_loss: 0.1912 - val_accuracy: 0.7586\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1205 - accuracy: 0.8957 - val_loss: 0.1900 - val_accuracy: 0.7586\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1220 - accuracy: 0.8783 - val_loss: 0.1885 - val_accuracy: 0.7931\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1167 - accuracy: 0.8957 - val_loss: 0.1866 - val_accuracy: 0.7931\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1131 - accuracy: 0.9217 - val_loss: 0.1850 - val_accuracy: 0.7931\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1183 - accuracy: 0.8783 - val_loss: 0.1834 - val_accuracy: 0.7931\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1121 - accuracy: 0.8783 - val_loss: 0.1816 - val_accuracy: 0.7931\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1161 - accuracy: 0.8696 - val_loss: 0.1796 - val_accuracy: 0.8276\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1135 - accuracy: 0.8783 - val_loss: 0.1780 - val_accuracy: 0.8276\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1086 - accuracy: 0.9043 - val_loss: 0.1766 - val_accuracy: 0.8276\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1089 - accuracy: 0.8870 - val_loss: 0.1751 - val_accuracy: 0.8276\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1088 - accuracy: 0.9130 - val_loss: 0.1735 - val_accuracy: 0.8276\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1058 - accuracy: 0.8870 - val_loss: 0.1716 - val_accuracy: 0.8276\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1041 - accuracy: 0.9043 - val_loss: 0.1701 - val_accuracy: 0.8276\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1091 - accuracy: 0.8870 - val_loss: 0.1689 - val_accuracy: 0.8276\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1003 - accuracy: 0.9130 - val_loss: 0.1678 - val_accuracy: 0.8276\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1022 - accuracy: 0.8870 - val_loss: 0.1671 - val_accuracy: 0.8276\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1057 - accuracy: 0.8870 - val_loss: 0.1656 - val_accuracy: 0.8276\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0951 - accuracy: 0.9043 - val_loss: 0.1645 - val_accuracy: 0.8276\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0907 - accuracy: 0.9043 - val_loss: 0.1637 - val_accuracy: 0.8276\n",
      "0.8854166865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101111011101111000001001110100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_86 (LSTM)               (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_87 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 0.2653 - accuracy: 0.6522 - val_loss: 0.3431 - val_accuracy: 0.5517\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2590 - accuracy: 0.6174 - val_loss: 0.4103 - val_accuracy: 0.6207\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2515 - accuracy: 0.6696 - val_loss: 0.3168 - val_accuracy: 0.6207\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2375 - accuracy: 0.7304 - val_loss: 0.3531 - val_accuracy: 0.5862\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2410 - accuracy: 0.7478 - val_loss: 0.3369 - val_accuracy: 0.5862\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2486 - accuracy: 0.6870 - val_loss: 0.2707 - val_accuracy: 0.6207\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2582 - accuracy: 0.6957 - val_loss: 0.3067 - val_accuracy: 0.6552\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2532 - accuracy: 0.7478 - val_loss: 0.2439 - val_accuracy: 0.7241\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2286 - accuracy: 0.8087 - val_loss: 0.2958 - val_accuracy: 0.6897\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2267 - accuracy: 0.8087 - val_loss: 0.2812 - val_accuracy: 0.6552\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2236 - accuracy: 0.8087 - val_loss: 0.2784 - val_accuracy: 0.7241\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2364 - accuracy: 0.8000 - val_loss: 0.2724 - val_accuracy: 0.7241\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2363 - accuracy: 0.7913 - val_loss: 0.2514 - val_accuracy: 0.6207\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2285 - accuracy: 0.8000 - val_loss: 0.2685 - val_accuracy: 0.6552\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2296 - accuracy: 0.7913 - val_loss: 0.2540 - val_accuracy: 0.7241\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2228 - accuracy: 0.8087 - val_loss: 0.2833 - val_accuracy: 0.6897\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2206 - accuracy: 0.8087 - val_loss: 0.2849 - val_accuracy: 0.7241\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2194 - accuracy: 0.8261 - val_loss: 0.2927 - val_accuracy: 0.7241\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2191 - accuracy: 0.8174 - val_loss: 0.2697 - val_accuracy: 0.7586\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2030 - accuracy: 0.8174 - val_loss: 0.2735 - val_accuracy: 0.7586\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2081 - accuracy: 0.8087 - val_loss: 0.2696 - val_accuracy: 0.7241\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1915 - accuracy: 0.8522 - val_loss: 0.2561 - val_accuracy: 0.7586\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1899 - accuracy: 0.8435 - val_loss: 0.2542 - val_accuracy: 0.7586\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1903 - accuracy: 0.8435 - val_loss: 0.2564 - val_accuracy: 0.7241\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1896 - accuracy: 0.8783 - val_loss: 0.2546 - val_accuracy: 0.6897\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1953 - accuracy: 0.8435 - val_loss: 0.2537 - val_accuracy: 0.6897\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1859 - accuracy: 0.8696 - val_loss: 0.2438 - val_accuracy: 0.6897\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1743 - accuracy: 0.8957 - val_loss: 0.2383 - val_accuracy: 0.6897\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1916 - accuracy: 0.8522 - val_loss: 0.2492 - val_accuracy: 0.7241\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2050 - accuracy: 0.8174 - val_loss: 0.2410 - val_accuracy: 0.7241\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2135 - accuracy: 0.8435 - val_loss: 0.2638 - val_accuracy: 0.6897\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2151 - accuracy: 0.8087 - val_loss: 0.2349 - val_accuracy: 0.6897\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2299 - accuracy: 0.8087 - val_loss: 0.2306 - val_accuracy: 0.6552\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2229 - accuracy: 0.8087 - val_loss: 0.2245 - val_accuracy: 0.6552\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2067 - accuracy: 0.8870 - val_loss: 0.2406 - val_accuracy: 0.6552\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2087 - accuracy: 0.8435 - val_loss: 0.2152 - val_accuracy: 0.7586\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2077 - accuracy: 0.8522 - val_loss: 0.2116 - val_accuracy: 0.7586\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1947 - accuracy: 0.8609 - val_loss: 0.2238 - val_accuracy: 0.7241\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2052 - accuracy: 0.8609 - val_loss: 0.2180 - val_accuracy: 0.7241\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1894 - accuracy: 0.8609 - val_loss: 0.2039 - val_accuracy: 0.7586\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1916 - accuracy: 0.8870 - val_loss: 0.2031 - val_accuracy: 0.7586\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1920 - accuracy: 0.8870 - val_loss: 0.2052 - val_accuracy: 0.7586\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2010 - accuracy: 0.8348 - val_loss: 0.1995 - val_accuracy: 0.7586\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1942 - accuracy: 0.8696 - val_loss: 0.2053 - val_accuracy: 0.7586\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1945 - accuracy: 0.8522 - val_loss: 0.2041 - val_accuracy: 0.7586\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1847 - accuracy: 0.8609 - val_loss: 0.2014 - val_accuracy: 0.7586\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1759 - accuracy: 0.9043 - val_loss: 0.2008 - val_accuracy: 0.7586\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1831 - accuracy: 0.8609 - val_loss: 0.1988 - val_accuracy: 0.7586\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1845 - accuracy: 0.8957 - val_loss: 0.1961 - val_accuracy: 0.7586\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1720 - accuracy: 0.9304 - val_loss: 0.1952 - val_accuracy: 0.7586\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1700 - accuracy: 0.9043 - val_loss: 0.1932 - val_accuracy: 0.7586\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1661 - accuracy: 0.9043 - val_loss: 0.1928 - val_accuracy: 0.7586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1672 - accuracy: 0.9217 - val_loss: 0.1917 - val_accuracy: 0.7586\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1794 - accuracy: 0.9043 - val_loss: 0.1900 - val_accuracy: 0.7931\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1631 - accuracy: 0.9043 - val_loss: 0.1898 - val_accuracy: 0.7931\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1690 - accuracy: 0.9130 - val_loss: 0.2041 - val_accuracy: 0.7241\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1561 - accuracy: 0.9304 - val_loss: 0.1905 - val_accuracy: 0.7586\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1608 - accuracy: 0.9130 - val_loss: 0.2018 - val_accuracy: 0.7241\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1511 - accuracy: 0.9217 - val_loss: 0.1991 - val_accuracy: 0.7241\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1516 - accuracy: 0.9217 - val_loss: 0.2025 - val_accuracy: 0.7241\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1463 - accuracy: 0.9304 - val_loss: 0.2007 - val_accuracy: 0.7241\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1410 - accuracy: 0.9304 - val_loss: 0.1987 - val_accuracy: 0.7241\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1511 - accuracy: 0.9217 - val_loss: 0.1885 - val_accuracy: 0.7586\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1518 - accuracy: 0.9478 - val_loss: 0.1845 - val_accuracy: 0.7586\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1344 - accuracy: 0.9478 - val_loss: 0.1816 - val_accuracy: 0.8276\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1381 - accuracy: 0.9304 - val_loss: 0.1894 - val_accuracy: 0.7931\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1393 - accuracy: 0.9304 - val_loss: 0.1867 - val_accuracy: 0.7931\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1256 - accuracy: 0.9391 - val_loss: 0.1864 - val_accuracy: 0.7931\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1289 - accuracy: 0.9304 - val_loss: 0.1898 - val_accuracy: 0.7931\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1347 - accuracy: 0.9391 - val_loss: 0.1946 - val_accuracy: 0.7586\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1376 - accuracy: 0.9391 - val_loss: 0.2039 - val_accuracy: 0.6897\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1332 - accuracy: 0.9304 - val_loss: 0.1973 - val_accuracy: 0.7586\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1219 - accuracy: 0.9304 - val_loss: 0.1905 - val_accuracy: 0.7586\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1308 - accuracy: 0.9391 - val_loss: 0.1894 - val_accuracy: 0.7586\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1212 - accuracy: 0.9565 - val_loss: 0.1892 - val_accuracy: 0.7586\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1287 - accuracy: 0.9478 - val_loss: 0.1876 - val_accuracy: 0.7586\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1258 - accuracy: 0.9478 - val_loss: 0.1856 - val_accuracy: 0.7586\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1129 - accuracy: 0.9652 - val_loss: 0.1836 - val_accuracy: 0.7586\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1191 - accuracy: 0.9478 - val_loss: 0.1737 - val_accuracy: 0.7931\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1209 - accuracy: 0.9478 - val_loss: 0.1743 - val_accuracy: 0.7931\n",
      "0.9166666865348816\n",
      "fitness pass\n",
      "[(0.8333333134651184, 957148127537610), (0.4583333432674408, 923441258232480), (0.7291666865348816, 923441258232480), (0.6145833134651184, 957462487713885), (0.7708333134651184, 957257731074506), (0.6458333134651184, 923441258232480), (0.6354166865348816, 923441258211786), (0.59375, 923441258232266), (0.6041666865348816, 923441306069450), (0.8854166865348816, 957462487713885), (0.9166666865348816, 923447748520394)]\n",
      "[923447748520394, 957462487713885]\n",
      "[923447748520394, 957462487713885, 957148127537610, 957257731074506, 923441258232480, 923441258211786, 957462487713885, 923441306069450, 923441258232266, 923441258232480]\n",
      "selection pass\n",
      "target_count:\n",
      "1\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "0\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "1\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "2\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "3\n",
      "957257731074506\n",
      "11011001101001111011101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "4\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "5\n",
      "923441258211786\n",
      "11010001111101110101101100001010101010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "6\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "7\n",
      "923441306069450\n",
      "11010001111101110101101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "8\n",
      "923441258232266\n",
      "11010001111101110101101100001010101111100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "9\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "10\n",
      "957526118693322\n",
      "11011001101101110101101100001010101111100111001010\n",
      "crossover pass\n",
      "變異後的種群\n",
      "染色體：\n",
      "0\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "1\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "2\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "3\n",
      "957257731074506\n",
      "11011001101001111011101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "4\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "變異後的種群\n",
      "染色體：\n",
      "5\n",
      "923441258211786\n",
      "11010001111101110101101100001010101010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "6\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "7\n",
      "923441306069450\n",
      "11010001111101110101101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "8\n",
      "923441258232266\n",
      "11010001111101110101101100001010101111100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "9\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "變異後的種群\n",
      "染色體：\n",
      "10\n",
      "957526118693322\n",
      "11011001101101110101101100001010101111100111001010\n",
      "mutation pass\n",
      "迭代次數： 4\n",
      "4\n",
      "所選擇的染色體：\n",
      "11010001111101111011101111000001001110100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_88 (LSTM)               (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_89 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.2870 - accuracy: 0.5913 - val_loss: 0.5019 - val_accuracy: 0.4138\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2443 - accuracy: 0.6957 - val_loss: 0.4492 - val_accuracy: 0.4138\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2549 - accuracy: 0.6174 - val_loss: 0.4288 - val_accuracy: 0.4138\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2239 - accuracy: 0.7391 - val_loss: 0.3831 - val_accuracy: 0.4138\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1979 - accuracy: 0.8087 - val_loss: 0.2873 - val_accuracy: 0.5862\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1911 - accuracy: 0.8870 - val_loss: 0.2900 - val_accuracy: 0.5517\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2440 - accuracy: 0.7217 - val_loss: 0.3549 - val_accuracy: 0.4828\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2605 - accuracy: 0.7043 - val_loss: 0.3315 - val_accuracy: 0.5517\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2879 - accuracy: 0.4870 - val_loss: 0.4427 - val_accuracy: 0.3448\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3062 - accuracy: 0.4696 - val_loss: 0.5049 - val_accuracy: 0.3103\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3141 - accuracy: 0.4261 - val_loss: 0.4601 - val_accuracy: 0.5172\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2996 - accuracy: 0.4783 - val_loss: 0.4670 - val_accuracy: 0.4138\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2915 - accuracy: 0.5217 - val_loss: 0.3679 - val_accuracy: 0.5172\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2873 - accuracy: 0.5391 - val_loss: 0.3318 - val_accuracy: 0.5517\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2541 - accuracy: 0.7043 - val_loss: 0.2815 - val_accuracy: 0.3793\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2568 - accuracy: 0.6609 - val_loss: 0.3066 - val_accuracy: 0.4138\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2607 - accuracy: 0.6435 - val_loss: 0.2936 - val_accuracy: 0.4138\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2413 - accuracy: 0.6870 - val_loss: 0.2953 - val_accuracy: 0.4483\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2550 - accuracy: 0.6174 - val_loss: 0.3248 - val_accuracy: 0.4138\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2475 - accuracy: 0.6522 - val_loss: 0.2762 - val_accuracy: 0.4138\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2531 - accuracy: 0.6522 - val_loss: 0.2704 - val_accuracy: 0.4828\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2354 - accuracy: 0.6783 - val_loss: 0.2627 - val_accuracy: 0.4483\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2324 - accuracy: 0.7739 - val_loss: 0.2685 - val_accuracy: 0.4483\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2773 - accuracy: 0.5478 - val_loss: 0.2660 - val_accuracy: 0.3793\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2510 - accuracy: 0.6696 - val_loss: 0.2533 - val_accuracy: 0.4483\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2770 - accuracy: 0.5391 - val_loss: 0.2995 - val_accuracy: 0.4483\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2590 - accuracy: 0.5043 - val_loss: 0.2854 - val_accuracy: 0.3793\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2465 - accuracy: 0.6000 - val_loss: 0.3464 - val_accuracy: 0.4138\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2769 - accuracy: 0.5652 - val_loss: 0.3614 - val_accuracy: 0.3793\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2698 - accuracy: 0.6174 - val_loss: 0.3496 - val_accuracy: 0.4483\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2862 - accuracy: 0.5304 - val_loss: 0.4992 - val_accuracy: 0.3448\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2831 - accuracy: 0.5652 - val_loss: 0.2605 - val_accuracy: 0.4828\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2557 - accuracy: 0.6000 - val_loss: 0.2672 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2491 - accuracy: 0.6000 - val_loss: 0.2670 - val_accuracy: 0.4138\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2597 - accuracy: 0.4957 - val_loss: 0.2678 - val_accuracy: 0.4138\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2536 - accuracy: 0.5826 - val_loss: 0.2681 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2528 - accuracy: 0.4783 - val_loss: 0.2684 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2474 - accuracy: 0.6000 - val_loss: 0.2685 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2642 - accuracy: 0.5652 - val_loss: 0.2687 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2360 - accuracy: 0.5652 - val_loss: 0.2691 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2495 - accuracy: 0.5304 - val_loss: 0.2694 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2446 - accuracy: 0.5217 - val_loss: 0.2704 - val_accuracy: 0.4138\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2576 - accuracy: 0.5652 - val_loss: 0.2704 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2578 - accuracy: 0.5478 - val_loss: 0.2710 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2519 - accuracy: 0.5565 - val_loss: 0.2714 - val_accuracy: 0.4138\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2446 - accuracy: 0.5565 - val_loss: 0.2716 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2289 - accuracy: 0.6000 - val_loss: 0.2719 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2349 - accuracy: 0.6000 - val_loss: 0.2723 - val_accuracy: 0.4138\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2339 - accuracy: 0.6000 - val_loss: 0.2725 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2426 - accuracy: 0.5913 - val_loss: 0.2729 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2372 - accuracy: 0.5913 - val_loss: 0.2735 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2373 - accuracy: 0.5826 - val_loss: 0.2739 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2378 - accuracy: 0.5652 - val_loss: 0.2740 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2346 - accuracy: 0.5739 - val_loss: 0.2744 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2309 - accuracy: 0.6000 - val_loss: 0.2745 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2326 - accuracy: 0.5913 - val_loss: 0.2749 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2281 - accuracy: 0.6000 - val_loss: 0.2750 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2251 - accuracy: 0.6000 - val_loss: 0.2754 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2265 - accuracy: 0.6000 - val_loss: 0.2757 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2276 - accuracy: 0.5826 - val_loss: 0.2760 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2294 - accuracy: 0.5739 - val_loss: 0.2763 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2345 - accuracy: 0.5913 - val_loss: 0.2764 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2276 - accuracy: 0.5652 - val_loss: 0.2764 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2351 - accuracy: 0.5478 - val_loss: 0.2765 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2292 - accuracy: 0.6000 - val_loss: 0.2765 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2306 - accuracy: 0.6000 - val_loss: 0.2765 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2293 - accuracy: 0.5913 - val_loss: 0.2764 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2290 - accuracy: 0.5739 - val_loss: 0.2764 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2322 - accuracy: 0.5478 - val_loss: 0.2760 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2261 - accuracy: 0.6000 - val_loss: 0.2760 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2277 - accuracy: 0.6000 - val_loss: 0.2764 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2304 - accuracy: 0.5913 - val_loss: 0.2762 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2299 - accuracy: 0.6000 - val_loss: 0.2760 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2280 - accuracy: 0.5913 - val_loss: 0.2759 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2282 - accuracy: 0.5826 - val_loss: 0.2764 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2282 - accuracy: 0.6000 - val_loss: 0.2765 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2314 - accuracy: 0.5913 - val_loss: 0.2772 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2433 - accuracy: 0.6087 - val_loss: 0.2906 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2450 - accuracy: 0.6261 - val_loss: 0.2791 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2449 - accuracy: 0.5739 - val_loss: 0.2812 - val_accuracy: 0.4138\n",
      "0.6145833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101100111010011011011101110100100001011101\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_90 (LSTM)               (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_91 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 191ms/step - loss: 0.2649 - accuracy: 0.5739 - val_loss: 0.3130 - val_accuracy: 0.7241\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2919 - accuracy: 0.4261 - val_loss: 0.3317 - val_accuracy: 0.4828\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2778 - accuracy: 0.4696 - val_loss: 0.4150 - val_accuracy: 0.5172\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2832 - accuracy: 0.5217 - val_loss: 0.2988 - val_accuracy: 0.6207\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2758 - accuracy: 0.5478 - val_loss: 0.2765 - val_accuracy: 0.5862\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2544 - accuracy: 0.6087 - val_loss: 0.2912 - val_accuracy: 0.4828\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2900 - accuracy: 0.4087 - val_loss: 0.3093 - val_accuracy: 0.4138\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2627 - accuracy: 0.5217 - val_loss: 0.3400 - val_accuracy: 0.2069\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2778 - accuracy: 0.4870 - val_loss: 0.3470 - val_accuracy: 0.4483\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3019 - accuracy: 0.4522 - val_loss: 0.2619 - val_accuracy: 0.6207\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2654 - accuracy: 0.5391 - val_loss: 0.3056 - val_accuracy: 0.4828\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2653 - accuracy: 0.5391 - val_loss: 0.2597 - val_accuracy: 0.5862\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2968 - accuracy: 0.3913 - val_loss: 0.2984 - val_accuracy: 0.4828\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2927 - accuracy: 0.3826 - val_loss: 0.3066 - val_accuracy: 0.4138\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2500 - accuracy: 0.5826 - val_loss: 0.2790 - val_accuracy: 0.4138\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2722 - accuracy: 0.4696 - val_loss: 0.2659 - val_accuracy: 0.4483\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2824 - accuracy: 0.4522 - val_loss: 0.2842 - val_accuracy: 0.4138\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2906 - accuracy: 0.4348 - val_loss: 0.2561 - val_accuracy: 0.5172\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2942 - accuracy: 0.4870 - val_loss: 0.2536 - val_accuracy: 0.4483\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2678 - accuracy: 0.6522 - val_loss: 0.2148 - val_accuracy: 0.5862\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2729 - accuracy: 0.6000 - val_loss: 0.2260 - val_accuracy: 0.5172\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2763 - accuracy: 0.5826 - val_loss: 0.2325 - val_accuracy: 0.4828\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2679 - accuracy: 0.5913 - val_loss: 0.1952 - val_accuracy: 0.6207\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2544 - accuracy: 0.6000 - val_loss: 0.2748 - val_accuracy: 0.3793\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2488 - accuracy: 0.6522 - val_loss: 0.2875 - val_accuracy: 0.4828\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2668 - accuracy: 0.4957 - val_loss: 0.2783 - val_accuracy: 0.3793\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2479 - accuracy: 0.7304 - val_loss: 0.2772 - val_accuracy: 0.4138\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2346 - accuracy: 0.7565 - val_loss: 0.3197 - val_accuracy: 0.3793\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2532 - accuracy: 0.6435 - val_loss: 0.3015 - val_accuracy: 0.3793\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2457 - accuracy: 0.6870 - val_loss: 0.3065 - val_accuracy: 0.4138\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2551 - accuracy: 0.6348 - val_loss: 0.2697 - val_accuracy: 0.4138\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2387 - accuracy: 0.7304 - val_loss: 0.2825 - val_accuracy: 0.4483\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2492 - accuracy: 0.6087 - val_loss: 0.3598 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2554 - accuracy: 0.6261 - val_loss: 0.2691 - val_accuracy: 0.4483\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2580 - accuracy: 0.5217 - val_loss: 0.2572 - val_accuracy: 0.5172\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2564 - accuracy: 0.6261 - val_loss: 0.2534 - val_accuracy: 0.4828\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2596 - accuracy: 0.5304 - val_loss: 0.2916 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2345 - accuracy: 0.7217 - val_loss: 0.2540 - val_accuracy: 0.4483\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2152 - accuracy: 0.7217 - val_loss: 0.2528 - val_accuracy: 0.4483\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2029 - accuracy: 0.7478 - val_loss: 0.2439 - val_accuracy: 0.5172\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2345 - accuracy: 0.7217 - val_loss: 0.2641 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2400 - accuracy: 0.6087 - val_loss: 0.2588 - val_accuracy: 0.4483\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2430 - accuracy: 0.6435 - val_loss: 0.2732 - val_accuracy: 0.3448\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2629 - accuracy: 0.5739 - val_loss: 0.2905 - val_accuracy: 0.3448\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2341 - accuracy: 0.7478 - val_loss: 0.2719 - val_accuracy: 0.3793\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2696 - accuracy: 0.5913 - val_loss: 0.2620 - val_accuracy: 0.3793\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2234 - accuracy: 0.7304 - val_loss: 0.2793 - val_accuracy: 0.3793\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2178 - accuracy: 0.6609 - val_loss: 0.2743 - val_accuracy: 0.3793\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2176 - accuracy: 0.6522 - val_loss: 0.2564 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2517 - accuracy: 0.6000 - val_loss: 0.2594 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2606 - accuracy: 0.5826 - val_loss: 0.2684 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2291 - accuracy: 0.7217 - val_loss: 0.2733 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2471 - accuracy: 0.6609 - val_loss: 0.2690 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2324 - accuracy: 0.6261 - val_loss: 0.2735 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2498 - accuracy: 0.5826 - val_loss: 0.2765 - val_accuracy: 0.3793\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2296 - accuracy: 0.6609 - val_loss: 0.2720 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2552 - accuracy: 0.6000 - val_loss: 0.2654 - val_accuracy: 0.4483\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2308 - accuracy: 0.6609 - val_loss: 0.2666 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2237 - accuracy: 0.7043 - val_loss: 0.2729 - val_accuracy: 0.3793\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2329 - accuracy: 0.6522 - val_loss: 0.2710 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2100 - accuracy: 0.6696 - val_loss: 0.2617 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2265 - accuracy: 0.7304 - val_loss: 0.2612 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2007 - accuracy: 0.7652 - val_loss: 0.2598 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2165 - accuracy: 0.7130 - val_loss: 0.2638 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2269 - accuracy: 0.7043 - val_loss: 0.2732 - val_accuracy: 0.3793\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2218 - accuracy: 0.7043 - val_loss: 0.2727 - val_accuracy: 0.3793\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2260 - accuracy: 0.6696 - val_loss: 0.2729 - val_accuracy: 0.3448\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2252 - accuracy: 0.6522 - val_loss: 0.2597 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2128 - accuracy: 0.7130 - val_loss: 0.2580 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2041 - accuracy: 0.7652 - val_loss: 0.2587 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2004 - accuracy: 0.7130 - val_loss: 0.2733 - val_accuracy: 0.3793\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2099 - accuracy: 0.6696 - val_loss: 0.2637 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1931 - accuracy: 0.7652 - val_loss: 0.2571 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1976 - accuracy: 0.7391 - val_loss: 0.2589 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2066 - accuracy: 0.7478 - val_loss: 0.2688 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2115 - accuracy: 0.6957 - val_loss: 0.2660 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1936 - accuracy: 0.7478 - val_loss: 0.2618 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2225 - accuracy: 0.6435 - val_loss: 0.2697 - val_accuracy: 0.3793\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2280 - accuracy: 0.6261 - val_loss: 0.2583 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2107 - accuracy: 0.6696 - val_loss: 0.2585 - val_accuracy: 0.4138\n",
      "0.59375\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101000010101101010001000111010100111001010\n",
      "26\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 2880)\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_92 (LSTM)               (None, 100, 20)           232080    \n",
      "_________________________________________________________________\n",
      "lstm_93 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 235,482\n",
      "Trainable params: 235,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.3421 - accuracy: 0.3913 - val_loss: 0.4303 - val_accuracy: 0.4828\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2761 - accuracy: 0.5565 - val_loss: 0.4580 - val_accuracy: 0.2069\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.3273 - accuracy: 0.3304 - val_loss: 0.4796 - val_accuracy: 0.1724\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2835 - accuracy: 0.4696 - val_loss: 0.3371 - val_accuracy: 0.3448\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2911 - accuracy: 0.5217 - val_loss: 0.3662 - val_accuracy: 0.4828\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2605 - accuracy: 0.5739 - val_loss: 0.4435 - val_accuracy: 0.3103\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2753 - accuracy: 0.4957 - val_loss: 0.3328 - val_accuracy: 0.5172\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2351 - accuracy: 0.6261 - val_loss: 0.2649 - val_accuracy: 0.6207\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1639 - accuracy: 0.9043 - val_loss: 0.3022 - val_accuracy: 0.5517\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1896 - accuracy: 0.7913 - val_loss: 0.2594 - val_accuracy: 0.7241\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2183 - accuracy: 0.6522 - val_loss: 0.3171 - val_accuracy: 0.6207\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2289 - accuracy: 0.7304 - val_loss: 0.2135 - val_accuracy: 0.6552\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1861 - accuracy: 0.8087 - val_loss: 0.1849 - val_accuracy: 0.6552\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1695 - accuracy: 0.8348 - val_loss: 0.1196 - val_accuracy: 0.8621\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1726 - accuracy: 0.8783 - val_loss: 0.1696 - val_accuracy: 0.6552\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1826 - accuracy: 0.8957 - val_loss: 0.2285 - val_accuracy: 0.6207\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1750 - accuracy: 0.8870 - val_loss: 0.2248 - val_accuracy: 0.6552\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1677 - accuracy: 0.9217 - val_loss: 0.2210 - val_accuracy: 0.6207\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1695 - accuracy: 0.8261 - val_loss: 0.2127 - val_accuracy: 0.6207\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1803 - accuracy: 0.8435 - val_loss: 0.2219 - val_accuracy: 0.5862\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1497 - accuracy: 0.8870 - val_loss: 0.1534 - val_accuracy: 0.8621\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1344 - accuracy: 0.8957 - val_loss: 0.1331 - val_accuracy: 0.8966\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1677 - accuracy: 0.8522 - val_loss: 0.1148 - val_accuracy: 0.8621\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1424 - accuracy: 0.8609 - val_loss: 0.1887 - val_accuracy: 0.6897\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1620 - accuracy: 0.8348 - val_loss: 0.1429 - val_accuracy: 0.7586\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1375 - accuracy: 0.8957 - val_loss: 0.1454 - val_accuracy: 0.8621\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1369 - accuracy: 0.9391 - val_loss: 0.1378 - val_accuracy: 0.8621\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1373 - accuracy: 0.9304 - val_loss: 0.1607 - val_accuracy: 0.7586\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1125 - accuracy: 0.9391 - val_loss: 0.1515 - val_accuracy: 0.8621\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1788 - accuracy: 0.7913 - val_loss: 0.1315 - val_accuracy: 0.9310\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1696 - accuracy: 0.8348 - val_loss: 0.1268 - val_accuracy: 0.9310\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1544 - accuracy: 0.8174 - val_loss: 0.1489 - val_accuracy: 0.8621\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1408 - accuracy: 0.8522 - val_loss: 0.1033 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1502 - accuracy: 0.8174 - val_loss: 0.1269 - val_accuracy: 0.8276\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2025 - accuracy: 0.7043 - val_loss: 0.2707 - val_accuracy: 0.4483\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2189 - accuracy: 0.6783 - val_loss: 0.2829 - val_accuracy: 0.4483\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1991 - accuracy: 0.6957 - val_loss: 0.2178 - val_accuracy: 0.7241\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2049 - accuracy: 0.7130 - val_loss: 0.1842 - val_accuracy: 0.7586\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1923 - accuracy: 0.7217 - val_loss: 0.2308 - val_accuracy: 0.7241\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1960 - accuracy: 0.7130 - val_loss: 0.2419 - val_accuracy: 0.5517\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2399 - accuracy: 0.6348 - val_loss: 0.2403 - val_accuracy: 0.5172\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2131 - accuracy: 0.6522 - val_loss: 0.2544 - val_accuracy: 0.5172\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2300 - accuracy: 0.6261 - val_loss: 0.2404 - val_accuracy: 0.5172\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2183 - accuracy: 0.6957 - val_loss: 0.2591 - val_accuracy: 0.5517\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1823 - accuracy: 0.7826 - val_loss: 0.0940 - val_accuracy: 0.8966\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1132 - accuracy: 0.9130 - val_loss: 0.0723 - val_accuracy: 0.9310\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.1128 - accuracy: 0.9043 - val_loss: 0.0727 - val_accuracy: 0.9310\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1224 - accuracy: 0.9130 - val_loss: 0.0949 - val_accuracy: 0.8966\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1139 - accuracy: 0.8957 - val_loss: 0.0998 - val_accuracy: 0.8966\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1317 - accuracy: 0.8435 - val_loss: 0.1494 - val_accuracy: 0.7931\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1095 - accuracy: 0.9304 - val_loss: 0.0913 - val_accuracy: 0.9655\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1167 - accuracy: 0.8870 - val_loss: 0.2645 - val_accuracy: 0.5172\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2081 - accuracy: 0.6609 - val_loss: 0.3859 - val_accuracy: 0.3103\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2466 - accuracy: 0.6435 - val_loss: 0.3449 - val_accuracy: 0.4483\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2290 - accuracy: 0.6435 - val_loss: 0.3443 - val_accuracy: 0.4828\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2219 - accuracy: 0.7043 - val_loss: 0.3094 - val_accuracy: 0.5517\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2610 - accuracy: 0.6174 - val_loss: 0.3378 - val_accuracy: 0.5862\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2409 - accuracy: 0.5913 - val_loss: 0.3944 - val_accuracy: 0.3793\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2726 - accuracy: 0.5304 - val_loss: 0.3522 - val_accuracy: 0.3793\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2859 - accuracy: 0.5478 - val_loss: 0.3180 - val_accuracy: 0.4483\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2513 - accuracy: 0.6348 - val_loss: 0.2956 - val_accuracy: 0.4483\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.2657 - accuracy: 0.5652 - val_loss: 0.2801 - val_accuracy: 0.4828\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2734 - accuracy: 0.5739 - val_loss: 0.4037 - val_accuracy: 0.3448\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2912 - accuracy: 0.5304 - val_loss: 0.3515 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2740 - accuracy: 0.6174 - val_loss: 0.2993 - val_accuracy: 0.5172\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.3309 - accuracy: 0.5391 - val_loss: 0.4231 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2832 - accuracy: 0.6087 - val_loss: 0.3856 - val_accuracy: 0.5172\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.2944 - accuracy: 0.6000 - val_loss: 0.3820 - val_accuracy: 0.4483\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2754 - accuracy: 0.6000 - val_loss: 0.3098 - val_accuracy: 0.4828\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.2743 - accuracy: 0.5652 - val_loss: 0.3776 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.3025 - accuracy: 0.4957 - val_loss: 0.3320 - val_accuracy: 0.4483\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2686 - accuracy: 0.5391 - val_loss: 0.3471 - val_accuracy: 0.4828\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2804 - accuracy: 0.4957 - val_loss: 0.3113 - val_accuracy: 0.6207\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2898 - accuracy: 0.4696 - val_loss: 0.3440 - val_accuracy: 0.4483\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.3140 - accuracy: 0.4261 - val_loss: 0.3364 - val_accuracy: 0.4828\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.3021 - accuracy: 0.4261 - val_loss: 0.3260 - val_accuracy: 0.4828\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.3015 - accuracy: 0.4435 - val_loss: 0.3540 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2944 - accuracy: 0.4609 - val_loss: 0.3371 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.2807 - accuracy: 0.5043 - val_loss: 0.2942 - val_accuracy: 0.4483\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2958 - accuracy: 0.4696 - val_loss: 0.2843 - val_accuracy: 0.4483\n",
      "0.625\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101001111011101111000001001110100111001010\n",
      "22\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3360)\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_94 (LSTM)               (None, 100, 20)           270480    \n",
      "_________________________________________________________________\n",
      "lstm_95 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 273,882\n",
      "Trainable params: 273,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 0.3864 - accuracy: 0.2348 - val_loss: 0.3884 - val_accuracy: 0.5862\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2717 - accuracy: 0.3913 - val_loss: 0.2735 - val_accuracy: 0.6552\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2441 - accuracy: 0.5565 - val_loss: 0.3548 - val_accuracy: 0.6552\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2843 - accuracy: 0.5478 - val_loss: 0.4283 - val_accuracy: 0.3793\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2550 - accuracy: 0.5739 - val_loss: 0.3641 - val_accuracy: 0.4138\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.3634 - accuracy: 0.3217 - val_loss: 0.6103 - val_accuracy: 0.3793\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3544 - accuracy: 0.4000 - val_loss: 0.4636 - val_accuracy: 0.4483\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3437 - accuracy: 0.4261 - val_loss: 0.2609 - val_accuracy: 0.6207\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2316 - accuracy: 0.7217 - val_loss: 0.3235 - val_accuracy: 0.5172\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2929 - accuracy: 0.6087 - val_loss: 0.2443 - val_accuracy: 0.6552\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2785 - accuracy: 0.5478 - val_loss: 0.3151 - val_accuracy: 0.5517\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2487 - accuracy: 0.6522 - val_loss: 0.3248 - val_accuracy: 0.5172\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3155 - accuracy: 0.5478 - val_loss: 0.3273 - val_accuracy: 0.5517\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3141 - accuracy: 0.5304 - val_loss: 0.3455 - val_accuracy: 0.5862\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3245 - accuracy: 0.4435 - val_loss: 0.3246 - val_accuracy: 0.5517\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3079 - accuracy: 0.4957 - val_loss: 0.3441 - val_accuracy: 0.5172\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3380 - accuracy: 0.4783 - val_loss: 0.3472 - val_accuracy: 0.5172\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3254 - accuracy: 0.4783 - val_loss: 0.3160 - val_accuracy: 0.5862\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.3027 - accuracy: 0.5478 - val_loss: 0.3265 - val_accuracy: 0.5517\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3139 - accuracy: 0.4696 - val_loss: 0.3598 - val_accuracy: 0.5172\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3143 - accuracy: 0.4435 - val_loss: 0.2583 - val_accuracy: 0.5862\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3184 - accuracy: 0.5043 - val_loss: 0.3468 - val_accuracy: 0.5517\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3025 - accuracy: 0.4957 - val_loss: 0.3051 - val_accuracy: 0.5517\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3076 - accuracy: 0.5304 - val_loss: 0.2982 - val_accuracy: 0.5517\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3116 - accuracy: 0.5826 - val_loss: 0.3470 - val_accuracy: 0.4828\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3069 - accuracy: 0.5565 - val_loss: 0.2943 - val_accuracy: 0.5862\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2832 - accuracy: 0.5826 - val_loss: 0.2564 - val_accuracy: 0.6552\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2275 - accuracy: 0.7130 - val_loss: 0.2104 - val_accuracy: 0.7241\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2218 - accuracy: 0.6609 - val_loss: 0.2359 - val_accuracy: 0.6207\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2191 - accuracy: 0.6696 - val_loss: 0.2455 - val_accuracy: 0.6897\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2755 - accuracy: 0.5652 - val_loss: 0.2956 - val_accuracy: 0.5517\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2888 - accuracy: 0.5304 - val_loss: 0.3154 - val_accuracy: 0.4828\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2965 - accuracy: 0.5391 - val_loss: 0.2896 - val_accuracy: 0.6207\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3023 - accuracy: 0.5826 - val_loss: 0.2950 - val_accuracy: 0.5517\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3079 - accuracy: 0.5478 - val_loss: 0.2964 - val_accuracy: 0.6207\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2841 - accuracy: 0.5739 - val_loss: 0.2958 - val_accuracy: 0.6207\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2738 - accuracy: 0.6087 - val_loss: 0.3075 - val_accuracy: 0.5517\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2715 - accuracy: 0.6174 - val_loss: 0.2917 - val_accuracy: 0.5862\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2899 - accuracy: 0.6000 - val_loss: 0.2883 - val_accuracy: 0.5517\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2842 - accuracy: 0.6261 - val_loss: 0.3060 - val_accuracy: 0.5172\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2690 - accuracy: 0.6522 - val_loss: 0.3060 - val_accuracy: 0.5517\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2654 - accuracy: 0.6522 - val_loss: 0.2742 - val_accuracy: 0.5172\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2622 - accuracy: 0.6435 - val_loss: 0.2959 - val_accuracy: 0.5517\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2513 - accuracy: 0.6348 - val_loss: 0.2838 - val_accuracy: 0.6207\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2687 - accuracy: 0.6435 - val_loss: 0.2819 - val_accuracy: 0.6207\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2621 - accuracy: 0.6000 - val_loss: 0.2679 - val_accuracy: 0.5862\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2787 - accuracy: 0.5826 - val_loss: 0.2797 - val_accuracy: 0.5172\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2492 - accuracy: 0.6348 - val_loss: 0.3106 - val_accuracy: 0.5172\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2625 - accuracy: 0.6522 - val_loss: 0.3221 - val_accuracy: 0.5172\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2510 - accuracy: 0.6609 - val_loss: 0.3204 - val_accuracy: 0.4828\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2577 - accuracy: 0.6348 - val_loss: 0.3226 - val_accuracy: 0.5517\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2433 - accuracy: 0.6696 - val_loss: 0.2907 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2575 - accuracy: 0.6870 - val_loss: 0.2902 - val_accuracy: 0.5862\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2451 - accuracy: 0.6783 - val_loss: 0.2826 - val_accuracy: 0.6207\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2463 - accuracy: 0.6783 - val_loss: 0.2584 - val_accuracy: 0.5862\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2376 - accuracy: 0.6435 - val_loss: 0.2693 - val_accuracy: 0.5517\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2301 - accuracy: 0.6696 - val_loss: 0.2904 - val_accuracy: 0.5172\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2261 - accuracy: 0.6870 - val_loss: 0.2823 - val_accuracy: 0.5172\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2317 - accuracy: 0.6783 - val_loss: 0.2649 - val_accuracy: 0.5517\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2425 - accuracy: 0.6522 - val_loss: 0.2690 - val_accuracy: 0.5517\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2352 - accuracy: 0.6696 - val_loss: 0.2937 - val_accuracy: 0.5517\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2238 - accuracy: 0.7217 - val_loss: 0.2973 - val_accuracy: 0.5517\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2185 - accuracy: 0.7217 - val_loss: 0.2823 - val_accuracy: 0.5862\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2296 - accuracy: 0.6870 - val_loss: 0.2906 - val_accuracy: 0.5517\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2144 - accuracy: 0.7043 - val_loss: 0.2889 - val_accuracy: 0.5862\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2108 - accuracy: 0.7130 - val_loss: 0.2993 - val_accuracy: 0.5517\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2052 - accuracy: 0.7304 - val_loss: 0.3043 - val_accuracy: 0.5862\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2183 - accuracy: 0.7043 - val_loss: 0.3002 - val_accuracy: 0.6207\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2090 - accuracy: 0.7304 - val_loss: 0.2989 - val_accuracy: 0.6207\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2124 - accuracy: 0.7043 - val_loss: 0.3005 - val_accuracy: 0.5862\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2133 - accuracy: 0.7130 - val_loss: 0.2760 - val_accuracy: 0.5862\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2081 - accuracy: 0.7217 - val_loss: 0.2774 - val_accuracy: 0.5862\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2215 - accuracy: 0.6870 - val_loss: 0.2729 - val_accuracy: 0.6207\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2139 - accuracy: 0.7304 - val_loss: 0.2743 - val_accuracy: 0.6207\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2175 - accuracy: 0.7217 - val_loss: 0.2705 - val_accuracy: 0.6552\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2070 - accuracy: 0.7478 - val_loss: 0.2844 - val_accuracy: 0.6552\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2001 - accuracy: 0.7565 - val_loss: 0.2498 - val_accuracy: 0.6897\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2014 - accuracy: 0.7217 - val_loss: 0.2480 - val_accuracy: 0.6552\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1993 - accuracy: 0.7043 - val_loss: 0.2596 - val_accuracy: 0.6552\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2001 - accuracy: 0.7304 - val_loss: 0.2519 - val_accuracy: 0.6897\n",
      "0.6979166865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111101010100000\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n",
      "(144, 100, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_96 (LSTM)               (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_97 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.2511 - accuracy: 0.5826 - val_loss: 0.2724 - val_accuracy: 0.6207\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1752 - accuracy: 0.7478 - val_loss: 0.1881 - val_accuracy: 0.8621\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1369 - accuracy: 0.8435 - val_loss: 0.2562 - val_accuracy: 0.6207\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1725 - accuracy: 0.7739 - val_loss: 0.3175 - val_accuracy: 0.5172\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1880 - accuracy: 0.7565 - val_loss: 0.3893 - val_accuracy: 0.5172\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2625 - accuracy: 0.5652 - val_loss: 0.3822 - val_accuracy: 0.5172\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2833 - accuracy: 0.5826 - val_loss: 0.2630 - val_accuracy: 0.6207\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2833 - accuracy: 0.4957 - val_loss: 0.2774 - val_accuracy: 0.5862\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2668 - accuracy: 0.5913 - val_loss: 0.2820 - val_accuracy: 0.5517\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2247 - accuracy: 0.5913 - val_loss: 0.2723 - val_accuracy: 0.6207\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2396 - accuracy: 0.5739 - val_loss: 0.2741 - val_accuracy: 0.5172\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2528 - accuracy: 0.5913 - val_loss: 0.2584 - val_accuracy: 0.5862\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2575 - accuracy: 0.5739 - val_loss: 0.2452 - val_accuracy: 0.6207\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2608 - accuracy: 0.5913 - val_loss: 0.2936 - val_accuracy: 0.5862\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2463 - accuracy: 0.7043 - val_loss: 0.2261 - val_accuracy: 0.5862\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2263 - accuracy: 0.7130 - val_loss: 0.1915 - val_accuracy: 0.6897\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2267 - accuracy: 0.7130 - val_loss: 0.2596 - val_accuracy: 0.5517\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2473 - accuracy: 0.6870 - val_loss: 0.2316 - val_accuracy: 0.5862\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2410 - accuracy: 0.7739 - val_loss: 0.2198 - val_accuracy: 0.6207\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2413 - accuracy: 0.5565 - val_loss: 0.2284 - val_accuracy: 0.5862\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2316 - accuracy: 0.7217 - val_loss: 0.2650 - val_accuracy: 0.5517\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2361 - accuracy: 0.6696 - val_loss: 0.2387 - val_accuracy: 0.5862\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2167 - accuracy: 0.7739 - val_loss: 0.2419 - val_accuracy: 0.5862\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2184 - accuracy: 0.8000 - val_loss: 0.2336 - val_accuracy: 0.6207\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2153 - accuracy: 0.8174 - val_loss: 0.2407 - val_accuracy: 0.6207\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2070 - accuracy: 0.8174 - val_loss: 0.2420 - val_accuracy: 0.6552\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2120 - accuracy: 0.8174 - val_loss: 0.2559 - val_accuracy: 0.5862\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2044 - accuracy: 0.8261 - val_loss: 0.2512 - val_accuracy: 0.6207\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2018 - accuracy: 0.8087 - val_loss: 0.2534 - val_accuracy: 0.6207\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2016 - accuracy: 0.7913 - val_loss: 0.2516 - val_accuracy: 0.6552\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1979 - accuracy: 0.8000 - val_loss: 0.2492 - val_accuracy: 0.6552\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2023 - accuracy: 0.7826 - val_loss: 0.2474 - val_accuracy: 0.6207\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2006 - accuracy: 0.8000 - val_loss: 0.2462 - val_accuracy: 0.6207\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1915 - accuracy: 0.8174 - val_loss: 0.2456 - val_accuracy: 0.6207\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1916 - accuracy: 0.8000 - val_loss: 0.2454 - val_accuracy: 0.6207\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1974 - accuracy: 0.7826 - val_loss: 0.2452 - val_accuracy: 0.6207\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1949 - accuracy: 0.7913 - val_loss: 0.2452 - val_accuracy: 0.6207\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1878 - accuracy: 0.8000 - val_loss: 0.2450 - val_accuracy: 0.6207\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1932 - accuracy: 0.7826 - val_loss: 0.2447 - val_accuracy: 0.6207\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1922 - accuracy: 0.7565 - val_loss: 0.2443 - val_accuracy: 0.6207\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1771 - accuracy: 0.8174 - val_loss: 0.2438 - val_accuracy: 0.6207\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1936 - accuracy: 0.7913 - val_loss: 0.2433 - val_accuracy: 0.6207\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1847 - accuracy: 0.8087 - val_loss: 0.2427 - val_accuracy: 0.6207\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1784 - accuracy: 0.8000 - val_loss: 0.2423 - val_accuracy: 0.6207\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1753 - accuracy: 0.8435 - val_loss: 0.2420 - val_accuracy: 0.6207\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1813 - accuracy: 0.7739 - val_loss: 0.2415 - val_accuracy: 0.6207\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1877 - accuracy: 0.7739 - val_loss: 0.2412 - val_accuracy: 0.6207\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1697 - accuracy: 0.8261 - val_loss: 0.2408 - val_accuracy: 0.6207\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1700 - accuracy: 0.8348 - val_loss: 0.2402 - val_accuracy: 0.6207\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1752 - accuracy: 0.8087 - val_loss: 0.2397 - val_accuracy: 0.6207\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1727 - accuracy: 0.7913 - val_loss: 0.2390 - val_accuracy: 0.6207\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1764 - accuracy: 0.8087 - val_loss: 0.2384 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1688 - accuracy: 0.8348 - val_loss: 0.2376 - val_accuracy: 0.6207\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1705 - accuracy: 0.7913 - val_loss: 0.2366 - val_accuracy: 0.6207\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1655 - accuracy: 0.8174 - val_loss: 0.2358 - val_accuracy: 0.6207\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1664 - accuracy: 0.8087 - val_loss: 0.2354 - val_accuracy: 0.6207\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1701 - accuracy: 0.8174 - val_loss: 0.2346 - val_accuracy: 0.6207\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1601 - accuracy: 0.8261 - val_loss: 0.2340 - val_accuracy: 0.6207\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1609 - accuracy: 0.8435 - val_loss: 0.2335 - val_accuracy: 0.6207\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1627 - accuracy: 0.8522 - val_loss: 0.2330 - val_accuracy: 0.6207\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1581 - accuracy: 0.8348 - val_loss: 0.2323 - val_accuracy: 0.6207\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1590 - accuracy: 0.8261 - val_loss: 0.2318 - val_accuracy: 0.6207\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1662 - accuracy: 0.8174 - val_loss: 0.2309 - val_accuracy: 0.6207\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1600 - accuracy: 0.8174 - val_loss: 0.2302 - val_accuracy: 0.6207\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1548 - accuracy: 0.8348 - val_loss: 0.2292 - val_accuracy: 0.6207\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1513 - accuracy: 0.8522 - val_loss: 0.2282 - val_accuracy: 0.6207\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1513 - accuracy: 0.8435 - val_loss: 0.2270 - val_accuracy: 0.6207\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1428 - accuracy: 0.8435 - val_loss: 0.2256 - val_accuracy: 0.6207\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1625 - accuracy: 0.8261 - val_loss: 0.2244 - val_accuracy: 0.6207\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1444 - accuracy: 0.8522 - val_loss: 0.2235 - val_accuracy: 0.6207\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1443 - accuracy: 0.8435 - val_loss: 0.2225 - val_accuracy: 0.6207\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1463 - accuracy: 0.8435 - val_loss: 0.2211 - val_accuracy: 0.6207\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1434 - accuracy: 0.8522 - val_loss: 0.2200 - val_accuracy: 0.6207\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1425 - accuracy: 0.8522 - val_loss: 0.2193 - val_accuracy: 0.6207\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1452 - accuracy: 0.8609 - val_loss: 0.2185 - val_accuracy: 0.6207\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1470 - accuracy: 0.8522 - val_loss: 0.2176 - val_accuracy: 0.6207\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1421 - accuracy: 0.8522 - val_loss: 0.2170 - val_accuracy: 0.6207\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1445 - accuracy: 0.8609 - val_loss: 0.2167 - val_accuracy: 0.6207\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1370 - accuracy: 0.8609 - val_loss: 0.2160 - val_accuracy: 0.6207\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1385 - accuracy: 0.8696 - val_loss: 0.2151 - val_accuracy: 0.6207\n",
      "0.8020833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101010100111001010\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n",
      "(144, 100, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_98 (LSTM)               (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_99 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.2677 - accuracy: 0.5565 - val_loss: 0.3845 - val_accuracy: 0.5517\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3146 - accuracy: 0.3826 - val_loss: 0.3267 - val_accuracy: 0.3448\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3599 - accuracy: 0.3565 - val_loss: 0.2970 - val_accuracy: 0.3793\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.3080 - accuracy: 0.5304 - val_loss: 0.2867 - val_accuracy: 0.4138\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2989 - accuracy: 0.4957 - val_loss: 0.2873 - val_accuracy: 0.3103\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2918 - accuracy: 0.5043 - val_loss: 0.3050 - val_accuracy: 0.3103\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2584 - accuracy: 0.6174 - val_loss: 0.2945 - val_accuracy: 0.3793\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2797 - accuracy: 0.4783 - val_loss: 0.2887 - val_accuracy: 0.3793\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2549 - accuracy: 0.5913 - val_loss: 0.2891 - val_accuracy: 0.3103\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2696 - accuracy: 0.4000 - val_loss: 0.3105 - val_accuracy: 0.3103\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2265 - accuracy: 0.7043 - val_loss: 0.2782 - val_accuracy: 0.3448\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2033 - accuracy: 0.7739 - val_loss: 0.2743 - val_accuracy: 0.3103\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2145 - accuracy: 0.7391 - val_loss: 0.2857 - val_accuracy: 0.2414\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1968 - accuracy: 0.8522 - val_loss: 0.2851 - val_accuracy: 0.2414\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2083 - accuracy: 0.7913 - val_loss: 0.2891 - val_accuracy: 0.3448\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2000 - accuracy: 0.8609 - val_loss: 0.2669 - val_accuracy: 0.4138\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1982 - accuracy: 0.8783 - val_loss: 0.2618 - val_accuracy: 0.4483\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2089 - accuracy: 0.8522 - val_loss: 0.2689 - val_accuracy: 0.3793\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1941 - accuracy: 0.8783 - val_loss: 0.2686 - val_accuracy: 0.3793\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1890 - accuracy: 0.8609 - val_loss: 0.2678 - val_accuracy: 0.4138\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1877 - accuracy: 0.8609 - val_loss: 0.2670 - val_accuracy: 0.4138\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1844 - accuracy: 0.8522 - val_loss: 0.2687 - val_accuracy: 0.3793\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1827 - accuracy: 0.8348 - val_loss: 0.2662 - val_accuracy: 0.4138\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1820 - accuracy: 0.8696 - val_loss: 0.2664 - val_accuracy: 0.4138\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1817 - accuracy: 0.8609 - val_loss: 0.2676 - val_accuracy: 0.4138\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1750 - accuracy: 0.8696 - val_loss: 0.2657 - val_accuracy: 0.4138\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1760 - accuracy: 0.9043 - val_loss: 0.2674 - val_accuracy: 0.4138\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1714 - accuracy: 0.8870 - val_loss: 0.2678 - val_accuracy: 0.4138\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1707 - accuracy: 0.8957 - val_loss: 0.2669 - val_accuracy: 0.4138\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1680 - accuracy: 0.9130 - val_loss: 0.2669 - val_accuracy: 0.4138\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1662 - accuracy: 0.8870 - val_loss: 0.2670 - val_accuracy: 0.4138\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1617 - accuracy: 0.9130 - val_loss: 0.2669 - val_accuracy: 0.4138\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1640 - accuracy: 0.9304 - val_loss: 0.2679 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1632 - accuracy: 0.9391 - val_loss: 0.2684 - val_accuracy: 0.4138\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1554 - accuracy: 0.9391 - val_loss: 0.2686 - val_accuracy: 0.4138\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1596 - accuracy: 0.9130 - val_loss: 0.2680 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1538 - accuracy: 0.9391 - val_loss: 0.2683 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1542 - accuracy: 0.9391 - val_loss: 0.2697 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1508 - accuracy: 0.9391 - val_loss: 0.2692 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1524 - accuracy: 0.9217 - val_loss: 0.2703 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1457 - accuracy: 0.9478 - val_loss: 0.2702 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1457 - accuracy: 0.9304 - val_loss: 0.2704 - val_accuracy: 0.4138\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1537 - accuracy: 0.9043 - val_loss: 0.2683 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1553 - accuracy: 0.8957 - val_loss: 0.2687 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1559 - accuracy: 0.8957 - val_loss: 0.2688 - val_accuracy: 0.4138\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1562 - accuracy: 0.8870 - val_loss: 0.2690 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1720 - accuracy: 0.8087 - val_loss: 0.2687 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1993 - accuracy: 0.6870 - val_loss: 0.2688 - val_accuracy: 0.4138\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1996 - accuracy: 0.6783 - val_loss: 0.2687 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1931 - accuracy: 0.6957 - val_loss: 0.2686 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2054 - accuracy: 0.6696 - val_loss: 0.2685 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2041 - accuracy: 0.6522 - val_loss: 0.2684 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2046 - accuracy: 0.6870 - val_loss: 0.2681 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1911 - accuracy: 0.6783 - val_loss: 0.2679 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1911 - accuracy: 0.6696 - val_loss: 0.2676 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1811 - accuracy: 0.7043 - val_loss: 0.2672 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1771 - accuracy: 0.7217 - val_loss: 0.2668 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1691 - accuracy: 0.7652 - val_loss: 0.2664 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1589 - accuracy: 0.8174 - val_loss: 0.2660 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1507 - accuracy: 0.8522 - val_loss: 0.2653 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1397 - accuracy: 0.9043 - val_loss: 0.2649 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1336 - accuracy: 0.8870 - val_loss: 0.2644 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1309 - accuracy: 0.9043 - val_loss: 0.2640 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1247 - accuracy: 0.9304 - val_loss: 0.2636 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1245 - accuracy: 0.9217 - val_loss: 0.2633 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1228 - accuracy: 0.9304 - val_loss: 0.2637 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1203 - accuracy: 0.9304 - val_loss: 0.2630 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1158 - accuracy: 0.9304 - val_loss: 0.2626 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1182 - accuracy: 0.9391 - val_loss: 0.2626 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1187 - accuracy: 0.9304 - val_loss: 0.2625 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1127 - accuracy: 0.9304 - val_loss: 0.2626 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1107 - accuracy: 0.9304 - val_loss: 0.2629 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1126 - accuracy: 0.9304 - val_loss: 0.2633 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1099 - accuracy: 0.9217 - val_loss: 0.2634 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1121 - accuracy: 0.9130 - val_loss: 0.2632 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1103 - accuracy: 0.9130 - val_loss: 0.2627 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1164 - accuracy: 0.8957 - val_loss: 0.2629 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1213 - accuracy: 0.9043 - val_loss: 0.2627 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1109 - accuracy: 0.9217 - val_loss: 0.2627 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1050 - accuracy: 0.9391 - val_loss: 0.2628 - val_accuracy: 0.4138\n",
      "0.6145833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101100111010011011011101110100100001011101\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_100 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_101 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.2725 - accuracy: 0.5043 - val_loss: 0.3688 - val_accuracy: 0.4483\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3358 - accuracy: 0.3826 - val_loss: 0.4527 - val_accuracy: 0.4828\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3275 - accuracy: 0.4000 - val_loss: 0.3472 - val_accuracy: 0.5172\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2618 - accuracy: 0.6087 - val_loss: 0.4160 - val_accuracy: 0.4138\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2868 - accuracy: 0.4522 - val_loss: 0.3768 - val_accuracy: 0.4828\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2766 - accuracy: 0.5913 - val_loss: 0.3158 - val_accuracy: 0.4828\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3101 - accuracy: 0.4783 - val_loss: 0.2942 - val_accuracy: 0.4828\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2709 - accuracy: 0.5043 - val_loss: 0.3205 - val_accuracy: 0.3793\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2741 - accuracy: 0.6261 - val_loss: 0.3279 - val_accuracy: 0.4138\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2658 - accuracy: 0.4957 - val_loss: 0.3233 - val_accuracy: 0.3793\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2779 - accuracy: 0.4957 - val_loss: 0.3227 - val_accuracy: 0.2759\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2932 - accuracy: 0.5217 - val_loss: 0.3122 - val_accuracy: 0.4138\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2631 - accuracy: 0.5130 - val_loss: 0.3095 - val_accuracy: 0.3793\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2604 - accuracy: 0.4957 - val_loss: 0.3066 - val_accuracy: 0.3448\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2606 - accuracy: 0.5826 - val_loss: 0.2999 - val_accuracy: 0.3793\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2898 - accuracy: 0.5304 - val_loss: 0.3119 - val_accuracy: 0.4483\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2668 - accuracy: 0.6087 - val_loss: 0.4429 - val_accuracy: 0.4138\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3149 - accuracy: 0.4174 - val_loss: 0.3969 - val_accuracy: 0.3793\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3171 - accuracy: 0.4609 - val_loss: 0.3887 - val_accuracy: 0.3793\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3122 - accuracy: 0.4174 - val_loss: 0.3344 - val_accuracy: 0.4828\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3313 - accuracy: 0.3478 - val_loss: 0.3438 - val_accuracy: 0.4828\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3043 - accuracy: 0.4870 - val_loss: 0.2542 - val_accuracy: 0.5172\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3078 - accuracy: 0.4957 - val_loss: 0.3246 - val_accuracy: 0.5172\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3337 - accuracy: 0.4261 - val_loss: 0.3606 - val_accuracy: 0.4828\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3144 - accuracy: 0.4783 - val_loss: 0.3606 - val_accuracy: 0.5172\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2852 - accuracy: 0.4870 - val_loss: 0.3249 - val_accuracy: 0.5517\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2836 - accuracy: 0.5304 - val_loss: 0.3358 - val_accuracy: 0.5172\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2987 - accuracy: 0.5652 - val_loss: 0.3467 - val_accuracy: 0.5172\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3306 - accuracy: 0.4522 - val_loss: 0.3264 - val_accuracy: 0.5517\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3136 - accuracy: 0.4435 - val_loss: 0.3315 - val_accuracy: 0.5517\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2964 - accuracy: 0.5217 - val_loss: 0.3020 - val_accuracy: 0.5517\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2826 - accuracy: 0.4957 - val_loss: 0.3129 - val_accuracy: 0.5517\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2893 - accuracy: 0.4957 - val_loss: 0.3212 - val_accuracy: 0.5517\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2883 - accuracy: 0.5304 - val_loss: 0.3156 - val_accuracy: 0.5517\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2886 - accuracy: 0.5304 - val_loss: 0.3335 - val_accuracy: 0.5172\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2918 - accuracy: 0.5304 - val_loss: 0.3113 - val_accuracy: 0.5517\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2806 - accuracy: 0.5217 - val_loss: 0.2764 - val_accuracy: 0.5517\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2879 - accuracy: 0.5826 - val_loss: 0.2746 - val_accuracy: 0.5862\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2964 - accuracy: 0.4870 - val_loss: 0.2710 - val_accuracy: 0.5862\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2818 - accuracy: 0.5478 - val_loss: 0.2714 - val_accuracy: 0.5862\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2860 - accuracy: 0.5652 - val_loss: 0.3102 - val_accuracy: 0.5172\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2867 - accuracy: 0.5739 - val_loss: 0.3089 - val_accuracy: 0.5172\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2891 - accuracy: 0.5391 - val_loss: 0.3095 - val_accuracy: 0.5172\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2863 - accuracy: 0.5043 - val_loss: 0.3083 - val_accuracy: 0.4828\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2859 - accuracy: 0.5565 - val_loss: 0.3080 - val_accuracy: 0.4828\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2805 - accuracy: 0.5652 - val_loss: 0.3037 - val_accuracy: 0.4828\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2900 - accuracy: 0.5043 - val_loss: 0.2998 - val_accuracy: 0.4828\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2900 - accuracy: 0.5826 - val_loss: 0.3024 - val_accuracy: 0.4828\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2852 - accuracy: 0.5130 - val_loss: 0.3066 - val_accuracy: 0.4828\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3020 - accuracy: 0.5130 - val_loss: 0.3055 - val_accuracy: 0.5517\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3040 - accuracy: 0.4957 - val_loss: 0.3035 - val_accuracy: 0.5517\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2820 - accuracy: 0.5043 - val_loss: 0.2930 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2872 - accuracy: 0.5826 - val_loss: 0.2945 - val_accuracy: 0.5517\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2817 - accuracy: 0.5391 - val_loss: 0.2925 - val_accuracy: 0.5517\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2784 - accuracy: 0.5739 - val_loss: 0.2907 - val_accuracy: 0.5517\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2897 - accuracy: 0.5130 - val_loss: 0.2880 - val_accuracy: 0.5517\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2803 - accuracy: 0.5043 - val_loss: 0.2879 - val_accuracy: 0.5517\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2737 - accuracy: 0.5565 - val_loss: 0.2852 - val_accuracy: 0.5517\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2750 - accuracy: 0.5565 - val_loss: 0.2816 - val_accuracy: 0.5517\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2713 - accuracy: 0.5652 - val_loss: 0.2843 - val_accuracy: 0.4828\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2565 - accuracy: 0.6000 - val_loss: 0.2935 - val_accuracy: 0.4483\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2596 - accuracy: 0.6000 - val_loss: 0.2866 - val_accuracy: 0.4828\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2675 - accuracy: 0.5565 - val_loss: 0.2838 - val_accuracy: 0.4828\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2658 - accuracy: 0.5217 - val_loss: 0.2883 - val_accuracy: 0.4828\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2763 - accuracy: 0.5478 - val_loss: 0.2880 - val_accuracy: 0.4828\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2728 - accuracy: 0.5391 - val_loss: 0.2802 - val_accuracy: 0.5172\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2660 - accuracy: 0.5304 - val_loss: 0.2774 - val_accuracy: 0.5172\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2626 - accuracy: 0.5913 - val_loss: 0.2637 - val_accuracy: 0.5172\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2808 - accuracy: 0.5304 - val_loss: 0.2566 - val_accuracy: 0.5517\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2968 - accuracy: 0.5043 - val_loss: 0.2588 - val_accuracy: 0.5517\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2865 - accuracy: 0.4957 - val_loss: 0.2604 - val_accuracy: 0.5517\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2882 - accuracy: 0.4957 - val_loss: 0.2612 - val_accuracy: 0.5517\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2810 - accuracy: 0.5130 - val_loss: 0.2602 - val_accuracy: 0.5517\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2792 - accuracy: 0.5304 - val_loss: 0.2594 - val_accuracy: 0.5517\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2928 - accuracy: 0.4870 - val_loss: 0.2585 - val_accuracy: 0.5517\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2900 - accuracy: 0.4957 - val_loss: 0.2580 - val_accuracy: 0.5517\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2753 - accuracy: 0.5304 - val_loss: 0.2592 - val_accuracy: 0.5517\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2872 - accuracy: 0.5130 - val_loss: 0.2593 - val_accuracy: 0.5517\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2677 - accuracy: 0.5652 - val_loss: 0.2694 - val_accuracy: 0.5517\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2625 - accuracy: 0.5739 - val_loss: 0.2693 - val_accuracy: 0.5172\n",
      "0.65625\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101111000001001110100111001010\n",
      "22\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3360)\n",
      "(144, 100, 3360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_102 (LSTM)              (None, 100, 20)           270480    \n",
      "_________________________________________________________________\n",
      "lstm_103 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 273,882\n",
      "Trainable params: 273,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 277ms/step - loss: 0.2970 - accuracy: 0.4696 - val_loss: 0.3899 - val_accuracy: 0.5517\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3152 - accuracy: 0.5565 - val_loss: 0.4319 - val_accuracy: 0.6207\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2426 - accuracy: 0.6087 - val_loss: 0.3799 - val_accuracy: 0.5862\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3211 - accuracy: 0.4696 - val_loss: 0.5069 - val_accuracy: 0.4138\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3186 - accuracy: 0.3304 - val_loss: 0.4022 - val_accuracy: 0.4138\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2805 - accuracy: 0.4609 - val_loss: 0.3940 - val_accuracy: 0.3793\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3012 - accuracy: 0.3739 - val_loss: 0.4497 - val_accuracy: 0.4138\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3015 - accuracy: 0.4609 - val_loss: 0.4427 - val_accuracy: 0.4138\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3055 - accuracy: 0.4348 - val_loss: 0.5049 - val_accuracy: 0.3448\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3174 - accuracy: 0.4870 - val_loss: 0.4118 - val_accuracy: 0.4138\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2974 - accuracy: 0.4522 - val_loss: 0.3414 - val_accuracy: 0.5172\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2858 - accuracy: 0.5043 - val_loss: 0.3553 - val_accuracy: 0.5172\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3096 - accuracy: 0.4261 - val_loss: 0.3956 - val_accuracy: 0.4828\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2942 - accuracy: 0.4870 - val_loss: 0.3249 - val_accuracy: 0.4138\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2935 - accuracy: 0.5130 - val_loss: 0.3738 - val_accuracy: 0.4828\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3163 - accuracy: 0.4609 - val_loss: 0.3613 - val_accuracy: 0.5172\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2980 - accuracy: 0.5304 - val_loss: 0.3334 - val_accuracy: 0.5172\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2945 - accuracy: 0.5304 - val_loss: 0.3852 - val_accuracy: 0.4483\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2898 - accuracy: 0.4870 - val_loss: 0.3538 - val_accuracy: 0.4483\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2940 - accuracy: 0.5043 - val_loss: 0.3800 - val_accuracy: 0.4828\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3097 - accuracy: 0.4174 - val_loss: 0.3580 - val_accuracy: 0.4828\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2959 - accuracy: 0.5304 - val_loss: 0.3811 - val_accuracy: 0.4828\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2884 - accuracy: 0.4870 - val_loss: 0.3148 - val_accuracy: 0.4828\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2970 - accuracy: 0.4783 - val_loss: 0.4241 - val_accuracy: 0.4138\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3280 - accuracy: 0.3739 - val_loss: 0.4006 - val_accuracy: 0.4828\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3254 - accuracy: 0.4348 - val_loss: 0.3566 - val_accuracy: 0.4828\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3078 - accuracy: 0.4348 - val_loss: 0.3872 - val_accuracy: 0.4828\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3340 - accuracy: 0.4000 - val_loss: 0.3223 - val_accuracy: 0.4483\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2911 - accuracy: 0.6348 - val_loss: 0.3870 - val_accuracy: 0.4828\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2972 - accuracy: 0.5739 - val_loss: 0.3426 - val_accuracy: 0.4828\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2974 - accuracy: 0.4870 - val_loss: 0.3808 - val_accuracy: 0.4483\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2649 - accuracy: 0.5217 - val_loss: 0.2987 - val_accuracy: 0.4828\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2746 - accuracy: 0.5652 - val_loss: 0.3085 - val_accuracy: 0.5172\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2931 - accuracy: 0.5652 - val_loss: 0.3409 - val_accuracy: 0.4828\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3052 - accuracy: 0.5739 - val_loss: 0.3635 - val_accuracy: 0.4828\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2939 - accuracy: 0.6696 - val_loss: 0.3275 - val_accuracy: 0.5517\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2922 - accuracy: 0.6696 - val_loss: 0.3448 - val_accuracy: 0.3793\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2975 - accuracy: 0.5826 - val_loss: 0.3610 - val_accuracy: 0.5172\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3023 - accuracy: 0.5826 - val_loss: 0.2992 - val_accuracy: 0.5517\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3146 - accuracy: 0.6000 - val_loss: 0.2898 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2876 - accuracy: 0.5739 - val_loss: 0.3005 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2723 - accuracy: 0.6174 - val_loss: 0.2744 - val_accuracy: 0.4483\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2781 - accuracy: 0.5565 - val_loss: 0.3026 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2749 - accuracy: 0.6000 - val_loss: 0.2734 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3107 - accuracy: 0.5565 - val_loss: 0.2782 - val_accuracy: 0.3793\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2714 - accuracy: 0.5913 - val_loss: 0.2826 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2703 - accuracy: 0.6000 - val_loss: 0.2773 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3405 - accuracy: 0.4609 - val_loss: 0.3126 - val_accuracy: 0.2759\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2827 - accuracy: 0.4522 - val_loss: 0.2948 - val_accuracy: 0.3103\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2868 - accuracy: 0.5391 - val_loss: 0.2884 - val_accuracy: 0.3448\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2639 - accuracy: 0.5217 - val_loss: 0.2850 - val_accuracy: 0.3448\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2633 - accuracy: 0.5130 - val_loss: 0.2850 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3280 - accuracy: 0.4696 - val_loss: 0.2918 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3197 - accuracy: 0.4261 - val_loss: 0.3005 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2797 - accuracy: 0.4783 - val_loss: 0.2857 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2933 - accuracy: 0.4609 - val_loss: 0.3058 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2803 - accuracy: 0.5043 - val_loss: 0.2703 - val_accuracy: 0.4828\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2566 - accuracy: 0.5478 - val_loss: 0.2973 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3020 - accuracy: 0.4696 - val_loss: 0.3264 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2856 - accuracy: 0.4870 - val_loss: 0.2744 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2895 - accuracy: 0.5217 - val_loss: 0.3392 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2902 - accuracy: 0.5217 - val_loss: 0.3158 - val_accuracy: 0.3793\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2901 - accuracy: 0.5304 - val_loss: 0.2526 - val_accuracy: 0.5517\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2884 - accuracy: 0.5217 - val_loss: 0.2715 - val_accuracy: 0.5172\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2743 - accuracy: 0.5739 - val_loss: 0.3064 - val_accuracy: 0.4828\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2800 - accuracy: 0.5739 - val_loss: 0.3268 - val_accuracy: 0.4828\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2872 - accuracy: 0.5478 - val_loss: 0.2584 - val_accuracy: 0.5517\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2955 - accuracy: 0.5217 - val_loss: 0.2779 - val_accuracy: 0.5517\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2816 - accuracy: 0.5739 - val_loss: 0.2677 - val_accuracy: 0.5517\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2680 - accuracy: 0.5652 - val_loss: 0.2489 - val_accuracy: 0.5517\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3031 - accuracy: 0.5217 - val_loss: 0.2812 - val_accuracy: 0.5172\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2898 - accuracy: 0.5739 - val_loss: 0.2725 - val_accuracy: 0.4828\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2345 - accuracy: 0.6435 - val_loss: 0.2944 - val_accuracy: 0.4483\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2664 - accuracy: 0.5391 - val_loss: 0.2755 - val_accuracy: 0.4483\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2675 - accuracy: 0.6087 - val_loss: 0.3105 - val_accuracy: 0.3793\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2591 - accuracy: 0.6174 - val_loss: 0.3033 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2574 - accuracy: 0.6174 - val_loss: 0.2952 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2367 - accuracy: 0.6609 - val_loss: 0.2996 - val_accuracy: 0.3793\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2377 - accuracy: 0.6000 - val_loss: 0.2795 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2241 - accuracy: 0.6609 - val_loss: 0.2736 - val_accuracy: 0.4138\n",
      "0.6145833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_104 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_105 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 191ms/step - loss: 0.2492 - accuracy: 0.7478 - val_loss: 0.2311 - val_accuracy: 0.8276\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1563 - accuracy: 0.8783 - val_loss: 0.0874 - val_accuracy: 0.9655\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1588 - accuracy: 0.8348 - val_loss: 0.0747 - val_accuracy: 0.9655\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1336 - accuracy: 0.8870 - val_loss: 0.0663 - val_accuracy: 0.9310\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0919 - accuracy: 0.9565 - val_loss: 0.0682 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0870 - accuracy: 0.9739 - val_loss: 0.0670 - val_accuracy: 0.9310\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0689 - accuracy: 0.9826 - val_loss: 0.0578 - val_accuracy: 0.9655\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0960 - accuracy: 0.9565 - val_loss: 0.1320 - val_accuracy: 0.9310\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1071 - accuracy: 0.9565 - val_loss: 0.1195 - val_accuracy: 0.8966\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1274 - accuracy: 0.9043 - val_loss: 0.1008 - val_accuracy: 0.8621\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0969 - accuracy: 0.9478 - val_loss: 0.0686 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1001 - accuracy: 0.9565 - val_loss: 0.0897 - val_accuracy: 0.9310\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0963 - accuracy: 0.9304 - val_loss: 0.1295 - val_accuracy: 0.8276\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0987 - accuracy: 0.9304 - val_loss: 0.0918 - val_accuracy: 0.9310\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0964 - accuracy: 0.9391 - val_loss: 0.1545 - val_accuracy: 0.7931\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1455 - accuracy: 0.8696 - val_loss: 0.1258 - val_accuracy: 0.8621\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1439 - accuracy: 0.8609 - val_loss: 0.1410 - val_accuracy: 0.8621\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1572 - accuracy: 0.8783 - val_loss: 0.1529 - val_accuracy: 0.7931\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1787 - accuracy: 0.8522 - val_loss: 0.2981 - val_accuracy: 0.7241\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2176 - accuracy: 0.7391 - val_loss: 0.2872 - val_accuracy: 0.6552\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2530 - accuracy: 0.6261 - val_loss: 0.1474 - val_accuracy: 0.8966\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2175 - accuracy: 0.7043 - val_loss: 0.2551 - val_accuracy: 0.7586\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1957 - accuracy: 0.7391 - val_loss: 0.1067 - val_accuracy: 0.8966\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1635 - accuracy: 0.8174 - val_loss: 0.1749 - val_accuracy: 0.9310\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2005 - accuracy: 0.7652 - val_loss: 0.1241 - val_accuracy: 0.9310\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1732 - accuracy: 0.7913 - val_loss: 0.1159 - val_accuracy: 0.9310\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1485 - accuracy: 0.8174 - val_loss: 0.1119 - val_accuracy: 0.9655\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1271 - accuracy: 0.8696 - val_loss: 0.1155 - val_accuracy: 0.8966\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1531 - accuracy: 0.8348 - val_loss: 0.1109 - val_accuracy: 0.9310\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1425 - accuracy: 0.8522 - val_loss: 0.1074 - val_accuracy: 0.9310\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1199 - accuracy: 0.8957 - val_loss: 0.0965 - val_accuracy: 0.9655\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0990 - accuracy: 0.9304 - val_loss: 0.0987 - val_accuracy: 0.9655\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0952 - accuracy: 0.9217 - val_loss: 0.1016 - val_accuracy: 0.9655\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0922 - accuracy: 0.9565 - val_loss: 0.0992 - val_accuracy: 0.9655\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0903 - accuracy: 0.9391 - val_loss: 0.0925 - val_accuracy: 0.9655\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0895 - accuracy: 0.9565 - val_loss: 0.0850 - val_accuracy: 0.9310\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0815 - accuracy: 0.9478 - val_loss: 0.0824 - val_accuracy: 0.9310\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0849 - accuracy: 0.9478 - val_loss: 0.0829 - val_accuracy: 0.9655\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0828 - accuracy: 0.9565 - val_loss: 0.0821 - val_accuracy: 0.9655\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0702 - accuracy: 0.9652 - val_loss: 0.0875 - val_accuracy: 0.9655\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0655 - accuracy: 0.9826 - val_loss: 0.0913 - val_accuracy: 0.9655\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0565 - accuracy: 0.9913 - val_loss: 0.0867 - val_accuracy: 0.9655\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0629 - accuracy: 0.9739 - val_loss: 0.0824 - val_accuracy: 0.9655\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0561 - accuracy: 0.9739 - val_loss: 0.0795 - val_accuracy: 0.9655\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0643 - accuracy: 0.9652 - val_loss: 0.0766 - val_accuracy: 0.9655\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0561 - accuracy: 0.9739 - val_loss: 0.0735 - val_accuracy: 0.9655\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0509 - accuracy: 0.9913 - val_loss: 0.0725 - val_accuracy: 0.9655\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0474 - accuracy: 0.9826 - val_loss: 0.0718 - val_accuracy: 0.9655\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0496 - accuracy: 0.9739 - val_loss: 0.0724 - val_accuracy: 0.9655\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0476 - accuracy: 0.9826 - val_loss: 0.0734 - val_accuracy: 0.9655\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0474 - accuracy: 0.9913 - val_loss: 0.0730 - val_accuracy: 0.9655\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0483 - accuracy: 0.9826 - val_loss: 0.0718 - val_accuracy: 0.9655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0438 - accuracy: 0.9826 - val_loss: 0.0707 - val_accuracy: 0.9655\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0500 - accuracy: 0.9826 - val_loss: 0.0698 - val_accuracy: 0.9655\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0506 - accuracy: 0.9826 - val_loss: 0.0697 - val_accuracy: 0.9655\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0431 - accuracy: 0.9826 - val_loss: 0.0685 - val_accuracy: 0.9655\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0391 - accuracy: 0.9913 - val_loss: 0.0669 - val_accuracy: 0.9655\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0372 - accuracy: 0.9913 - val_loss: 0.0656 - val_accuracy: 0.9655\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0458 - accuracy: 0.9826 - val_loss: 0.0657 - val_accuracy: 0.9655\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0397 - accuracy: 0.9913 - val_loss: 0.0646 - val_accuracy: 0.9655\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0491 - accuracy: 0.9565 - val_loss: 0.0651 - val_accuracy: 0.9655\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0349 - accuracy: 0.9913 - val_loss: 0.0654 - val_accuracy: 0.9655\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0332 - accuracy: 0.9913 - val_loss: 0.0649 - val_accuracy: 0.9655\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9655\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0422 - accuracy: 0.9739 - val_loss: 0.0654 - val_accuracy: 0.9655\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0370 - accuracy: 0.9913 - val_loss: 0.0662 - val_accuracy: 0.9655\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0487 - accuracy: 0.9826 - val_loss: 0.0654 - val_accuracy: 0.9655\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0302 - accuracy: 0.9913 - val_loss: 0.0637 - val_accuracy: 0.9655\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0333 - accuracy: 0.9913 - val_loss: 0.0631 - val_accuracy: 0.9655\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0377 - accuracy: 0.9913 - val_loss: 0.0615 - val_accuracy: 0.9655\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 0.0601 - val_accuracy: 0.9655\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0336 - accuracy: 0.9826 - val_loss: 0.0583 - val_accuracy: 0.9655\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0325 - accuracy: 0.9826 - val_loss: 0.0571 - val_accuracy: 0.9655\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0332 - accuracy: 0.9913 - val_loss: 0.0560 - val_accuracy: 0.9655\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0320 - accuracy: 0.9913 - val_loss: 0.0546 - val_accuracy: 0.9655\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 0.9655\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0311 - accuracy: 0.9913 - val_loss: 0.0542 - val_accuracy: 0.9655\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0272 - accuracy: 0.9913 - val_loss: 0.0540 - val_accuracy: 0.9655\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9655\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9655\n",
      "0.9895833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111101010100000\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n",
      "(144, 100, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_106 (LSTM)              (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_107 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 0.2092 - accuracy: 0.6609 - val_loss: 0.2204 - val_accuracy: 0.6897\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1607 - accuracy: 0.8522 - val_loss: 0.2624 - val_accuracy: 0.7931\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1757 - accuracy: 0.8000 - val_loss: 0.2336 - val_accuracy: 0.5862\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1564 - accuracy: 0.8609 - val_loss: 0.2067 - val_accuracy: 0.8621\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2296 - accuracy: 0.7217 - val_loss: 0.2959 - val_accuracy: 0.6207\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2324 - accuracy: 0.7217 - val_loss: 0.3076 - val_accuracy: 0.4483\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.3013 - accuracy: 0.5304 - val_loss: 0.3346 - val_accuracy: 0.4138\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3233 - accuracy: 0.5043 - val_loss: 0.3330 - val_accuracy: 0.5172\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.3160 - accuracy: 0.4609 - val_loss: 0.3004 - val_accuracy: 0.4828\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2740 - accuracy: 0.5304 - val_loss: 0.3528 - val_accuracy: 0.4138\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2754 - accuracy: 0.5565 - val_loss: 0.2872 - val_accuracy: 0.6207\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3064 - accuracy: 0.4957 - val_loss: 0.3583 - val_accuracy: 0.4828\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.3140 - accuracy: 0.4000 - val_loss: 0.3401 - val_accuracy: 0.4483\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3181 - accuracy: 0.4000 - val_loss: 0.3443 - val_accuracy: 0.3103\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3149 - accuracy: 0.4174 - val_loss: 0.3125 - val_accuracy: 0.3793\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.3070 - accuracy: 0.4435 - val_loss: 0.3245 - val_accuracy: 0.2759\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.3134 - accuracy: 0.4261 - val_loss: 0.2769 - val_accuracy: 0.3448\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.3063 - accuracy: 0.4522 - val_loss: 0.2844 - val_accuracy: 0.4483\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2707 - accuracy: 0.5826 - val_loss: 0.2761 - val_accuracy: 0.4828\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2306 - accuracy: 0.6609 - val_loss: 0.2824 - val_accuracy: 0.4828\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2405 - accuracy: 0.6348 - val_loss: 0.2814 - val_accuracy: 0.4483\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2267 - accuracy: 0.6783 - val_loss: 0.2497 - val_accuracy: 0.5517\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2284 - accuracy: 0.7043 - val_loss: 0.2526 - val_accuracy: 0.5172\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2304 - accuracy: 0.6870 - val_loss: 0.2685 - val_accuracy: 0.5172\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2271 - accuracy: 0.6696 - val_loss: 0.2410 - val_accuracy: 0.5862\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2319 - accuracy: 0.6696 - val_loss: 0.2659 - val_accuracy: 0.5862\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2446 - accuracy: 0.6696 - val_loss: 0.2514 - val_accuracy: 0.6207\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2402 - accuracy: 0.6609 - val_loss: 0.2642 - val_accuracy: 0.5172\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2560 - accuracy: 0.5913 - val_loss: 0.2263 - val_accuracy: 0.6207\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2669 - accuracy: 0.5478 - val_loss: 0.2948 - val_accuracy: 0.4138\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2790 - accuracy: 0.6000 - val_loss: 0.3258 - val_accuracy: 0.5517\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2571 - accuracy: 0.6522 - val_loss: 0.3405 - val_accuracy: 0.3448\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2568 - accuracy: 0.6174 - val_loss: 0.3103 - val_accuracy: 0.5172\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2302 - accuracy: 0.6870 - val_loss: 0.3470 - val_accuracy: 0.4138\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2694 - accuracy: 0.5652 - val_loss: 0.3377 - val_accuracy: 0.4483\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2881 - accuracy: 0.4783 - val_loss: 0.3323 - val_accuracy: 0.3103\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2795 - accuracy: 0.5130 - val_loss: 0.3247 - val_accuracy: 0.3793\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2751 - accuracy: 0.5043 - val_loss: 0.3247 - val_accuracy: 0.3793\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2762 - accuracy: 0.5304 - val_loss: 0.3159 - val_accuracy: 0.5172\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2785 - accuracy: 0.5391 - val_loss: 0.3083 - val_accuracy: 0.4483\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2675 - accuracy: 0.5391 - val_loss: 0.3072 - val_accuracy: 0.3448\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2596 - accuracy: 0.5913 - val_loss: 0.3160 - val_accuracy: 0.3103\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2573 - accuracy: 0.6087 - val_loss: 0.3144 - val_accuracy: 0.3103\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2638 - accuracy: 0.5391 - val_loss: 0.3154 - val_accuracy: 0.3103\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2688 - accuracy: 0.5217 - val_loss: 0.3158 - val_accuracy: 0.3448\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2715 - accuracy: 0.5391 - val_loss: 0.3112 - val_accuracy: 0.3448\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2619 - accuracy: 0.5478 - val_loss: 0.3065 - val_accuracy: 0.3793\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2711 - accuracy: 0.5739 - val_loss: 0.3052 - val_accuracy: 0.3793\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2650 - accuracy: 0.5478 - val_loss: 0.3094 - val_accuracy: 0.3103\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2576 - accuracy: 0.5391 - val_loss: 0.3116 - val_accuracy: 0.3103\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2583 - accuracy: 0.5826 - val_loss: 0.3112 - val_accuracy: 0.2759\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2524 - accuracy: 0.5826 - val_loss: 0.3090 - val_accuracy: 0.2759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2543 - accuracy: 0.5739 - val_loss: 0.3045 - val_accuracy: 0.2759\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2541 - accuracy: 0.5913 - val_loss: 0.3033 - val_accuracy: 0.2759\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2521 - accuracy: 0.5739 - val_loss: 0.3034 - val_accuracy: 0.3103\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2552 - accuracy: 0.5739 - val_loss: 0.2997 - val_accuracy: 0.3448\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2484 - accuracy: 0.5739 - val_loss: 0.3024 - val_accuracy: 0.3103\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2531 - accuracy: 0.5565 - val_loss: 0.2959 - val_accuracy: 0.3103\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2490 - accuracy: 0.5739 - val_loss: 0.2848 - val_accuracy: 0.3448\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2405 - accuracy: 0.5913 - val_loss: 0.2879 - val_accuracy: 0.3103\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2369 - accuracy: 0.6609 - val_loss: 0.2838 - val_accuracy: 0.3793\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2445 - accuracy: 0.6087 - val_loss: 0.2812 - val_accuracy: 0.3793\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2396 - accuracy: 0.6174 - val_loss: 0.2773 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2368 - accuracy: 0.6261 - val_loss: 0.2761 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2304 - accuracy: 0.6435 - val_loss: 0.2830 - val_accuracy: 0.3793\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2315 - accuracy: 0.6435 - val_loss: 0.2760 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2397 - accuracy: 0.6174 - val_loss: 0.2805 - val_accuracy: 0.3793\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2404 - accuracy: 0.6174 - val_loss: 0.2792 - val_accuracy: 0.3793\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2420 - accuracy: 0.6261 - val_loss: 0.2711 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2342 - accuracy: 0.6522 - val_loss: 0.2704 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2412 - accuracy: 0.6000 - val_loss: 0.2789 - val_accuracy: 0.3793\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2413 - accuracy: 0.6174 - val_loss: 0.2736 - val_accuracy: 0.3793\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2405 - accuracy: 0.6174 - val_loss: 0.2659 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2433 - accuracy: 0.6087 - val_loss: 0.2720 - val_accuracy: 0.3793\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2460 - accuracy: 0.5826 - val_loss: 0.2688 - val_accuracy: 0.3793\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2410 - accuracy: 0.6087 - val_loss: 0.2709 - val_accuracy: 0.3793\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2462 - accuracy: 0.6087 - val_loss: 0.2665 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2374 - accuracy: 0.6000 - val_loss: 0.2674 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2337 - accuracy: 0.6087 - val_loss: 0.2648 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2358 - accuracy: 0.6000 - val_loss: 0.2673 - val_accuracy: 0.4483\n",
      "0.5729166865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101101110101101100001010101111100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n",
      "(144, 100, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_108 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_109 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 193ms/step - loss: 0.2891 - accuracy: 0.6348 - val_loss: 0.3331 - val_accuracy: 0.2414\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1860 - accuracy: 0.8696 - val_loss: 0.2260 - val_accuracy: 0.4483\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1748 - accuracy: 0.8957 - val_loss: 0.2224 - val_accuracy: 0.5862\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1765 - accuracy: 0.8174 - val_loss: 0.2018 - val_accuracy: 0.5862\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2131 - accuracy: 0.7739 - val_loss: 0.1780 - val_accuracy: 0.6897\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2344 - accuracy: 0.7652 - val_loss: 0.1892 - val_accuracy: 0.6207\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2351 - accuracy: 0.7652 - val_loss: 0.1894 - val_accuracy: 0.6552\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2132 - accuracy: 0.7913 - val_loss: 0.2035 - val_accuracy: 0.6897\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2132 - accuracy: 0.8000 - val_loss: 0.2534 - val_accuracy: 0.6552\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2003 - accuracy: 0.7478 - val_loss: 0.1810 - val_accuracy: 0.8966\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1926 - accuracy: 0.8261 - val_loss: 0.2005 - val_accuracy: 0.7931\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1965 - accuracy: 0.8261 - val_loss: 0.1659 - val_accuracy: 0.8966\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2096 - accuracy: 0.7652 - val_loss: 0.2425 - val_accuracy: 0.7241\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2010 - accuracy: 0.7565 - val_loss: 0.2410 - val_accuracy: 0.7241\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2141 - accuracy: 0.7565 - val_loss: 0.2314 - val_accuracy: 0.7241\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2051 - accuracy: 0.7391 - val_loss: 0.2266 - val_accuracy: 0.7241\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2032 - accuracy: 0.7478 - val_loss: 0.2239 - val_accuracy: 0.7241\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2110 - accuracy: 0.7217 - val_loss: 0.1968 - val_accuracy: 0.7931\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1964 - accuracy: 0.7652 - val_loss: 0.2051 - val_accuracy: 0.7586\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1947 - accuracy: 0.7478 - val_loss: 0.2106 - val_accuracy: 0.7586\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1888 - accuracy: 0.7826 - val_loss: 0.1902 - val_accuracy: 0.7586\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1727 - accuracy: 0.8435 - val_loss: 0.1908 - val_accuracy: 0.7586\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1774 - accuracy: 0.8435 - val_loss: 0.1508 - val_accuracy: 0.8966\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1824 - accuracy: 0.8261 - val_loss: 0.1478 - val_accuracy: 0.8966\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1616 - accuracy: 0.8696 - val_loss: 0.1590 - val_accuracy: 0.8621\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1609 - accuracy: 0.8696 - val_loss: 0.1396 - val_accuracy: 0.8966\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1579 - accuracy: 0.8783 - val_loss: 0.1497 - val_accuracy: 0.8966\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1558 - accuracy: 0.8696 - val_loss: 0.1603 - val_accuracy: 0.8621\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1577 - accuracy: 0.8783 - val_loss: 0.1834 - val_accuracy: 0.7241\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1537 - accuracy: 0.8435 - val_loss: 0.2112 - val_accuracy: 0.7241\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1734 - accuracy: 0.8696 - val_loss: 0.2054 - val_accuracy: 0.7241\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1813 - accuracy: 0.7913 - val_loss: 0.2032 - val_accuracy: 0.6897\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1732 - accuracy: 0.7913 - val_loss: 0.2319 - val_accuracy: 0.6207\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1765 - accuracy: 0.7913 - val_loss: 0.2126 - val_accuracy: 0.6552\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1706 - accuracy: 0.8348 - val_loss: 0.1982 - val_accuracy: 0.6897\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1597 - accuracy: 0.8000 - val_loss: 0.1899 - val_accuracy: 0.7241\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1588 - accuracy: 0.8522 - val_loss: 0.1842 - val_accuracy: 0.7586\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1486 - accuracy: 0.8522 - val_loss: 0.1960 - val_accuracy: 0.7241\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1623 - accuracy: 0.8522 - val_loss: 0.1865 - val_accuracy: 0.7241\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1694 - accuracy: 0.7739 - val_loss: 0.1939 - val_accuracy: 0.7241\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1547 - accuracy: 0.8174 - val_loss: 0.1882 - val_accuracy: 0.7241\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1683 - accuracy: 0.8087 - val_loss: 0.1938 - val_accuracy: 0.6552\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2041 - accuracy: 0.7217 - val_loss: 0.1879 - val_accuracy: 0.7241\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1678 - accuracy: 0.7913 - val_loss: 0.1491 - val_accuracy: 0.7931\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1537 - accuracy: 0.8174 - val_loss: 0.1434 - val_accuracy: 0.8276\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1582 - accuracy: 0.8261 - val_loss: 0.1716 - val_accuracy: 0.7241\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1509 - accuracy: 0.8435 - val_loss: 0.1767 - val_accuracy: 0.7931\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1558 - accuracy: 0.8000 - val_loss: 0.1816 - val_accuracy: 0.6897\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1565 - accuracy: 0.8348 - val_loss: 0.1740 - val_accuracy: 0.7241\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1589 - accuracy: 0.7739 - val_loss: 0.1774 - val_accuracy: 0.7586\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1624 - accuracy: 0.8087 - val_loss: 0.1615 - val_accuracy: 0.7586\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1691 - accuracy: 0.8000 - val_loss: 0.1901 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1497 - accuracy: 0.8435 - val_loss: 0.2101 - val_accuracy: 0.6897\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1566 - accuracy: 0.8087 - val_loss: 0.2084 - val_accuracy: 0.6552\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1555 - accuracy: 0.8435 - val_loss: 0.2215 - val_accuracy: 0.6207\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1587 - accuracy: 0.8261 - val_loss: 0.2197 - val_accuracy: 0.6207\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1559 - accuracy: 0.8261 - val_loss: 0.2203 - val_accuracy: 0.6207\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1354 - accuracy: 0.8783 - val_loss: 0.2235 - val_accuracy: 0.6207\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1350 - accuracy: 0.8696 - val_loss: 0.2187 - val_accuracy: 0.6207\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1372 - accuracy: 0.8522 - val_loss: 0.2218 - val_accuracy: 0.6207\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1440 - accuracy: 0.8435 - val_loss: 0.2198 - val_accuracy: 0.6207\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1365 - accuracy: 0.8522 - val_loss: 0.2202 - val_accuracy: 0.6207\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1398 - accuracy: 0.8435 - val_loss: 0.2204 - val_accuracy: 0.6207\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1353 - accuracy: 0.8696 - val_loss: 0.2199 - val_accuracy: 0.6207\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1316 - accuracy: 0.8783 - val_loss: 0.2192 - val_accuracy: 0.6207\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1371 - accuracy: 0.8435 - val_loss: 0.2189 - val_accuracy: 0.6207\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1232 - accuracy: 0.8522 - val_loss: 0.2190 - val_accuracy: 0.6207\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1308 - accuracy: 0.8522 - val_loss: 0.2182 - val_accuracy: 0.6207\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1388 - accuracy: 0.8174 - val_loss: 0.1993 - val_accuracy: 0.6552\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1333 - accuracy: 0.8609 - val_loss: 0.2065 - val_accuracy: 0.6207\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1242 - accuracy: 0.8696 - val_loss: 0.2186 - val_accuracy: 0.5862\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1287 - accuracy: 0.8870 - val_loss: 0.2193 - val_accuracy: 0.6207\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1287 - accuracy: 0.8522 - val_loss: 0.2184 - val_accuracy: 0.6207\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1214 - accuracy: 0.8609 - val_loss: 0.1926 - val_accuracy: 0.6897\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1143 - accuracy: 0.8870 - val_loss: 0.1765 - val_accuracy: 0.6897\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1233 - accuracy: 0.8609 - val_loss: 0.1646 - val_accuracy: 0.6897\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1257 - accuracy: 0.8696 - val_loss: 0.1581 - val_accuracy: 0.7241\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1316 - accuracy: 0.8435 - val_loss: 0.1584 - val_accuracy: 0.7241\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1342 - accuracy: 0.8522 - val_loss: 0.1577 - val_accuracy: 0.7241\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1267 - accuracy: 0.8522 - val_loss: 0.1574 - val_accuracy: 0.7241\n",
      "0.8229166865348816\n",
      "fitness pass\n",
      "[(0.6145833134651184, 923447748520394), (0.59375, 957462487713885), (0.625, 957148127537610), (0.6979166865348816, 957257731074506), (0.8020833134651184, 923441258232480), (0.6145833134651184, 923441258211786), (0.65625, 957462487713885), (0.6145833134651184, 923441306069450), (0.9895833134651184, 923441258232266), (0.5729166865348816, 923441258232480), (0.8229166865348816, 957526118693322)]\n",
      "[923441258232266, 957526118693322]\n",
      "[923441258232266, 957526118693322, 923441258232480, 957257731074506, 957462487713885, 957148127537610, 923447748520394, 923441306069450, 923441258211786, 923441258232480]\n",
      "selection pass\n",
      "target_count:\n",
      "1\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "0\n",
      "923441258232266\n",
      "11010001111101110101101100001010101111100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "1\n",
      "957526118693322\n",
      "11011001101101110101101100001010101111100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "2\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "3\n",
      "957257731074506\n",
      "11011001101001111011101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "4\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "5\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "6\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "7\n",
      "923441306069450\n",
      "11010001111101110101101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "8\n",
      "923441258211786\n",
      "11010001111101110101101100001010101010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "9\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "10\n",
      "957251206752714\n",
      "11011001101001110101101010001000111010100111001010\n",
      "crossover pass\n",
      "變異後的種群\n",
      "染色體：\n",
      "0\n",
      "923441258232266\n",
      "11010001111101110101101100001010101111100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "1\n",
      "957526118693322\n",
      "11011001101101110101101100001010101111100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "2\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "變異後的種群\n",
      "染色體：\n",
      "3\n",
      "957257731074506\n",
      "11011001101001111011101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "4\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "5\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "6\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "7\n",
      "923441306069450\n",
      "11010001111101110101101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "8\n",
      "923441258211786\n",
      "11010001111101110101101100001010101010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "9\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "變異後的種群\n",
      "染色體：\n",
      "10\n",
      "957251206752714\n",
      "11011001101001110101101010001000111010100111001010\n",
      "mutation pass\n",
      "迭代次數： 5\n",
      "5\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_110 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_111 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 0.3405 - accuracy: 0.3913 - val_loss: 0.5223 - val_accuracy: 0.3448\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2768 - accuracy: 0.4609 - val_loss: 0.4501 - val_accuracy: 0.4483\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3211 - accuracy: 0.4087 - val_loss: 0.4630 - val_accuracy: 0.3793\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3430 - accuracy: 0.3826 - val_loss: 0.4245 - val_accuracy: 0.3448\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3304 - accuracy: 0.3826 - val_loss: 0.5149 - val_accuracy: 0.4138\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3300 - accuracy: 0.3652 - val_loss: 0.4270 - val_accuracy: 0.4138\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3241 - accuracy: 0.4000 - val_loss: 0.5252 - val_accuracy: 0.3448\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3469 - accuracy: 0.4174 - val_loss: 0.3790 - val_accuracy: 0.5172\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2969 - accuracy: 0.4261 - val_loss: 0.3506 - val_accuracy: 0.5862\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3098 - accuracy: 0.3565 - val_loss: 0.3934 - val_accuracy: 0.5172\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3003 - accuracy: 0.4000 - val_loss: 0.4050 - val_accuracy: 0.4138\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3135 - accuracy: 0.4870 - val_loss: 0.3383 - val_accuracy: 0.5862\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3228 - accuracy: 0.3739 - val_loss: 0.3949 - val_accuracy: 0.3793\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.3276 - accuracy: 0.3478 - val_loss: 0.3394 - val_accuracy: 0.4138\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3007 - accuracy: 0.4348 - val_loss: 0.3759 - val_accuracy: 0.5517\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3164 - accuracy: 0.3739 - val_loss: 0.4387 - val_accuracy: 0.4483\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2810 - accuracy: 0.5391 - val_loss: 0.4367 - val_accuracy: 0.3793\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3192 - accuracy: 0.4609 - val_loss: 0.3352 - val_accuracy: 0.5862\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2940 - accuracy: 0.4435 - val_loss: 0.3723 - val_accuracy: 0.4828\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2940 - accuracy: 0.4783 - val_loss: 0.4265 - val_accuracy: 0.4138\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3082 - accuracy: 0.4696 - val_loss: 0.3994 - val_accuracy: 0.4483\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3240 - accuracy: 0.4870 - val_loss: 0.3628 - val_accuracy: 0.4483\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2907 - accuracy: 0.5478 - val_loss: 0.2954 - val_accuracy: 0.5862\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2972 - accuracy: 0.5565 - val_loss: 0.3594 - val_accuracy: 0.4828\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.3080 - accuracy: 0.4783 - val_loss: 0.3166 - val_accuracy: 0.3793\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2795 - accuracy: 0.5565 - val_loss: 0.3193 - val_accuracy: 0.4828\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2613 - accuracy: 0.6000 - val_loss: 0.3892 - val_accuracy: 0.4138\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3056 - accuracy: 0.4783 - val_loss: 0.2938 - val_accuracy: 0.4483\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2816 - accuracy: 0.5304 - val_loss: 0.3093 - val_accuracy: 0.4483\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2967 - accuracy: 0.4870 - val_loss: 0.3141 - val_accuracy: 0.5517\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2830 - accuracy: 0.5478 - val_loss: 0.2797 - val_accuracy: 0.5517\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2698 - accuracy: 0.5739 - val_loss: 0.3293 - val_accuracy: 0.5862\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3015 - accuracy: 0.5565 - val_loss: 0.3408 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2958 - accuracy: 0.5304 - val_loss: 0.3122 - val_accuracy: 0.5172\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2568 - accuracy: 0.5652 - val_loss: 0.3262 - val_accuracy: 0.4828\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3129 - accuracy: 0.5130 - val_loss: 0.3420 - val_accuracy: 0.4483\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2798 - accuracy: 0.5478 - val_loss: 0.3238 - val_accuracy: 0.3793\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3102 - accuracy: 0.5043 - val_loss: 0.3114 - val_accuracy: 0.4483\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3040 - accuracy: 0.5043 - val_loss: 0.3302 - val_accuracy: 0.5172\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3051 - accuracy: 0.4696 - val_loss: 0.3716 - val_accuracy: 0.3793\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3075 - accuracy: 0.5217 - val_loss: 0.3167 - val_accuracy: 0.4483\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2756 - accuracy: 0.5565 - val_loss: 0.3287 - val_accuracy: 0.4483\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3235 - accuracy: 0.4783 - val_loss: 0.3961 - val_accuracy: 0.3448\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2676 - accuracy: 0.6000 - val_loss: 0.3341 - val_accuracy: 0.4483\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2497 - accuracy: 0.6000 - val_loss: 0.2869 - val_accuracy: 0.6207\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2538 - accuracy: 0.6348 - val_loss: 0.3574 - val_accuracy: 0.5172\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2854 - accuracy: 0.5391 - val_loss: 0.2463 - val_accuracy: 0.5862\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2868 - accuracy: 0.5391 - val_loss: 0.2898 - val_accuracy: 0.5172\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2986 - accuracy: 0.5043 - val_loss: 0.3472 - val_accuracy: 0.4483\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2917 - accuracy: 0.5304 - val_loss: 0.3077 - val_accuracy: 0.5172\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2950 - accuracy: 0.5478 - val_loss: 0.3006 - val_accuracy: 0.5862\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2639 - accuracy: 0.6087 - val_loss: 0.3642 - val_accuracy: 0.4483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2803 - accuracy: 0.5565 - val_loss: 0.3344 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2676 - accuracy: 0.5478 - val_loss: 0.3244 - val_accuracy: 0.4828\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2546 - accuracy: 0.6261 - val_loss: 0.3268 - val_accuracy: 0.4828\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2729 - accuracy: 0.5478 - val_loss: 0.3001 - val_accuracy: 0.5172\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2533 - accuracy: 0.6435 - val_loss: 0.3219 - val_accuracy: 0.5172\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2777 - accuracy: 0.6087 - val_loss: 0.2788 - val_accuracy: 0.5517\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2689 - accuracy: 0.5826 - val_loss: 0.3157 - val_accuracy: 0.5517\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2678 - accuracy: 0.5304 - val_loss: 0.3078 - val_accuracy: 0.5517\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2724 - accuracy: 0.5739 - val_loss: 0.2990 - val_accuracy: 0.4828\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2666 - accuracy: 0.5913 - val_loss: 0.3309 - val_accuracy: 0.5517\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2761 - accuracy: 0.5826 - val_loss: 0.2839 - val_accuracy: 0.4828\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2672 - accuracy: 0.6174 - val_loss: 0.2859 - val_accuracy: 0.4828\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2685 - accuracy: 0.5478 - val_loss: 0.2991 - val_accuracy: 0.4828\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2675 - accuracy: 0.6522 - val_loss: 0.2628 - val_accuracy: 0.4483\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2575 - accuracy: 0.5826 - val_loss: 0.2977 - val_accuracy: 0.4828\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2522 - accuracy: 0.6348 - val_loss: 0.2955 - val_accuracy: 0.3448\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2570 - accuracy: 0.5913 - val_loss: 0.2741 - val_accuracy: 0.4828\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2637 - accuracy: 0.5913 - val_loss: 0.3190 - val_accuracy: 0.4483\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2588 - accuracy: 0.6261 - val_loss: 0.2727 - val_accuracy: 0.6552\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2729 - accuracy: 0.5739 - val_loss: 0.3192 - val_accuracy: 0.3793\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2475 - accuracy: 0.6435 - val_loss: 0.2896 - val_accuracy: 0.4828\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2611 - accuracy: 0.5913 - val_loss: 0.3158 - val_accuracy: 0.5172\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2548 - accuracy: 0.6522 - val_loss: 0.3066 - val_accuracy: 0.5172\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2649 - accuracy: 0.6000 - val_loss: 0.2628 - val_accuracy: 0.5862\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2625 - accuracy: 0.6348 - val_loss: 0.2692 - val_accuracy: 0.6207\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2607 - accuracy: 0.6000 - val_loss: 0.3090 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2432 - accuracy: 0.6609 - val_loss: 0.3081 - val_accuracy: 0.4828\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2484 - accuracy: 0.6348 - val_loss: 0.3053 - val_accuracy: 0.4828\n",
      "0.65625\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101101110101101100001010101111100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_112 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_113 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 0.2788 - accuracy: 0.4783 - val_loss: 0.4053 - val_accuracy: 0.4138\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2304 - accuracy: 0.6783 - val_loss: 0.3803 - val_accuracy: 0.7586\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1956 - accuracy: 0.7217 - val_loss: 0.2502 - val_accuracy: 0.8621\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1714 - accuracy: 0.8696 - val_loss: 0.2067 - val_accuracy: 0.8966\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1574 - accuracy: 0.8957 - val_loss: 0.1882 - val_accuracy: 0.8621\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1490 - accuracy: 0.9652 - val_loss: 0.1774 - val_accuracy: 0.8621\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1515 - accuracy: 0.9130 - val_loss: 0.1726 - val_accuracy: 0.8621\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1500 - accuracy: 0.9130 - val_loss: 0.1266 - val_accuracy: 0.8966\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1379 - accuracy: 0.9478 - val_loss: 0.0974 - val_accuracy: 0.9310\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1316 - accuracy: 0.9826 - val_loss: 0.1194 - val_accuracy: 0.9310\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1264 - accuracy: 0.9652 - val_loss: 0.1236 - val_accuracy: 0.8966\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1244 - accuracy: 0.9739 - val_loss: 0.1569 - val_accuracy: 0.8966\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1229 - accuracy: 0.9739 - val_loss: 0.1442 - val_accuracy: 0.8621\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1179 - accuracy: 0.9826 - val_loss: 0.1715 - val_accuracy: 0.8966\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1149 - accuracy: 0.9652 - val_loss: 0.1231 - val_accuracy: 0.8966\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1190 - accuracy: 0.9826 - val_loss: 0.1435 - val_accuracy: 0.8966\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1376 - accuracy: 0.9304 - val_loss: 0.1786 - val_accuracy: 0.8276\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1754 - accuracy: 0.8348 - val_loss: 0.2581 - val_accuracy: 0.5517\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2435 - accuracy: 0.6609 - val_loss: 0.3629 - val_accuracy: 0.5172\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2411 - accuracy: 0.5217 - val_loss: 0.3410 - val_accuracy: 0.4138\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2311 - accuracy: 0.6870 - val_loss: 0.3358 - val_accuracy: 0.4483\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2305 - accuracy: 0.6783 - val_loss: 0.3819 - val_accuracy: 0.4828\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2219 - accuracy: 0.7304 - val_loss: 0.3105 - val_accuracy: 0.4483\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2310 - accuracy: 0.8000 - val_loss: 0.2829 - val_accuracy: 0.5172\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2245 - accuracy: 0.7130 - val_loss: 0.2943 - val_accuracy: 0.5862\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2290 - accuracy: 0.6174 - val_loss: 0.2485 - val_accuracy: 0.5517\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2341 - accuracy: 0.6870 - val_loss: 0.2806 - val_accuracy: 0.6207\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2389 - accuracy: 0.6522 - val_loss: 0.2633 - val_accuracy: 0.5862\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2483 - accuracy: 0.6957 - val_loss: 0.2551 - val_accuracy: 0.7241\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2623 - accuracy: 0.7043 - val_loss: 0.3059 - val_accuracy: 0.5862\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2546 - accuracy: 0.5652 - val_loss: 0.2943 - val_accuracy: 0.5172\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2514 - accuracy: 0.6261 - val_loss: 0.3106 - val_accuracy: 0.4483\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2615 - accuracy: 0.5826 - val_loss: 0.4024 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2688 - accuracy: 0.4174 - val_loss: 0.3659 - val_accuracy: 0.4138\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2820 - accuracy: 0.3739 - val_loss: 0.4092 - val_accuracy: 0.4483\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2717 - accuracy: 0.4261 - val_loss: 0.3589 - val_accuracy: 0.3793\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2731 - accuracy: 0.5391 - val_loss: 0.3330 - val_accuracy: 0.3448\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2741 - accuracy: 0.4696 - val_loss: 0.3669 - val_accuracy: 0.3793\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2661 - accuracy: 0.5217 - val_loss: 0.3981 - val_accuracy: 0.3793\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2765 - accuracy: 0.5304 - val_loss: 0.3857 - val_accuracy: 0.3793\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2692 - accuracy: 0.5565 - val_loss: 0.3045 - val_accuracy: 0.3793\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2579 - accuracy: 0.5652 - val_loss: 0.2961 - val_accuracy: 0.3793\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2519 - accuracy: 0.5913 - val_loss: 0.2939 - val_accuracy: 0.3793\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2459 - accuracy: 0.5739 - val_loss: 0.2881 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2416 - accuracy: 0.6000 - val_loss: 0.2841 - val_accuracy: 0.4138\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2381 - accuracy: 0.5652 - val_loss: 0.2801 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2422 - accuracy: 0.5913 - val_loss: 0.2821 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2381 - accuracy: 0.5043 - val_loss: 0.2690 - val_accuracy: 0.4483\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2503 - accuracy: 0.5304 - val_loss: 0.2685 - val_accuracy: 0.4483\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2429 - accuracy: 0.6000 - val_loss: 0.2706 - val_accuracy: 0.4483\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2285 - accuracy: 0.6261 - val_loss: 0.2744 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2452 - accuracy: 0.5043 - val_loss: 0.3220 - val_accuracy: 0.3793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2665 - accuracy: 0.5913 - val_loss: 0.3003 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2677 - accuracy: 0.5217 - val_loss: 0.2742 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2392 - accuracy: 0.6348 - val_loss: 0.3236 - val_accuracy: 0.3793\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2306 - accuracy: 0.6957 - val_loss: 0.3221 - val_accuracy: 0.3448\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2198 - accuracy: 0.7217 - val_loss: 0.3293 - val_accuracy: 0.3793\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2252 - accuracy: 0.7130 - val_loss: 0.3640 - val_accuracy: 0.3448\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2346 - accuracy: 0.6435 - val_loss: 0.3217 - val_accuracy: 0.4828\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2357 - accuracy: 0.6783 - val_loss: 0.3295 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2370 - accuracy: 0.6609 - val_loss: 0.3193 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2323 - accuracy: 0.6696 - val_loss: 0.3310 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2354 - accuracy: 0.6087 - val_loss: 0.3176 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2422 - accuracy: 0.6174 - val_loss: 0.3048 - val_accuracy: 0.4483\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2288 - accuracy: 0.6174 - val_loss: 0.3053 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2216 - accuracy: 0.6609 - val_loss: 0.3045 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2179 - accuracy: 0.7043 - val_loss: 0.2921 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2163 - accuracy: 0.6783 - val_loss: 0.2849 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2139 - accuracy: 0.6957 - val_loss: 0.2803 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2156 - accuracy: 0.6783 - val_loss: 0.2829 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2090 - accuracy: 0.7217 - val_loss: 0.2871 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2111 - accuracy: 0.6870 - val_loss: 0.2637 - val_accuracy: 0.4828\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1995 - accuracy: 0.7217 - val_loss: 0.2810 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1979 - accuracy: 0.7391 - val_loss: 0.2703 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2007 - accuracy: 0.7391 - val_loss: 0.2685 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2060 - accuracy: 0.7391 - val_loss: 0.2447 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2046 - accuracy: 0.6957 - val_loss: 0.2504 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1963 - accuracy: 0.7913 - val_loss: 0.2234 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1943 - accuracy: 0.7739 - val_loss: 0.2238 - val_accuracy: 0.4483\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1816 - accuracy: 0.8174 - val_loss: 0.2249 - val_accuracy: 0.4483\n",
      "0.6354166865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111101010100000\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n",
      "(144, 100, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_114 (LSTM)              (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_115 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.3469 - accuracy: 0.3826 - val_loss: 0.4536 - val_accuracy: 0.4828\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3147 - accuracy: 0.4522 - val_loss: 0.4146 - val_accuracy: 0.5517\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.3632 - accuracy: 0.3826 - val_loss: 0.3802 - val_accuracy: 0.4483\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3285 - accuracy: 0.3826 - val_loss: 0.3571 - val_accuracy: 0.3448\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3335 - accuracy: 0.3565 - val_loss: 0.3703 - val_accuracy: 0.3103\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3284 - accuracy: 0.3217 - val_loss: 0.3262 - val_accuracy: 0.5862\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3498 - accuracy: 0.3130 - val_loss: 0.3655 - val_accuracy: 0.3793\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3013 - accuracy: 0.3826 - val_loss: 0.3311 - val_accuracy: 0.4138\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2826 - accuracy: 0.4261 - val_loss: 0.3610 - val_accuracy: 0.3103\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3206 - accuracy: 0.3478 - val_loss: 0.3330 - val_accuracy: 0.3448\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3081 - accuracy: 0.3565 - val_loss: 0.3345 - val_accuracy: 0.3793\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.3067 - accuracy: 0.3739 - val_loss: 0.3357 - val_accuracy: 0.3793\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2874 - accuracy: 0.4261 - val_loss: 0.3411 - val_accuracy: 0.3103\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.3056 - accuracy: 0.3130 - val_loss: 0.3271 - val_accuracy: 0.4138\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2961 - accuracy: 0.4000 - val_loss: 0.3268 - val_accuracy: 0.4138\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2904 - accuracy: 0.4000 - val_loss: 0.3252 - val_accuracy: 0.3793\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2867 - accuracy: 0.3913 - val_loss: 0.2910 - val_accuracy: 0.3448\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2855 - accuracy: 0.4696 - val_loss: 0.3000 - val_accuracy: 0.3793\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2643 - accuracy: 0.4522 - val_loss: 0.3237 - val_accuracy: 0.3793\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2606 - accuracy: 0.4783 - val_loss: 0.2964 - val_accuracy: 0.3793\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2525 - accuracy: 0.5043 - val_loss: 0.2897 - val_accuracy: 0.4483\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2582 - accuracy: 0.4783 - val_loss: 0.3158 - val_accuracy: 0.3793\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2616 - accuracy: 0.4696 - val_loss: 0.2972 - val_accuracy: 0.3793\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2640 - accuracy: 0.5304 - val_loss: 0.2868 - val_accuracy: 0.3793\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2823 - accuracy: 0.4435 - val_loss: 0.3333 - val_accuracy: 0.4483\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2917 - accuracy: 0.4261 - val_loss: 0.3245 - val_accuracy: 0.4138\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2624 - accuracy: 0.5130 - val_loss: 0.3533 - val_accuracy: 0.3793\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2622 - accuracy: 0.5391 - val_loss: 0.3416 - val_accuracy: 0.4138\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2588 - accuracy: 0.5304 - val_loss: 0.3482 - val_accuracy: 0.4138\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2585 - accuracy: 0.5391 - val_loss: 0.3430 - val_accuracy: 0.4138\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2625 - accuracy: 0.4957 - val_loss: 0.3210 - val_accuracy: 0.4138\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2634 - accuracy: 0.5391 - val_loss: 0.3161 - val_accuracy: 0.4138\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2500 - accuracy: 0.5304 - val_loss: 0.3282 - val_accuracy: 0.3793\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2776 - accuracy: 0.4783 - val_loss: 0.3691 - val_accuracy: 0.4483\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2808 - accuracy: 0.5130 - val_loss: 0.4549 - val_accuracy: 0.4138\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2696 - accuracy: 0.4696 - val_loss: 0.3816 - val_accuracy: 0.4483\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2577 - accuracy: 0.5652 - val_loss: 0.3954 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2805 - accuracy: 0.5652 - val_loss: 0.4007 - val_accuracy: 0.4483\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2647 - accuracy: 0.5565 - val_loss: 0.3699 - val_accuracy: 0.4483\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2739 - accuracy: 0.4783 - val_loss: 0.3666 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2619 - accuracy: 0.5652 - val_loss: 0.3539 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2560 - accuracy: 0.5739 - val_loss: 0.4478 - val_accuracy: 0.4138\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2668 - accuracy: 0.5391 - val_loss: 0.3961 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2796 - accuracy: 0.4348 - val_loss: 0.3984 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2842 - accuracy: 0.5652 - val_loss: 0.2930 - val_accuracy: 0.4828\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2776 - accuracy: 0.6000 - val_loss: 0.3064 - val_accuracy: 0.3793\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2646 - accuracy: 0.6000 - val_loss: 0.3224 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2794 - accuracy: 0.5565 - val_loss: 0.3357 - val_accuracy: 0.4138\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2630 - accuracy: 0.6087 - val_loss: 0.3157 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2675 - accuracy: 0.5739 - val_loss: 0.3243 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2783 - accuracy: 0.6000 - val_loss: 0.3797 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2649 - accuracy: 0.6000 - val_loss: 0.3691 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2713 - accuracy: 0.6000 - val_loss: 0.3034 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2628 - accuracy: 0.6000 - val_loss: 0.2871 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2745 - accuracy: 0.6000 - val_loss: 0.2811 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2698 - accuracy: 0.6000 - val_loss: 0.2765 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2716 - accuracy: 0.6000 - val_loss: 0.2963 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2639 - accuracy: 0.6000 - val_loss: 0.2725 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2635 - accuracy: 0.6000 - val_loss: 0.2881 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2625 - accuracy: 0.6000 - val_loss: 0.2934 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2663 - accuracy: 0.6000 - val_loss: 0.2756 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2617 - accuracy: 0.6000 - val_loss: 0.2930 - val_accuracy: 0.3793\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2670 - accuracy: 0.5913 - val_loss: 0.3004 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2523 - accuracy: 0.6000 - val_loss: 0.2983 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2586 - accuracy: 0.6000 - val_loss: 0.2915 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2609 - accuracy: 0.6000 - val_loss: 0.2921 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2721 - accuracy: 0.5913 - val_loss: 0.2799 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2511 - accuracy: 0.5913 - val_loss: 0.2980 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2555 - accuracy: 0.5913 - val_loss: 0.2994 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2556 - accuracy: 0.6000 - val_loss: 0.3024 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2591 - accuracy: 0.6000 - val_loss: 0.3017 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2540 - accuracy: 0.6000 - val_loss: 0.3156 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2582 - accuracy: 0.5913 - val_loss: 0.3049 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2442 - accuracy: 0.6087 - val_loss: 0.3509 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2546 - accuracy: 0.6000 - val_loss: 0.3380 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2585 - accuracy: 0.6087 - val_loss: 0.3324 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2535 - accuracy: 0.6000 - val_loss: 0.3535 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2614 - accuracy: 0.6000 - val_loss: 0.3527 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2631 - accuracy: 0.6087 - val_loss: 0.3935 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2640 - accuracy: 0.6000 - val_loss: 0.3939 - val_accuracy: 0.4138\n",
      "0.6145833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101001111011101111000001001110100111001010\n",
      "22\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3360)\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_116 (LSTM)              (None, 100, 20)           270480    \n",
      "_________________________________________________________________\n",
      "lstm_117 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 273,882\n",
      "Trainable params: 273,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 0.2584 - accuracy: 0.5478 - val_loss: 0.2465 - val_accuracy: 0.6207\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1980 - accuracy: 0.8087 - val_loss: 0.1549 - val_accuracy: 0.7586\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2105 - accuracy: 0.7043 - val_loss: 0.1794 - val_accuracy: 0.7931\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2002 - accuracy: 0.7739 - val_loss: 0.1587 - val_accuracy: 0.8276\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2186 - accuracy: 0.7130 - val_loss: 0.1740 - val_accuracy: 0.7931\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2037 - accuracy: 0.7217 - val_loss: 0.1704 - val_accuracy: 0.8276\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1903 - accuracy: 0.7652 - val_loss: 0.1987 - val_accuracy: 0.7586\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1920 - accuracy: 0.8000 - val_loss: 0.2053 - val_accuracy: 0.7241\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1826 - accuracy: 0.8261 - val_loss: 0.2010 - val_accuracy: 0.7586\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1886 - accuracy: 0.8261 - val_loss: 0.2076 - val_accuracy: 0.7586\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1711 - accuracy: 0.8870 - val_loss: 0.2005 - val_accuracy: 0.7931\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1553 - accuracy: 0.8870 - val_loss: 0.1934 - val_accuracy: 0.7586\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1703 - accuracy: 0.8261 - val_loss: 0.2014 - val_accuracy: 0.7586\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1565 - accuracy: 0.8957 - val_loss: 0.1823 - val_accuracy: 0.6897\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1374 - accuracy: 0.9217 - val_loss: 0.1705 - val_accuracy: 0.7241\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1323 - accuracy: 0.9217 - val_loss: 0.1639 - val_accuracy: 0.9310\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1206 - accuracy: 0.9217 - val_loss: 0.1532 - val_accuracy: 0.9310\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1172 - accuracy: 0.9304 - val_loss: 0.1428 - val_accuracy: 0.9655\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1138 - accuracy: 0.9304 - val_loss: 0.1320 - val_accuracy: 0.9655\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1046 - accuracy: 0.9565 - val_loss: 0.1241 - val_accuracy: 0.9655\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1075 - accuracy: 0.9478 - val_loss: 0.1182 - val_accuracy: 0.9655\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0894 - accuracy: 0.9478 - val_loss: 0.1106 - val_accuracy: 0.9655\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0847 - accuracy: 0.9739 - val_loss: 0.1066 - val_accuracy: 0.9655\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0791 - accuracy: 0.9739 - val_loss: 0.0974 - val_accuracy: 0.9655\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0802 - accuracy: 0.9739 - val_loss: 0.0926 - val_accuracy: 0.9655\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0685 - accuracy: 0.9739 - val_loss: 0.0955 - val_accuracy: 0.9655\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0704 - accuracy: 0.9826 - val_loss: 0.0946 - val_accuracy: 0.9655\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0667 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0575 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0598 - accuracy: 0.9913 - val_loss: 0.0744 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0491 - accuracy: 0.9913 - val_loss: 0.0740 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.0623 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.0574 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0484 - accuracy: 0.9913 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0507 - accuracy: 0.9913 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0247 - accuracy: 0.9913 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0171 - accuracy: 0.9913 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "1.0\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101100111010011011011101110100100001011101\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_118 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_119 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 0.2942 - accuracy: 0.4870 - val_loss: 0.3661 - val_accuracy: 0.5172\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2825 - accuracy: 0.5391 - val_loss: 0.4213 - val_accuracy: 0.4138\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2929 - accuracy: 0.4609 - val_loss: 0.4527 - val_accuracy: 0.2069\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3222 - accuracy: 0.4348 - val_loss: 0.3271 - val_accuracy: 0.5172\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2913 - accuracy: 0.5043 - val_loss: 0.3403 - val_accuracy: 0.4483\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3073 - accuracy: 0.4696 - val_loss: 0.4138 - val_accuracy: 0.3103\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3524 - accuracy: 0.2522 - val_loss: 0.4039 - val_accuracy: 0.3103\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3553 - accuracy: 0.2174 - val_loss: 0.3317 - val_accuracy: 0.4138\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2921 - accuracy: 0.3478 - val_loss: 0.3594 - val_accuracy: 0.3103\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3306 - accuracy: 0.2174 - val_loss: 0.3142 - val_accuracy: 0.2414\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2852 - accuracy: 0.4000 - val_loss: 0.3426 - val_accuracy: 0.4138\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2679 - accuracy: 0.4957 - val_loss: 0.3776 - val_accuracy: 0.3793\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2920 - accuracy: 0.4522 - val_loss: 0.3827 - val_accuracy: 0.4483\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3252 - accuracy: 0.3304 - val_loss: 0.4021 - val_accuracy: 0.3793\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3148 - accuracy: 0.4087 - val_loss: 0.3447 - val_accuracy: 0.4828\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2893 - accuracy: 0.4435 - val_loss: 0.3782 - val_accuracy: 0.5172\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2644 - accuracy: 0.4522 - val_loss: 0.3335 - val_accuracy: 0.4138\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2628 - accuracy: 0.6261 - val_loss: 0.3113 - val_accuracy: 0.4828\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2462 - accuracy: 0.6087 - val_loss: 0.3139 - val_accuracy: 0.4483\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2612 - accuracy: 0.6522 - val_loss: 0.3601 - val_accuracy: 0.2759\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2635 - accuracy: 0.5739 - val_loss: 0.3446 - val_accuracy: 0.3103\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2402 - accuracy: 0.6174 - val_loss: 0.3048 - val_accuracy: 0.4483\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2522 - accuracy: 0.6174 - val_loss: 0.2352 - val_accuracy: 0.5172\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2393 - accuracy: 0.6174 - val_loss: 0.2624 - val_accuracy: 0.4483\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2378 - accuracy: 0.6957 - val_loss: 0.2447 - val_accuracy: 0.4828\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2402 - accuracy: 0.6435 - val_loss: 0.2584 - val_accuracy: 0.4483\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2308 - accuracy: 0.7130 - val_loss: 0.2631 - val_accuracy: 0.4138\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2383 - accuracy: 0.6783 - val_loss: 0.2548 - val_accuracy: 0.4483\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2404 - accuracy: 0.6522 - val_loss: 0.2609 - val_accuracy: 0.4483\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2312 - accuracy: 0.6609 - val_loss: 0.2531 - val_accuracy: 0.4828\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2431 - accuracy: 0.6348 - val_loss: 0.2538 - val_accuracy: 0.4828\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2427 - accuracy: 0.6348 - val_loss: 0.2515 - val_accuracy: 0.4483\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2251 - accuracy: 0.6957 - val_loss: 0.2739 - val_accuracy: 0.3793\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2369 - accuracy: 0.6087 - val_loss: 0.2510 - val_accuracy: 0.4483\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2289 - accuracy: 0.6696 - val_loss: 0.2820 - val_accuracy: 0.5172\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2179 - accuracy: 0.6957 - val_loss: 0.2642 - val_accuracy: 0.5172\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2324 - accuracy: 0.6696 - val_loss: 0.2777 - val_accuracy: 0.4828\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2580 - accuracy: 0.6174 - val_loss: 0.2817 - val_accuracy: 0.4483\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2180 - accuracy: 0.7478 - val_loss: 0.2617 - val_accuracy: 0.4483\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2160 - accuracy: 0.6261 - val_loss: 0.2621 - val_accuracy: 0.4828\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1977 - accuracy: 0.6696 - val_loss: 0.2635 - val_accuracy: 0.4828\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1988 - accuracy: 0.7304 - val_loss: 0.2657 - val_accuracy: 0.4828\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1944 - accuracy: 0.7391 - val_loss: 0.2667 - val_accuracy: 0.5172\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2009 - accuracy: 0.6783 - val_loss: 0.2787 - val_accuracy: 0.5517\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1927 - accuracy: 0.7217 - val_loss: 0.2617 - val_accuracy: 0.5862\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2014 - accuracy: 0.6609 - val_loss: 0.2669 - val_accuracy: 0.5862\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2015 - accuracy: 0.7043 - val_loss: 0.2647 - val_accuracy: 0.5862\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1890 - accuracy: 0.7217 - val_loss: 0.2609 - val_accuracy: 0.6207\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1828 - accuracy: 0.7217 - val_loss: 0.2642 - val_accuracy: 0.6207\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1952 - accuracy: 0.7478 - val_loss: 0.2685 - val_accuracy: 0.6207\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2106 - accuracy: 0.70 - 0s 119ms/step - loss: 0.2106 - accuracy: 0.7043 - val_loss: 0.2678 - val_accuracy: 0.6207\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2090 - accuracy: 0.6957 - val_loss: 0.2680 - val_accuracy: 0.6207\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2025 - accuracy: 0.6783 - val_loss: 0.2665 - val_accuracy: 0.6207\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1964 - accuracy: 0.6957 - val_loss: 0.2639 - val_accuracy: 0.6207\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1915 - accuracy: 0.7217 - val_loss: 0.2605 - val_accuracy: 0.6207\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1688 - accuracy: 0.7739 - val_loss: 0.2603 - val_accuracy: 0.6207\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1708 - accuracy: 0.6957 - val_loss: 0.2594 - val_accuracy: 0.6207\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1748 - accuracy: 0.7565 - val_loss: 0.2594 - val_accuracy: 0.6207\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1659 - accuracy: 0.7826 - val_loss: 0.2585 - val_accuracy: 0.6552\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1643 - accuracy: 0.7652 - val_loss: 0.2577 - val_accuracy: 0.6552\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1618 - accuracy: 0.7739 - val_loss: 0.2569 - val_accuracy: 0.6552\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1563 - accuracy: 0.8261 - val_loss: 0.2562 - val_accuracy: 0.6897\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1635 - accuracy: 0.7739 - val_loss: 0.2554 - val_accuracy: 0.6897\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1591 - accuracy: 0.7739 - val_loss: 0.2545 - val_accuracy: 0.6552\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1557 - accuracy: 0.8348 - val_loss: 0.2534 - val_accuracy: 0.6552\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1536 - accuracy: 0.7913 - val_loss: 0.2513 - val_accuracy: 0.6207\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1510 - accuracy: 0.7565 - val_loss: 0.2504 - val_accuracy: 0.6207\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1461 - accuracy: 0.8696 - val_loss: 0.2495 - val_accuracy: 0.5862\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1441 - accuracy: 0.8000 - val_loss: 0.2479 - val_accuracy: 0.6207\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1458 - accuracy: 0.8522 - val_loss: 0.2467 - val_accuracy: 0.6207\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1449 - accuracy: 0.8522 - val_loss: 0.2456 - val_accuracy: 0.5862\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1471 - accuracy: 0.8174 - val_loss: 0.2446 - val_accuracy: 0.5862\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1475 - accuracy: 0.8522 - val_loss: 0.2438 - val_accuracy: 0.5862\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1405 - accuracy: 0.8435 - val_loss: 0.2428 - val_accuracy: 0.5862\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1449 - accuracy: 0.9043 - val_loss: 0.2419 - val_accuracy: 0.5862\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1445 - accuracy: 0.9217 - val_loss: 0.2410 - val_accuracy: 0.5862\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1426 - accuracy: 0.9130 - val_loss: 0.2402 - val_accuracy: 0.5862\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1383 - accuracy: 0.9130 - val_loss: 0.2393 - val_accuracy: 0.5862\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1393 - accuracy: 0.9217 - val_loss: 0.2384 - val_accuracy: 0.5862\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1390 - accuracy: 0.9130 - val_loss: 0.2375 - val_accuracy: 0.5862\n",
      "0.5833333134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101000010101101010001000111010100111001010\n",
      "26\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2880)\n",
      "(144, 100, 2880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_120 (LSTM)              (None, 100, 20)           232080    \n",
      "_________________________________________________________________\n",
      "lstm_121 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 235,482\n",
      "Trainable params: 235,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.1410 - accuracy: 0.8870 - val_loss: 0.2764 - val_accuracy: 0.6897\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2633 - accuracy: 0.5478 - val_loss: 0.3438 - val_accuracy: 0.5862\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.3001 - accuracy: 0.4435 - val_loss: 0.2853 - val_accuracy: 0.5862\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2911 - accuracy: 0.4783 - val_loss: 0.3277 - val_accuracy: 0.6207\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2919 - accuracy: 0.5565 - val_loss: 0.4074 - val_accuracy: 0.3793\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.3282 - accuracy: 0.4174 - val_loss: 0.4076 - val_accuracy: 0.3103\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3017 - accuracy: 0.4522 - val_loss: 0.3981 - val_accuracy: 0.3793\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2863 - accuracy: 0.4609 - val_loss: 0.3357 - val_accuracy: 0.5517\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2797 - accuracy: 0.5391 - val_loss: 0.3553 - val_accuracy: 0.4138\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2614 - accuracy: 0.4783 - val_loss: 0.3623 - val_accuracy: 0.3448\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2725 - accuracy: 0.6435 - val_loss: 0.3509 - val_accuracy: 0.4828\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2861 - accuracy: 0.4957 - val_loss: 0.3826 - val_accuracy: 0.3448\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2892 - accuracy: 0.5304 - val_loss: 0.3526 - val_accuracy: 0.4138\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2636 - accuracy: 0.5826 - val_loss: 0.3517 - val_accuracy: 0.5862\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2510 - accuracy: 0.6783 - val_loss: 0.3569 - val_accuracy: 0.6897\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2736 - accuracy: 0.5739 - val_loss: 0.3689 - val_accuracy: 0.3793\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2729 - accuracy: 0.5478 - val_loss: 0.3787 - val_accuracy: 0.4138\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2635 - accuracy: 0.5391 - val_loss: 0.3730 - val_accuracy: 0.5517\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2567 - accuracy: 0.6261 - val_loss: 0.3390 - val_accuracy: 0.6207\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2446 - accuracy: 0.6522 - val_loss: 0.3560 - val_accuracy: 0.5172\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2460 - accuracy: 0.5913 - val_loss: 0.3574 - val_accuracy: 0.5862\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2416 - accuracy: 0.5913 - val_loss: 0.3497 - val_accuracy: 0.5517\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2479 - accuracy: 0.5826 - val_loss: 0.2937 - val_accuracy: 0.6552\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2476 - accuracy: 0.5478 - val_loss: 0.2897 - val_accuracy: 0.6207\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2364 - accuracy: 0.5826 - val_loss: 0.3102 - val_accuracy: 0.5172\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2318 - accuracy: 0.6696 - val_loss: 0.3323 - val_accuracy: 0.4483\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2399 - accuracy: 0.5565 - val_loss: 0.3314 - val_accuracy: 0.4828\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2406 - accuracy: 0.6435 - val_loss: 0.3231 - val_accuracy: 0.4828\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2449 - accuracy: 0.6174 - val_loss: 0.3037 - val_accuracy: 0.4828\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2453 - accuracy: 0.6609 - val_loss: 0.3226 - val_accuracy: 0.4138\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2524 - accuracy: 0.6261 - val_loss: 0.2873 - val_accuracy: 0.4828\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2480 - accuracy: 0.6087 - val_loss: 0.2973 - val_accuracy: 0.5172\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2329 - accuracy: 0.6609 - val_loss: 0.2934 - val_accuracy: 0.4828\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2306 - accuracy: 0.6522 - val_loss: 0.2519 - val_accuracy: 0.6897\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2348 - accuracy: 0.6435 - val_loss: 0.2968 - val_accuracy: 0.3448\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2348 - accuracy: 0.6609 - val_loss: 0.3162 - val_accuracy: 0.3103\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2536 - accuracy: 0.5739 - val_loss: 0.3198 - val_accuracy: 0.3448\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2309 - accuracy: 0.6783 - val_loss: 0.2716 - val_accuracy: 0.6207\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2471 - accuracy: 0.5913 - val_loss: 0.2760 - val_accuracy: 0.6207\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2519 - accuracy: 0.6174 - val_loss: 0.2504 - val_accuracy: 0.7241\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2308 - accuracy: 0.7217 - val_loss: 0.2805 - val_accuracy: 0.3793\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2235 - accuracy: 0.7565 - val_loss: 0.2885 - val_accuracy: 0.4483\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2329 - accuracy: 0.7130 - val_loss: 0.3030 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2539 - accuracy: 0.6609 - val_loss: 0.2645 - val_accuracy: 0.5517\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2308 - accuracy: 0.7043 - val_loss: 0.3022 - val_accuracy: 0.4483\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2215 - accuracy: 0.7217 - val_loss: 0.2958 - val_accuracy: 0.4483\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2320 - accuracy: 0.6435 - val_loss: 0.2832 - val_accuracy: 0.4828\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2224 - accuracy: 0.7130 - val_loss: 0.2490 - val_accuracy: 0.6552\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2170 - accuracy: 0.7043 - val_loss: 0.2545 - val_accuracy: 0.6207\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2101 - accuracy: 0.7478 - val_loss: 0.2792 - val_accuracy: 0.4828\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2199 - accuracy: 0.6609 - val_loss: 0.2467 - val_accuracy: 0.6207\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2228 - accuracy: 0.6696 - val_loss: 0.2543 - val_accuracy: 0.6552\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2146 - accuracy: 0.7130 - val_loss: 0.2554 - val_accuracy: 0.6552\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2298 - accuracy: 0.6609 - val_loss: 0.2577 - val_accuracy: 0.5862\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2225 - accuracy: 0.6696 - val_loss: 0.2429 - val_accuracy: 0.6897\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2206 - accuracy: 0.6783 - val_loss: 0.2417 - val_accuracy: 0.6207\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2241 - accuracy: 0.6522 - val_loss: 0.2432 - val_accuracy: 0.6552\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2239 - accuracy: 0.6870 - val_loss: 0.2523 - val_accuracy: 0.5172\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2229 - accuracy: 0.7043 - val_loss: 0.2625 - val_accuracy: 0.4483\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2195 - accuracy: 0.6522 - val_loss: 0.2629 - val_accuracy: 0.4828\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2256 - accuracy: 0.6783 - val_loss: 0.2519 - val_accuracy: 0.5862\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2176 - accuracy: 0.7043 - val_loss: 0.2535 - val_accuracy: 0.4828\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2264 - accuracy: 0.6609 - val_loss: 0.2528 - val_accuracy: 0.5517\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2225 - accuracy: 0.6696 - val_loss: 0.2284 - val_accuracy: 0.6897\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2180 - accuracy: 0.6522 - val_loss: 0.2466 - val_accuracy: 0.6207\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2252 - accuracy: 0.6696 - val_loss: 0.2451 - val_accuracy: 0.6552\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2208 - accuracy: 0.6870 - val_loss: 0.2562 - val_accuracy: 0.5517\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2187 - accuracy: 0.6783 - val_loss: 0.2696 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2275 - accuracy: 0.6522 - val_loss: 0.2597 - val_accuracy: 0.5172\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2183 - accuracy: 0.6957 - val_loss: 0.2565 - val_accuracy: 0.4828\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2137 - accuracy: 0.7130 - val_loss: 0.2737 - val_accuracy: 0.4483\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2194 - accuracy: 0.6522 - val_loss: 0.2713 - val_accuracy: 0.4483\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2181 - accuracy: 0.7130 - val_loss: 0.2667 - val_accuracy: 0.4828\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2174 - accuracy: 0.7217 - val_loss: 0.2828 - val_accuracy: 0.4483\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2136 - accuracy: 0.6783 - val_loss: 0.2601 - val_accuracy: 0.4828\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2196 - accuracy: 0.6957 - val_loss: 0.2864 - val_accuracy: 0.4483\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2205 - accuracy: 0.6696 - val_loss: 0.2603 - val_accuracy: 0.5172\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2142 - accuracy: 0.7304 - val_loss: 0.2687 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2130 - accuracy: 0.6870 - val_loss: 0.2681 - val_accuracy: 0.4483\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2206 - accuracy: 0.6783 - val_loss: 0.2784 - val_accuracy: 0.4138\n",
      "0.65625\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101111011101111000001001110100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_122 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_123 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 0.3149 - accuracy: 0.4087 - val_loss: 0.3036 - val_accuracy: 0.6207\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3179 - accuracy: 0.4087 - val_loss: 0.3347 - val_accuracy: 0.6207\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3075 - accuracy: 0.4696 - val_loss: 0.4082 - val_accuracy: 0.4828\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3095 - accuracy: 0.4696 - val_loss: 0.3857 - val_accuracy: 0.4138\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3164 - accuracy: 0.4435 - val_loss: 0.3904 - val_accuracy: 0.4138\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3213 - accuracy: 0.4609 - val_loss: 0.3232 - val_accuracy: 0.5172\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3050 - accuracy: 0.5217 - val_loss: 0.3328 - val_accuracy: 0.4483\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3121 - accuracy: 0.4609 - val_loss: 0.3476 - val_accuracy: 0.3793\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2656 - accuracy: 0.6000 - val_loss: 0.3022 - val_accuracy: 0.5862\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2613 - accuracy: 0.6000 - val_loss: 0.4029 - val_accuracy: 0.3448\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.3190 - accuracy: 0.4609 - val_loss: 0.3157 - val_accuracy: 0.5517\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2981 - accuracy: 0.5217 - val_loss: 0.4253 - val_accuracy: 0.2759\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3411 - accuracy: 0.3913 - val_loss: 0.3694 - val_accuracy: 0.3448\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3166 - accuracy: 0.4522 - val_loss: 0.3722 - val_accuracy: 0.3103\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3186 - accuracy: 0.4522 - val_loss: 0.3596 - val_accuracy: 0.3793\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2991 - accuracy: 0.4957 - val_loss: 0.3155 - val_accuracy: 0.4138\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2798 - accuracy: 0.5826 - val_loss: 0.3168 - val_accuracy: 0.5172\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2706 - accuracy: 0.5565 - val_loss: 0.2936 - val_accuracy: 0.4138\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3279 - accuracy: 0.3913 - val_loss: 0.2901 - val_accuracy: 0.5172\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2991 - accuracy: 0.4870 - val_loss: 0.3073 - val_accuracy: 0.4828\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2930 - accuracy: 0.4609 - val_loss: 0.2576 - val_accuracy: 0.5862\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2806 - accuracy: 0.5043 - val_loss: 0.2855 - val_accuracy: 0.5862\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2828 - accuracy: 0.5304 - val_loss: 0.3099 - val_accuracy: 0.5172\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2616 - accuracy: 0.6174 - val_loss: 0.2750 - val_accuracy: 0.5517\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2720 - accuracy: 0.5826 - val_loss: 0.3129 - val_accuracy: 0.3793\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2825 - accuracy: 0.5565 - val_loss: 0.2912 - val_accuracy: 0.5517\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2852 - accuracy: 0.5739 - val_loss: 0.3402 - val_accuracy: 0.4483\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2936 - accuracy: 0.5217 - val_loss: 0.2985 - val_accuracy: 0.5172\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3110 - accuracy: 0.4522 - val_loss: 0.3553 - val_accuracy: 0.4483\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3067 - accuracy: 0.4609 - val_loss: 0.3296 - val_accuracy: 0.4138\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2951 - accuracy: 0.5043 - val_loss: 0.3249 - val_accuracy: 0.3793\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3014 - accuracy: 0.4087 - val_loss: 0.3225 - val_accuracy: 0.4828\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2711 - accuracy: 0.5043 - val_loss: 0.3660 - val_accuracy: 0.3448\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2954 - accuracy: 0.5043 - val_loss: 0.3596 - val_accuracy: 0.3103\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2905 - accuracy: 0.5391 - val_loss: 0.3287 - val_accuracy: 0.3448\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2633 - accuracy: 0.6174 - val_loss: 0.4118 - val_accuracy: 0.3103\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2798 - accuracy: 0.4870 - val_loss: 0.3298 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2848 - accuracy: 0.5391 - val_loss: 0.3214 - val_accuracy: 0.3448\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2929 - accuracy: 0.4870 - val_loss: 0.3374 - val_accuracy: 0.3793\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2902 - accuracy: 0.5304 - val_loss: 0.3130 - val_accuracy: 0.4828\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2984 - accuracy: 0.5043 - val_loss: 0.3300 - val_accuracy: 0.3793\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2828 - accuracy: 0.5130 - val_loss: 0.3604 - val_accuracy: 0.3448\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2788 - accuracy: 0.5478 - val_loss: 0.3013 - val_accuracy: 0.4483\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2863 - accuracy: 0.5391 - val_loss: 0.2813 - val_accuracy: 0.5172\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2725 - accuracy: 0.5652 - val_loss: 0.3566 - val_accuracy: 0.3103\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2950 - accuracy: 0.5304 - val_loss: 0.3055 - val_accuracy: 0.5172\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2871 - accuracy: 0.5391 - val_loss: 0.3821 - val_accuracy: 0.3448\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2842 - accuracy: 0.5391 - val_loss: 0.3423 - val_accuracy: 0.4483\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2848 - accuracy: 0.5391 - val_loss: 0.3474 - val_accuracy: 0.3793\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3022 - accuracy: 0.5043 - val_loss: 0.3364 - val_accuracy: 0.3448\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3050 - accuracy: 0.5043 - val_loss: 0.3301 - val_accuracy: 0.4483\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2856 - accuracy: 0.5304 - val_loss: 0.3549 - val_accuracy: 0.4483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3027 - accuracy: 0.5304 - val_loss: 0.3325 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2730 - accuracy: 0.5652 - val_loss: 0.4066 - val_accuracy: 0.2414\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2820 - accuracy: 0.5304 - val_loss: 0.3559 - val_accuracy: 0.3448\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3114 - accuracy: 0.4348 - val_loss: 0.3806 - val_accuracy: 0.3448\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3138 - accuracy: 0.4435 - val_loss: 0.3418 - val_accuracy: 0.4828\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3048 - accuracy: 0.4522 - val_loss: 0.3116 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2999 - accuracy: 0.5130 - val_loss: 0.3415 - val_accuracy: 0.3448\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2962 - accuracy: 0.5217 - val_loss: 0.3331 - val_accuracy: 0.3793\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2985 - accuracy: 0.4870 - val_loss: 0.3268 - val_accuracy: 0.3448\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2955 - accuracy: 0.4609 - val_loss: 0.3354 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2867 - accuracy: 0.5304 - val_loss: 0.3237 - val_accuracy: 0.3793\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2743 - accuracy: 0.5652 - val_loss: 0.3088 - val_accuracy: 0.4828\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2850 - accuracy: 0.5130 - val_loss: 0.3278 - val_accuracy: 0.3448\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2747 - accuracy: 0.5478 - val_loss: 0.3154 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2984 - accuracy: 0.4870 - val_loss: 0.2990 - val_accuracy: 0.3793\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2684 - accuracy: 0.5652 - val_loss: 0.2668 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2407 - accuracy: 0.6522 - val_loss: 0.2664 - val_accuracy: 0.3793\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2321 - accuracy: 0.6522 - val_loss: 0.3028 - val_accuracy: 0.3793\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2552 - accuracy: 0.6174 - val_loss: 0.2868 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2398 - accuracy: 0.6348 - val_loss: 0.2687 - val_accuracy: 0.4483\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2573 - accuracy: 0.6000 - val_loss: 0.2711 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2496 - accuracy: 0.6174 - val_loss: 0.2675 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2394 - accuracy: 0.6174 - val_loss: 0.2718 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2477 - accuracy: 0.6000 - val_loss: 0.2663 - val_accuracy: 0.4483\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2322 - accuracy: 0.6696 - val_loss: 0.2673 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2496 - accuracy: 0.6435 - val_loss: 0.2703 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2444 - accuracy: 0.6609 - val_loss: 0.2715 - val_accuracy: 0.3793\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2665 - accuracy: 0.5826 - val_loss: 0.2718 - val_accuracy: 0.4138\n",
      "0.6145833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101111000001001110100111001010\n",
      "22\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3360)\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_124 (LSTM)              (None, 100, 20)           270480    \n",
      "_________________________________________________________________\n",
      "lstm_125 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 273,882\n",
      "Trainable params: 273,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 0.3134 - accuracy: 0.3826 - val_loss: 0.3231 - val_accuracy: 0.3448\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2866 - accuracy: 0.3826 - val_loss: 0.3575 - val_accuracy: 0.3103\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2948 - accuracy: 0.3565 - val_loss: 0.5000 - val_accuracy: 0.1724\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2944 - accuracy: 0.4609 - val_loss: 0.4270 - val_accuracy: 0.3448\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2917 - accuracy: 0.4957 - val_loss: 0.3439 - val_accuracy: 0.4483\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2911 - accuracy: 0.4348 - val_loss: 0.3581 - val_accuracy: 0.4828\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2917 - accuracy: 0.5652 - val_loss: 0.2732 - val_accuracy: 0.5172\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2670 - accuracy: 0.5478 - val_loss: 0.3396 - val_accuracy: 0.2414\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2930 - accuracy: 0.4783 - val_loss: 0.2638 - val_accuracy: 0.5517\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.3125 - accuracy: 0.5043 - val_loss: 0.3182 - val_accuracy: 0.3103\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2919 - accuracy: 0.4696 - val_loss: 0.2919 - val_accuracy: 0.4138\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2968 - accuracy: 0.5565 - val_loss: 0.3555 - val_accuracy: 0.3793\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2958 - accuracy: 0.5826 - val_loss: 0.2582 - val_accuracy: 0.5862\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2692 - accuracy: 0.6087 - val_loss: 0.3244 - val_accuracy: 0.6207\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2802 - accuracy: 0.6348 - val_loss: 0.2875 - val_accuracy: 0.7586\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2755 - accuracy: 0.5739 - val_loss: 0.3042 - val_accuracy: 0.5517\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2755 - accuracy: 0.5913 - val_loss: 0.2902 - val_accuracy: 0.5172\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2573 - accuracy: 0.7130 - val_loss: 0.2745 - val_accuracy: 0.5862\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2640 - accuracy: 0.6870 - val_loss: 0.2677 - val_accuracy: 0.5517\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2880 - accuracy: 0.5913 - val_loss: 0.2413 - val_accuracy: 0.6207\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2666 - accuracy: 0.6696 - val_loss: 0.2558 - val_accuracy: 0.5517\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2957 - accuracy: 0.6261 - val_loss: 0.2720 - val_accuracy: 0.6552\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2776 - accuracy: 0.6870 - val_loss: 0.2614 - val_accuracy: 0.5517\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2837 - accuracy: 0.5826 - val_loss: 0.2575 - val_accuracy: 0.5517\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2819 - accuracy: 0.6609 - val_loss: 0.2448 - val_accuracy: 0.5517\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2818 - accuracy: 0.5043 - val_loss: 0.2318 - val_accuracy: 0.4828\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2947 - accuracy: 0.6174 - val_loss: 0.2701 - val_accuracy: 0.4483\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2897 - accuracy: 0.5739 - val_loss: 0.2578 - val_accuracy: 0.6552\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3033 - accuracy: 0.5130 - val_loss: 0.2750 - val_accuracy: 0.6207\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2772 - accuracy: 0.6348 - val_loss: 0.3658 - val_accuracy: 0.4483\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2601 - accuracy: 0.6261 - val_loss: 0.4412 - val_accuracy: 0.4138\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2937 - accuracy: 0.5913 - val_loss: 0.3856 - val_accuracy: 0.4483\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2739 - accuracy: 0.6348 - val_loss: 0.3950 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2801 - accuracy: 0.5826 - val_loss: 0.3926 - val_accuracy: 0.4138\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2782 - accuracy: 0.6000 - val_loss: 0.3583 - val_accuracy: 0.4138\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2668 - accuracy: 0.6435 - val_loss: 0.3698 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2557 - accuracy: 0.6870 - val_loss: 0.3527 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2759 - accuracy: 0.6087 - val_loss: 0.3452 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2625 - accuracy: 0.6261 - val_loss: 0.3538 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2656 - accuracy: 0.5913 - val_loss: 0.3380 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2441 - accuracy: 0.6261 - val_loss: 0.3196 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2593 - accuracy: 0.5652 - val_loss: 0.3131 - val_accuracy: 0.4483\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2864 - accuracy: 0.5652 - val_loss: 0.3580 - val_accuracy: 0.3793\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2784 - accuracy: 0.5478 - val_loss: 0.3078 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2728 - accuracy: 0.5478 - val_loss: 0.2992 - val_accuracy: 0.4828\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2712 - accuracy: 0.5913 - val_loss: 0.3155 - val_accuracy: 0.4483\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2708 - accuracy: 0.5826 - val_loss: 0.3257 - val_accuracy: 0.4828\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2725 - accuracy: 0.5391 - val_loss: 0.3200 - val_accuracy: 0.4138\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2370 - accuracy: 0.6261 - val_loss: 0.2903 - val_accuracy: 0.4483\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2476 - accuracy: 0.5565 - val_loss: 0.2932 - val_accuracy: 0.4483\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2486 - accuracy: 0.5739 - val_loss: 0.2791 - val_accuracy: 0.4483\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2394 - accuracy: 0.6174 - val_loss: 0.2778 - val_accuracy: 0.4828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2447 - accuracy: 0.6174 - val_loss: 0.2718 - val_accuracy: 0.4483\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2545 - accuracy: 0.5913 - val_loss: 0.2760 - val_accuracy: 0.4483\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2793 - accuracy: 0.5652 - val_loss: 0.2799 - val_accuracy: 0.4483\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2775 - accuracy: 0.5565 - val_loss: 0.2800 - val_accuracy: 0.4483\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2698 - accuracy: 0.5739 - val_loss: 0.2758 - val_accuracy: 0.4483\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2698 - accuracy: 0.5826 - val_loss: 0.2779 - val_accuracy: 0.4483\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2624 - accuracy: 0.5652 - val_loss: 0.2774 - val_accuracy: 0.4828\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2588 - accuracy: 0.5826 - val_loss: 0.2771 - val_accuracy: 0.4828\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2682 - accuracy: 0.6000 - val_loss: 0.2760 - val_accuracy: 0.4828\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2588 - accuracy: 0.6087 - val_loss: 0.2726 - val_accuracy: 0.5172\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2607 - accuracy: 0.6000 - val_loss: 0.2713 - val_accuracy: 0.5172\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2585 - accuracy: 0.5739 - val_loss: 0.2703 - val_accuracy: 0.5172\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2569 - accuracy: 0.5565 - val_loss: 0.2695 - val_accuracy: 0.5172\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2623 - accuracy: 0.5565 - val_loss: 0.2685 - val_accuracy: 0.5517\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2580 - accuracy: 0.5739 - val_loss: 0.2678 - val_accuracy: 0.5517\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2549 - accuracy: 0.6174 - val_loss: 0.2672 - val_accuracy: 0.5517\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2548 - accuracy: 0.6174 - val_loss: 0.2665 - val_accuracy: 0.5517\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2489 - accuracy: 0.5913 - val_loss: 0.2659 - val_accuracy: 0.5517\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2467 - accuracy: 0.6087 - val_loss: 0.2651 - val_accuracy: 0.5517\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2557 - accuracy: 0.5913 - val_loss: 0.2644 - val_accuracy: 0.5517\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2486 - accuracy: 0.6174 - val_loss: 0.2637 - val_accuracy: 0.5517\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2488 - accuracy: 0.6087 - val_loss: 0.2631 - val_accuracy: 0.5517\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2451 - accuracy: 0.6000 - val_loss: 0.2625 - val_accuracy: 0.5517\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2463 - accuracy: 0.6000 - val_loss: 0.2620 - val_accuracy: 0.5517\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2446 - accuracy: 0.6000 - val_loss: 0.2613 - val_accuracy: 0.5517\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2490 - accuracy: 0.6087 - val_loss: 0.2605 - val_accuracy: 0.5517\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2474 - accuracy: 0.6174 - val_loss: 0.2598 - val_accuracy: 0.5517\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2429 - accuracy: 0.5913 - val_loss: 0.2592 - val_accuracy: 0.5517\n",
      "0.6041666865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101010100111001010\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3240)\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_126 (LSTM)              (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_127 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.2426 - accuracy: 0.6696 - val_loss: 0.3167 - val_accuracy: 0.4828\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2261 - accuracy: 0.6522 - val_loss: 0.2496 - val_accuracy: 0.5862\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2354 - accuracy: 0.6435 - val_loss: 0.2175 - val_accuracy: 0.6207\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2471 - accuracy: 0.6000 - val_loss: 0.3257 - val_accuracy: 0.5172\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2733 - accuracy: 0.5217 - val_loss: 0.2324 - val_accuracy: 0.5172\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3074 - accuracy: 0.4783 - val_loss: 0.3429 - val_accuracy: 0.3793\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2819 - accuracy: 0.5652 - val_loss: 0.3000 - val_accuracy: 0.7586\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2829 - accuracy: 0.6261 - val_loss: 0.3194 - val_accuracy: 0.4138\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2831 - accuracy: 0.5043 - val_loss: 0.3475 - val_accuracy: 0.4138\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2761 - accuracy: 0.6087 - val_loss: 0.3468 - val_accuracy: 0.5172\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2803 - accuracy: 0.6000 - val_loss: 0.3378 - val_accuracy: 0.5517\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2711 - accuracy: 0.6522 - val_loss: 0.3213 - val_accuracy: 0.5517\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2827 - accuracy: 0.5652 - val_loss: 0.3418 - val_accuracy: 0.4483\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2622 - accuracy: 0.6435 - val_loss: 0.2452 - val_accuracy: 0.6552\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2718 - accuracy: 0.6348 - val_loss: 0.3072 - val_accuracy: 0.5172\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2751 - accuracy: 0.6174 - val_loss: 0.3455 - val_accuracy: 0.5172\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2710 - accuracy: 0.6087 - val_loss: 0.3253 - val_accuracy: 0.4828\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2934 - accuracy: 0.5304 - val_loss: 0.2938 - val_accuracy: 0.4138\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2907 - accuracy: 0.5565 - val_loss: 0.3487 - val_accuracy: 0.3448\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2893 - accuracy: 0.5652 - val_loss: 0.3490 - val_accuracy: 0.4138\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2802 - accuracy: 0.5739 - val_loss: 0.3176 - val_accuracy: 0.4483\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2815 - accuracy: 0.5304 - val_loss: 0.3002 - val_accuracy: 0.4828\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2751 - accuracy: 0.5913 - val_loss: 0.2741 - val_accuracy: 0.5172\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2687 - accuracy: 0.6348 - val_loss: 0.2608 - val_accuracy: 0.5172\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2687 - accuracy: 0.5826 - val_loss: 0.2864 - val_accuracy: 0.4138\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2678 - accuracy: 0.6348 - val_loss: 0.2568 - val_accuracy: 0.5172\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2858 - accuracy: 0.5652 - val_loss: 0.2762 - val_accuracy: 0.4483\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.3091 - accuracy: 0.4870 - val_loss: 0.2654 - val_accuracy: 0.4828\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2999 - accuracy: 0.5217 - val_loss: 0.2982 - val_accuracy: 0.4138\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3071 - accuracy: 0.4696 - val_loss: 0.2987 - val_accuracy: 0.4138\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2840 - accuracy: 0.5130 - val_loss: 0.3302 - val_accuracy: 0.3103\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2715 - accuracy: 0.5478 - val_loss: 0.3026 - val_accuracy: 0.3793\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.3032 - accuracy: 0.4783 - val_loss: 0.2890 - val_accuracy: 0.4828\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2999 - accuracy: 0.3913 - val_loss: 0.2750 - val_accuracy: 0.4828\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2944 - accuracy: 0.5565 - val_loss: 0.2819 - val_accuracy: 0.5172\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2672 - accuracy: 0.4870 - val_loss: 0.2589 - val_accuracy: 0.5172\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2494 - accuracy: 0.5826 - val_loss: 0.2813 - val_accuracy: 0.4828\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2633 - accuracy: 0.5652 - val_loss: 0.2883 - val_accuracy: 0.4483\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2803 - accuracy: 0.5130 - val_loss: 0.2855 - val_accuracy: 0.4483\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2385 - accuracy: 0.6000 - val_loss: 0.2746 - val_accuracy: 0.4828\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2435 - accuracy: 0.6261 - val_loss: 0.2766 - val_accuracy: 0.5172\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2452 - accuracy: 0.5826 - val_loss: 0.2828 - val_accuracy: 0.4483\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2344 - accuracy: 0.6261 - val_loss: 0.2786 - val_accuracy: 0.4828\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2524 - accuracy: 0.6000 - val_loss: 0.2791 - val_accuracy: 0.4483\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2246 - accuracy: 0.6435 - val_loss: 0.2921 - val_accuracy: 0.4483\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2231 - accuracy: 0.6435 - val_loss: 0.2864 - val_accuracy: 0.4828\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2295 - accuracy: 0.6957 - val_loss: 0.2632 - val_accuracy: 0.5172\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2224 - accuracy: 0.6609 - val_loss: 0.2773 - val_accuracy: 0.4483\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2377 - accuracy: 0.6783 - val_loss: 0.2793 - val_accuracy: 0.4483\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2560 - accuracy: 0.6000 - val_loss: 0.2849 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2212 - accuracy: 0.7391 - val_loss: 0.2846 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2276 - accuracy: 0.6870 - val_loss: 0.2783 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2504 - accuracy: 0.6348 - val_loss: 0.2795 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2830 - accuracy: 0.5304 - val_loss: 0.2872 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3006 - accuracy: 0.4957 - val_loss: 0.3034 - val_accuracy: 0.3793\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2809 - accuracy: 0.5739 - val_loss: 0.2942 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2463 - accuracy: 0.6000 - val_loss: 0.2967 - val_accuracy: 0.3793\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2558 - accuracy: 0.6087 - val_loss: 0.2885 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2673 - accuracy: 0.6000 - val_loss: 0.2913 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2794 - accuracy: 0.5652 - val_loss: 0.2864 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2590 - accuracy: 0.6000 - val_loss: 0.2953 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2517 - accuracy: 0.5478 - val_loss: 0.2888 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2896 - accuracy: 0.5304 - val_loss: 0.2978 - val_accuracy: 0.3793\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.3062 - accuracy: 0.4870 - val_loss: 0.2889 - val_accuracy: 0.3793\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2684 - accuracy: 0.5652 - val_loss: 0.2847 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2830 - accuracy: 0.5652 - val_loss: 0.2930 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2773 - accuracy: 0.5391 - val_loss: 0.2921 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2437 - accuracy: 0.5565 - val_loss: 0.2898 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2689 - accuracy: 0.5304 - val_loss: 0.2944 - val_accuracy: 0.3793\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2705 - accuracy: 0.5304 - val_loss: 0.2923 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2640 - accuracy: 0.6087 - val_loss: 0.3016 - val_accuracy: 0.3793\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2571 - accuracy: 0.6696 - val_loss: 0.2904 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2441 - accuracy: 0.5739 - val_loss: 0.2817 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2450 - accuracy: 0.6174 - val_loss: 0.2938 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2576 - accuracy: 0.5217 - val_loss: 0.2910 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2419 - accuracy: 0.5304 - val_loss: 0.2951 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2157 - accuracy: 0.6783 - val_loss: 0.2937 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2539 - accuracy: 0.6000 - val_loss: 0.2860 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2623 - accuracy: 0.5652 - val_loss: 0.2942 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2589 - accuracy: 0.5739 - val_loss: 0.3022 - val_accuracy: 0.4138\n",
      "0.6145833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111101010100000\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n",
      "(144, 100, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_128 (LSTM)              (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_129 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.2377 - accuracy: 0.6870 - val_loss: 0.3434 - val_accuracy: 0.6897\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2720 - accuracy: 0.6783 - val_loss: 0.4804 - val_accuracy: 0.4138\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3011 - accuracy: 0.4870 - val_loss: 0.3118 - val_accuracy: 0.6207\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2705 - accuracy: 0.6261 - val_loss: 0.3552 - val_accuracy: 0.5517\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2811 - accuracy: 0.5565 - val_loss: 0.2569 - val_accuracy: 0.6207\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2644 - accuracy: 0.6087 - val_loss: 0.2919 - val_accuracy: 0.7586\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2728 - accuracy: 0.5565 - val_loss: 0.2632 - val_accuracy: 0.6207\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2592 - accuracy: 0.5739 - val_loss: 0.2575 - val_accuracy: 0.6552\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2276 - accuracy: 0.6870 - val_loss: 0.3351 - val_accuracy: 0.4483\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2434 - accuracy: 0.6609 - val_loss: 0.3190 - val_accuracy: 0.4483\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2370 - accuracy: 0.6609 - val_loss: 0.3195 - val_accuracy: 0.5862\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2600 - accuracy: 0.5130 - val_loss: 0.2878 - val_accuracy: 0.6207\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2597 - accuracy: 0.6000 - val_loss: 0.2265 - val_accuracy: 0.6207\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2491 - accuracy: 0.6174 - val_loss: 0.2360 - val_accuracy: 0.6897\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2394 - accuracy: 0.6522 - val_loss: 0.1805 - val_accuracy: 0.7241\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2589 - accuracy: 0.5739 - val_loss: 0.2583 - val_accuracy: 0.6207\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2323 - accuracy: 0.6522 - val_loss: 0.2265 - val_accuracy: 0.7241\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2273 - accuracy: 0.7217 - val_loss: 0.2516 - val_accuracy: 0.7241\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2457 - accuracy: 0.6435 - val_loss: 0.1930 - val_accuracy: 0.7586\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2417 - accuracy: 0.6435 - val_loss: 0.2389 - val_accuracy: 0.7241\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2367 - accuracy: 0.6435 - val_loss: 0.2423 - val_accuracy: 0.6552\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2324 - accuracy: 0.6087 - val_loss: 0.2327 - val_accuracy: 0.7241\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2139 - accuracy: 0.7391 - val_loss: 0.1757 - val_accuracy: 0.8621\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2017 - accuracy: 0.7913 - val_loss: 0.2289 - val_accuracy: 0.7241\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2584 - accuracy: 0.6087 - val_loss: 0.2692 - val_accuracy: 0.5862\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2489 - accuracy: 0.5826 - val_loss: 0.2198 - val_accuracy: 0.6207\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2408 - accuracy: 0.6435 - val_loss: 0.1913 - val_accuracy: 0.7241\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2341 - accuracy: 0.6261 - val_loss: 0.1890 - val_accuracy: 0.7586\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2177 - accuracy: 0.7304 - val_loss: 0.2182 - val_accuracy: 0.6897\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2203 - accuracy: 0.7130 - val_loss: 0.2288 - val_accuracy: 0.5862\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2174 - accuracy: 0.6957 - val_loss: 0.2414 - val_accuracy: 0.5517\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1968 - accuracy: 0.7652 - val_loss: 0.2363 - val_accuracy: 0.5517\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1932 - accuracy: 0.7739 - val_loss: 0.2149 - val_accuracy: 0.6207\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1970 - accuracy: 0.7130 - val_loss: 0.2375 - val_accuracy: 0.4828\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1993 - accuracy: 0.7217 - val_loss: 0.2139 - val_accuracy: 0.6897\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1979 - accuracy: 0.7391 - val_loss: 0.2224 - val_accuracy: 0.5862\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2006 - accuracy: 0.6783 - val_loss: 0.2268 - val_accuracy: 0.5862\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1949 - accuracy: 0.7304 - val_loss: 0.2156 - val_accuracy: 0.6552\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1956 - accuracy: 0.7217 - val_loss: 0.1965 - val_accuracy: 0.6897\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2089 - accuracy: 0.6783 - val_loss: 0.2165 - val_accuracy: 0.6207\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2189 - accuracy: 0.6348 - val_loss: 0.1960 - val_accuracy: 0.6552\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2248 - accuracy: 0.6261 - val_loss: 0.1748 - val_accuracy: 0.7586\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2096 - accuracy: 0.6609 - val_loss: 0.1852 - val_accuracy: 0.6897\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2078 - accuracy: 0.6435 - val_loss: 0.1680 - val_accuracy: 0.8276\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2086 - accuracy: 0.6696 - val_loss: 0.1865 - val_accuracy: 0.7586\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2046 - accuracy: 0.6870 - val_loss: 0.1908 - val_accuracy: 0.6552\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2081 - accuracy: 0.6261 - val_loss: 0.1787 - val_accuracy: 0.7586\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2036 - accuracy: 0.6261 - val_loss: 0.1781 - val_accuracy: 0.7241\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1993 - accuracy: 0.6870 - val_loss: 0.1813 - val_accuracy: 0.6552\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1997 - accuracy: 0.6348 - val_loss: 0.1755 - val_accuracy: 0.7931\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1944 - accuracy: 0.7130 - val_loss: 0.1645 - val_accuracy: 0.7586\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1874 - accuracy: 0.7304 - val_loss: 0.1737 - val_accuracy: 0.7586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1919 - accuracy: 0.7391 - val_loss: 0.1571 - val_accuracy: 0.7586\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1905 - accuracy: 0.7304 - val_loss: 0.1570 - val_accuracy: 0.8966\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1718 - accuracy: 0.7043 - val_loss: 0.1746 - val_accuracy: 0.7586\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1769 - accuracy: 0.7652 - val_loss: 0.1684 - val_accuracy: 0.7586\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1780 - accuracy: 0.7130 - val_loss: 0.1512 - val_accuracy: 0.7931\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1778 - accuracy: 0.7304 - val_loss: 0.1480 - val_accuracy: 0.8276\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1749 - accuracy: 0.7565 - val_loss: 0.1652 - val_accuracy: 0.7586\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1667 - accuracy: 0.7652 - val_loss: 0.1574 - val_accuracy: 0.7586\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1737 - accuracy: 0.7652 - val_loss: 0.1514 - val_accuracy: 0.9310\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1697 - accuracy: 0.7478 - val_loss: 0.1415 - val_accuracy: 0.8276\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1666 - accuracy: 0.7130 - val_loss: 0.1359 - val_accuracy: 0.8276\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1503 - accuracy: 0.7565 - val_loss: 0.1468 - val_accuracy: 0.8621\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1475 - accuracy: 0.8174 - val_loss: 0.1510 - val_accuracy: 0.7931\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1611 - accuracy: 0.7739 - val_loss: 0.1264 - val_accuracy: 0.8966\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1582 - accuracy: 0.8174 - val_loss: 0.1248 - val_accuracy: 0.8966\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1618 - accuracy: 0.8261 - val_loss: 0.1425 - val_accuracy: 0.8276\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1536 - accuracy: 0.8087 - val_loss: 0.1409 - val_accuracy: 0.8621\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1557 - accuracy: 0.8087 - val_loss: 0.1288 - val_accuracy: 0.8621\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1524 - accuracy: 0.7826 - val_loss: 0.1221 - val_accuracy: 0.8966\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1569 - accuracy: 0.8435 - val_loss: 0.1454 - val_accuracy: 0.8276\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1514 - accuracy: 0.8087 - val_loss: 0.1475 - val_accuracy: 0.7241\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1678 - accuracy: 0.8000 - val_loss: 0.1590 - val_accuracy: 0.8621\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1633 - accuracy: 0.7739 - val_loss: 0.1862 - val_accuracy: 0.7241\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1623 - accuracy: 0.7652 - val_loss: 0.2006 - val_accuracy: 0.7241\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1897 - accuracy: 0.7391 - val_loss: 0.1867 - val_accuracy: 0.7241\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1745 - accuracy: 0.7478 - val_loss: 0.1985 - val_accuracy: 0.7241\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1687 - accuracy: 0.7652 - val_loss: 0.1574 - val_accuracy: 0.8276\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1444 - accuracy: 0.8435 - val_loss: 0.1699 - val_accuracy: 0.7931\n",
      "0.84375\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101001110101101010001000111010100111001010\n",
      "24\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3120)\n",
      "(144, 100, 3120)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_130 (LSTM)              (None, 100, 20)           251280    \n",
      "_________________________________________________________________\n",
      "lstm_131 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 254,682\n",
      "Trainable params: 254,642\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 0.2552 - accuracy: 0.5826 - val_loss: 0.3456 - val_accuracy: 0.6207\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2709 - accuracy: 0.6087 - val_loss: 0.2741 - val_accuracy: 0.6207\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2762 - accuracy: 0.5217 - val_loss: 0.3221 - val_accuracy: 0.5862\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2871 - accuracy: 0.5043 - val_loss: 0.3371 - val_accuracy: 0.5172\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2601 - accuracy: 0.5217 - val_loss: 0.2797 - val_accuracy: 0.6897\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2599 - accuracy: 0.5652 - val_loss: 0.3051 - val_accuracy: 0.5172\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2649 - accuracy: 0.5652 - val_loss: 0.2825 - val_accuracy: 0.6207\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2485 - accuracy: 0.5391 - val_loss: 0.3094 - val_accuracy: 0.5517\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2622 - accuracy: 0.5826 - val_loss: 0.3643 - val_accuracy: 0.4483\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2653 - accuracy: 0.5739 - val_loss: 0.2979 - val_accuracy: 0.4828\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2691 - accuracy: 0.4957 - val_loss: 0.2718 - val_accuracy: 0.4483\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2752 - accuracy: 0.5217 - val_loss: 0.2585 - val_accuracy: 0.5172\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2632 - accuracy: 0.5913 - val_loss: 0.2433 - val_accuracy: 0.5517\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2517 - accuracy: 0.6435 - val_loss: 0.2303 - val_accuracy: 0.6207\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2660 - accuracy: 0.5826 - val_loss: 0.2823 - val_accuracy: 0.4483\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2714 - accuracy: 0.4783 - val_loss: 0.2713 - val_accuracy: 0.5172\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2738 - accuracy: 0.5565 - val_loss: 0.2713 - val_accuracy: 0.4483\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2902 - accuracy: 0.4870 - val_loss: 0.2278 - val_accuracy: 0.6552\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2863 - accuracy: 0.4870 - val_loss: 0.2463 - val_accuracy: 0.4828\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2795 - accuracy: 0.5304 - val_loss: 0.2351 - val_accuracy: 0.5862\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2824 - accuracy: 0.5391 - val_loss: 0.2422 - val_accuracy: 0.6552\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2659 - accuracy: 0.6174 - val_loss: 0.2706 - val_accuracy: 0.4828\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2809 - accuracy: 0.5043 - val_loss: 0.2589 - val_accuracy: 0.4828\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2742 - accuracy: 0.6000 - val_loss: 0.2629 - val_accuracy: 0.4483\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2720 - accuracy: 0.5913 - val_loss: 0.2561 - val_accuracy: 0.5862\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2697 - accuracy: 0.5565 - val_loss: 0.2493 - val_accuracy: 0.5172\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2652 - accuracy: 0.5913 - val_loss: 0.2482 - val_accuracy: 0.4828\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2427 - accuracy: 0.7043 - val_loss: 0.2189 - val_accuracy: 0.6552\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2488 - accuracy: 0.6870 - val_loss: 0.2166 - val_accuracy: 0.6552\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2285 - accuracy: 0.7304 - val_loss: 0.2719 - val_accuracy: 0.5172\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2409 - accuracy: 0.6957 - val_loss: 0.2338 - val_accuracy: 0.5862\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2460 - accuracy: 0.6696 - val_loss: 0.1876 - val_accuracy: 0.8621\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2470 - accuracy: 0.6783 - val_loss: 0.2151 - val_accuracy: 0.6897\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2419 - accuracy: 0.6783 - val_loss: 0.2301 - val_accuracy: 0.5862\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2460 - accuracy: 0.6435 - val_loss: 0.2825 - val_accuracy: 0.5172\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2459 - accuracy: 0.6957 - val_loss: 0.2418 - val_accuracy: 0.5517\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2483 - accuracy: 0.6870 - val_loss: 0.2856 - val_accuracy: 0.5517\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2286 - accuracy: 0.6957 - val_loss: 0.2754 - val_accuracy: 0.5172\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2385 - accuracy: 0.7043 - val_loss: 0.2536 - val_accuracy: 0.5517\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2431 - accuracy: 0.6783 - val_loss: 0.2656 - val_accuracy: 0.4483\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2296 - accuracy: 0.6870 - val_loss: 0.2199 - val_accuracy: 0.5862\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2311 - accuracy: 0.7130 - val_loss: 0.2314 - val_accuracy: 0.6897\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2344 - accuracy: 0.7304 - val_loss: 0.2548 - val_accuracy: 0.5172\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2368 - accuracy: 0.6783 - val_loss: 0.2357 - val_accuracy: 0.5862\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2290 - accuracy: 0.7565 - val_loss: 0.2454 - val_accuracy: 0.4828\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2298 - accuracy: 0.7304 - val_loss: 0.2540 - val_accuracy: 0.5517\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2447 - accuracy: 0.6870 - val_loss: 0.2475 - val_accuracy: 0.5172\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2433 - accuracy: 0.6522 - val_loss: 0.2172 - val_accuracy: 0.6207\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2418 - accuracy: 0.6696 - val_loss: 0.3006 - val_accuracy: 0.5172\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2598 - accuracy: 0.6348 - val_loss: 0.2307 - val_accuracy: 0.6207\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2057 - accuracy: 0.7565 - val_loss: 0.2831 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2275 - accuracy: 0.7826 - val_loss: 0.2800 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2206 - accuracy: 0.7652 - val_loss: 0.2662 - val_accuracy: 0.4483\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2580 - accuracy: 0.6522 - val_loss: 0.2735 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2599 - accuracy: 0.6174 - val_loss: 0.2780 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2731 - accuracy: 0.6000 - val_loss: 0.2705 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2534 - accuracy: 0.6783 - val_loss: 0.2651 - val_accuracy: 0.4828\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2593 - accuracy: 0.5739 - val_loss: 0.2679 - val_accuracy: 0.4483\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2658 - accuracy: 0.5304 - val_loss: 0.2745 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2388 - accuracy: 0.6000 - val_loss: 0.2796 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2388 - accuracy: 0.5826 - val_loss: 0.2706 - val_accuracy: 0.4483\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2287 - accuracy: 0.7652 - val_loss: 0.2757 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2320 - accuracy: 0.6609 - val_loss: 0.2759 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2142 - accuracy: 0.6957 - val_loss: 0.2738 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2171 - accuracy: 0.6957 - val_loss: 0.2653 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2087 - accuracy: 0.7652 - val_loss: 0.2678 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2273 - accuracy: 0.6348 - val_loss: 0.2730 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2283 - accuracy: 0.6435 - val_loss: 0.2702 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2181 - accuracy: 0.7043 - val_loss: 0.2725 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2318 - accuracy: 0.6957 - val_loss: 0.2614 - val_accuracy: 0.5172\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1990 - accuracy: 0.7565 - val_loss: 0.2800 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2782 - accuracy: 0.4696 - val_loss: 0.3190 - val_accuracy: 0.3793\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2905 - accuracy: 0.4522 - val_loss: 0.3615 - val_accuracy: 0.2759\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3088 - accuracy: 0.5130 - val_loss: 0.3394 - val_accuracy: 0.3103\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2483 - accuracy: 0.5913 - val_loss: 0.2807 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2545 - accuracy: 0.5565 - val_loss: 0.2836 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2706 - accuracy: 0.4261 - val_loss: 0.2813 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2660 - accuracy: 0.5130 - val_loss: 0.2890 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2777 - accuracy: 0.4261 - val_loss: 0.2905 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2790 - accuracy: 0.4261 - val_loss: 0.2854 - val_accuracy: 0.4138\n",
      "0.6145833134651184\n",
      "fitness pass\n",
      "[(0.65625, 923441258232266), (0.6354166865348816, 957526118693322), (0.6145833134651184, 923441258232480), (1.0, 957257731074506), (0.5833333134651184, 957462487713885), (0.65625, 957148127537610), (0.6145833134651184, 923447748520394), (0.6041666865348816, 923441306069450), (0.6145833134651184, 923441258211786), (0.84375, 923441258232480), (0.6145833134651184, 957251206752714)]\n",
      "[957257731074506, 923441258232480]\n",
      "[957257731074506, 923441258232480, 957148127537610, 923441258232266, 957251206752714, 923447748520394, 923441258232480, 923441306069450, 957462487713885]\n",
      "selection pass\n",
      "target_count:\n",
      "2\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "0\n",
      "957257731074506\n",
      "11011001101001111011101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "1\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "2\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "3\n",
      "923441258232266\n",
      "11010001111101110101101100001010101111100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "4\n",
      "957251206752714\n",
      "11011001101001110101101010001000111010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "5\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "6\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "7\n",
      "923441306069450\n",
      "11010001111101110101101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "8\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "9\n",
      "957532608981450\n",
      "11011001101101111011101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "10\n",
      "957257733569184\n",
      "11011001101001111011101111001010101111101010100000\n",
      "crossover pass\n",
      "變異後的種群\n",
      "染色體：\n",
      "0\n",
      "957257731074506\n",
      "11011001101001111011101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "1\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "變異後的種群\n",
      "染色體：\n",
      "2\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "3\n",
      "923441258232266\n",
      "11010001111101110101101100001010101111100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "4\n",
      "957251206752714\n",
      "11011001101001110101101010001000111010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "5\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "6\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "變異後的種群\n",
      "染色體：\n",
      "7\n",
      "923441306069450\n",
      "11010001111101110101101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "8\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "9\n",
      "957532608981450\n",
      "11011001101101111011101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "10\n",
      "957257733569184\n",
      "11011001101001111011101111001010101111101010100000\n",
      "mutation pass\n",
      "迭代次數： 6\n",
      "6\n",
      "所選擇的染色體：\n",
      "11011001101001111011101111000001001110100111001010\n",
      "22\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3360)\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_132 (LSTM)              (None, 100, 20)           270480    \n",
      "_________________________________________________________________\n",
      "lstm_133 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 273,882\n",
      "Trainable params: 273,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 0.3114 - accuracy: 0.4261 - val_loss: 0.3747 - val_accuracy: 0.4828\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2943 - accuracy: 0.4696 - val_loss: 0.3292 - val_accuracy: 0.3793\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3529 - accuracy: 0.3130 - val_loss: 0.3567 - val_accuracy: 0.4828\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3270 - accuracy: 0.3391 - val_loss: 0.3307 - val_accuracy: 0.2414\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3510 - accuracy: 0.1913 - val_loss: 0.3040 - val_accuracy: 0.1724\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3284 - accuracy: 0.2435 - val_loss: 0.3252 - val_accuracy: 0.2069\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.3444 - accuracy: 0.2174 - val_loss: 0.3061 - val_accuracy: 0.3103\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.3319 - accuracy: 0.2435 - val_loss: 0.2966 - val_accuracy: 0.2759\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.3244 - accuracy: 0.4000 - val_loss: 0.3075 - val_accuracy: 0.3103\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3126 - accuracy: 0.2870 - val_loss: 0.3088 - val_accuracy: 0.1724\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3183 - accuracy: 0.3478 - val_loss: 0.2930 - val_accuracy: 0.2414\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3134 - accuracy: 0.3652 - val_loss: 0.2807 - val_accuracy: 0.2759\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2925 - accuracy: 0.4174 - val_loss: 0.2883 - val_accuracy: 0.2414\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2960 - accuracy: 0.4087 - val_loss: 0.2773 - val_accuracy: 0.3103\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2865 - accuracy: 0.3913 - val_loss: 0.2715 - val_accuracy: 0.3103\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2829 - accuracy: 0.4174 - val_loss: 0.2778 - val_accuracy: 0.3103\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2939 - accuracy: 0.3826 - val_loss: 0.2819 - val_accuracy: 0.2759\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3028 - accuracy: 0.3739 - val_loss: 0.2803 - val_accuracy: 0.2759\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3033 - accuracy: 0.3739 - val_loss: 0.2772 - val_accuracy: 0.2414\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3080 - accuracy: 0.3478 - val_loss: 0.2829 - val_accuracy: 0.2759\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2942 - accuracy: 0.3652 - val_loss: 0.2791 - val_accuracy: 0.3103\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2893 - accuracy: 0.3478 - val_loss: 0.2742 - val_accuracy: 0.3448\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2664 - accuracy: 0.4783 - val_loss: 0.2695 - val_accuracy: 0.3448\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2631 - accuracy: 0.4522 - val_loss: 0.2625 - val_accuracy: 0.4138\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2534 - accuracy: 0.5652 - val_loss: 0.2607 - val_accuracy: 0.6552\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2288 - accuracy: 0.7130 - val_loss: 0.2560 - val_accuracy: 0.6897\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2201 - accuracy: 0.8000 - val_loss: 0.2506 - val_accuracy: 0.6897\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2100 - accuracy: 0.8261 - val_loss: 0.2454 - val_accuracy: 0.6897\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2007 - accuracy: 0.8783 - val_loss: 0.2404 - val_accuracy: 0.6897\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1961 - accuracy: 0.9130 - val_loss: 0.2358 - val_accuracy: 0.6897\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1851 - accuracy: 0.9304 - val_loss: 0.2321 - val_accuracy: 0.6207\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1820 - accuracy: 0.9304 - val_loss: 0.2291 - val_accuracy: 0.6207\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1776 - accuracy: 0.9391 - val_loss: 0.2263 - val_accuracy: 0.5517\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1705 - accuracy: 0.9130 - val_loss: 0.2251 - val_accuracy: 0.5862\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1732 - accuracy: 0.9304 - val_loss: 0.2228 - val_accuracy: 0.6207\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1705 - accuracy: 0.9565 - val_loss: 0.2214 - val_accuracy: 0.6552\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1697 - accuracy: 0.9391 - val_loss: 0.2227 - val_accuracy: 0.6207\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1643 - accuracy: 0.9565 - val_loss: 0.2253 - val_accuracy: 0.6207\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1673 - accuracy: 0.9652 - val_loss: 0.2256 - val_accuracy: 0.8276\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1608 - accuracy: 0.9826 - val_loss: 0.2223 - val_accuracy: 0.7931\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1546 - accuracy: 0.9652 - val_loss: 0.2022 - val_accuracy: 0.8966\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1518 - accuracy: 0.9478 - val_loss: 0.1971 - val_accuracy: 0.8966\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1460 - accuracy: 0.9565 - val_loss: 0.1963 - val_accuracy: 0.8621\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1447 - accuracy: 0.9391 - val_loss: 0.1901 - val_accuracy: 0.8966\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1986 - accuracy: 0.8783 - val_loss: 0.2239 - val_accuracy: 0.8276\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2126 - accuracy: 0.7391 - val_loss: 0.2001 - val_accuracy: 0.5862\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2141 - accuracy: 0.7304 - val_loss: 0.2562 - val_accuracy: 0.4828\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2066 - accuracy: 0.7130 - val_loss: 0.2459 - val_accuracy: 0.5172\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2103 - accuracy: 0.7130 - val_loss: 0.2376 - val_accuracy: 0.5862\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2464 - accuracy: 0.6348 - val_loss: 0.2490 - val_accuracy: 0.6897\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2645 - accuracy: 0.6435 - val_loss: 0.3253 - val_accuracy: 0.6897\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2998 - accuracy: 0.3826 - val_loss: 0.3200 - val_accuracy: 0.4483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2915 - accuracy: 0.4087 - val_loss: 0.3144 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2696 - accuracy: 0.4435 - val_loss: 0.2978 - val_accuracy: 0.3103\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2859 - accuracy: 0.4609 - val_loss: 0.2925 - val_accuracy: 0.3103\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2838 - accuracy: 0.4696 - val_loss: 0.2858 - val_accuracy: 0.3103\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2854 - accuracy: 0.4957 - val_loss: 0.2889 - val_accuracy: 0.3103\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2883 - accuracy: 0.4870 - val_loss: 0.2864 - val_accuracy: 0.3103\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2914 - accuracy: 0.4348 - val_loss: 0.2824 - val_accuracy: 0.3103\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2833 - accuracy: 0.3913 - val_loss: 0.2811 - val_accuracy: 0.3103\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2733 - accuracy: 0.4783 - val_loss: 0.2762 - val_accuracy: 0.3448\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2613 - accuracy: 0.5043 - val_loss: 0.2728 - val_accuracy: 0.3793\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2418 - accuracy: 0.6870 - val_loss: 0.2691 - val_accuracy: 0.3793\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2174 - accuracy: 0.7391 - val_loss: 0.2677 - val_accuracy: 0.3793\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2024 - accuracy: 0.7652 - val_loss: 0.2660 - val_accuracy: 0.3793\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1958 - accuracy: 0.7652 - val_loss: 0.2659 - val_accuracy: 0.3793\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1954 - accuracy: 0.7652 - val_loss: 0.2632 - val_accuracy: 0.3793\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1924 - accuracy: 0.7565 - val_loss: 0.2654 - val_accuracy: 0.3793\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2096 - accuracy: 0.6609 - val_loss: 0.2653 - val_accuracy: 0.3793\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1997 - accuracy: 0.6783 - val_loss: 0.2661 - val_accuracy: 0.3793\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2055 - accuracy: 0.6783 - val_loss: 0.2660 - val_accuracy: 0.3793\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2028 - accuracy: 0.6870 - val_loss: 0.2653 - val_accuracy: 0.3793\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2023 - accuracy: 0.6609 - val_loss: 0.2650 - val_accuracy: 0.3793\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1961 - accuracy: 0.6870 - val_loss: 0.2644 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1919 - accuracy: 0.6870 - val_loss: 0.2633 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1887 - accuracy: 0.6870 - val_loss: 0.2627 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1820 - accuracy: 0.7391 - val_loss: 0.2620 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1853 - accuracy: 0.7043 - val_loss: 0.2612 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1834 - accuracy: 0.7130 - val_loss: 0.2601 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1811 - accuracy: 0.7043 - val_loss: 0.2586 - val_accuracy: 0.4138\n",
      "0.5729166865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111101010100000\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n",
      "(144, 100, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_134 (LSTM)              (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_135 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 0.3257 - accuracy: 0.4348 - val_loss: 0.4212 - val_accuracy: 0.4138\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2728 - accuracy: 0.6522 - val_loss: 0.3207 - val_accuracy: 0.7586\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2652 - accuracy: 0.4348 - val_loss: 0.3371 - val_accuracy: 0.7241\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2340 - accuracy: 0.6348 - val_loss: 0.3784 - val_accuracy: 0.6552\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2423 - accuracy: 0.6348 - val_loss: 0.4238 - val_accuracy: 0.5517\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2654 - accuracy: 0.5739 - val_loss: 0.3871 - val_accuracy: 0.6897\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2469 - accuracy: 0.5565 - val_loss: 0.3403 - val_accuracy: 0.7241\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2044 - accuracy: 0.7826 - val_loss: 0.3468 - val_accuracy: 0.6897\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1870 - accuracy: 0.8000 - val_loss: 0.3591 - val_accuracy: 0.6897\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2165 - accuracy: 0.6957 - val_loss: 0.3667 - val_accuracy: 0.7241\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1954 - accuracy: 0.7826 - val_loss: 0.3731 - val_accuracy: 0.7241\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2240 - accuracy: 0.7304 - val_loss: 0.3103 - val_accuracy: 0.6897\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2336 - accuracy: 0.7565 - val_loss: 0.3199 - val_accuracy: 0.5517\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2571 - accuracy: 0.6174 - val_loss: 0.3654 - val_accuracy: 0.5517\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2578 - accuracy: 0.7043 - val_loss: 0.3906 - val_accuracy: 0.5862\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2621 - accuracy: 0.5913 - val_loss: 0.3880 - val_accuracy: 0.5517\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2348 - accuracy: 0.6174 - val_loss: 0.3873 - val_accuracy: 0.5172\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2421 - accuracy: 0.5826 - val_loss: 0.3573 - val_accuracy: 0.5172\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2316 - accuracy: 0.6174 - val_loss: 0.3427 - val_accuracy: 0.5517\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2253 - accuracy: 0.6957 - val_loss: 0.3201 - val_accuracy: 0.5862\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2194 - accuracy: 0.7043 - val_loss: 0.3135 - val_accuracy: 0.6207\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2109 - accuracy: 0.6870 - val_loss: 0.3239 - val_accuracy: 0.5862\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2038 - accuracy: 0.7478 - val_loss: 0.3190 - val_accuracy: 0.6552\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2165 - accuracy: 0.7478 - val_loss: 0.3013 - val_accuracy: 0.6897\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2027 - accuracy: 0.7652 - val_loss: 0.3005 - val_accuracy: 0.6897\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2037 - accuracy: 0.7826 - val_loss: 0.2978 - val_accuracy: 0.7241\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2001 - accuracy: 0.7739 - val_loss: 0.2880 - val_accuracy: 0.6897\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2085 - accuracy: 0.7739 - val_loss: 0.2853 - val_accuracy: 0.7586\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1987 - accuracy: 0.7826 - val_loss: 0.2807 - val_accuracy: 0.7586\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2007 - accuracy: 0.7739 - val_loss: 0.2772 - val_accuracy: 0.7586\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1915 - accuracy: 0.8261 - val_loss: 0.2749 - val_accuracy: 0.7586\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1936 - accuracy: 0.7913 - val_loss: 0.2714 - val_accuracy: 0.7586\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2003 - accuracy: 0.7652 - val_loss: 0.2689 - val_accuracy: 0.7241\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1852 - accuracy: 0.7826 - val_loss: 0.2668 - val_accuracy: 0.7241\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1912 - accuracy: 0.7826 - val_loss: 0.2646 - val_accuracy: 0.7241\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1805 - accuracy: 0.7913 - val_loss: 0.2622 - val_accuracy: 0.7241\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1793 - accuracy: 0.8087 - val_loss: 0.2602 - val_accuracy: 0.6552\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1815 - accuracy: 0.7913 - val_loss: 0.2579 - val_accuracy: 0.6207\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1817 - accuracy: 0.7913 - val_loss: 0.2567 - val_accuracy: 0.6207\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1688 - accuracy: 0.8348 - val_loss: 0.2558 - val_accuracy: 0.6207\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1714 - accuracy: 0.8174 - val_loss: 0.2544 - val_accuracy: 0.6552\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1736 - accuracy: 0.8000 - val_loss: 0.2521 - val_accuracy: 0.6552\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1641 - accuracy: 0.8174 - val_loss: 0.2499 - val_accuracy: 0.6552\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1649 - accuracy: 0.8000 - val_loss: 0.2484 - val_accuracy: 0.6552\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1585 - accuracy: 0.8348 - val_loss: 0.2472 - val_accuracy: 0.6552\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1548 - accuracy: 0.8696 - val_loss: 0.2467 - val_accuracy: 0.6552\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1566 - accuracy: 0.8609 - val_loss: 0.2468 - val_accuracy: 0.6552\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1474 - accuracy: 0.8783 - val_loss: 0.2474 - val_accuracy: 0.6552\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1556 - accuracy: 0.8696 - val_loss: 0.2481 - val_accuracy: 0.6897\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1470 - accuracy: 0.8783 - val_loss: 0.2485 - val_accuracy: 0.6897\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1483 - accuracy: 0.8783 - val_loss: 0.2490 - val_accuracy: 0.6897\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1428 - accuracy: 0.8609 - val_loss: 0.2489 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1398 - accuracy: 0.8783 - val_loss: 0.2506 - val_accuracy: 0.6552\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1367 - accuracy: 0.8609 - val_loss: 0.2499 - val_accuracy: 0.6552\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1414 - accuracy: 0.8435 - val_loss: 0.2486 - val_accuracy: 0.6552\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1375 - accuracy: 0.8783 - val_loss: 0.2470 - val_accuracy: 0.6552\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1441 - accuracy: 0.8696 - val_loss: 0.2452 - val_accuracy: 0.6552\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1280 - accuracy: 0.8783 - val_loss: 0.2434 - val_accuracy: 0.6552\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1318 - accuracy: 0.8870 - val_loss: 0.2415 - val_accuracy: 0.6552\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1247 - accuracy: 0.9130 - val_loss: 0.2395 - val_accuracy: 0.6552\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1301 - accuracy: 0.8609 - val_loss: 0.2379 - val_accuracy: 0.6552\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1233 - accuracy: 0.8696 - val_loss: 0.2364 - val_accuracy: 0.6552\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1252 - accuracy: 0.8609 - val_loss: 0.2350 - val_accuracy: 0.6552\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1247 - accuracy: 0.8609 - val_loss: 0.2340 - val_accuracy: 0.6552\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1186 - accuracy: 0.8870 - val_loss: 0.2327 - val_accuracy: 0.6552\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1235 - accuracy: 0.8696 - val_loss: 0.2321 - val_accuracy: 0.6552\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1213 - accuracy: 0.8696 - val_loss: 0.2321 - val_accuracy: 0.6552\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1264 - accuracy: 0.8696 - val_loss: 0.2318 - val_accuracy: 0.6552\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1190 - accuracy: 0.8870 - val_loss: 0.2318 - val_accuracy: 0.6552\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1121 - accuracy: 0.8870 - val_loss: 0.2315 - val_accuracy: 0.6552\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1169 - accuracy: 0.8783 - val_loss: 0.2305 - val_accuracy: 0.6552\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1156 - accuracy: 0.8696 - val_loss: 0.2291 - val_accuracy: 0.6552\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1158 - accuracy: 0.8870 - val_loss: 0.2277 - val_accuracy: 0.6552\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1173 - accuracy: 0.8870 - val_loss: 0.2260 - val_accuracy: 0.6897\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1099 - accuracy: 0.8870 - val_loss: 0.2255 - val_accuracy: 0.6897\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1078 - accuracy: 0.8783 - val_loss: 0.2241 - val_accuracy: 0.6897\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1128 - accuracy: 0.9043 - val_loss: 0.2230 - val_accuracy: 0.6897\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1071 - accuracy: 0.9043 - val_loss: 0.2219 - val_accuracy: 0.6897\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1024 - accuracy: 0.9130 - val_loss: 0.2204 - val_accuracy: 0.6897\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0971 - accuracy: 0.9130 - val_loss: 0.2187 - val_accuracy: 0.6897\n",
      "0.7916666865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101000010101101010001000111010100111001010\n",
      "26\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2880)\n",
      "(144, 100, 2880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_136 (LSTM)              (None, 100, 20)           232080    \n",
      "_________________________________________________________________\n",
      "lstm_137 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 235,482\n",
      "Trainable params: 235,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 167ms/step - loss: 0.3084 - accuracy: 0.4435 - val_loss: 0.3974 - val_accuracy: 0.5172\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2417 - accuracy: 0.6000 - val_loss: 0.3671 - val_accuracy: 0.4138\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3332 - accuracy: 0.4957 - val_loss: 0.3710 - val_accuracy: 0.3448\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.3383 - accuracy: 0.4696 - val_loss: 0.4455 - val_accuracy: 0.3103\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.3876 - accuracy: 0.2870 - val_loss: 0.4467 - val_accuracy: 0.3103\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.3277 - accuracy: 0.4087 - val_loss: 0.4190 - val_accuracy: 0.3793\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3195 - accuracy: 0.5130 - val_loss: 0.3921 - val_accuracy: 0.4483\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.3261 - accuracy: 0.4261 - val_loss: 0.4117 - val_accuracy: 0.3793\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3087 - accuracy: 0.4087 - val_loss: 0.4313 - val_accuracy: 0.3103\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3076 - accuracy: 0.4522 - val_loss: 0.3913 - val_accuracy: 0.3448\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3474 - accuracy: 0.3652 - val_loss: 0.4457 - val_accuracy: 0.2414\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.3480 - accuracy: 0.3391 - val_loss: 0.3996 - val_accuracy: 0.3103\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.3423 - accuracy: 0.3652 - val_loss: 0.3553 - val_accuracy: 0.2759\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.3659 - accuracy: 0.2783 - val_loss: 0.4106 - val_accuracy: 0.2759\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3563 - accuracy: 0.2609 - val_loss: 0.3538 - val_accuracy: 0.3793\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3245 - accuracy: 0.2957 - val_loss: 0.4161 - val_accuracy: 0.3448\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.3412 - accuracy: 0.2870 - val_loss: 0.3605 - val_accuracy: 0.4138\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.3387 - accuracy: 0.2783 - val_loss: 0.3783 - val_accuracy: 0.2759\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3401 - accuracy: 0.3565 - val_loss: 0.4182 - val_accuracy: 0.2759\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3371 - accuracy: 0.3913 - val_loss: 0.4019 - val_accuracy: 0.3103\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.3297 - accuracy: 0.3652 - val_loss: 0.3145 - val_accuracy: 0.5172\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3274 - accuracy: 0.3478 - val_loss: 0.2822 - val_accuracy: 0.5517\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.3068 - accuracy: 0.4522 - val_loss: 0.3442 - val_accuracy: 0.4828\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.3360 - accuracy: 0.4000 - val_loss: 0.3141 - val_accuracy: 0.5172\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3341 - accuracy: 0.3739 - val_loss: 0.2879 - val_accuracy: 0.5517\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3603 - accuracy: 0.3565 - val_loss: 0.3153 - val_accuracy: 0.5517\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3560 - accuracy: 0.3478 - val_loss: 0.3019 - val_accuracy: 0.5172\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.3265 - accuracy: 0.4261 - val_loss: 0.2880 - val_accuracy: 0.5517\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.3154 - accuracy: 0.4348 - val_loss: 0.2925 - val_accuracy: 0.5172\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.3087 - accuracy: 0.4783 - val_loss: 0.2947 - val_accuracy: 0.4828\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.3207 - accuracy: 0.4435 - val_loss: 0.2870 - val_accuracy: 0.5517\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.3067 - accuracy: 0.4957 - val_loss: 0.2959 - val_accuracy: 0.5172\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3117 - accuracy: 0.4957 - val_loss: 0.2857 - val_accuracy: 0.5517\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.3234 - accuracy: 0.4348 - val_loss: 0.2867 - val_accuracy: 0.5517\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3137 - accuracy: 0.4870 - val_loss: 0.2822 - val_accuracy: 0.5862\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.3194 - accuracy: 0.4870 - val_loss: 0.2799 - val_accuracy: 0.5862\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3145 - accuracy: 0.5130 - val_loss: 0.2812 - val_accuracy: 0.5517\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.3119 - accuracy: 0.5130 - val_loss: 0.2849 - val_accuracy: 0.5172\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3018 - accuracy: 0.5565 - val_loss: 0.2811 - val_accuracy: 0.5517\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.3093 - accuracy: 0.4957 - val_loss: 0.2819 - val_accuracy: 0.5517\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.3000 - accuracy: 0.5565 - val_loss: 0.2802 - val_accuracy: 0.5517\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.3034 - accuracy: 0.5739 - val_loss: 0.2808 - val_accuracy: 0.5172\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2979 - accuracy: 0.5913 - val_loss: 0.2837 - val_accuracy: 0.5517\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3050 - accuracy: 0.6000 - val_loss: 0.2786 - val_accuracy: 0.5862\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.3063 - accuracy: 0.5478 - val_loss: 0.2836 - val_accuracy: 0.5172\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2952 - accuracy: 0.5826 - val_loss: 0.2819 - val_accuracy: 0.5517\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2919 - accuracy: 0.6435 - val_loss: 0.2772 - val_accuracy: 0.5517\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2988 - accuracy: 0.6087 - val_loss: 0.2780 - val_accuracy: 0.5517\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2957 - accuracy: 0.6261 - val_loss: 0.2784 - val_accuracy: 0.5862\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2928 - accuracy: 0.6348 - val_loss: 0.2913 - val_accuracy: 0.5517\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2890 - accuracy: 0.6522 - val_loss: 0.2816 - val_accuracy: 0.5517\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2971 - accuracy: 0.6261 - val_loss: 0.2825 - val_accuracy: 0.5517\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2895 - accuracy: 0.6174 - val_loss: 0.2929 - val_accuracy: 0.5517\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2873 - accuracy: 0.6609 - val_loss: 0.2933 - val_accuracy: 0.5517\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2830 - accuracy: 0.6870 - val_loss: 0.2863 - val_accuracy: 0.5517\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2738 - accuracy: 0.6609 - val_loss: 0.2895 - val_accuracy: 0.5517\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2757 - accuracy: 0.6783 - val_loss: 0.2838 - val_accuracy: 0.5517\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2796 - accuracy: 0.6522 - val_loss: 0.2775 - val_accuracy: 0.5862\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2750 - accuracy: 0.6522 - val_loss: 0.2813 - val_accuracy: 0.5517\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2748 - accuracy: 0.6609 - val_loss: 0.2818 - val_accuracy: 0.5517\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2754 - accuracy: 0.6696 - val_loss: 0.2820 - val_accuracy: 0.5517\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2613 - accuracy: 0.7130 - val_loss: 0.2821 - val_accuracy: 0.5517\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2699 - accuracy: 0.6870 - val_loss: 0.2818 - val_accuracy: 0.5517\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2695 - accuracy: 0.6957 - val_loss: 0.2815 - val_accuracy: 0.5517\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2611 - accuracy: 0.7043 - val_loss: 0.2818 - val_accuracy: 0.5517\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2683 - accuracy: 0.6783 - val_loss: 0.2816 - val_accuracy: 0.5517\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2639 - accuracy: 0.6957 - val_loss: 0.2815 - val_accuracy: 0.5517\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2572 - accuracy: 0.7043 - val_loss: 0.2815 - val_accuracy: 0.5517\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2627 - accuracy: 0.6783 - val_loss: 0.2813 - val_accuracy: 0.5517\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.2607 - accuracy: 0.6957 - val_loss: 0.2811 - val_accuracy: 0.5517\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2573 - accuracy: 0.6957 - val_loss: 0.2810 - val_accuracy: 0.5517\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2526 - accuracy: 0.6957 - val_loss: 0.2818 - val_accuracy: 0.5517\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2573 - accuracy: 0.6783 - val_loss: 0.2819 - val_accuracy: 0.5517\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2528 - accuracy: 0.7043 - val_loss: 0.2817 - val_accuracy: 0.5517\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2526 - accuracy: 0.6957 - val_loss: 0.2814 - val_accuracy: 0.5517\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2508 - accuracy: 0.6957 - val_loss: 0.2804 - val_accuracy: 0.5517\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.2541 - accuracy: 0.6870 - val_loss: 0.2763 - val_accuracy: 0.5862\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2562 - accuracy: 0.7043 - val_loss: 0.2757 - val_accuracy: 0.5862\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2528 - accuracy: 0.7043 - val_loss: 0.2751 - val_accuracy: 0.5862\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.2416 - accuracy: 0.7217 - val_loss: 0.2747 - val_accuracy: 0.5862\n",
      "0.6458333134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n",
      "(144, 100, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_138 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_139 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 0.2784 - accuracy: 0.5652 - val_loss: 0.5130 - val_accuracy: 0.4828\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3050 - accuracy: 0.3565 - val_loss: 0.5451 - val_accuracy: 0.3793\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3195 - accuracy: 0.3478 - val_loss: 0.4156 - val_accuracy: 0.4138\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2820 - accuracy: 0.4522 - val_loss: 0.3780 - val_accuracy: 0.4828\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2602 - accuracy: 0.5130 - val_loss: 0.3911 - val_accuracy: 0.4483\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3102 - accuracy: 0.4435 - val_loss: 0.5257 - val_accuracy: 0.3103\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3538 - accuracy: 0.2000 - val_loss: 0.5117 - val_accuracy: 0.1379\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3460 - accuracy: 0.3652 - val_loss: 0.4932 - val_accuracy: 0.3103\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3359 - accuracy: 0.4957 - val_loss: 0.3962 - val_accuracy: 0.3103\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3073 - accuracy: 0.5217 - val_loss: 0.3440 - val_accuracy: 0.4138\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3385 - accuracy: 0.4435 - val_loss: 0.3201 - val_accuracy: 0.4138\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3238 - accuracy: 0.4957 - val_loss: 0.3330 - val_accuracy: 0.3103\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3337 - accuracy: 0.3913 - val_loss: 0.2804 - val_accuracy: 0.4828\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3279 - accuracy: 0.4348 - val_loss: 0.2622 - val_accuracy: 0.4828\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3514 - accuracy: 0.3043 - val_loss: 0.3829 - val_accuracy: 0.3448\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3897 - accuracy: 0.2609 - val_loss: 0.2629 - val_accuracy: 0.2759\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3538 - accuracy: 0.3652 - val_loss: 0.2777 - val_accuracy: 0.4828\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2932 - accuracy: 0.4783 - val_loss: 0.3178 - val_accuracy: 0.3448\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3165 - accuracy: 0.4435 - val_loss: 0.3445 - val_accuracy: 0.3448\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3064 - accuracy: 0.4261 - val_loss: 0.3712 - val_accuracy: 0.3448\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2839 - accuracy: 0.6000 - val_loss: 0.3323 - val_accuracy: 0.3448\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3139 - accuracy: 0.4435 - val_loss: 0.3328 - val_accuracy: 0.4138\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3083 - accuracy: 0.3913 - val_loss: 0.3216 - val_accuracy: 0.4138\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2786 - accuracy: 0.6348 - val_loss: 0.3405 - val_accuracy: 0.4138\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2866 - accuracy: 0.5826 - val_loss: 0.5051 - val_accuracy: 0.4138\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3094 - accuracy: 0.4609 - val_loss: 0.2734 - val_accuracy: 0.4828\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3096 - accuracy: 0.4870 - val_loss: 0.2732 - val_accuracy: 0.4828\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2818 - accuracy: 0.5304 - val_loss: 0.2740 - val_accuracy: 0.4828\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2891 - accuracy: 0.5304 - val_loss: 0.2736 - val_accuracy: 0.4828\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2807 - accuracy: 0.5043 - val_loss: 0.2733 - val_accuracy: 0.4828\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2781 - accuracy: 0.5478 - val_loss: 0.2725 - val_accuracy: 0.4828\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2767 - accuracy: 0.5217 - val_loss: 0.2719 - val_accuracy: 0.4828\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2767 - accuracy: 0.5130 - val_loss: 0.2707 - val_accuracy: 0.5172\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2743 - accuracy: 0.5478 - val_loss: 0.2709 - val_accuracy: 0.5172\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2649 - accuracy: 0.5739 - val_loss: 0.2713 - val_accuracy: 0.5172\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2673 - accuracy: 0.5217 - val_loss: 0.2714 - val_accuracy: 0.5172\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2567 - accuracy: 0.5739 - val_loss: 0.2715 - val_accuracy: 0.5172\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2580 - accuracy: 0.5826 - val_loss: 0.2716 - val_accuracy: 0.5172\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2672 - accuracy: 0.5391 - val_loss: 0.2718 - val_accuracy: 0.5172\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2533 - accuracy: 0.5739 - val_loss: 0.2721 - val_accuracy: 0.5172\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2489 - accuracy: 0.5913 - val_loss: 0.2725 - val_accuracy: 0.4828\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2429 - accuracy: 0.5826 - val_loss: 0.2727 - val_accuracy: 0.4828\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2509 - accuracy: 0.5652 - val_loss: 0.2727 - val_accuracy: 0.4828\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2466 - accuracy: 0.6087 - val_loss: 0.2727 - val_accuracy: 0.4828\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2399 - accuracy: 0.6000 - val_loss: 0.2728 - val_accuracy: 0.4828\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2478 - accuracy: 0.6087 - val_loss: 0.2730 - val_accuracy: 0.4828\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2407 - accuracy: 0.6000 - val_loss: 0.2731 - val_accuracy: 0.4828\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2390 - accuracy: 0.6087 - val_loss: 0.2734 - val_accuracy: 0.4828\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2395 - accuracy: 0.6348 - val_loss: 0.2736 - val_accuracy: 0.4828\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2372 - accuracy: 0.5913 - val_loss: 0.2736 - val_accuracy: 0.4828\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2222 - accuracy: 0.6435 - val_loss: 0.2735 - val_accuracy: 0.4828\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2420 - accuracy: 0.6000 - val_loss: 0.2734 - val_accuracy: 0.4828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2343 - accuracy: 0.6261 - val_loss: 0.2731 - val_accuracy: 0.4828\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2298 - accuracy: 0.6696 - val_loss: 0.2731 - val_accuracy: 0.4828\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2210 - accuracy: 0.6783 - val_loss: 0.2731 - val_accuracy: 0.4828\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2280 - accuracy: 0.6087 - val_loss: 0.2728 - val_accuracy: 0.4828\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2275 - accuracy: 0.6522 - val_loss: 0.2725 - val_accuracy: 0.4828\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2249 - accuracy: 0.6348 - val_loss: 0.2724 - val_accuracy: 0.4828\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2266 - accuracy: 0.6522 - val_loss: 0.2723 - val_accuracy: 0.4828\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2219 - accuracy: 0.6522 - val_loss: 0.2721 - val_accuracy: 0.4828\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2218 - accuracy: 0.6783 - val_loss: 0.2721 - val_accuracy: 0.4828\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2126 - accuracy: 0.6522 - val_loss: 0.2720 - val_accuracy: 0.4828\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2129 - accuracy: 0.6957 - val_loss: 0.2718 - val_accuracy: 0.4828\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2074 - accuracy: 0.6870 - val_loss: 0.2715 - val_accuracy: 0.4828\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2146 - accuracy: 0.6696 - val_loss: 0.2714 - val_accuracy: 0.4828\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2041 - accuracy: 0.6957 - val_loss: 0.2713 - val_accuracy: 0.4828\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2116 - accuracy: 0.6696 - val_loss: 0.2709 - val_accuracy: 0.4828\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2135 - accuracy: 0.6609 - val_loss: 0.2707 - val_accuracy: 0.4828\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2104 - accuracy: 0.6870 - val_loss: 0.2703 - val_accuracy: 0.4828\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2015 - accuracy: 0.6870 - val_loss: 0.2698 - val_accuracy: 0.4828\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2052 - accuracy: 0.6957 - val_loss: 0.2694 - val_accuracy: 0.4828\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2080 - accuracy: 0.7130 - val_loss: 0.2691 - val_accuracy: 0.4828\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1985 - accuracy: 0.7304 - val_loss: 0.2688 - val_accuracy: 0.4828\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1989 - accuracy: 0.7217 - val_loss: 0.2685 - val_accuracy: 0.4828\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2009 - accuracy: 0.7043 - val_loss: 0.2684 - val_accuracy: 0.4828\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2089 - accuracy: 0.6957 - val_loss: 0.2682 - val_accuracy: 0.4828\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2015 - accuracy: 0.7043 - val_loss: 0.2678 - val_accuracy: 0.4828\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2064 - accuracy: 0.7130 - val_loss: 0.2676 - val_accuracy: 0.4828\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2023 - accuracy: 0.6957 - val_loss: 0.2672 - val_accuracy: 0.4828\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1967 - accuracy: 0.6957 - val_loss: 0.2671 - val_accuracy: 0.4828\n",
      "0.65625\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101001110101101010001000111010100111001010\n",
      "24\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3120)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3120)\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_140 (LSTM)              (None, 100, 20)           251280    \n",
      "_________________________________________________________________\n",
      "lstm_141 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 254,682\n",
      "Trainable params: 254,642\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 0.2353 - accuracy: 0.6696 - val_loss: 0.3770 - val_accuracy: 0.4828\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2775 - accuracy: 0.4783 - val_loss: 0.4491 - val_accuracy: 0.5862\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2542 - accuracy: 0.5565 - val_loss: 0.3806 - val_accuracy: 0.6207\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2444 - accuracy: 0.5913 - val_loss: 0.3809 - val_accuracy: 0.6207\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2422 - accuracy: 0.5826 - val_loss: 0.3442 - val_accuracy: 0.7241\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2451 - accuracy: 0.5826 - val_loss: 0.3099 - val_accuracy: 0.6897\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2407 - accuracy: 0.6522 - val_loss: 0.3087 - val_accuracy: 0.6207\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2584 - accuracy: 0.5565 - val_loss: 0.3715 - val_accuracy: 0.5517\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2591 - accuracy: 0.5913 - val_loss: 0.3093 - val_accuracy: 0.6552\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2703 - accuracy: 0.5652 - val_loss: 0.4059 - val_accuracy: 0.5172\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2927 - accuracy: 0.5043 - val_loss: 0.4199 - val_accuracy: 0.4483\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.3025 - accuracy: 0.5304 - val_loss: 0.5062 - val_accuracy: 0.3793\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2620 - accuracy: 0.5217 - val_loss: 0.3515 - val_accuracy: 0.5517\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2635 - accuracy: 0.5304 - val_loss: 0.3001 - val_accuracy: 0.6552\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2793 - accuracy: 0.6957 - val_loss: 0.3248 - val_accuracy: 0.6207\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2974 - accuracy: 0.5565 - val_loss: 0.3147 - val_accuracy: 0.4483\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2902 - accuracy: 0.5217 - val_loss: 0.2835 - val_accuracy: 0.5172\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3092 - accuracy: 0.4870 - val_loss: 0.2900 - val_accuracy: 0.4828\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2817 - accuracy: 0.5826 - val_loss: 0.2701 - val_accuracy: 0.4828\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2839 - accuracy: 0.5217 - val_loss: 0.2499 - val_accuracy: 0.5172\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2693 - accuracy: 0.6000 - val_loss: 0.2654 - val_accuracy: 0.5172\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2536 - accuracy: 0.6435 - val_loss: 0.2500 - val_accuracy: 0.5172\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2830 - accuracy: 0.5217 - val_loss: 0.2468 - val_accuracy: 0.5172\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2911 - accuracy: 0.5130 - val_loss: 0.2421 - val_accuracy: 0.5517\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2733 - accuracy: 0.4870 - val_loss: 0.2432 - val_accuracy: 0.5172\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2401 - accuracy: 0.6261 - val_loss: 0.2474 - val_accuracy: 0.4828\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2403 - accuracy: 0.5739 - val_loss: 0.2578 - val_accuracy: 0.4483\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2558 - accuracy: 0.5739 - val_loss: 0.2704 - val_accuracy: 0.4483\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2500 - accuracy: 0.6000 - val_loss: 0.2752 - val_accuracy: 0.3793\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2720 - accuracy: 0.5652 - val_loss: 0.2793 - val_accuracy: 0.3793\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2444 - accuracy: 0.6174 - val_loss: 0.2716 - val_accuracy: 0.3793\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2409 - accuracy: 0.6435 - val_loss: 0.2680 - val_accuracy: 0.3793\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2755 - accuracy: 0.6609 - val_loss: 0.2719 - val_accuracy: 0.4483\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2579 - accuracy: 0.6696 - val_loss: 0.2588 - val_accuracy: 0.4828\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2566 - accuracy: 0.6696 - val_loss: 0.2584 - val_accuracy: 0.5172\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2423 - accuracy: 0.6696 - val_loss: 0.2631 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2190 - accuracy: 0.6783 - val_loss: 0.2388 - val_accuracy: 0.5517\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2070 - accuracy: 0.7043 - val_loss: 0.2436 - val_accuracy: 0.5517\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1997 - accuracy: 0.7043 - val_loss: 0.2652 - val_accuracy: 0.5172\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2040 - accuracy: 0.7217 - val_loss: 0.2641 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2054 - accuracy: 0.7304 - val_loss: 0.2783 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2060 - accuracy: 0.7130 - val_loss: 0.2781 - val_accuracy: 0.4138\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2157 - accuracy: 0.6783 - val_loss: 0.2789 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1891 - accuracy: 0.7913 - val_loss: 0.2801 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2056 - accuracy: 0.7043 - val_loss: 0.2763 - val_accuracy: 0.4483\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2379 - accuracy: 0.6087 - val_loss: 0.2716 - val_accuracy: 0.4483\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2145 - accuracy: 0.6957 - val_loss: 0.2718 - val_accuracy: 0.4483\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2025 - accuracy: 0.7739 - val_loss: 0.2765 - val_accuracy: 0.4483\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2231 - accuracy: 0.6696 - val_loss: 0.2838 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2249 - accuracy: 0.6957 - val_loss: 0.2965 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2277 - accuracy: 0.6522 - val_loss: 0.2829 - val_accuracy: 0.4828\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2564 - accuracy: 0.6261 - val_loss: 0.2575 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2597 - accuracy: 0.6957 - val_loss: 0.2623 - val_accuracy: 0.4828\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2690 - accuracy: 0.5826 - val_loss: 0.2881 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2523 - accuracy: 0.6522 - val_loss: 0.2830 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2581 - accuracy: 0.6087 - val_loss: 0.2785 - val_accuracy: 0.4483\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2535 - accuracy: 0.6261 - val_loss: 0.2822 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2460 - accuracy: 0.6348 - val_loss: 0.2779 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2576 - accuracy: 0.6174 - val_loss: 0.2616 - val_accuracy: 0.4483\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2454 - accuracy: 0.6348 - val_loss: 0.2742 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2450 - accuracy: 0.6087 - val_loss: 0.2769 - val_accuracy: 0.4483\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2341 - accuracy: 0.6261 - val_loss: 0.2706 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2317 - accuracy: 0.6261 - val_loss: 0.2740 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2318 - accuracy: 0.6522 - val_loss: 0.2575 - val_accuracy: 0.4483\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2209 - accuracy: 0.6957 - val_loss: 0.2720 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2467 - accuracy: 0.6261 - val_loss: 0.2738 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2507 - accuracy: 0.6000 - val_loss: 0.2728 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2393 - accuracy: 0.6348 - val_loss: 0.2700 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2466 - accuracy: 0.6174 - val_loss: 0.2722 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2309 - accuracy: 0.6609 - val_loss: 0.2578 - val_accuracy: 0.4483\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2496 - accuracy: 0.6348 - val_loss: 0.2692 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2309 - accuracy: 0.6783 - val_loss: 0.2611 - val_accuracy: 0.4483\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2412 - accuracy: 0.6435 - val_loss: 0.2685 - val_accuracy: 0.4483\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2415 - accuracy: 0.6522 - val_loss: 0.2769 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2442 - accuracy: 0.6348 - val_loss: 0.2634 - val_accuracy: 0.4483\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2331 - accuracy: 0.6522 - val_loss: 0.2626 - val_accuracy: 0.4483\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2379 - accuracy: 0.6348 - val_loss: 0.2622 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2348 - accuracy: 0.6348 - val_loss: 0.2619 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2193 - accuracy: 0.7217 - val_loss: 0.2621 - val_accuracy: 0.4483\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2333 - accuracy: 0.6609 - val_loss: 0.2711 - val_accuracy: 0.4483\n",
      "0.6354166865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101111011101111000001001110100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_142 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_143 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 0.2962 - accuracy: 0.4783 - val_loss: 0.2851 - val_accuracy: 0.4828\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3024 - accuracy: 0.4435 - val_loss: 0.3136 - val_accuracy: 0.5172\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2872 - accuracy: 0.5826 - val_loss: 0.2657 - val_accuracy: 0.5517\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2991 - accuracy: 0.5130 - val_loss: 0.4179 - val_accuracy: 0.4138\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3142 - accuracy: 0.3913 - val_loss: 0.3585 - val_accuracy: 0.3448\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.3307 - accuracy: 0.2783 - val_loss: 0.3530 - val_accuracy: 0.2069\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.3130 - accuracy: 0.3565 - val_loss: 0.2985 - val_accuracy: 0.4138\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2990 - accuracy: 0.4435 - val_loss: 0.2899 - val_accuracy: 0.4483\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2853 - accuracy: 0.4870 - val_loss: 0.2880 - val_accuracy: 0.3793\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2625 - accuracy: 0.5391 - val_loss: 0.2742 - val_accuracy: 0.3793\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2661 - accuracy: 0.5130 - val_loss: 0.3115 - val_accuracy: 0.3448\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2739 - accuracy: 0.5565 - val_loss: 0.2955 - val_accuracy: 0.3448\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2776 - accuracy: 0.5478 - val_loss: 0.2995 - val_accuracy: 0.3793\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2830 - accuracy: 0.5130 - val_loss: 0.2876 - val_accuracy: 0.3448\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2675 - accuracy: 0.6261 - val_loss: 0.2853 - val_accuracy: 0.4138\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2940 - accuracy: 0.4783 - val_loss: 0.3356 - val_accuracy: 0.3793\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.3124 - accuracy: 0.4696 - val_loss: 0.3023 - val_accuracy: 0.4483\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3170 - accuracy: 0.4609 - val_loss: 0.2833 - val_accuracy: 0.4483\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3308 - accuracy: 0.4261 - val_loss: 0.2659 - val_accuracy: 0.4828\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3207 - accuracy: 0.4174 - val_loss: 0.3490 - val_accuracy: 0.4483\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.3259 - accuracy: 0.4174 - val_loss: 0.3038 - val_accuracy: 0.4138\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.3162 - accuracy: 0.4174 - val_loss: 0.3523 - val_accuracy: 0.4483\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.3063 - accuracy: 0.5043 - val_loss: 0.2776 - val_accuracy: 0.4138\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2707 - accuracy: 0.5217 - val_loss: 0.2958 - val_accuracy: 0.4483\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2719 - accuracy: 0.5565 - val_loss: 0.2671 - val_accuracy: 0.4483\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2585 - accuracy: 0.5043 - val_loss: 0.2577 - val_accuracy: 0.4138\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2455 - accuracy: 0.4957 - val_loss: 0.2649 - val_accuracy: 0.4138\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2494 - accuracy: 0.4870 - val_loss: 0.2610 - val_accuracy: 0.4138\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2533 - accuracy: 0.6174 - val_loss: 0.2614 - val_accuracy: 0.4138\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2866 - accuracy: 0.4522 - val_loss: 0.2862 - val_accuracy: 0.4138\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2561 - accuracy: 0.5217 - val_loss: 0.2169 - val_accuracy: 0.5862\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2489 - accuracy: 0.6348 - val_loss: 0.2268 - val_accuracy: 0.5517\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2749 - accuracy: 0.4261 - val_loss: 0.2373 - val_accuracy: 0.5172\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2375 - accuracy: 0.5913 - val_loss: 0.2423 - val_accuracy: 0.5862\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2434 - accuracy: 0.5217 - val_loss: 0.2560 - val_accuracy: 0.4828\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2425 - accuracy: 0.5652 - val_loss: 0.2588 - val_accuracy: 0.5517\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2470 - accuracy: 0.5565 - val_loss: 0.2529 - val_accuracy: 0.5172\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2574 - accuracy: 0.4348 - val_loss: 0.2705 - val_accuracy: 0.5172\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2488 - accuracy: 0.4957 - val_loss: 0.2432 - val_accuracy: 0.5172\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2382 - accuracy: 0.5391 - val_loss: 0.2388 - val_accuracy: 0.5172\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2308 - accuracy: 0.5652 - val_loss: 0.2678 - val_accuracy: 0.4483\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2277 - accuracy: 0.6087 - val_loss: 0.2742 - val_accuracy: 0.4828\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2239 - accuracy: 0.6522 - val_loss: 0.2451 - val_accuracy: 0.5517\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2150 - accuracy: 0.6609 - val_loss: 0.2757 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2192 - accuracy: 0.6609 - val_loss: 0.2666 - val_accuracy: 0.4138\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2117 - accuracy: 0.6609 - val_loss: 0.2627 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2108 - accuracy: 0.6609 - val_loss: 0.2672 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2161 - accuracy: 0.6870 - val_loss: 0.2733 - val_accuracy: 0.3793\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2118 - accuracy: 0.6783 - val_loss: 0.2704 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2071 - accuracy: 0.6957 - val_loss: 0.2688 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2072 - accuracy: 0.6870 - val_loss: 0.2691 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2021 - accuracy: 0.6783 - val_loss: 0.2702 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2076 - accuracy: 0.7130 - val_loss: 0.2701 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2022 - accuracy: 0.6957 - val_loss: 0.2587 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1968 - accuracy: 0.6957 - val_loss: 0.2696 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2011 - accuracy: 0.7130 - val_loss: 0.2865 - val_accuracy: 0.3793\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2014 - accuracy: 0.7043 - val_loss: 0.2676 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2023 - accuracy: 0.6957 - val_loss: 0.2698 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2196 - accuracy: 0.6522 - val_loss: 0.2731 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2188 - accuracy: 0.6696 - val_loss: 0.2591 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2151 - accuracy: 0.6696 - val_loss: 0.2725 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2117 - accuracy: 0.6870 - val_loss: 0.2746 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2105 - accuracy: 0.6870 - val_loss: 0.2773 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2198 - accuracy: 0.6783 - val_loss: 0.2559 - val_accuracy: 0.4828\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2224 - accuracy: 0.7130 - val_loss: 0.2574 - val_accuracy: 0.5172\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2216 - accuracy: 0.6783 - val_loss: 0.2563 - val_accuracy: 0.4828\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2149 - accuracy: 0.6783 - val_loss: 0.2487 - val_accuracy: 0.5172\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2208 - accuracy: 0.6957 - val_loss: 0.2509 - val_accuracy: 0.5172\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2149 - accuracy: 0.6957 - val_loss: 0.2521 - val_accuracy: 0.4828\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2143 - accuracy: 0.6957 - val_loss: 0.2533 - val_accuracy: 0.4828\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2133 - accuracy: 0.7130 - val_loss: 0.2529 - val_accuracy: 0.4828\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2102 - accuracy: 0.7043 - val_loss: 0.2526 - val_accuracy: 0.4828\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2074 - accuracy: 0.6957 - val_loss: 0.2522 - val_accuracy: 0.4828\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2026 - accuracy: 0.7130 - val_loss: 0.2518 - val_accuracy: 0.4828\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2069 - accuracy: 0.7217 - val_loss: 0.2503 - val_accuracy: 0.4828\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2178 - accuracy: 0.6696 - val_loss: 0.2434 - val_accuracy: 0.4828\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2177 - accuracy: 0.6696 - val_loss: 0.2432 - val_accuracy: 0.4828\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2036 - accuracy: 0.6957 - val_loss: 0.2425 - val_accuracy: 0.4828\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1972 - accuracy: 0.7043 - val_loss: 0.2418 - val_accuracy: 0.4828\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2027 - accuracy: 0.7130 - val_loss: 0.2411 - val_accuracy: 0.5172\n",
      "0.6458333134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111101010100000\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3240)\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_144 (LSTM)              (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_145 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 0.2358 - accuracy: 0.6609 - val_loss: 0.5013 - val_accuracy: 0.4138\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2357 - accuracy: 0.6522 - val_loss: 0.2271 - val_accuracy: 0.7931\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2232 - accuracy: 0.6174 - val_loss: 0.3922 - val_accuracy: 0.6552\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.3139 - accuracy: 0.3652 - val_loss: 0.2975 - val_accuracy: 0.5862\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2727 - accuracy: 0.4783 - val_loss: 0.3213 - val_accuracy: 0.4138\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3117 - accuracy: 0.4174 - val_loss: 0.2817 - val_accuracy: 0.6207\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3047 - accuracy: 0.4609 - val_loss: 0.2472 - val_accuracy: 0.6897\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2967 - accuracy: 0.4174 - val_loss: 0.2702 - val_accuracy: 0.6207\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2651 - accuracy: 0.5130 - val_loss: 0.2538 - val_accuracy: 0.7241\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.3218 - accuracy: 0.3130 - val_loss: 0.2541 - val_accuracy: 0.6897\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2871 - accuracy: 0.4783 - val_loss: 0.2777 - val_accuracy: 0.4483\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2942 - accuracy: 0.4870 - val_loss: 0.2953 - val_accuracy: 0.4483\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2814 - accuracy: 0.4957 - val_loss: 0.2924 - val_accuracy: 0.3793\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2645 - accuracy: 0.5478 - val_loss: 0.2943 - val_accuracy: 0.4483\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2954 - accuracy: 0.5043 - val_loss: 0.2848 - val_accuracy: 0.4828\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2820 - accuracy: 0.4957 - val_loss: 0.2568 - val_accuracy: 0.5862\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2511 - accuracy: 0.5826 - val_loss: 0.2582 - val_accuracy: 0.5862\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2557 - accuracy: 0.5478 - val_loss: 0.2535 - val_accuracy: 0.7241\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2531 - accuracy: 0.5739 - val_loss: 0.2540 - val_accuracy: 0.8621\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2566 - accuracy: 0.5478 - val_loss: 0.2448 - val_accuracy: 0.8966\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2512 - accuracy: 0.5652 - val_loss: 0.2212 - val_accuracy: 0.8966\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2522 - accuracy: 0.5913 - val_loss: 0.2200 - val_accuracy: 0.9655\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2493 - accuracy: 0.6348 - val_loss: 0.2159 - val_accuracy: 0.8966\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2245 - accuracy: 0.7130 - val_loss: 0.2360 - val_accuracy: 0.6207\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2165 - accuracy: 0.7217 - val_loss: 0.2142 - val_accuracy: 0.7586\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2164 - accuracy: 0.7478 - val_loss: 0.2305 - val_accuracy: 0.5172\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2205 - accuracy: 0.7043 - val_loss: 0.2342 - val_accuracy: 0.4828\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2238 - accuracy: 0.7304 - val_loss: 0.2268 - val_accuracy: 0.5172\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2120 - accuracy: 0.7565 - val_loss: 0.2199 - val_accuracy: 0.7241\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1958 - accuracy: 0.7739 - val_loss: 0.2531 - val_accuracy: 0.4828\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2409 - accuracy: 0.6957 - val_loss: 0.2543 - val_accuracy: 0.5517\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2222 - accuracy: 0.7304 - val_loss: 0.2749 - val_accuracy: 0.4483\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2397 - accuracy: 0.6000 - val_loss: 0.2821 - val_accuracy: 0.4828\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2567 - accuracy: 0.5739 - val_loss: 0.2951 - val_accuracy: 0.4138\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.3018 - accuracy: 0.4783 - val_loss: 0.3223 - val_accuracy: 0.4138\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3096 - accuracy: 0.5304 - val_loss: 0.3221 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3073 - accuracy: 0.5043 - val_loss: 0.3305 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3017 - accuracy: 0.5391 - val_loss: 0.3069 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2870 - accuracy: 0.6087 - val_loss: 0.2989 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2913 - accuracy: 0.5130 - val_loss: 0.3129 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2832 - accuracy: 0.5652 - val_loss: 0.3003 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2769 - accuracy: 0.5826 - val_loss: 0.2864 - val_accuracy: 0.4483\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2643 - accuracy: 0.6000 - val_loss: 0.2930 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2554 - accuracy: 0.5739 - val_loss: 0.2969 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2542 - accuracy: 0.5478 - val_loss: 0.2940 - val_accuracy: 0.4138\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2516 - accuracy: 0.5913 - val_loss: 0.2895 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2490 - accuracy: 0.6261 - val_loss: 0.2809 - val_accuracy: 0.4483\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2462 - accuracy: 0.5826 - val_loss: 0.2944 - val_accuracy: 0.4138\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2563 - accuracy: 0.5652 - val_loss: 0.2782 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2430 - accuracy: 0.6000 - val_loss: 0.3051 - val_accuracy: 0.4483\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2774 - accuracy: 0.5130 - val_loss: 0.3141 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2768 - accuracy: 0.5478 - val_loss: 0.2939 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2396 - accuracy: 0.6087 - val_loss: 0.2860 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2417 - accuracy: 0.5826 - val_loss: 0.2779 - val_accuracy: 0.4483\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2501 - accuracy: 0.6000 - val_loss: 0.2748 - val_accuracy: 0.4483\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2413 - accuracy: 0.6087 - val_loss: 0.2722 - val_accuracy: 0.4483\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2429 - accuracy: 0.6348 - val_loss: 0.2719 - val_accuracy: 0.4483\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2340 - accuracy: 0.6435 - val_loss: 0.2712 - val_accuracy: 0.4483\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2377 - accuracy: 0.5913 - val_loss: 0.2709 - val_accuracy: 0.4483\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2395 - accuracy: 0.6609 - val_loss: 0.2702 - val_accuracy: 0.4483\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2445 - accuracy: 0.5739 - val_loss: 0.2696 - val_accuracy: 0.4483\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2400 - accuracy: 0.6087 - val_loss: 0.2688 - val_accuracy: 0.4483\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2357 - accuracy: 0.6174 - val_loss: 0.2678 - val_accuracy: 0.4483\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2348 - accuracy: 0.6435 - val_loss: 0.2669 - val_accuracy: 0.4483\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2254 - accuracy: 0.7043 - val_loss: 0.2668 - val_accuracy: 0.4483\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2309 - accuracy: 0.6696 - val_loss: 0.2656 - val_accuracy: 0.4483\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2184 - accuracy: 0.6957 - val_loss: 0.2653 - val_accuracy: 0.4483\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2107 - accuracy: 0.6870 - val_loss: 0.2646 - val_accuracy: 0.4483\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2103 - accuracy: 0.7130 - val_loss: 0.2645 - val_accuracy: 0.4483\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2164 - accuracy: 0.6696 - val_loss: 0.2642 - val_accuracy: 0.4483\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2154 - accuracy: 0.6435 - val_loss: 0.2638 - val_accuracy: 0.4483\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2087 - accuracy: 0.6870 - val_loss: 0.2633 - val_accuracy: 0.4483\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2108 - accuracy: 0.6783 - val_loss: 0.2626 - val_accuracy: 0.4483\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1977 - accuracy: 0.6783 - val_loss: 0.2616 - val_accuracy: 0.4483\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2020 - accuracy: 0.7130 - val_loss: 0.2602 - val_accuracy: 0.4483\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2013 - accuracy: 0.7043 - val_loss: 0.2587 - val_accuracy: 0.4483\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2070 - accuracy: 0.7130 - val_loss: 0.2575 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2086 - accuracy: 0.6957 - val_loss: 0.2566 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1955 - accuracy: 0.7478 - val_loss: 0.2559 - val_accuracy: 0.4483\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2007 - accuracy: 0.6957 - val_loss: 0.2552 - val_accuracy: 0.4483\n",
      "0.625\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101111000001001110100111001010\n",
      "22\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3360)\n",
      "(144, 100, 3360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_146 (LSTM)              (None, 100, 20)           270480    \n",
      "_________________________________________________________________\n",
      "lstm_147 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 273,882\n",
      "Trainable params: 273,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 0.2505 - accuracy: 0.5913 - val_loss: 0.2741 - val_accuracy: 0.6552\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2563 - accuracy: 0.6261 - val_loss: 0.2650 - val_accuracy: 0.6552\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1978 - accuracy: 0.8000 - val_loss: 0.2397 - val_accuracy: 0.6897\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1727 - accuracy: 0.8087 - val_loss: 0.1984 - val_accuracy: 0.7241\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1665 - accuracy: 0.7652 - val_loss: 0.2826 - val_accuracy: 0.6552\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1712 - accuracy: 0.8957 - val_loss: 0.2687 - val_accuracy: 0.6552\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1601 - accuracy: 0.8261 - val_loss: 0.2287 - val_accuracy: 0.6552\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1531 - accuracy: 0.9391 - val_loss: 0.2576 - val_accuracy: 0.7241\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1367 - accuracy: 0.9391 - val_loss: 0.1337 - val_accuracy: 0.9310\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1668 - accuracy: 0.8087 - val_loss: 0.2500 - val_accuracy: 0.6552\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1820 - accuracy: 0.7913 - val_loss: 0.2294 - val_accuracy: 0.7241\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1842 - accuracy: 0.8609 - val_loss: 0.2689 - val_accuracy: 0.6552\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2080 - accuracy: 0.8000 - val_loss: 0.3015 - val_accuracy: 0.5517\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2147 - accuracy: 0.7391 - val_loss: 0.3161 - val_accuracy: 0.5517\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2194 - accuracy: 0.6957 - val_loss: 0.2669 - val_accuracy: 0.7241\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2461 - accuracy: 0.6783 - val_loss: 0.2932 - val_accuracy: 0.5517\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2122 - accuracy: 0.7304 - val_loss: 0.1465 - val_accuracy: 0.8276\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1925 - accuracy: 0.7391 - val_loss: 0.2461 - val_accuracy: 0.6207\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2044 - accuracy: 0.7913 - val_loss: 0.3207 - val_accuracy: 0.6207\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2162 - accuracy: 0.7043 - val_loss: 0.2710 - val_accuracy: 0.7241\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2287 - accuracy: 0.7826 - val_loss: 0.3218 - val_accuracy: 0.5172\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2727 - accuracy: 0.5826 - val_loss: 0.3047 - val_accuracy: 0.5172\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2851 - accuracy: 0.6087 - val_loss: 0.3226 - val_accuracy: 0.4828\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2588 - accuracy: 0.6522 - val_loss: 0.2620 - val_accuracy: 0.5517\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1753 - accuracy: 0.8870 - val_loss: 0.2505 - val_accuracy: 0.6552\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2074 - accuracy: 0.7826 - val_loss: 0.3064 - val_accuracy: 0.5172\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2092 - accuracy: 0.7043 - val_loss: 0.2515 - val_accuracy: 0.5862\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1928 - accuracy: 0.7565 - val_loss: 0.2760 - val_accuracy: 0.5517\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1983 - accuracy: 0.7826 - val_loss: 0.1814 - val_accuracy: 0.8276\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2458 - accuracy: 0.7043 - val_loss: 0.2378 - val_accuracy: 0.6207\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2205 - accuracy: 0.7217 - val_loss: 0.2426 - val_accuracy: 0.5862\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2179 - accuracy: 0.7478 - val_loss: 0.2625 - val_accuracy: 0.6207\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2322 - accuracy: 0.7391 - val_loss: 0.2254 - val_accuracy: 0.7241\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2222 - accuracy: 0.6783 - val_loss: 0.4250 - val_accuracy: 0.4138\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2731 - accuracy: 0.5652 - val_loss: 0.3847 - val_accuracy: 0.4483\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2630 - accuracy: 0.5913 - val_loss: 0.3246 - val_accuracy: 0.6552\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2808 - accuracy: 0.5304 - val_loss: 0.3164 - val_accuracy: 0.5517\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2797 - accuracy: 0.5391 - val_loss: 0.4577 - val_accuracy: 0.3448\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2751 - accuracy: 0.5739 - val_loss: 0.3821 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2613 - accuracy: 0.6000 - val_loss: 0.4410 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2824 - accuracy: 0.5391 - val_loss: 0.4037 - val_accuracy: 0.3793\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2754 - accuracy: 0.6087 - val_loss: 0.3211 - val_accuracy: 0.5517\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2528 - accuracy: 0.6000 - val_loss: 0.3141 - val_accuracy: 0.4828\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2698 - accuracy: 0.5913 - val_loss: 0.2990 - val_accuracy: 0.5172\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2586 - accuracy: 0.6435 - val_loss: 0.3859 - val_accuracy: 0.4828\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2653 - accuracy: 0.6000 - val_loss: 0.3349 - val_accuracy: 0.4483\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2638 - accuracy: 0.6087 - val_loss: 0.3245 - val_accuracy: 0.5172\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2680 - accuracy: 0.6087 - val_loss: 0.4021 - val_accuracy: 0.4138\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2647 - accuracy: 0.6261 - val_loss: 0.3431 - val_accuracy: 0.4828\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2684 - accuracy: 0.6174 - val_loss: 0.3431 - val_accuracy: 0.4828\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2676 - accuracy: 0.6000 - val_loss: 0.3718 - val_accuracy: 0.4483\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2791 - accuracy: 0.6174 - val_loss: 0.3256 - val_accuracy: 0.5172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2767 - accuracy: 0.5217 - val_loss: 0.3048 - val_accuracy: 0.5172\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2916 - accuracy: 0.5739 - val_loss: 0.3569 - val_accuracy: 0.5172\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2888 - accuracy: 0.5652 - val_loss: 0.3462 - val_accuracy: 0.5517\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2872 - accuracy: 0.5652 - val_loss: 0.3719 - val_accuracy: 0.5172\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2770 - accuracy: 0.5826 - val_loss: 0.3696 - val_accuracy: 0.5517\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2765 - accuracy: 0.6261 - val_loss: 0.3764 - val_accuracy: 0.5517\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2777 - accuracy: 0.6087 - val_loss: 0.3559 - val_accuracy: 0.5517\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2866 - accuracy: 0.5739 - val_loss: 0.3877 - val_accuracy: 0.4483\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2813 - accuracy: 0.6087 - val_loss: 0.3675 - val_accuracy: 0.5517\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2810 - accuracy: 0.6000 - val_loss: 0.3347 - val_accuracy: 0.5862\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2695 - accuracy: 0.6435 - val_loss: 0.3364 - val_accuracy: 0.5862\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2749 - accuracy: 0.5913 - val_loss: 0.3392 - val_accuracy: 0.5517\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2743 - accuracy: 0.5913 - val_loss: 0.3311 - val_accuracy: 0.5517\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2590 - accuracy: 0.6261 - val_loss: 0.3259 - val_accuracy: 0.5862\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2663 - accuracy: 0.6261 - val_loss: 0.3284 - val_accuracy: 0.5517\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2627 - accuracy: 0.6435 - val_loss: 0.3274 - val_accuracy: 0.5517\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2654 - accuracy: 0.6000 - val_loss: 0.3129 - val_accuracy: 0.5517\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2582 - accuracy: 0.6522 - val_loss: 0.3093 - val_accuracy: 0.6207\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2593 - accuracy: 0.6348 - val_loss: 0.2984 - val_accuracy: 0.6207\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2589 - accuracy: 0.6087 - val_loss: 0.3164 - val_accuracy: 0.5172\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2519 - accuracy: 0.6783 - val_loss: 0.3214 - val_accuracy: 0.5172\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2568 - accuracy: 0.6696 - val_loss: 0.3095 - val_accuracy: 0.6207\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2606 - accuracy: 0.6609 - val_loss: 0.3174 - val_accuracy: 0.5517\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2641 - accuracy: 0.6435 - val_loss: 0.3149 - val_accuracy: 0.6207\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2482 - accuracy: 0.6957 - val_loss: 0.3153 - val_accuracy: 0.6207\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2609 - accuracy: 0.6783 - val_loss: 0.3076 - val_accuracy: 0.5862\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2586 - accuracy: 0.6522 - val_loss: 0.3036 - val_accuracy: 0.5862\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2495 - accuracy: 0.6609 - val_loss: 0.3035 - val_accuracy: 0.5862\n",
      "0.6666666865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101100111010011011011101110100100001011101\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_148 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_149 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 198ms/step - loss: 0.2678 - accuracy: 0.6348 - val_loss: 0.2801 - val_accuracy: 0.7241\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2165 - accuracy: 0.6957 - val_loss: 0.2881 - val_accuracy: 0.7241\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2409 - accuracy: 0.5913 - val_loss: 0.2900 - val_accuracy: 0.6207\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2506 - accuracy: 0.6348 - val_loss: 0.2414 - val_accuracy: 0.7241\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2409 - accuracy: 0.6000 - val_loss: 0.2409 - val_accuracy: 0.7241\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2329 - accuracy: 0.6174 - val_loss: 0.2646 - val_accuracy: 0.6207\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2637 - accuracy: 0.6261 - val_loss: 0.2224 - val_accuracy: 0.7241\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2371 - accuracy: 0.6522 - val_loss: 0.2078 - val_accuracy: 0.7241\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2043 - accuracy: 0.8000 - val_loss: 0.1989 - val_accuracy: 0.7241\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1860 - accuracy: 0.8174 - val_loss: 0.1815 - val_accuracy: 0.8276\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1828 - accuracy: 0.8261 - val_loss: 0.1657 - val_accuracy: 0.8276\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1759 - accuracy: 0.8261 - val_loss: 0.1548 - val_accuracy: 0.8276\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1598 - accuracy: 0.8870 - val_loss: 0.1450 - val_accuracy: 0.8621\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1524 - accuracy: 0.8783 - val_loss: 0.1379 - val_accuracy: 0.8621\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1496 - accuracy: 0.8609 - val_loss: 0.1372 - val_accuracy: 0.8966\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1401 - accuracy: 0.8957 - val_loss: 0.1354 - val_accuracy: 0.8966\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1358 - accuracy: 0.8783 - val_loss: 0.1260 - val_accuracy: 0.8966\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1311 - accuracy: 0.9043 - val_loss: 0.1184 - val_accuracy: 0.9655\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1316 - accuracy: 0.9391 - val_loss: 0.1080 - val_accuracy: 0.9655\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1606 - accuracy: 0.8609 - val_loss: 0.1214 - val_accuracy: 0.9310\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1719 - accuracy: 0.8435 - val_loss: 0.1155 - val_accuracy: 0.9310\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1644 - accuracy: 0.8870 - val_loss: 0.0923 - val_accuracy: 0.9655\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1552 - accuracy: 0.8696 - val_loss: 0.1066 - val_accuracy: 0.9310\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1452 - accuracy: 0.8783 - val_loss: 0.0832 - val_accuracy: 0.9655\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1304 - accuracy: 0.9130 - val_loss: 0.0853 - val_accuracy: 0.9655\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1018 - accuracy: 0.9304 - val_loss: 0.0825 - val_accuracy: 0.9655\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1016 - accuracy: 0.9478 - val_loss: 0.0875 - val_accuracy: 0.9655\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0972 - accuracy: 0.9739 - val_loss: 0.0909 - val_accuracy: 0.9655\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0968 - accuracy: 0.9652 - val_loss: 0.0797 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0920 - accuracy: 0.9565 - val_loss: 0.0771 - val_accuracy: 0.9655\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0856 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9655\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0878 - accuracy: 0.9826 - val_loss: 0.0679 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0905 - accuracy: 0.9826 - val_loss: 0.0663 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0917 - accuracy: 0.9826 - val_loss: 0.0650 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0846 - accuracy: 0.9913 - val_loss: 0.0664 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0773 - accuracy: 0.9826 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0757 - accuracy: 0.9913 - val_loss: 0.0639 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0800 - accuracy: 0.9826 - val_loss: 0.0636 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.0622 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0772 - accuracy: 0.9652 - val_loss: 0.0613 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0686 - accuracy: 0.9913 - val_loss: 0.0602 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0680 - accuracy: 0.9826 - val_loss: 0.0595 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0676 - accuracy: 0.9739 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0635 - accuracy: 0.9913 - val_loss: 0.0578 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0600 - accuracy: 0.9913 - val_loss: 0.0559 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0599 - accuracy: 0.9913 - val_loss: 0.0574 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0591 - accuracy: 0.9826 - val_loss: 0.0705 - val_accuracy: 0.9655\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0672 - accuracy: 0.9478 - val_loss: 0.0701 - val_accuracy: 0.9655\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0578 - accuracy: 0.9913 - val_loss: 0.0596 - val_accuracy: 0.9655\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0507 - accuracy: 0.9913 - val_loss: 0.0563 - val_accuracy: 0.9655\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0541 - accuracy: 0.9826 - val_loss: 0.0482 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0617 - accuracy: 0.9739 - val_loss: 0.0460 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0693 - accuracy: 0.9739 - val_loss: 0.0500 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0677 - accuracy: 0.9565 - val_loss: 0.0440 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0829 - accuracy: 0.9478 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0670 - accuracy: 0.9478 - val_loss: 0.0398 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0654 - accuracy: 0.9478 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0644 - accuracy: 0.9565 - val_loss: 0.0397 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0522 - accuracy: 0.9652 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0499 - accuracy: 0.9739 - val_loss: 0.0381 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0481 - accuracy: 0.9826 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0502 - accuracy: 0.9913 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0457 - accuracy: 0.9826 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0453 - accuracy: 0.9826 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0421 - accuracy: 0.9913 - val_loss: 0.0398 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0389 - accuracy: 0.9913 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0322 - accuracy: 0.9913 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "1.0\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101101111011101111000001001110100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_150 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_151 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 0.3147 - accuracy: 0.3826 - val_loss: 0.2358 - val_accuracy: 0.4828\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2838 - accuracy: 0.4435 - val_loss: 0.2163 - val_accuracy: 0.6207\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2502 - accuracy: 0.5130 - val_loss: 0.2154 - val_accuracy: 0.6552\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2370 - accuracy: 0.5043 - val_loss: 0.2035 - val_accuracy: 0.5862\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2369 - accuracy: 0.4783 - val_loss: 0.2114 - val_accuracy: 0.6897\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2208 - accuracy: 0.5391 - val_loss: 0.2097 - val_accuracy: 0.6552\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1991 - accuracy: 0.6261 - val_loss: 0.2042 - val_accuracy: 0.7241\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1857 - accuracy: 0.7478 - val_loss: 0.2026 - val_accuracy: 0.7241\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1816 - accuracy: 0.8957 - val_loss: 0.1804 - val_accuracy: 0.7241\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1754 - accuracy: 0.8261 - val_loss: 0.2071 - val_accuracy: 0.7586\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2034 - accuracy: 0.8000 - val_loss: 0.2060 - val_accuracy: 0.7586\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1914 - accuracy: 0.8087 - val_loss: 0.1983 - val_accuracy: 0.7241\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1798 - accuracy: 0.8696 - val_loss: 0.1800 - val_accuracy: 0.7931\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1533 - accuracy: 0.9304 - val_loss: 0.1814 - val_accuracy: 0.8621\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1533 - accuracy: 0.8870 - val_loss: 0.1767 - val_accuracy: 0.8621\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1474 - accuracy: 0.8957 - val_loss: 0.1531 - val_accuracy: 0.8621\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1353 - accuracy: 0.9652 - val_loss: 0.1395 - val_accuracy: 0.8621\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1318 - accuracy: 0.9826 - val_loss: 0.1448 - val_accuracy: 0.8621\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1161 - accuracy: 0.9826 - val_loss: 0.1508 - val_accuracy: 0.8621\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1231 - accuracy: 0.9565 - val_loss: 0.1689 - val_accuracy: 0.8966\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1281 - accuracy: 0.8609 - val_loss: 0.1649 - val_accuracy: 0.8966\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1170 - accuracy: 0.9565 - val_loss: 0.1600 - val_accuracy: 0.8966\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1487 - accuracy: 0.9043 - val_loss: 0.1914 - val_accuracy: 0.6897\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1559 - accuracy: 0.8957 - val_loss: 0.1591 - val_accuracy: 0.7931\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1413 - accuracy: 0.9478 - val_loss: 0.1481 - val_accuracy: 0.6897\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1597 - accuracy: 0.8870 - val_loss: 0.1421 - val_accuracy: 0.7241\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1730 - accuracy: 0.8696 - val_loss: 0.1906 - val_accuracy: 0.6897\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1981 - accuracy: 0.8261 - val_loss: 0.2431 - val_accuracy: 0.6207\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2054 - accuracy: 0.7826 - val_loss: 0.3101 - val_accuracy: 0.5862\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2401 - accuracy: 0.6957 - val_loss: 0.2847 - val_accuracy: 0.5517\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2497 - accuracy: 0.6609 - val_loss: 0.3305 - val_accuracy: 0.5517\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2627 - accuracy: 0.5739 - val_loss: 0.3179 - val_accuracy: 0.5172\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2581 - accuracy: 0.6000 - val_loss: 0.3096 - val_accuracy: 0.4828\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2742 - accuracy: 0.5826 - val_loss: 0.4551 - val_accuracy: 0.3793\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2918 - accuracy: 0.5652 - val_loss: 0.3836 - val_accuracy: 0.3793\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2829 - accuracy: 0.5565 - val_loss: 0.3937 - val_accuracy: 0.3448\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2884 - accuracy: 0.5391 - val_loss: 0.3438 - val_accuracy: 0.3103\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2775 - accuracy: 0.5304 - val_loss: 0.3325 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2876 - accuracy: 0.5478 - val_loss: 0.3125 - val_accuracy: 0.4828\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2659 - accuracy: 0.5826 - val_loss: 0.3049 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2892 - accuracy: 0.5043 - val_loss: 0.3037 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2835 - accuracy: 0.4870 - val_loss: 0.3458 - val_accuracy: 0.4138\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2834 - accuracy: 0.5130 - val_loss: 0.3339 - val_accuracy: 0.4483\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2845 - accuracy: 0.4609 - val_loss: 0.3326 - val_accuracy: 0.3793\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2603 - accuracy: 0.6174 - val_loss: 0.3100 - val_accuracy: 0.4828\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2750 - accuracy: 0.5652 - val_loss: 0.3272 - val_accuracy: 0.4483\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.3089 - accuracy: 0.4609 - val_loss: 0.3229 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.3035 - accuracy: 0.4870 - val_loss: 0.3339 - val_accuracy: 0.4138\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2865 - accuracy: 0.5043 - val_loss: 0.3369 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3096 - accuracy: 0.4261 - val_loss: 0.3368 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2893 - accuracy: 0.5652 - val_loss: 0.3377 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3003 - accuracy: 0.4870 - val_loss: 0.3408 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2845 - accuracy: 0.5739 - val_loss: 0.3409 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2890 - accuracy: 0.5217 - val_loss: 0.3437 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2793 - accuracy: 0.5391 - val_loss: 0.3441 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2800 - accuracy: 0.5478 - val_loss: 0.3438 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2766 - accuracy: 0.5391 - val_loss: 0.3436 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2778 - accuracy: 0.5478 - val_loss: 0.3415 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2704 - accuracy: 0.5565 - val_loss: 0.3386 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2704 - accuracy: 0.5739 - val_loss: 0.3361 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2682 - accuracy: 0.5739 - val_loss: 0.3347 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2662 - accuracy: 0.5391 - val_loss: 0.3336 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2622 - accuracy: 0.5913 - val_loss: 0.3313 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2620 - accuracy: 0.5913 - val_loss: 0.3291 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2613 - accuracy: 0.5913 - val_loss: 0.3273 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2579 - accuracy: 0.6000 - val_loss: 0.3256 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2608 - accuracy: 0.6174 - val_loss: 0.3234 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2664 - accuracy: 0.5652 - val_loss: 0.3207 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2510 - accuracy: 0.6435 - val_loss: 0.3179 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2544 - accuracy: 0.6174 - val_loss: 0.3159 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2426 - accuracy: 0.6696 - val_loss: 0.3144 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2489 - accuracy: 0.6000 - val_loss: 0.3134 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2512 - accuracy: 0.6261 - val_loss: 0.3123 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2471 - accuracy: 0.6348 - val_loss: 0.3112 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2455 - accuracy: 0.6435 - val_loss: 0.3099 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2413 - accuracy: 0.6348 - val_loss: 0.3087 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2506 - accuracy: 0.5913 - val_loss: 0.3069 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2370 - accuracy: 0.6783 - val_loss: 0.3039 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2402 - accuracy: 0.6522 - val_loss: 0.3015 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2466 - accuracy: 0.6348 - val_loss: 0.2992 - val_accuracy: 0.4138\n",
      "0.625\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101001111011101111001010101111101010100000\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_152 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_153 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 0.2833 - accuracy: 0.5478 - val_loss: 0.1779 - val_accuracy: 0.7931\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2436 - accuracy: 0.7391 - val_loss: 0.2589 - val_accuracy: 0.7241\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2296 - accuracy: 0.7565 - val_loss: 0.2691 - val_accuracy: 0.6897\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2330 - accuracy: 0.7826 - val_loss: 0.2889 - val_accuracy: 0.5862\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2233 - accuracy: 0.8087 - val_loss: 0.2387 - val_accuracy: 0.6552\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2496 - accuracy: 0.6870 - val_loss: 0.2678 - val_accuracy: 0.8276\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2317 - accuracy: 0.7913 - val_loss: 0.2691 - val_accuracy: 0.6897\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2141 - accuracy: 0.7478 - val_loss: 0.1682 - val_accuracy: 0.8621\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1961 - accuracy: 0.8522 - val_loss: 0.2862 - val_accuracy: 0.7586\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2132 - accuracy: 0.8087 - val_loss: 0.2088 - val_accuracy: 0.8276\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2128 - accuracy: 0.7913 - val_loss: 0.3253 - val_accuracy: 0.6207\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3007 - accuracy: 0.5043 - val_loss: 0.3294 - val_accuracy: 0.5172\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2968 - accuracy: 0.4870 - val_loss: 0.2813 - val_accuracy: 0.5517\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2628 - accuracy: 0.6261 - val_loss: 0.2541 - val_accuracy: 0.5517\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2267 - accuracy: 0.6783 - val_loss: 0.2660 - val_accuracy: 0.6207\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2425 - accuracy: 0.6609 - val_loss: 0.2223 - val_accuracy: 0.5517\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2511 - accuracy: 0.5652 - val_loss: 0.2207 - val_accuracy: 0.6552\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2600 - accuracy: 0.6609 - val_loss: 0.2582 - val_accuracy: 0.5172\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2687 - accuracy: 0.5304 - val_loss: 0.2800 - val_accuracy: 0.4483\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2593 - accuracy: 0.6000 - val_loss: 0.2965 - val_accuracy: 0.4828\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2642 - accuracy: 0.5826 - val_loss: 0.3579 - val_accuracy: 0.4138\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2570 - accuracy: 0.6261 - val_loss: 0.2773 - val_accuracy: 0.5172\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2617 - accuracy: 0.5826 - val_loss: 0.2646 - val_accuracy: 0.6207\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2687 - accuracy: 0.6087 - val_loss: 0.2804 - val_accuracy: 0.4828\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2742 - accuracy: 0.5913 - val_loss: 0.2492 - val_accuracy: 0.5862\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2481 - accuracy: 0.6609 - val_loss: 0.2495 - val_accuracy: 0.5172\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2448 - accuracy: 0.6261 - val_loss: 0.2894 - val_accuracy: 0.4138\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2546 - accuracy: 0.5826 - val_loss: 0.2954 - val_accuracy: 0.5172\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2658 - accuracy: 0.6087 - val_loss: 0.3319 - val_accuracy: 0.3793\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2639 - accuracy: 0.6435 - val_loss: 0.2960 - val_accuracy: 0.5862\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2718 - accuracy: 0.5565 - val_loss: 0.2905 - val_accuracy: 0.6207\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2544 - accuracy: 0.6000 - val_loss: 0.3327 - val_accuracy: 0.7586\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2416 - accuracy: 0.6870 - val_loss: 0.3355 - val_accuracy: 0.4483\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2384 - accuracy: 0.7043 - val_loss: 0.3493 - val_accuracy: 0.5862\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2426 - accuracy: 0.6348 - val_loss: 0.3339 - val_accuracy: 0.5517\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2523 - accuracy: 0.6435 - val_loss: 0.2471 - val_accuracy: 0.8276\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2378 - accuracy: 0.6957 - val_loss: 0.3719 - val_accuracy: 0.5517\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2362 - accuracy: 0.6783 - val_loss: 0.2986 - val_accuracy: 0.7241\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2296 - accuracy: 0.6783 - val_loss: 0.3429 - val_accuracy: 0.5172\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2321 - accuracy: 0.6783 - val_loss: 0.3045 - val_accuracy: 0.5517\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2607 - accuracy: 0.6435 - val_loss: 0.2350 - val_accuracy: 0.6207\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2547 - accuracy: 0.6087 - val_loss: 0.2917 - val_accuracy: 0.5517\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2676 - accuracy: 0.6435 - val_loss: 0.3337 - val_accuracy: 0.4828\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2633 - accuracy: 0.6087 - val_loss: 0.3279 - val_accuracy: 0.4483\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2789 - accuracy: 0.6087 - val_loss: 0.3048 - val_accuracy: 0.5172\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.3086 - accuracy: 0.5391 - val_loss: 0.3444 - val_accuracy: 0.4828\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2969 - accuracy: 0.5478 - val_loss: 0.3247 - val_accuracy: 0.4828\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2961 - accuracy: 0.5217 - val_loss: 0.3697 - val_accuracy: 0.5172\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2792 - accuracy: 0.6087 - val_loss: 0.2778 - val_accuracy: 0.5862\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2409 - accuracy: 0.6957 - val_loss: 0.2585 - val_accuracy: 0.5862\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2654 - accuracy: 0.6087 - val_loss: 0.3169 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2400 - accuracy: 0.6696 - val_loss: 0.3057 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2560 - accuracy: 0.6435 - val_loss: 0.2354 - val_accuracy: 0.6552\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.3026 - accuracy: 0.5391 - val_loss: 0.2708 - val_accuracy: 0.6207\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2765 - accuracy: 0.5565 - val_loss: 0.3119 - val_accuracy: 0.5517\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2690 - accuracy: 0.5913 - val_loss: 0.2626 - val_accuracy: 0.6207\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2687 - accuracy: 0.5913 - val_loss: 0.2698 - val_accuracy: 0.5517\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2628 - accuracy: 0.6261 - val_loss: 0.2980 - val_accuracy: 0.4483\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2697 - accuracy: 0.5739 - val_loss: 0.2895 - val_accuracy: 0.5862\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2718 - accuracy: 0.6000 - val_loss: 0.3338 - val_accuracy: 0.5172\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2651 - accuracy: 0.6000 - val_loss: 0.2862 - val_accuracy: 0.4828\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2680 - accuracy: 0.5739 - val_loss: 0.3325 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2571 - accuracy: 0.6522 - val_loss: 0.3250 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2712 - accuracy: 0.5826 - val_loss: 0.3733 - val_accuracy: 0.3448\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2812 - accuracy: 0.5391 - val_loss: 0.3379 - val_accuracy: 0.3793\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2834 - accuracy: 0.5217 - val_loss: 0.3514 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2643 - accuracy: 0.5739 - val_loss: 0.2834 - val_accuracy: 0.5517\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2556 - accuracy: 0.6174 - val_loss: 0.3424 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2517 - accuracy: 0.6348 - val_loss: 0.3540 - val_accuracy: 0.3793\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2550 - accuracy: 0.6174 - val_loss: 0.3208 - val_accuracy: 0.4483\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2286 - accuracy: 0.6609 - val_loss: 0.2762 - val_accuracy: 0.4483\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2502 - accuracy: 0.6000 - val_loss: 0.2691 - val_accuracy: 0.4483\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2510 - accuracy: 0.6000 - val_loss: 0.3112 - val_accuracy: 0.4483\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2460 - accuracy: 0.6000 - val_loss: 0.3213 - val_accuracy: 0.4483\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2330 - accuracy: 0.6522 - val_loss: 0.2722 - val_accuracy: 0.4828\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2449 - accuracy: 0.6261 - val_loss: 0.3002 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2388 - accuracy: 0.6261 - val_loss: 0.2896 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2475 - accuracy: 0.6261 - val_loss: 0.2992 - val_accuracy: 0.3793\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2473 - accuracy: 0.6348 - val_loss: 0.3684 - val_accuracy: 0.3793\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2392 - accuracy: 0.6435 - val_loss: 0.3314 - val_accuracy: 0.4483\n",
      "0.6041666865348816\n",
      "fitness pass\n",
      "[(0.5729166865348816, 957257731074506), (0.7916666865348816, 923441258232480), (0.6458333134651184, 957148127537610), (0.65625, 923441258232266), (0.6354166865348816, 957251206752714), (0.6458333134651184, 923447748520394), (0.625, 923441258232480), (0.6666666865348816, 923441306069450), (1.0, 957462487713885), (0.625, 957532608981450), (0.6041666865348816, 957257733569184)]\n",
      "[957462487713885, 923441258232480]\n",
      "[957462487713885, 923441258232480, 957148127537610, 923447748520394]\n",
      "selection pass\n",
      "target_count:\n",
      "7\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "0\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "1\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "2\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "3\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "4\n",
      "923447748438474\n",
      "11010001111101111011101111000000111010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "5\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "6\n",
      "957146807617629\n",
      "11011001101000010100011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "7\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "8\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "9\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "10\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "crossover pass\n",
      "變異後的種群\n",
      "染色體：\n",
      "0\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "1\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "變異後的種群\n",
      "染色體：\n",
      "2\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "3\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "4\n",
      "923447748438474\n",
      "11010001111101111011101111000000111010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "5\n",
      "923441258232480\n",
      "11010001111101110101101100001010101111101010100000\n",
      "變異後的種群\n",
      "染色體：\n",
      "6\n",
      "957146807617629\n",
      "11011001101000010100011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "7\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "8\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "9\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "10\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "mutation pass\n",
      "迭代次數： 7\n",
      "7\n",
      "所選擇的染色體：\n",
      "11011001101100111010011011011101110100100001011101\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_154 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_155 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 0.3222 - accuracy: 0.4174 - val_loss: 0.3328 - val_accuracy: 0.3448\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2020 - accuracy: 0.8174 - val_loss: 0.3267 - val_accuracy: 0.5517\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2313 - accuracy: 0.6957 - val_loss: 0.2174 - val_accuracy: 0.8621\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2403 - accuracy: 0.6696 - val_loss: 0.3317 - val_accuracy: 0.6897\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2567 - accuracy: 0.6522 - val_loss: 0.3133 - val_accuracy: 0.6552\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2788 - accuracy: 0.4696 - val_loss: 0.3303 - val_accuracy: 0.6552\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2454 - accuracy: 0.6783 - val_loss: 0.3651 - val_accuracy: 0.4483\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.3063 - accuracy: 0.4348 - val_loss: 0.4310 - val_accuracy: 0.4138\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.3016 - accuracy: 0.5043 - val_loss: 0.4628 - val_accuracy: 0.3103\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.3399 - accuracy: 0.4000 - val_loss: 0.3749 - val_accuracy: 0.4138\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2888 - accuracy: 0.4957 - val_loss: 0.3696 - val_accuracy: 0.4483\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.3073 - accuracy: 0.5130 - val_loss: 0.4532 - val_accuracy: 0.2414\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3007 - accuracy: 0.5130 - val_loss: 0.4041 - val_accuracy: 0.3793\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2667 - accuracy: 0.5652 - val_loss: 0.4308 - val_accuracy: 0.3448\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2761 - accuracy: 0.5739 - val_loss: 0.3585 - val_accuracy: 0.3793\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2874 - accuracy: 0.5391 - val_loss: 0.3697 - val_accuracy: 0.3448\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2906 - accuracy: 0.5217 - val_loss: 0.3909 - val_accuracy: 0.3448\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2933 - accuracy: 0.5391 - val_loss: 0.3541 - val_accuracy: 0.3103\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2799 - accuracy: 0.4870 - val_loss: 0.3524 - val_accuracy: 0.3793\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.3024 - accuracy: 0.4609 - val_loss: 0.4449 - val_accuracy: 0.2414\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2979 - accuracy: 0.4783 - val_loss: 0.3369 - val_accuracy: 0.3103\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2794 - accuracy: 0.5304 - val_loss: 0.3954 - val_accuracy: 0.5172\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2958 - accuracy: 0.4522 - val_loss: 0.3389 - val_accuracy: 0.4138\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2631 - accuracy: 0.5826 - val_loss: 0.3185 - val_accuracy: 0.5172\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2947 - accuracy: 0.5217 - val_loss: 0.3580 - val_accuracy: 0.4828\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2764 - accuracy: 0.6261 - val_loss: 0.3364 - val_accuracy: 0.4828\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2939 - accuracy: 0.4957 - val_loss: 0.3066 - val_accuracy: 0.5172\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2827 - accuracy: 0.5826 - val_loss: 0.2891 - val_accuracy: 0.6207\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2805 - accuracy: 0.5391 - val_loss: 0.2483 - val_accuracy: 0.6207\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2513 - accuracy: 0.5913 - val_loss: 0.2723 - val_accuracy: 0.4828\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2707 - accuracy: 0.5565 - val_loss: 0.2463 - val_accuracy: 0.4828\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2619 - accuracy: 0.5652 - val_loss: 0.2670 - val_accuracy: 0.5172\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2700 - accuracy: 0.5652 - val_loss: 0.2622 - val_accuracy: 0.5517\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2615 - accuracy: 0.5739 - val_loss: 0.2592 - val_accuracy: 0.5517\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2683 - accuracy: 0.5391 - val_loss: 0.2366 - val_accuracy: 0.6207\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2535 - accuracy: 0.6261 - val_loss: 0.2649 - val_accuracy: 0.5172\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2679 - accuracy: 0.5739 - val_loss: 0.2713 - val_accuracy: 0.4828\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2613 - accuracy: 0.5565 - val_loss: 0.2674 - val_accuracy: 0.4828\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2540 - accuracy: 0.5565 - val_loss: 0.2724 - val_accuracy: 0.4828\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2567 - accuracy: 0.6000 - val_loss: 0.2688 - val_accuracy: 0.4828\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2536 - accuracy: 0.6000 - val_loss: 0.2709 - val_accuracy: 0.4828\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2650 - accuracy: 0.5304 - val_loss: 0.2744 - val_accuracy: 0.4828\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2565 - accuracy: 0.5739 - val_loss: 0.2729 - val_accuracy: 0.4828\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2467 - accuracy: 0.6000 - val_loss: 0.2750 - val_accuracy: 0.4828\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2536 - accuracy: 0.5652 - val_loss: 0.2762 - val_accuracy: 0.4828\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2576 - accuracy: 0.5391 - val_loss: 0.2304 - val_accuracy: 0.6552\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2279 - accuracy: 0.6435 - val_loss: 0.2575 - val_accuracy: 0.5862\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2475 - accuracy: 0.6261 - val_loss: 0.2572 - val_accuracy: 0.5862\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2392 - accuracy: 0.6696 - val_loss: 0.2530 - val_accuracy: 0.5862\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2548 - accuracy: 0.6522 - val_loss: 0.2538 - val_accuracy: 0.6207\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2428 - accuracy: 0.6522 - val_loss: 0.2510 - val_accuracy: 0.6207\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2471 - accuracy: 0.6261 - val_loss: 0.2556 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2365 - accuracy: 0.6783 - val_loss: 0.2502 - val_accuracy: 0.6207\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2422 - accuracy: 0.6261 - val_loss: 0.2451 - val_accuracy: 0.6207\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.2368 - accuracy: 0.6609 - val_loss: 0.2436 - val_accuracy: 0.6207\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2341 - accuracy: 0.6696 - val_loss: 0.2439 - val_accuracy: 0.6207\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2261 - accuracy: 0.6696 - val_loss: 0.2446 - val_accuracy: 0.6207\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2254 - accuracy: 0.6870 - val_loss: 0.2459 - val_accuracy: 0.6207\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2306 - accuracy: 0.6783 - val_loss: 0.2465 - val_accuracy: 0.6207\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2331 - accuracy: 0.6783 - val_loss: 0.2467 - val_accuracy: 0.6207\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2252 - accuracy: 0.6957 - val_loss: 0.2467 - val_accuracy: 0.6207\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2288 - accuracy: 0.6522 - val_loss: 0.2466 - val_accuracy: 0.6207\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2316 - accuracy: 0.6696 - val_loss: 0.2465 - val_accuracy: 0.6207\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2223 - accuracy: 0.6957 - val_loss: 0.2464 - val_accuracy: 0.6207\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2116 - accuracy: 0.6870 - val_loss: 0.2463 - val_accuracy: 0.6207\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2253 - accuracy: 0.7043 - val_loss: 0.2460 - val_accuracy: 0.6207\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2153 - accuracy: 0.6696 - val_loss: 0.2456 - val_accuracy: 0.6207\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2251 - accuracy: 0.6609 - val_loss: 0.2452 - val_accuracy: 0.6207\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2223 - accuracy: 0.6522 - val_loss: 0.2450 - val_accuracy: 0.6207\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2175 - accuracy: 0.6783 - val_loss: 0.2446 - val_accuracy: 0.6207\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2160 - accuracy: 0.6957 - val_loss: 0.2443 - val_accuracy: 0.6207\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2093 - accuracy: 0.6957 - val_loss: 0.2440 - val_accuracy: 0.6207\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2155 - accuracy: 0.6957 - val_loss: 0.2437 - val_accuracy: 0.6207\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2199 - accuracy: 0.6696 - val_loss: 0.2435 - val_accuracy: 0.6207\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2129 - accuracy: 0.6783 - val_loss: 0.2434 - val_accuracy: 0.6207\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2090 - accuracy: 0.7130 - val_loss: 0.2435 - val_accuracy: 0.6207\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2148 - accuracy: 0.6957 - val_loss: 0.2434 - val_accuracy: 0.6207\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2117 - accuracy: 0.6783 - val_loss: 0.2432 - val_accuracy: 0.6207\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2109 - accuracy: 0.7130 - val_loss: 0.2428 - val_accuracy: 0.6207\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2037 - accuracy: 0.7304 - val_loss: 0.2427 - val_accuracy: 0.6207\n",
      "0.6875\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111101010100000\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3240)\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_156 (LSTM)              (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_157 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.2468 - accuracy: 0.6000 - val_loss: 0.3867 - val_accuracy: 0.6207\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2501 - accuracy: 0.6000 - val_loss: 0.3939 - val_accuracy: 0.5172\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2456 - accuracy: 0.6609 - val_loss: 0.2342 - val_accuracy: 0.7586\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2194 - accuracy: 0.7913 - val_loss: 0.2145 - val_accuracy: 0.7241\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2270 - accuracy: 0.7304 - val_loss: 0.2119 - val_accuracy: 0.7241\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2467 - accuracy: 0.6696 - val_loss: 0.2164 - val_accuracy: 0.6552\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2404 - accuracy: 0.6696 - val_loss: 0.1817 - val_accuracy: 0.6897\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2258 - accuracy: 0.7391 - val_loss: 0.2108 - val_accuracy: 0.6207\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2537 - accuracy: 0.6087 - val_loss: 0.2090 - val_accuracy: 0.5862\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2216 - accuracy: 0.6957 - val_loss: 0.2096 - val_accuracy: 0.6897\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2050 - accuracy: 0.7913 - val_loss: 0.1764 - val_accuracy: 0.8276\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1920 - accuracy: 0.7739 - val_loss: 0.1389 - val_accuracy: 0.8621\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1889 - accuracy: 0.8174 - val_loss: 0.1450 - val_accuracy: 0.8966\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2151 - accuracy: 0.7304 - val_loss: 0.1495 - val_accuracy: 0.8966\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1861 - accuracy: 0.8174 - val_loss: 0.2271 - val_accuracy: 0.5862\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2254 - accuracy: 0.7217 - val_loss: 0.2703 - val_accuracy: 0.4483\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2398 - accuracy: 0.7043 - val_loss: 0.2564 - val_accuracy: 0.4828\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2373 - accuracy: 0.7217 - val_loss: 0.2570 - val_accuracy: 0.4828\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2415 - accuracy: 0.6522 - val_loss: 0.2725 - val_accuracy: 0.4483\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2485 - accuracy: 0.6783 - val_loss: 0.2914 - val_accuracy: 0.3448\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2558 - accuracy: 0.6435 - val_loss: 0.2706 - val_accuracy: 0.4138\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2415 - accuracy: 0.6435 - val_loss: 0.2689 - val_accuracy: 0.4138\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2958 - accuracy: 0.5391 - val_loss: 0.2894 - val_accuracy: 0.4138\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2833 - accuracy: 0.5565 - val_loss: 0.2864 - val_accuracy: 0.3793\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2933 - accuracy: 0.5043 - val_loss: 0.2678 - val_accuracy: 0.4138\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2749 - accuracy: 0.6087 - val_loss: 0.2780 - val_accuracy: 0.4138\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2804 - accuracy: 0.5652 - val_loss: 0.2731 - val_accuracy: 0.4138\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2663 - accuracy: 0.6000 - val_loss: 0.2733 - val_accuracy: 0.4138\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2495 - accuracy: 0.6609 - val_loss: 0.2742 - val_accuracy: 0.4483\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2576 - accuracy: 0.6609 - val_loss: 0.2710 - val_accuracy: 0.4138\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2241 - accuracy: 0.7130 - val_loss: 0.2656 - val_accuracy: 0.4138\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2082 - accuracy: 0.6870 - val_loss: 0.2637 - val_accuracy: 0.4483\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2365 - accuracy: 0.6435 - val_loss: 0.2708 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2392 - accuracy: 0.6522 - val_loss: 0.2688 - val_accuracy: 0.4138\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2163 - accuracy: 0.7391 - val_loss: 0.2645 - val_accuracy: 0.4138\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2182 - accuracy: 0.6522 - val_loss: 0.2679 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2330 - accuracy: 0.6696 - val_loss: 0.2720 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2499 - accuracy: 0.6522 - val_loss: 0.2706 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2526 - accuracy: 0.6174 - val_loss: 0.2687 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2447 - accuracy: 0.6609 - val_loss: 0.2696 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2596 - accuracy: 0.6522 - val_loss: 0.2697 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2570 - accuracy: 0.6087 - val_loss: 0.2718 - val_accuracy: 0.4138\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2372 - accuracy: 0.6696 - val_loss: 0.2719 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2482 - accuracy: 0.6522 - val_loss: 0.2708 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2402 - accuracy: 0.6696 - val_loss: 0.2734 - val_accuracy: 0.4138\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2485 - accuracy: 0.6522 - val_loss: 0.2722 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2456 - accuracy: 0.6435 - val_loss: 0.2711 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2316 - accuracy: 0.6957 - val_loss: 0.2728 - val_accuracy: 0.4138\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2446 - accuracy: 0.6609 - val_loss: 0.2737 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2335 - accuracy: 0.6870 - val_loss: 0.2732 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2386 - accuracy: 0.6435 - val_loss: 0.2726 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2224 - accuracy: 0.6783 - val_loss: 0.2719 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2308 - accuracy: 0.6696 - val_loss: 0.2711 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2153 - accuracy: 0.7043 - val_loss: 0.2702 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2168 - accuracy: 0.6696 - val_loss: 0.2707 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2219 - accuracy: 0.6957 - val_loss: 0.2693 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2098 - accuracy: 0.6696 - val_loss: 0.2682 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2110 - accuracy: 0.6957 - val_loss: 0.2678 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1994 - accuracy: 0.7043 - val_loss: 0.2677 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2093 - accuracy: 0.7043 - val_loss: 0.2678 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1990 - accuracy: 0.7043 - val_loss: 0.2677 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2042 - accuracy: 0.6957 - val_loss: 0.2676 - val_accuracy: 0.4483\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1922 - accuracy: 0.7130 - val_loss: 0.2671 - val_accuracy: 0.4483\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1941 - accuracy: 0.6783 - val_loss: 0.2667 - val_accuracy: 0.4483\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1924 - accuracy: 0.7043 - val_loss: 0.2662 - val_accuracy: 0.4483\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1859 - accuracy: 0.7217 - val_loss: 0.2657 - val_accuracy: 0.4483\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1863 - accuracy: 0.7391 - val_loss: 0.2650 - val_accuracy: 0.4483\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1831 - accuracy: 0.7130 - val_loss: 0.2646 - val_accuracy: 0.4483\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1767 - accuracy: 0.7478 - val_loss: 0.2644 - val_accuracy: 0.4483\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1757 - accuracy: 0.7565 - val_loss: 0.2645 - val_accuracy: 0.4483\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1751 - accuracy: 0.7652 - val_loss: 0.2645 - val_accuracy: 0.4483\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1711 - accuracy: 0.7478 - val_loss: 0.2644 - val_accuracy: 0.4483\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1759 - accuracy: 0.7739 - val_loss: 0.2642 - val_accuracy: 0.4483\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1664 - accuracy: 0.7739 - val_loss: 0.2640 - val_accuracy: 0.4483\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1679 - accuracy: 0.7826 - val_loss: 0.2636 - val_accuracy: 0.4483\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1658 - accuracy: 0.7652 - val_loss: 0.2633 - val_accuracy: 0.4483\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1653 - accuracy: 0.7565 - val_loss: 0.2631 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1669 - accuracy: 0.7652 - val_loss: 0.2633 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1737 - accuracy: 0.7565 - val_loss: 0.2630 - val_accuracy: 0.4483\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1558 - accuracy: 0.7739 - val_loss: 0.2624 - val_accuracy: 0.4483\n",
      "0.625\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101000010101101010001000111010100111001010\n",
      "26\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2880)\n",
      "(144, 100, 2880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_158 (LSTM)              (None, 100, 20)           232080    \n",
      "_________________________________________________________________\n",
      "lstm_159 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 235,482\n",
      "Trainable params: 235,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.2647 - accuracy: 0.6348 - val_loss: 0.6011 - val_accuracy: 0.2759\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.3369 - accuracy: 0.2870 - val_loss: 0.4415 - val_accuracy: 0.4483\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3168 - accuracy: 0.3391 - val_loss: 0.4874 - val_accuracy: 0.4483\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3246 - accuracy: 0.3478 - val_loss: 0.4657 - val_accuracy: 0.3793\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2880 - accuracy: 0.3478 - val_loss: 0.4390 - val_accuracy: 0.4483\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.3224 - accuracy: 0.3913 - val_loss: 0.5103 - val_accuracy: 0.3448\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2945 - accuracy: 0.4957 - val_loss: 0.4152 - val_accuracy: 0.4483\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2928 - accuracy: 0.4957 - val_loss: 0.4195 - val_accuracy: 0.4138\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.3071 - accuracy: 0.4870 - val_loss: 0.3687 - val_accuracy: 0.4138\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2762 - accuracy: 0.6261 - val_loss: 0.3577 - val_accuracy: 0.4483\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2966 - accuracy: 0.4783 - val_loss: 0.3707 - val_accuracy: 0.4828\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2806 - accuracy: 0.5304 - val_loss: 0.2866 - val_accuracy: 0.6207\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2769 - accuracy: 0.6000 - val_loss: 0.3370 - val_accuracy: 0.4483\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2783 - accuracy: 0.6261 - val_loss: 0.3142 - val_accuracy: 0.4828\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2805 - accuracy: 0.6000 - val_loss: 0.3425 - val_accuracy: 0.4828\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2838 - accuracy: 0.6000 - val_loss: 0.3154 - val_accuracy: 0.3793\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2593 - accuracy: 0.6522 - val_loss: 0.2683 - val_accuracy: 0.6552\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2558 - accuracy: 0.6087 - val_loss: 0.2880 - val_accuracy: 0.6552\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2552 - accuracy: 0.6609 - val_loss: 0.3232 - val_accuracy: 0.5517\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2670 - accuracy: 0.6435 - val_loss: 0.2637 - val_accuracy: 0.5862\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2459 - accuracy: 0.7043 - val_loss: 0.3067 - val_accuracy: 0.5172\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2417 - accuracy: 0.6957 - val_loss: 0.2937 - val_accuracy: 0.6207\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2511 - accuracy: 0.6696 - val_loss: 0.2963 - val_accuracy: 0.6207\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2700 - accuracy: 0.6174 - val_loss: 0.3330 - val_accuracy: 0.5862\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2662 - accuracy: 0.6087 - val_loss: 0.3171 - val_accuracy: 0.5172\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2416 - accuracy: 0.6783 - val_loss: 0.3065 - val_accuracy: 0.5517\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2425 - accuracy: 0.6783 - val_loss: 0.3520 - val_accuracy: 0.4138\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2499 - accuracy: 0.6609 - val_loss: 0.3562 - val_accuracy: 0.4483\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2400 - accuracy: 0.6870 - val_loss: 0.3309 - val_accuracy: 0.4828\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2336 - accuracy: 0.6870 - val_loss: 0.2506 - val_accuracy: 0.6207\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.2386 - accuracy: 0.6870 - val_loss: 0.3034 - val_accuracy: 0.4828\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2436 - accuracy: 0.6957 - val_loss: 0.3110 - val_accuracy: 0.4828\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2379 - accuracy: 0.6783 - val_loss: 0.2952 - val_accuracy: 0.5172\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2410 - accuracy: 0.6783 - val_loss: 0.3079 - val_accuracy: 0.3793\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2261 - accuracy: 0.7217 - val_loss: 0.3441 - val_accuracy: 0.4138\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2439 - accuracy: 0.6696 - val_loss: 0.3061 - val_accuracy: 0.4828\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2500 - accuracy: 0.6261 - val_loss: 0.3062 - val_accuracy: 0.4483\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2395 - accuracy: 0.6609 - val_loss: 0.2755 - val_accuracy: 0.5172\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2435 - accuracy: 0.6609 - val_loss: 0.2969 - val_accuracy: 0.4483\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2337 - accuracy: 0.6435 - val_loss: 0.3329 - val_accuracy: 0.3448\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2328 - accuracy: 0.6783 - val_loss: 0.3236 - val_accuracy: 0.3448\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2450 - accuracy: 0.6609 - val_loss: 0.3313 - val_accuracy: 0.3448\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2294 - accuracy: 0.7043 - val_loss: 0.2984 - val_accuracy: 0.4828\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2315 - accuracy: 0.6783 - val_loss: 0.2799 - val_accuracy: 0.5862\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2349 - accuracy: 0.6783 - val_loss: 0.2845 - val_accuracy: 0.4828\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2525 - accuracy: 0.6174 - val_loss: 0.2624 - val_accuracy: 0.5862\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2396 - accuracy: 0.6087 - val_loss: 0.2459 - val_accuracy: 0.5862\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2267 - accuracy: 0.6609 - val_loss: 0.2386 - val_accuracy: 0.6207\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2406 - accuracy: 0.6261 - val_loss: 0.2193 - val_accuracy: 0.6552\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2369 - accuracy: 0.5913 - val_loss: 0.2235 - val_accuracy: 0.6552\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2356 - accuracy: 0.6435 - val_loss: 0.2437 - val_accuracy: 0.5517\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2440 - accuracy: 0.6261 - val_loss: 0.2481 - val_accuracy: 0.5172\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2313 - accuracy: 0.6609 - val_loss: 0.2407 - val_accuracy: 0.5517\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2238 - accuracy: 0.6522 - val_loss: 0.2525 - val_accuracy: 0.5172\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2375 - accuracy: 0.6522 - val_loss: 0.2710 - val_accuracy: 0.5172\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2307 - accuracy: 0.6522 - val_loss: 0.2655 - val_accuracy: 0.4828\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2399 - accuracy: 0.6174 - val_loss: 0.2536 - val_accuracy: 0.5172\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2368 - accuracy: 0.6174 - val_loss: 0.2695 - val_accuracy: 0.4828\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2472 - accuracy: 0.5739 - val_loss: 0.2817 - val_accuracy: 0.4483\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2385 - accuracy: 0.6174 - val_loss: 0.2252 - val_accuracy: 0.6207\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2390 - accuracy: 0.6609 - val_loss: 0.2398 - val_accuracy: 0.5172\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2478 - accuracy: 0.6348 - val_loss: 0.2379 - val_accuracy: 0.5172\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2401 - accuracy: 0.6174 - val_loss: 0.2424 - val_accuracy: 0.5172\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2318 - accuracy: 0.6435 - val_loss: 0.2360 - val_accuracy: 0.5517\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2317 - accuracy: 0.6522 - val_loss: 0.2519 - val_accuracy: 0.5172\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2316 - accuracy: 0.6435 - val_loss: 0.2596 - val_accuracy: 0.4828\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2358 - accuracy: 0.6087 - val_loss: 0.2654 - val_accuracy: 0.4828\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2343 - accuracy: 0.6435 - val_loss: 0.2423 - val_accuracy: 0.5517\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2397 - accuracy: 0.6435 - val_loss: 0.2550 - val_accuracy: 0.5172\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2379 - accuracy: 0.6348 - val_loss: 0.2868 - val_accuracy: 0.4828\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2296 - accuracy: 0.6522 - val_loss: 0.2893 - val_accuracy: 0.4483\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2364 - accuracy: 0.6174 - val_loss: 0.2747 - val_accuracy: 0.4828\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2266 - accuracy: 0.6348 - val_loss: 0.2788 - val_accuracy: 0.4828\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2397 - accuracy: 0.6174 - val_loss: 0.2775 - val_accuracy: 0.4828\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2469 - accuracy: 0.5826 - val_loss: 0.2748 - val_accuracy: 0.4828\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2419 - accuracy: 0.5913 - val_loss: 0.2709 - val_accuracy: 0.5172\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2266 - accuracy: 0.6348 - val_loss: 0.2721 - val_accuracy: 0.4828\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2288 - accuracy: 0.6435 - val_loss: 0.2784 - val_accuracy: 0.3793\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2099 - accuracy: 0.6957 - val_loss: 0.2897 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2097 - accuracy: 0.6870 - val_loss: 0.2850 - val_accuracy: 0.4483\n",
      "0.59375\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101111011101111000001001110100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_160 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_161 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 299ms/step - loss: 0.3416 - accuracy: 0.4696 - val_loss: 0.4746 - val_accuracy: 0.4483\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2709 - accuracy: 0.6609 - val_loss: 0.4256 - val_accuracy: 0.4828\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2995 - accuracy: 0.5217 - val_loss: 0.3883 - val_accuracy: 0.4483\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2762 - accuracy: 0.5913 - val_loss: 0.3566 - val_accuracy: 0.6207\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2866 - accuracy: 0.4957 - val_loss: 0.3587 - val_accuracy: 0.5172\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2998 - accuracy: 0.5391 - val_loss: 0.2537 - val_accuracy: 0.6207\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2667 - accuracy: 0.5565 - val_loss: 0.3759 - val_accuracy: 0.4138\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2830 - accuracy: 0.5304 - val_loss: 0.3577 - val_accuracy: 0.5172\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2639 - accuracy: 0.5043 - val_loss: 0.3998 - val_accuracy: 0.5862\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2976 - accuracy: 0.4696 - val_loss: 0.4249 - val_accuracy: 0.5172\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.3121 - accuracy: 0.4870 - val_loss: 0.2836 - val_accuracy: 0.5862\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.3270 - accuracy: 0.4261 - val_loss: 0.2821 - val_accuracy: 0.6552\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2601 - accuracy: 0.6087 - val_loss: 0.2596 - val_accuracy: 0.7241\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2604 - accuracy: 0.6348 - val_loss: 0.3208 - val_accuracy: 0.5517\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2899 - accuracy: 0.5739 - val_loss: 0.2855 - val_accuracy: 0.6897\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2436 - accuracy: 0.6783 - val_loss: 0.3298 - val_accuracy: 0.4828\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2413 - accuracy: 0.6783 - val_loss: 0.2679 - val_accuracy: 0.5517\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2818 - accuracy: 0.5826 - val_loss: 0.3058 - val_accuracy: 0.4483\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2966 - accuracy: 0.4957 - val_loss: 0.3277 - val_accuracy: 0.4483\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2933 - accuracy: 0.4783 - val_loss: 0.3308 - val_accuracy: 0.5172\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3168 - accuracy: 0.4957 - val_loss: 0.3657 - val_accuracy: 0.5517\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2894 - accuracy: 0.5565 - val_loss: 0.2963 - val_accuracy: 0.7931\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2248 - accuracy: 0.7391 - val_loss: 0.2891 - val_accuracy: 0.5862\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2507 - accuracy: 0.6609 - val_loss: 0.3296 - val_accuracy: 0.4828\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2309 - accuracy: 0.7130 - val_loss: 0.2584 - val_accuracy: 0.5862\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2809 - accuracy: 0.5565 - val_loss: 0.2448 - val_accuracy: 0.6207\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3194 - accuracy: 0.5304 - val_loss: 0.2557 - val_accuracy: 0.6207\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3012 - accuracy: 0.5478 - val_loss: 0.2486 - val_accuracy: 0.5172\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3038 - accuracy: 0.5217 - val_loss: 0.2807 - val_accuracy: 0.4483\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2837 - accuracy: 0.5652 - val_loss: 0.2712 - val_accuracy: 0.4483\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3133 - accuracy: 0.4783 - val_loss: 0.2703 - val_accuracy: 0.5172\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.3194 - accuracy: 0.4609 - val_loss: 0.2517 - val_accuracy: 0.5172\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.3084 - accuracy: 0.5391 - val_loss: 0.3210 - val_accuracy: 0.3793\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.3050 - accuracy: 0.4870 - val_loss: 0.2602 - val_accuracy: 0.5172\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2990 - accuracy: 0.4696 - val_loss: 0.2566 - val_accuracy: 0.4483\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2617 - accuracy: 0.5913 - val_loss: 0.2855 - val_accuracy: 0.3793\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3036 - accuracy: 0.5217 - val_loss: 0.2783 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2867 - accuracy: 0.5304 - val_loss: 0.2699 - val_accuracy: 0.4483\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2526 - accuracy: 0.5565 - val_loss: 0.2778 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3026 - accuracy: 0.4174 - val_loss: 0.2829 - val_accuracy: 0.4483\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2810 - accuracy: 0.4696 - val_loss: 0.2768 - val_accuracy: 0.3793\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3030 - accuracy: 0.4087 - val_loss: 0.2977 - val_accuracy: 0.4138\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2699 - accuracy: 0.5043 - val_loss: 0.2766 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2832 - accuracy: 0.4783 - val_loss: 0.2996 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2750 - accuracy: 0.5043 - val_loss: 0.2854 - val_accuracy: 0.4483\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2509 - accuracy: 0.5652 - val_loss: 0.2783 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2778 - accuracy: 0.5565 - val_loss: 0.2510 - val_accuracy: 0.4828\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2468 - accuracy: 0.6174 - val_loss: 0.2374 - val_accuracy: 0.5172\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2221 - accuracy: 0.6870 - val_loss: 0.2377 - val_accuracy: 0.5172\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2246 - accuracy: 0.6609 - val_loss: 0.2316 - val_accuracy: 0.5517\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2213 - accuracy: 0.6870 - val_loss: 0.2226 - val_accuracy: 0.5862\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2194 - accuracy: 0.6783 - val_loss: 0.2189 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2193 - accuracy: 0.6870 - val_loss: 0.2246 - val_accuracy: 0.6207\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2199 - accuracy: 0.6696 - val_loss: 0.2312 - val_accuracy: 0.5862\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2358 - accuracy: 0.5913 - val_loss: 0.2984 - val_accuracy: 0.3793\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2637 - accuracy: 0.5304 - val_loss: 0.2872 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2512 - accuracy: 0.5304 - val_loss: 0.2392 - val_accuracy: 0.5517\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2284 - accuracy: 0.6174 - val_loss: 0.2991 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2690 - accuracy: 0.5826 - val_loss: 0.3131 - val_accuracy: 0.4483\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2523 - accuracy: 0.6783 - val_loss: 0.3058 - val_accuracy: 0.4483\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2651 - accuracy: 0.5478 - val_loss: 0.2767 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2430 - accuracy: 0.5826 - val_loss: 0.2875 - val_accuracy: 0.4483\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2505 - accuracy: 0.6000 - val_loss: 0.2896 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2395 - accuracy: 0.6174 - val_loss: 0.2811 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2399 - accuracy: 0.6609 - val_loss: 0.3169 - val_accuracy: 0.4483\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2437 - accuracy: 0.6435 - val_loss: 0.3454 - val_accuracy: 0.4483\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2640 - accuracy: 0.6087 - val_loss: 0.3217 - val_accuracy: 0.4483\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2798 - accuracy: 0.5913 - val_loss: 0.3323 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2836 - accuracy: 0.5478 - val_loss: 0.3229 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2985 - accuracy: 0.5391 - val_loss: 0.2992 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2711 - accuracy: 0.5739 - val_loss: 0.3244 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3009 - accuracy: 0.5043 - val_loss: 0.3127 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2826 - accuracy: 0.5652 - val_loss: 0.3113 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3079 - accuracy: 0.4783 - val_loss: 0.2882 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2883 - accuracy: 0.4870 - val_loss: 0.2925 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2982 - accuracy: 0.5043 - val_loss: 0.3193 - val_accuracy: 0.3793\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2836 - accuracy: 0.5130 - val_loss: 0.1638 - val_accuracy: 0.7586\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2505 - accuracy: 0.5565 - val_loss: 0.1816 - val_accuracy: 0.7241\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2741 - accuracy: 0.5304 - val_loss: 0.2070 - val_accuracy: 0.6552\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2756 - accuracy: 0.5739 - val_loss: 0.3945 - val_accuracy: 0.3793\n",
      "0.59375\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101111011101111000000111010100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_162 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_163 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 0.3162 - accuracy: 0.4000 - val_loss: 0.2690 - val_accuracy: 0.4828\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2415 - accuracy: 0.6957 - val_loss: 0.3023 - val_accuracy: 0.3793\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2212 - accuracy: 0.7652 - val_loss: 0.3246 - val_accuracy: 0.4483\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2074 - accuracy: 0.7043 - val_loss: 0.3037 - val_accuracy: 0.4828\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1878 - accuracy: 0.8522 - val_loss: 0.3206 - val_accuracy: 0.5172\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2061 - accuracy: 0.7913 - val_loss: 0.3115 - val_accuracy: 0.5172\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2153 - accuracy: 0.8087 - val_loss: 0.3234 - val_accuracy: 0.5172\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2137 - accuracy: 0.7826 - val_loss: 0.2624 - val_accuracy: 0.5517\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2149 - accuracy: 0.7826 - val_loss: 0.3127 - val_accuracy: 0.5517\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2391 - accuracy: 0.6174 - val_loss: 0.2603 - val_accuracy: 0.7241\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2326 - accuracy: 0.6696 - val_loss: 0.2607 - val_accuracy: 0.6552\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2235 - accuracy: 0.6609 - val_loss: 0.2851 - val_accuracy: 0.6207\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2092 - accuracy: 0.6870 - val_loss: 0.2398 - val_accuracy: 0.7586\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2129 - accuracy: 0.7043 - val_loss: 0.2188 - val_accuracy: 0.7931\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2251 - accuracy: 0.6348 - val_loss: 0.2120 - val_accuracy: 0.8276\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2060 - accuracy: 0.7478 - val_loss: 0.2055 - val_accuracy: 0.7931\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2236 - accuracy: 0.6174 - val_loss: 0.2433 - val_accuracy: 0.7586\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2277 - accuracy: 0.6696 - val_loss: 0.2126 - val_accuracy: 0.7931\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2273 - accuracy: 0.6609 - val_loss: 0.2433 - val_accuracy: 0.7586\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2397 - accuracy: 0.6348 - val_loss: 0.2246 - val_accuracy: 0.7586\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2323 - accuracy: 0.6087 - val_loss: 0.2243 - val_accuracy: 0.7586\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2301 - accuracy: 0.6522 - val_loss: 0.2026 - val_accuracy: 0.8621\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1973 - accuracy: 0.7739 - val_loss: 0.1969 - val_accuracy: 0.8276\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1923 - accuracy: 0.8000 - val_loss: 0.1949 - val_accuracy: 0.8276\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2043 - accuracy: 0.7652 - val_loss: 0.1850 - val_accuracy: 0.8966\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2018 - accuracy: 0.7652 - val_loss: 0.1845 - val_accuracy: 0.8621\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2015 - accuracy: 0.7478 - val_loss: 0.1832 - val_accuracy: 0.8621\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2053 - accuracy: 0.7391 - val_loss: 0.1816 - val_accuracy: 0.8621\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1969 - accuracy: 0.7391 - val_loss: 0.1793 - val_accuracy: 0.8621\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1925 - accuracy: 0.7739 - val_loss: 0.1763 - val_accuracy: 0.8621\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1947 - accuracy: 0.7826 - val_loss: 0.1527 - val_accuracy: 0.8621\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1967 - accuracy: 0.7478 - val_loss: 0.1521 - val_accuracy: 0.8621\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1924 - accuracy: 0.7565 - val_loss: 0.1533 - val_accuracy: 0.8621\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1826 - accuracy: 0.7391 - val_loss: 0.1518 - val_accuracy: 0.8621\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1815 - accuracy: 0.7391 - val_loss: 0.1529 - val_accuracy: 0.8621\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1731 - accuracy: 0.7652 - val_loss: 0.1552 - val_accuracy: 0.8621\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1703 - accuracy: 0.8261 - val_loss: 0.1538 - val_accuracy: 0.8621\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1737 - accuracy: 0.7652 - val_loss: 0.1473 - val_accuracy: 0.8621\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1755 - accuracy: 0.7826 - val_loss: 0.1450 - val_accuracy: 0.8621\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1726 - accuracy: 0.7739 - val_loss: 0.1441 - val_accuracy: 0.8621\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1652 - accuracy: 0.7913 - val_loss: 0.1431 - val_accuracy: 0.8621\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1630 - accuracy: 0.7739 - val_loss: 0.1415 - val_accuracy: 0.8966\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1679 - accuracy: 0.8000 - val_loss: 0.1403 - val_accuracy: 0.8621\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1640 - accuracy: 0.8174 - val_loss: 0.1393 - val_accuracy: 0.8621\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1584 - accuracy: 0.8174 - val_loss: 0.1387 - val_accuracy: 0.8621\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1551 - accuracy: 0.8522 - val_loss: 0.1370 - val_accuracy: 0.8621\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1612 - accuracy: 0.7913 - val_loss: 0.1396 - val_accuracy: 0.8621\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1596 - accuracy: 0.8174 - val_loss: 0.1358 - val_accuracy: 0.8621\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1620 - accuracy: 0.7652 - val_loss: 0.1338 - val_accuracy: 0.8621\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1651 - accuracy: 0.8000 - val_loss: 0.1334 - val_accuracy: 0.8621\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1572 - accuracy: 0.8261 - val_loss: 0.1321 - val_accuracy: 0.8621\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1506 - accuracy: 0.8261 - val_loss: 0.1339 - val_accuracy: 0.8621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1517 - accuracy: 0.7652 - val_loss: 0.1395 - val_accuracy: 0.8621\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1506 - accuracy: 0.8261 - val_loss: 0.1407 - val_accuracy: 0.8621\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1482 - accuracy: 0.8435 - val_loss: 0.1255 - val_accuracy: 0.8621\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1467 - accuracy: 0.8174 - val_loss: 0.1223 - val_accuracy: 0.8621\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1410 - accuracy: 0.8348 - val_loss: 0.1453 - val_accuracy: 0.8621\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1402 - accuracy: 0.8435 - val_loss: 0.1583 - val_accuracy: 0.8621\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1331 - accuracy: 0.8783 - val_loss: 0.1556 - val_accuracy: 0.8621\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1491 - accuracy: 0.7913 - val_loss: 0.1614 - val_accuracy: 0.8276\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1414 - accuracy: 0.8087 - val_loss: 0.1693 - val_accuracy: 0.8621\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1403 - accuracy: 0.7826 - val_loss: 0.1666 - val_accuracy: 0.8621\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1384 - accuracy: 0.8348 - val_loss: 0.1618 - val_accuracy: 0.8621\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1383 - accuracy: 0.8087 - val_loss: 0.1848 - val_accuracy: 0.8276\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1798 - accuracy: 0.7043 - val_loss: 0.3123 - val_accuracy: 0.4483\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2602 - accuracy: 0.5913 - val_loss: 0.3828 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2634 - accuracy: 0.5217 - val_loss: 0.4169 - val_accuracy: 0.3793\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3186 - accuracy: 0.4435 - val_loss: 0.4305 - val_accuracy: 0.3793\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3424 - accuracy: 0.3826 - val_loss: 0.4257 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.3376 - accuracy: 0.4957 - val_loss: 0.3742 - val_accuracy: 0.3793\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2969 - accuracy: 0.5826 - val_loss: 0.3691 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3010 - accuracy: 0.5652 - val_loss: 0.3486 - val_accuracy: 0.4828\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2879 - accuracy: 0.5739 - val_loss: 0.3432 - val_accuracy: 0.4483\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2906 - accuracy: 0.6174 - val_loss: 0.3302 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2857 - accuracy: 0.6261 - val_loss: 0.3137 - val_accuracy: 0.5172\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2813 - accuracy: 0.6522 - val_loss: 0.3171 - val_accuracy: 0.5172\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2732 - accuracy: 0.6696 - val_loss: 0.3179 - val_accuracy: 0.4828\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2740 - accuracy: 0.6609 - val_loss: 0.3165 - val_accuracy: 0.4828\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2766 - accuracy: 0.6174 - val_loss: 0.3141 - val_accuracy: 0.4828\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2586 - accuracy: 0.6783 - val_loss: 0.3139 - val_accuracy: 0.4828\n",
      "0.6666666865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101110101101100001010101111101010100000\n",
      "23\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3240)\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_164 (LSTM)              (None, 100, 20)           260880    \n",
      "_________________________________________________________________\n",
      "lstm_165 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 264,282\n",
      "Trainable params: 264,242\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.2939 - accuracy: 0.5043 - val_loss: 0.3464 - val_accuracy: 0.4828\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2841 - accuracy: 0.5478 - val_loss: 0.2998 - val_accuracy: 0.4828\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2994 - accuracy: 0.4783 - val_loss: 0.3580 - val_accuracy: 0.3103\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2516 - accuracy: 0.5652 - val_loss: 0.3421 - val_accuracy: 0.4138\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2811 - accuracy: 0.5304 - val_loss: 0.3092 - val_accuracy: 0.3103\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2923 - accuracy: 0.5391 - val_loss: 0.2917 - val_accuracy: 0.4138\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2864 - accuracy: 0.5913 - val_loss: 0.3026 - val_accuracy: 0.4483\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2635 - accuracy: 0.6609 - val_loss: 0.2891 - val_accuracy: 0.4828\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2737 - accuracy: 0.5826 - val_loss: 0.2707 - val_accuracy: 0.5172\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2436 - accuracy: 0.6870 - val_loss: 0.2826 - val_accuracy: 0.4138\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2609 - accuracy: 0.6696 - val_loss: 0.2722 - val_accuracy: 0.4828\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2649 - accuracy: 0.6522 - val_loss: 0.2776 - val_accuracy: 0.3103\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2804 - accuracy: 0.6435 - val_loss: 0.2575 - val_accuracy: 0.4828\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2547 - accuracy: 0.7391 - val_loss: 0.2631 - val_accuracy: 0.4138\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2670 - accuracy: 0.6348 - val_loss: 0.2603 - val_accuracy: 0.4138\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2867 - accuracy: 0.6000 - val_loss: 0.2585 - val_accuracy: 0.3793\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2835 - accuracy: 0.5391 - val_loss: 0.2772 - val_accuracy: 0.4138\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2607 - accuracy: 0.6696 - val_loss: 0.2690 - val_accuracy: 0.3793\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2688 - accuracy: 0.6000 - val_loss: 0.2623 - val_accuracy: 0.3793\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2958 - accuracy: 0.5739 - val_loss: 0.2835 - val_accuracy: 0.3448\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2906 - accuracy: 0.5391 - val_loss: 0.2743 - val_accuracy: 0.3103\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2743 - accuracy: 0.5217 - val_loss: 0.2567 - val_accuracy: 0.4483\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2793 - accuracy: 0.5652 - val_loss: 0.2609 - val_accuracy: 0.4483\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2666 - accuracy: 0.5304 - val_loss: 0.2972 - val_accuracy: 0.4138\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2595 - accuracy: 0.6174 - val_loss: 0.2820 - val_accuracy: 0.4483\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2825 - accuracy: 0.5391 - val_loss: 0.2797 - val_accuracy: 0.4138\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2591 - accuracy: 0.6174 - val_loss: 0.2771 - val_accuracy: 0.3448\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2822 - accuracy: 0.5565 - val_loss: 0.2539 - val_accuracy: 0.4828\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2797 - accuracy: 0.5826 - val_loss: 0.2846 - val_accuracy: 0.4138\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2882 - accuracy: 0.5304 - val_loss: 0.2669 - val_accuracy: 0.4483\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2536 - accuracy: 0.5826 - val_loss: 0.2634 - val_accuracy: 0.4483\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2723 - accuracy: 0.6000 - val_loss: 0.2530 - val_accuracy: 0.4828\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2592 - accuracy: 0.6174 - val_loss: 0.2513 - val_accuracy: 0.4828\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2707 - accuracy: 0.5391 - val_loss: 0.2603 - val_accuracy: 0.4828\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2761 - accuracy: 0.5565 - val_loss: 0.2600 - val_accuracy: 0.4483\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2617 - accuracy: 0.6000 - val_loss: 0.2755 - val_accuracy: 0.3793\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2814 - accuracy: 0.5913 - val_loss: 0.2610 - val_accuracy: 0.4483\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2583 - accuracy: 0.5826 - val_loss: 0.2546 - val_accuracy: 0.4828\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2564 - accuracy: 0.6000 - val_loss: 0.2966 - val_accuracy: 0.3793\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2499 - accuracy: 0.5652 - val_loss: 0.2692 - val_accuracy: 0.4483\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2601 - accuracy: 0.6174 - val_loss: 0.2661 - val_accuracy: 0.5172\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2586 - accuracy: 0.6000 - val_loss: 0.3013 - val_accuracy: 0.3793\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2572 - accuracy: 0.6000 - val_loss: 0.2638 - val_accuracy: 0.5172\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2597 - accuracy: 0.5913 - val_loss: 0.2541 - val_accuracy: 0.4828\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2378 - accuracy: 0.6174 - val_loss: 0.2465 - val_accuracy: 0.4828\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2613 - accuracy: 0.6522 - val_loss: 0.2775 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2477 - accuracy: 0.6696 - val_loss: 0.2720 - val_accuracy: 0.3793\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2646 - accuracy: 0.6348 - val_loss: 0.2643 - val_accuracy: 0.4828\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2556 - accuracy: 0.6522 - val_loss: 0.2627 - val_accuracy: 0.4483\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2567 - accuracy: 0.6174 - val_loss: 0.2728 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2422 - accuracy: 0.6696 - val_loss: 0.2906 - val_accuracy: 0.4828\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2796 - accuracy: 0.5739 - val_loss: 0.2842 - val_accuracy: 0.4483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2763 - accuracy: 0.5478 - val_loss: 0.3020 - val_accuracy: 0.4483\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2852 - accuracy: 0.5304 - val_loss: 0.2854 - val_accuracy: 0.4483\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.3012 - accuracy: 0.5652 - val_loss: 0.2856 - val_accuracy: 0.3448\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.3041 - accuracy: 0.5478 - val_loss: 0.2945 - val_accuracy: 0.3793\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2607 - accuracy: 0.6348 - val_loss: 0.2751 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2745 - accuracy: 0.6000 - val_loss: 0.2972 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2928 - accuracy: 0.5826 - val_loss: 0.2831 - val_accuracy: 0.3793\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2797 - accuracy: 0.5652 - val_loss: 0.2798 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2532 - accuracy: 0.6174 - val_loss: 0.2989 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2890 - accuracy: 0.5391 - val_loss: 0.2819 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2715 - accuracy: 0.6348 - val_loss: 0.2810 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2675 - accuracy: 0.6174 - val_loss: 0.2862 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2495 - accuracy: 0.5739 - val_loss: 0.2696 - val_accuracy: 0.4483\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2870 - accuracy: 0.5391 - val_loss: 0.2898 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2273 - accuracy: 0.6522 - val_loss: 0.2841 - val_accuracy: 0.3793\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.3075 - accuracy: 0.5478 - val_loss: 0.3041 - val_accuracy: 0.3448\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2836 - accuracy: 0.5826 - val_loss: 0.2814 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2256 - accuracy: 0.6609 - val_loss: 0.2799 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2632 - accuracy: 0.6174 - val_loss: 0.2810 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2826 - accuracy: 0.5739 - val_loss: 0.2778 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2692 - accuracy: 0.6348 - val_loss: 0.2793 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2797 - accuracy: 0.6261 - val_loss: 0.2821 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2385 - accuracy: 0.6522 - val_loss: 0.2964 - val_accuracy: 0.3793\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2802 - accuracy: 0.6000 - val_loss: 0.2835 - val_accuracy: 0.3793\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2862 - accuracy: 0.5478 - val_loss: 0.2842 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2608 - accuracy: 0.6174 - val_loss: 0.2843 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2849 - accuracy: 0.5217 - val_loss: 0.2826 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2527 - accuracy: 0.6348 - val_loss: 0.2814 - val_accuracy: 0.3793\n",
      "0.6145833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101000010100011011011101110100100001011101\n",
      "24\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3120)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3120)\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_166 (LSTM)              (None, 100, 20)           251280    \n",
      "_________________________________________________________________\n",
      "lstm_167 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 254,682\n",
      "Trainable params: 254,642\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 0.2776 - accuracy: 0.5652 - val_loss: 0.3899 - val_accuracy: 0.3448\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2968 - accuracy: 0.5391 - val_loss: 0.3226 - val_accuracy: 0.5172\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2746 - accuracy: 0.4348 - val_loss: 0.3641 - val_accuracy: 0.4828\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2833 - accuracy: 0.4000 - val_loss: 0.3301 - val_accuracy: 0.7931\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2801 - accuracy: 0.5826 - val_loss: 0.3173 - val_accuracy: 0.5517\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2718 - accuracy: 0.4870 - val_loss: 0.2914 - val_accuracy: 0.5172\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2737 - accuracy: 0.5304 - val_loss: 0.2731 - val_accuracy: 0.5517\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2671 - accuracy: 0.5652 - val_loss: 0.3101 - val_accuracy: 0.5172\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2720 - accuracy: 0.5913 - val_loss: 0.2903 - val_accuracy: 0.5862\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2653 - accuracy: 0.5565 - val_loss: 0.2856 - val_accuracy: 0.4483\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2630 - accuracy: 0.5304 - val_loss: 0.2764 - val_accuracy: 0.4828\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2547 - accuracy: 0.5826 - val_loss: 0.2846 - val_accuracy: 0.2069\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2576 - accuracy: 0.5652 - val_loss: 0.2793 - val_accuracy: 0.3448\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2515 - accuracy: 0.6174 - val_loss: 0.2811 - val_accuracy: 0.4483\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2620 - accuracy: 0.4609 - val_loss: 0.3273 - val_accuracy: 0.3448\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2575 - accuracy: 0.5391 - val_loss: 0.2796 - val_accuracy: 0.5862\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2617 - accuracy: 0.5826 - val_loss: 0.3231 - val_accuracy: 0.5517\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3295 - accuracy: 0.5391 - val_loss: 0.3566 - val_accuracy: 0.6207\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2967 - accuracy: 0.5478 - val_loss: 0.3763 - val_accuracy: 0.3793\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2777 - accuracy: 0.6609 - val_loss: 0.2921 - val_accuracy: 0.4483\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2639 - accuracy: 0.6783 - val_loss: 0.3018 - val_accuracy: 0.5517\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2727 - accuracy: 0.5739 - val_loss: 0.2847 - val_accuracy: 0.7586\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2307 - accuracy: 0.8000 - val_loss: 0.2267 - val_accuracy: 0.5517\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2314 - accuracy: 0.6870 - val_loss: 0.2319 - val_accuracy: 0.6897\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2546 - accuracy: 0.7130 - val_loss: 0.3120 - val_accuracy: 0.6552\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2566 - accuracy: 0.7391 - val_loss: 0.3076 - val_accuracy: 0.5862\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2821 - accuracy: 0.6696 - val_loss: 0.2966 - val_accuracy: 0.6897\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2714 - accuracy: 0.7391 - val_loss: 0.2844 - val_accuracy: 0.6552\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2695 - accuracy: 0.6696 - val_loss: 0.2653 - val_accuracy: 0.6552\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2541 - accuracy: 0.6609 - val_loss: 0.2893 - val_accuracy: 0.5517\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2713 - accuracy: 0.6435 - val_loss: 0.2873 - val_accuracy: 0.6207\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2623 - accuracy: 0.7043 - val_loss: 0.2950 - val_accuracy: 0.5862\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2555 - accuracy: 0.6609 - val_loss: 0.2432 - val_accuracy: 0.7931\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2689 - accuracy: 0.6435 - val_loss: 0.2023 - val_accuracy: 0.8276\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2526 - accuracy: 0.6870 - val_loss: 0.1860 - val_accuracy: 0.8276\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2210 - accuracy: 0.7217 - val_loss: 0.2062 - val_accuracy: 0.7931\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2199 - accuracy: 0.7739 - val_loss: 0.2036 - val_accuracy: 0.7931\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2214 - accuracy: 0.7043 - val_loss: 0.3047 - val_accuracy: 0.5172\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2455 - accuracy: 0.6348 - val_loss: 0.2930 - val_accuracy: 0.5517\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2658 - accuracy: 0.6783 - val_loss: 0.2676 - val_accuracy: 0.6207\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2368 - accuracy: 0.7304 - val_loss: 0.2718 - val_accuracy: 0.6207\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2590 - accuracy: 0.6783 - val_loss: 0.3182 - val_accuracy: 0.5517\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2729 - accuracy: 0.6783 - val_loss: 0.3067 - val_accuracy: 0.5862\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2695 - accuracy: 0.5913 - val_loss: 0.3123 - val_accuracy: 0.5517\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2797 - accuracy: 0.6522 - val_loss: 0.2924 - val_accuracy: 0.5862\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2757 - accuracy: 0.5826 - val_loss: 0.3539 - val_accuracy: 0.5172\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2873 - accuracy: 0.6174 - val_loss: 0.3216 - val_accuracy: 0.5172\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2697 - accuracy: 0.6435 - val_loss: 0.3196 - val_accuracy: 0.5517\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.3018 - accuracy: 0.6000 - val_loss: 0.3117 - val_accuracy: 0.5517\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2788 - accuracy: 0.6087 - val_loss: 0.3045 - val_accuracy: 0.5517\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2695 - accuracy: 0.6522 - val_loss: 0.3104 - val_accuracy: 0.5517\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2374 - accuracy: 0.7652 - val_loss: 0.2593 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2497 - accuracy: 0.6435 - val_loss: 0.2688 - val_accuracy: 0.6552\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2447 - accuracy: 0.6957 - val_loss: 0.2690 - val_accuracy: 0.6552\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2032 - accuracy: 0.7826 - val_loss: 0.2687 - val_accuracy: 0.6552\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2247 - accuracy: 0.7043 - val_loss: 0.2749 - val_accuracy: 0.6552\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2160 - accuracy: 0.7217 - val_loss: 0.2682 - val_accuracy: 0.6552\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2152 - accuracy: 0.7304 - val_loss: 0.2817 - val_accuracy: 0.6552\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2025 - accuracy: 0.7739 - val_loss: 0.2677 - val_accuracy: 0.6552\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2238 - accuracy: 0.7217 - val_loss: 0.2739 - val_accuracy: 0.6552\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2256 - accuracy: 0.7217 - val_loss: 0.2740 - val_accuracy: 0.6552\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2155 - accuracy: 0.7304 - val_loss: 0.2721 - val_accuracy: 0.6552\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2144 - accuracy: 0.7391 - val_loss: 0.2648 - val_accuracy: 0.6552\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1898 - accuracy: 0.8087 - val_loss: 0.2782 - val_accuracy: 0.6552\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1888 - accuracy: 0.7913 - val_loss: 0.2684 - val_accuracy: 0.6207\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1827 - accuracy: 0.8000 - val_loss: 0.2645 - val_accuracy: 0.6207\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1882 - accuracy: 0.8087 - val_loss: 0.2537 - val_accuracy: 0.6552\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1988 - accuracy: 0.7826 - val_loss: 0.2607 - val_accuracy: 0.6207\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1902 - accuracy: 0.7826 - val_loss: 0.2649 - val_accuracy: 0.6207\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1843 - accuracy: 0.8000 - val_loss: 0.2793 - val_accuracy: 0.6207\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1792 - accuracy: 0.8000 - val_loss: 0.2793 - val_accuracy: 0.6552\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1786 - accuracy: 0.8000 - val_loss: 0.2772 - val_accuracy: 0.6552\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1840 - accuracy: 0.7826 - val_loss: 0.2767 - val_accuracy: 0.6552\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1700 - accuracy: 0.8174 - val_loss: 0.2660 - val_accuracy: 0.6552\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1715 - accuracy: 0.8261 - val_loss: 0.2641 - val_accuracy: 0.6552\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1800 - accuracy: 0.8000 - val_loss: 0.2712 - val_accuracy: 0.6552\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1694 - accuracy: 0.8087 - val_loss: 0.2711 - val_accuracy: 0.6552\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1598 - accuracy: 0.8261 - val_loss: 0.2595 - val_accuracy: 0.6552\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1672 - accuracy: 0.8174 - val_loss: 0.2504 - val_accuracy: 0.6897\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1614 - accuracy: 0.8348 - val_loss: 0.2619 - val_accuracy: 0.6552\n",
      "0.6875\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101111011101111000001001110100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_168 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_169 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 0.2428 - accuracy: 0.6261 - val_loss: 0.1570 - val_accuracy: 0.7586\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2098 - accuracy: 0.7217 - val_loss: 0.2544 - val_accuracy: 0.7241\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2194 - accuracy: 0.7217 - val_loss: 0.2650 - val_accuracy: 0.7241\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1940 - accuracy: 0.9043 - val_loss: 0.2519 - val_accuracy: 0.7931\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1667 - accuracy: 0.9391 - val_loss: 0.2400 - val_accuracy: 0.7931\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1678 - accuracy: 0.9478 - val_loss: 0.2062 - val_accuracy: 0.7931\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1795 - accuracy: 0.8696 - val_loss: 0.1843 - val_accuracy: 0.8276\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2355 - accuracy: 0.7217 - val_loss: 0.2054 - val_accuracy: 0.7931\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2236 - accuracy: 0.7652 - val_loss: 0.2211 - val_accuracy: 0.8276\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2130 - accuracy: 0.7652 - val_loss: 0.2452 - val_accuracy: 0.7241\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2183 - accuracy: 0.7043 - val_loss: 0.1805 - val_accuracy: 0.7586\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3106 - accuracy: 0.4783 - val_loss: 0.2015 - val_accuracy: 0.6207\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2965 - accuracy: 0.4609 - val_loss: 0.2904 - val_accuracy: 0.4483\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2783 - accuracy: 0.5217 - val_loss: 0.2845 - val_accuracy: 0.4138\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3022 - accuracy: 0.4957 - val_loss: 0.3226 - val_accuracy: 0.2759\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.3018 - accuracy: 0.5043 - val_loss: 0.3161 - val_accuracy: 0.3103\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2842 - accuracy: 0.5478 - val_loss: 0.2863 - val_accuracy: 0.5172\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.3093 - accuracy: 0.4870 - val_loss: 0.2720 - val_accuracy: 0.5172\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3307 - accuracy: 0.4348 - val_loss: 0.2867 - val_accuracy: 0.3103\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3139 - accuracy: 0.4522 - val_loss: 0.2903 - val_accuracy: 0.3793\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3008 - accuracy: 0.4783 - val_loss: 0.3464 - val_accuracy: 0.2759\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.3420 - accuracy: 0.3739 - val_loss: 0.3287 - val_accuracy: 0.2759\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.3084 - accuracy: 0.5043 - val_loss: 0.2675 - val_accuracy: 0.4138\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2710 - accuracy: 0.5652 - val_loss: 0.2620 - val_accuracy: 0.3793\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2925 - accuracy: 0.5217 - val_loss: 0.2323 - val_accuracy: 0.4828\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2746 - accuracy: 0.5217 - val_loss: 0.2148 - val_accuracy: 0.5517\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2765 - accuracy: 0.5217 - val_loss: 0.2159 - val_accuracy: 0.5517\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2640 - accuracy: 0.5652 - val_loss: 0.2200 - val_accuracy: 0.5862\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2673 - accuracy: 0.5565 - val_loss: 0.2209 - val_accuracy: 0.5517\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2560 - accuracy: 0.5565 - val_loss: 0.2232 - val_accuracy: 0.5517\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2508 - accuracy: 0.6000 - val_loss: 0.2155 - val_accuracy: 0.5172\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2436 - accuracy: 0.5652 - val_loss: 0.2158 - val_accuracy: 0.5862\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2468 - accuracy: 0.5913 - val_loss: 0.2182 - val_accuracy: 0.5862\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2330 - accuracy: 0.6174 - val_loss: 0.2186 - val_accuracy: 0.5862\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2378 - accuracy: 0.5739 - val_loss: 0.2219 - val_accuracy: 0.5517\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2341 - accuracy: 0.6087 - val_loss: 0.2243 - val_accuracy: 0.5172\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2297 - accuracy: 0.6261 - val_loss: 0.2257 - val_accuracy: 0.5172\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2265 - accuracy: 0.6000 - val_loss: 0.2275 - val_accuracy: 0.5172\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2188 - accuracy: 0.6435 - val_loss: 0.2284 - val_accuracy: 0.5172\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2154 - accuracy: 0.6696 - val_loss: 0.2296 - val_accuracy: 0.5517\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2128 - accuracy: 0.6696 - val_loss: 0.2299 - val_accuracy: 0.5517\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2126 - accuracy: 0.6522 - val_loss: 0.2306 - val_accuracy: 0.5517\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2211 - accuracy: 0.6609 - val_loss: 0.2313 - val_accuracy: 0.5862\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2046 - accuracy: 0.6696 - val_loss: 0.2320 - val_accuracy: 0.5862\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1991 - accuracy: 0.6870 - val_loss: 0.2328 - val_accuracy: 0.5517\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1982 - accuracy: 0.6783 - val_loss: 0.2332 - val_accuracy: 0.5517\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2020 - accuracy: 0.6609 - val_loss: 0.2334 - val_accuracy: 0.5517\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1991 - accuracy: 0.6783 - val_loss: 0.2335 - val_accuracy: 0.5517\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1948 - accuracy: 0.6957 - val_loss: 0.2341 - val_accuracy: 0.5517\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1985 - accuracy: 0.6957 - val_loss: 0.2345 - val_accuracy: 0.5517\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1917 - accuracy: 0.6957 - val_loss: 0.2347 - val_accuracy: 0.5517\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1940 - accuracy: 0.6957 - val_loss: 0.2349 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1874 - accuracy: 0.7130 - val_loss: 0.2352 - val_accuracy: 0.5517\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1823 - accuracy: 0.7478 - val_loss: 0.2353 - val_accuracy: 0.5517\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1846 - accuracy: 0.7130 - val_loss: 0.2354 - val_accuracy: 0.5517\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1808 - accuracy: 0.7217 - val_loss: 0.2355 - val_accuracy: 0.5517\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1823 - accuracy: 0.7043 - val_loss: 0.2356 - val_accuracy: 0.5517\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1727 - accuracy: 0.7304 - val_loss: 0.2354 - val_accuracy: 0.5517\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1770 - accuracy: 0.7217 - val_loss: 0.2352 - val_accuracy: 0.5172\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1794 - accuracy: 0.7391 - val_loss: 0.2353 - val_accuracy: 0.5172\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1681 - accuracy: 0.7391 - val_loss: 0.2352 - val_accuracy: 0.5172\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1633 - accuracy: 0.7739 - val_loss: 0.2351 - val_accuracy: 0.5172\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1686 - accuracy: 0.7478 - val_loss: 0.2350 - val_accuracy: 0.5172\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1674 - accuracy: 0.7565 - val_loss: 0.2348 - val_accuracy: 0.5172\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1677 - accuracy: 0.7478 - val_loss: 0.2349 - val_accuracy: 0.5172\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1621 - accuracy: 0.7739 - val_loss: 0.2344 - val_accuracy: 0.5172\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1646 - accuracy: 0.7652 - val_loss: 0.2341 - val_accuracy: 0.5172\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1501 - accuracy: 0.7826 - val_loss: 0.2343 - val_accuracy: 0.5172\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1570 - accuracy: 0.7652 - val_loss: 0.2341 - val_accuracy: 0.5172\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1499 - accuracy: 0.7739 - val_loss: 0.2336 - val_accuracy: 0.5172\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1442 - accuracy: 0.8000 - val_loss: 0.2333 - val_accuracy: 0.5172\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1544 - accuracy: 0.7565 - val_loss: 0.2330 - val_accuracy: 0.5172\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1466 - accuracy: 0.7913 - val_loss: 0.2326 - val_accuracy: 0.5172\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1457 - accuracy: 0.7826 - val_loss: 0.2319 - val_accuracy: 0.5172\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1482 - accuracy: 0.7913 - val_loss: 0.2311 - val_accuracy: 0.5172\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1390 - accuracy: 0.8000 - val_loss: 0.2306 - val_accuracy: 0.5172\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1441 - accuracy: 0.8087 - val_loss: 0.2300 - val_accuracy: 0.5172\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1402 - accuracy: 0.8087 - val_loss: 0.2298 - val_accuracy: 0.5172\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1349 - accuracy: 0.8174 - val_loss: 0.2292 - val_accuracy: 0.5172\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1328 - accuracy: 0.8174 - val_loss: 0.2288 - val_accuracy: 0.5172\n",
      "0.71875\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101111011101111000001001110100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_170 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_171 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 303ms/step - loss: 0.2569 - accuracy: 0.4957 - val_loss: 0.2195 - val_accuracy: 0.8276\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2227 - accuracy: 0.6783 - val_loss: 0.2011 - val_accuracy: 0.6552\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1881 - accuracy: 0.8087 - val_loss: 0.2027 - val_accuracy: 0.7931\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2069 - accuracy: 0.7913 - val_loss: 0.2175 - val_accuracy: 0.7931\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1905 - accuracy: 0.8000 - val_loss: 0.1685 - val_accuracy: 0.7931\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1872 - accuracy: 0.7913 - val_loss: 0.1864 - val_accuracy: 0.7241\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1935 - accuracy: 0.8261 - val_loss: 0.2026 - val_accuracy: 0.6897\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1870 - accuracy: 0.8609 - val_loss: 0.1933 - val_accuracy: 0.5862\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1970 - accuracy: 0.7913 - val_loss: 0.1891 - val_accuracy: 0.7241\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1753 - accuracy: 0.8783 - val_loss: 0.1955 - val_accuracy: 0.7931\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1867 - accuracy: 0.8348 - val_loss: 0.1543 - val_accuracy: 0.8966\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2313 - accuracy: 0.7913 - val_loss: 0.2028 - val_accuracy: 0.8621\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2213 - accuracy: 0.7826 - val_loss: 0.1833 - val_accuracy: 0.9310\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2612 - accuracy: 0.6957 - val_loss: 0.2601 - val_accuracy: 0.7241\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2252 - accuracy: 0.7217 - val_loss: 0.2089 - val_accuracy: 0.9655\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2297 - accuracy: 0.8000 - val_loss: 0.2161 - val_accuracy: 0.9655\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2323 - accuracy: 0.7739 - val_loss: 0.1889 - val_accuracy: 0.9310\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2148 - accuracy: 0.8087 - val_loss: 0.2669 - val_accuracy: 0.7931\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2546 - accuracy: 0.5652 - val_loss: 0.2944 - val_accuracy: 0.6207\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2565 - accuracy: 0.5391 - val_loss: 0.2997 - val_accuracy: 0.5862\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2541 - accuracy: 0.5913 - val_loss: 0.2887 - val_accuracy: 0.5517\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2579 - accuracy: 0.5739 - val_loss: 0.2625 - val_accuracy: 0.5172\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2577 - accuracy: 0.5913 - val_loss: 0.2709 - val_accuracy: 0.5517\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2436 - accuracy: 0.5478 - val_loss: 0.3105 - val_accuracy: 0.5862\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2314 - accuracy: 0.6174 - val_loss: 0.2452 - val_accuracy: 0.8276\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2182 - accuracy: 0.7391 - val_loss: 0.2371 - val_accuracy: 0.8621\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2129 - accuracy: 0.7043 - val_loss: 0.2386 - val_accuracy: 0.8276\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2084 - accuracy: 0.7478 - val_loss: 0.2403 - val_accuracy: 0.8276\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2002 - accuracy: 0.7304 - val_loss: 0.2347 - val_accuracy: 0.8276\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2076 - accuracy: 0.6870 - val_loss: 0.2371 - val_accuracy: 0.6207\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1984 - accuracy: 0.7652 - val_loss: 0.2239 - val_accuracy: 0.5862\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2021 - accuracy: 0.7043 - val_loss: 0.2281 - val_accuracy: 0.5862\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1838 - accuracy: 0.7913 - val_loss: 0.2129 - val_accuracy: 0.6207\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1812 - accuracy: 0.7913 - val_loss: 0.2074 - val_accuracy: 0.6552\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1917 - accuracy: 0.7826 - val_loss: 0.2291 - val_accuracy: 0.5862\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1727 - accuracy: 0.8696 - val_loss: 0.2169 - val_accuracy: 0.6897\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1712 - accuracy: 0.8609 - val_loss: 0.2640 - val_accuracy: 0.6552\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1631 - accuracy: 0.9217 - val_loss: 0.1758 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1536 - accuracy: 0.8696 - val_loss: 0.1832 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1413 - accuracy: 0.8957 - val_loss: 0.1841 - val_accuracy: 0.9655\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1463 - accuracy: 0.8870 - val_loss: 0.2099 - val_accuracy: 0.8966\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1421 - accuracy: 0.9304 - val_loss: 0.2065 - val_accuracy: 0.9310\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1436 - accuracy: 0.9043 - val_loss: 0.2042 - val_accuracy: 0.9310\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1288 - accuracy: 0.9217 - val_loss: 0.2062 - val_accuracy: 0.8966\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1318 - accuracy: 0.9304 - val_loss: 0.2078 - val_accuracy: 0.7241\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1428 - accuracy: 0.9130 - val_loss: 0.2133 - val_accuracy: 0.5517\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1215 - accuracy: 0.9565 - val_loss: 0.2107 - val_accuracy: 0.7241\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1272 - accuracy: 0.9217 - val_loss: 0.2047 - val_accuracy: 0.8276\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1176 - accuracy: 0.9478 - val_loss: 0.2051 - val_accuracy: 0.7931\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1107 - accuracy: 0.9826 - val_loss: 0.2033 - val_accuracy: 0.7931\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1139 - accuracy: 0.9652 - val_loss: 0.2022 - val_accuracy: 0.8276\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1106 - accuracy: 0.9565 - val_loss: 0.1990 - val_accuracy: 0.8276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1097 - accuracy: 0.9565 - val_loss: 0.1976 - val_accuracy: 0.8276\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1028 - accuracy: 0.9652 - val_loss: 0.1954 - val_accuracy: 0.8621\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1024 - accuracy: 0.9739 - val_loss: 0.1930 - val_accuracy: 0.8621\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1055 - accuracy: 0.9565 - val_loss: 0.1914 - val_accuracy: 0.8966\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0988 - accuracy: 0.9739 - val_loss: 0.1899 - val_accuracy: 0.9310\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1046 - accuracy: 0.9565 - val_loss: 0.1883 - val_accuracy: 0.8966\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0974 - accuracy: 0.9652 - val_loss: 0.1900 - val_accuracy: 0.8621\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0938 - accuracy: 0.9826 - val_loss: 0.1864 - val_accuracy: 0.9310\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0918 - accuracy: 0.9739 - val_loss: 0.1859 - val_accuracy: 0.8966\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0926 - accuracy: 0.9652 - val_loss: 0.1843 - val_accuracy: 0.9310\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0936 - accuracy: 0.9652 - val_loss: 0.1830 - val_accuracy: 0.8966\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0899 - accuracy: 0.9826 - val_loss: 0.1820 - val_accuracy: 0.9310\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0907 - accuracy: 0.9652 - val_loss: 0.1798 - val_accuracy: 0.9310\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0834 - accuracy: 0.9826 - val_loss: 0.1822 - val_accuracy: 0.8966\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0916 - accuracy: 0.9739 - val_loss: 0.1772 - val_accuracy: 0.9310\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0819 - accuracy: 0.9826 - val_loss: 0.1752 - val_accuracy: 0.9310\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0820 - accuracy: 0.9739 - val_loss: 0.1746 - val_accuracy: 0.9310\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0851 - accuracy: 0.9739 - val_loss: 0.1773 - val_accuracy: 0.8966\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0748 - accuracy: 0.9826 - val_loss: 0.1731 - val_accuracy: 0.9310\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0774 - accuracy: 0.9826 - val_loss: 0.1720 - val_accuracy: 0.9310\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0743 - accuracy: 0.9913 - val_loss: 0.1709 - val_accuracy: 0.9310\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0736 - accuracy: 0.9913 - val_loss: 0.1699 - val_accuracy: 0.9310\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0742 - accuracy: 0.9913 - val_loss: 0.1690 - val_accuracy: 0.9310\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0731 - accuracy: 0.9913 - val_loss: 0.1669 - val_accuracy: 0.9310\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0670 - accuracy: 0.9913 - val_loss: 0.1658 - val_accuracy: 0.9310\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0638 - accuracy: 0.9913 - val_loss: 0.1653 - val_accuracy: 0.9310\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0632 - accuracy: 0.9826 - val_loss: 0.1656 - val_accuracy: 0.9310\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0638 - accuracy: 0.9826 - val_loss: 0.1645 - val_accuracy: 0.9310\n",
      "0.9895833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101100111010011011011101110100100001011101\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n",
      "(144, 100, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_172 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_173 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 0.2608 - accuracy: 0.5739 - val_loss: 0.3105 - val_accuracy: 0.8621\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2550 - accuracy: 0.6087 - val_loss: 0.4255 - val_accuracy: 0.3793\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.3335 - accuracy: 0.4261 - val_loss: 0.4580 - val_accuracy: 0.2759\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3531 - accuracy: 0.3565 - val_loss: 0.3265 - val_accuracy: 0.4483\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3561 - accuracy: 0.3652 - val_loss: 0.4146 - val_accuracy: 0.2069\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3330 - accuracy: 0.3913 - val_loss: 0.3281 - val_accuracy: 0.4483\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3284 - accuracy: 0.4522 - val_loss: 0.3460 - val_accuracy: 0.2759\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3128 - accuracy: 0.4609 - val_loss: 0.2626 - val_accuracy: 0.3793\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3186 - accuracy: 0.4435 - val_loss: 0.2757 - val_accuracy: 0.6207\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3372 - accuracy: 0.4000 - val_loss: 0.3334 - val_accuracy: 0.4483\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3340 - accuracy: 0.3565 - val_loss: 0.3652 - val_accuracy: 0.3103\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3303 - accuracy: 0.3913 - val_loss: 0.3174 - val_accuracy: 0.4138\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3083 - accuracy: 0.4348 - val_loss: 0.3259 - val_accuracy: 0.4138\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3076 - accuracy: 0.4435 - val_loss: 0.3286 - val_accuracy: 0.4138\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3157 - accuracy: 0.3739 - val_loss: 0.3026 - val_accuracy: 0.5517\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2982 - accuracy: 0.4783 - val_loss: 0.2951 - val_accuracy: 0.4138\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2741 - accuracy: 0.5217 - val_loss: 0.3410 - val_accuracy: 0.2414\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2752 - accuracy: 0.4783 - val_loss: 0.3935 - val_accuracy: 0.3448\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2733 - accuracy: 0.5565 - val_loss: 0.3393 - val_accuracy: 0.4483\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2783 - accuracy: 0.5478 - val_loss: 0.3336 - val_accuracy: 0.3448\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2915 - accuracy: 0.5217 - val_loss: 0.3116 - val_accuracy: 0.4828\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2855 - accuracy: 0.5130 - val_loss: 0.3167 - val_accuracy: 0.4483\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2696 - accuracy: 0.5739 - val_loss: 0.2881 - val_accuracy: 0.4483\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2921 - accuracy: 0.4609 - val_loss: 0.3512 - val_accuracy: 0.3103\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3065 - accuracy: 0.4174 - val_loss: 0.3673 - val_accuracy: 0.3448\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3019 - accuracy: 0.4696 - val_loss: 0.3647 - val_accuracy: 0.3448\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2940 - accuracy: 0.4870 - val_loss: 0.2780 - val_accuracy: 0.4483\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2893 - accuracy: 0.4957 - val_loss: 0.2789 - val_accuracy: 0.5172\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2835 - accuracy: 0.5304 - val_loss: 0.2692 - val_accuracy: 0.5517\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2652 - accuracy: 0.5565 - val_loss: 0.2513 - val_accuracy: 0.6207\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2794 - accuracy: 0.4957 - val_loss: 0.2884 - val_accuracy: 0.3793\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2946 - accuracy: 0.4609 - val_loss: 0.2934 - val_accuracy: 0.4138\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2773 - accuracy: 0.4870 - val_loss: 0.3150 - val_accuracy: 0.3793\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2799 - accuracy: 0.5130 - val_loss: 0.3133 - val_accuracy: 0.4138\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2701 - accuracy: 0.5478 - val_loss: 0.3022 - val_accuracy: 0.4828\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2656 - accuracy: 0.5391 - val_loss: 0.3040 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2639 - accuracy: 0.5652 - val_loss: 0.2923 - val_accuracy: 0.4828\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2737 - accuracy: 0.5565 - val_loss: 0.2886 - val_accuracy: 0.4483\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2607 - accuracy: 0.6000 - val_loss: 0.2842 - val_accuracy: 0.4483\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2738 - accuracy: 0.5478 - val_loss: 0.2918 - val_accuracy: 0.4828\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2681 - accuracy: 0.5739 - val_loss: 0.2824 - val_accuracy: 0.4483\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2522 - accuracy: 0.6000 - val_loss: 0.2840 - val_accuracy: 0.4828\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2538 - accuracy: 0.6174 - val_loss: 0.2810 - val_accuracy: 0.4483\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2662 - accuracy: 0.5652 - val_loss: 0.2830 - val_accuracy: 0.4483\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2645 - accuracy: 0.5913 - val_loss: 0.2819 - val_accuracy: 0.4483\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2636 - accuracy: 0.5739 - val_loss: 0.2858 - val_accuracy: 0.4483\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2552 - accuracy: 0.5913 - val_loss: 0.2794 - val_accuracy: 0.4828\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2585 - accuracy: 0.5565 - val_loss: 0.2787 - val_accuracy: 0.4828\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2588 - accuracy: 0.5826 - val_loss: 0.2800 - val_accuracy: 0.4828\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2540 - accuracy: 0.6174 - val_loss: 0.2769 - val_accuracy: 0.4828\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2461 - accuracy: 0.6000 - val_loss: 0.2751 - val_accuracy: 0.4828\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2561 - accuracy: 0.6000 - val_loss: 0.2762 - val_accuracy: 0.4828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2569 - accuracy: 0.5826 - val_loss: 0.2771 - val_accuracy: 0.4828\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2577 - accuracy: 0.5565 - val_loss: 0.2808 - val_accuracy: 0.4483\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2529 - accuracy: 0.5826 - val_loss: 0.2773 - val_accuracy: 0.4828\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2457 - accuracy: 0.6261 - val_loss: 0.2758 - val_accuracy: 0.4828\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2510 - accuracy: 0.6000 - val_loss: 0.2753 - val_accuracy: 0.4828\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2453 - accuracy: 0.6087 - val_loss: 0.2776 - val_accuracy: 0.4828\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2507 - accuracy: 0.5652 - val_loss: 0.2812 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2381 - accuracy: 0.6261 - val_loss: 0.2807 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2457 - accuracy: 0.6174 - val_loss: 0.2817 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2336 - accuracy: 0.6174 - val_loss: 0.2799 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2402 - accuracy: 0.6087 - val_loss: 0.2791 - val_accuracy: 0.4483\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2474 - accuracy: 0.6000 - val_loss: 0.2853 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2440 - accuracy: 0.5826 - val_loss: 0.2751 - val_accuracy: 0.4483\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2427 - accuracy: 0.6261 - val_loss: 0.2769 - val_accuracy: 0.4483\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2384 - accuracy: 0.5739 - val_loss: 0.2790 - val_accuracy: 0.4483\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2356 - accuracy: 0.6435 - val_loss: 0.2780 - val_accuracy: 0.4483\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2304 - accuracy: 0.6261 - val_loss: 0.2791 - val_accuracy: 0.4483\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2225 - accuracy: 0.6783 - val_loss: 0.2818 - val_accuracy: 0.4483\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2241 - accuracy: 0.6870 - val_loss: 0.2812 - val_accuracy: 0.4483\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2235 - accuracy: 0.6783 - val_loss: 0.2804 - val_accuracy: 0.4483\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2275 - accuracy: 0.6696 - val_loss: 0.2770 - val_accuracy: 0.4483\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2249 - accuracy: 0.6609 - val_loss: 0.2795 - val_accuracy: 0.4483\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2203 - accuracy: 0.6783 - val_loss: 0.2832 - val_accuracy: 0.4483\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2239 - accuracy: 0.6696 - val_loss: 0.2862 - val_accuracy: 0.4483\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2247 - accuracy: 0.6696 - val_loss: 0.2856 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2259 - accuracy: 0.6522 - val_loss: 0.2807 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2248 - accuracy: 0.6435 - val_loss: 0.2822 - val_accuracy: 0.4483\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2187 - accuracy: 0.6783 - val_loss: 0.2820 - val_accuracy: 0.4483\n",
      "0.5729166865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101111011101111000001001110100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_174 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_175 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 0.2777 - accuracy: 0.6609 - val_loss: 0.4516 - val_accuracy: 0.5172\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2573 - accuracy: 0.6000 - val_loss: 0.3585 - val_accuracy: 0.4138\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2773 - accuracy: 0.5913 - val_loss: 0.3060 - val_accuracy: 0.5517\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2449 - accuracy: 0.7304 - val_loss: 0.3522 - val_accuracy: 0.3448\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2787 - accuracy: 0.6174 - val_loss: 0.3898 - val_accuracy: 0.4483\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2775 - accuracy: 0.6609 - val_loss: 0.3448 - val_accuracy: 0.3103\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2883 - accuracy: 0.5913 - val_loss: 0.3198 - val_accuracy: 0.4828\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.3016 - accuracy: 0.5043 - val_loss: 0.2916 - val_accuracy: 0.5517\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2622 - accuracy: 0.5652 - val_loss: 0.3050 - val_accuracy: 0.5172\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2564 - accuracy: 0.6087 - val_loss: 0.2709 - val_accuracy: 0.4828\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2693 - accuracy: 0.6348 - val_loss: 0.2681 - val_accuracy: 0.5862\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2678 - accuracy: 0.5913 - val_loss: 0.3101 - val_accuracy: 0.5862\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2940 - accuracy: 0.4870 - val_loss: 0.2990 - val_accuracy: 0.6207\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2813 - accuracy: 0.5652 - val_loss: 0.3267 - val_accuracy: 0.5862\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2771 - accuracy: 0.5913 - val_loss: 0.3293 - val_accuracy: 0.4828\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2807 - accuracy: 0.5826 - val_loss: 0.3128 - val_accuracy: 0.3793\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2789 - accuracy: 0.5652 - val_loss: 0.2950 - val_accuracy: 0.5517\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2565 - accuracy: 0.6348 - val_loss: 0.3037 - val_accuracy: 0.4483\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2657 - accuracy: 0.5913 - val_loss: 0.2914 - val_accuracy: 0.5172\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2895 - accuracy: 0.5217 - val_loss: 0.2989 - val_accuracy: 0.4138\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.3089 - accuracy: 0.4609 - val_loss: 0.2917 - val_accuracy: 0.4138\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.3227 - accuracy: 0.4522 - val_loss: 0.2493 - val_accuracy: 0.6207\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.3044 - accuracy: 0.5217 - val_loss: 0.3040 - val_accuracy: 0.4828\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.3096 - accuracy: 0.4522 - val_loss: 0.3242 - val_accuracy: 0.4483\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.3023 - accuracy: 0.4870 - val_loss: 0.3361 - val_accuracy: 0.3448\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2839 - accuracy: 0.5130 - val_loss: 0.3118 - val_accuracy: 0.3793\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2887 - accuracy: 0.5304 - val_loss: 0.3211 - val_accuracy: 0.3448\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2886 - accuracy: 0.5217 - val_loss: 0.3199 - val_accuracy: 0.3448\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2651 - accuracy: 0.5652 - val_loss: 0.3156 - val_accuracy: 0.3448\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2633 - accuracy: 0.5478 - val_loss: 0.3151 - val_accuracy: 0.3448\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2688 - accuracy: 0.5478 - val_loss: 0.3144 - val_accuracy: 0.3448\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2578 - accuracy: 0.5826 - val_loss: 0.3132 - val_accuracy: 0.3793\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2609 - accuracy: 0.5565 - val_loss: 0.3120 - val_accuracy: 0.3793\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2522 - accuracy: 0.6000 - val_loss: 0.3112 - val_accuracy: 0.3793\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2621 - accuracy: 0.5652 - val_loss: 0.3104 - val_accuracy: 0.3793\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2499 - accuracy: 0.6000 - val_loss: 0.3094 - val_accuracy: 0.3793\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2531 - accuracy: 0.5913 - val_loss: 0.3084 - val_accuracy: 0.3793\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2452 - accuracy: 0.6000 - val_loss: 0.3075 - val_accuracy: 0.3793\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2450 - accuracy: 0.6522 - val_loss: 0.3064 - val_accuracy: 0.3793\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2356 - accuracy: 0.6522 - val_loss: 0.3053 - val_accuracy: 0.3793\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2455 - accuracy: 0.6435 - val_loss: 0.3044 - val_accuracy: 0.3793\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2418 - accuracy: 0.6348 - val_loss: 0.3034 - val_accuracy: 0.3793\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2406 - accuracy: 0.6609 - val_loss: 0.3025 - val_accuracy: 0.3793\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2359 - accuracy: 0.6609 - val_loss: 0.3019 - val_accuracy: 0.3793\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2330 - accuracy: 0.6870 - val_loss: 0.3011 - val_accuracy: 0.3793\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2325 - accuracy: 0.6870 - val_loss: 0.3003 - val_accuracy: 0.3793\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2290 - accuracy: 0.7130 - val_loss: 0.2995 - val_accuracy: 0.3793\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2356 - accuracy: 0.6522 - val_loss: 0.2987 - val_accuracy: 0.3793\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2234 - accuracy: 0.7043 - val_loss: 0.2979 - val_accuracy: 0.3793\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2287 - accuracy: 0.6522 - val_loss: 0.2971 - val_accuracy: 0.3793\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2236 - accuracy: 0.6870 - val_loss: 0.2963 - val_accuracy: 0.3793\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2180 - accuracy: 0.7130 - val_loss: 0.2954 - val_accuracy: 0.3793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2251 - accuracy: 0.6957 - val_loss: 0.2945 - val_accuracy: 0.3793\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2268 - accuracy: 0.6957 - val_loss: 0.2935 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2159 - accuracy: 0.7043 - val_loss: 0.2925 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2247 - accuracy: 0.7130 - val_loss: 0.2916 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2186 - accuracy: 0.6783 - val_loss: 0.2908 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2150 - accuracy: 0.7043 - val_loss: 0.2899 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2132 - accuracy: 0.7043 - val_loss: 0.2889 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2055 - accuracy: 0.7217 - val_loss: 0.2880 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2127 - accuracy: 0.7043 - val_loss: 0.2872 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2067 - accuracy: 0.7217 - val_loss: 0.2863 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2056 - accuracy: 0.7217 - val_loss: 0.2854 - val_accuracy: 0.4483\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2053 - accuracy: 0.7391 - val_loss: 0.2844 - val_accuracy: 0.4483\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2117 - accuracy: 0.7130 - val_loss: 0.2833 - val_accuracy: 0.4483\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2156 - accuracy: 0.6957 - val_loss: 0.2821 - val_accuracy: 0.4483\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2001 - accuracy: 0.7304 - val_loss: 0.2810 - val_accuracy: 0.4483\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2026 - accuracy: 0.7130 - val_loss: 0.2799 - val_accuracy: 0.4483\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2012 - accuracy: 0.7391 - val_loss: 0.2787 - val_accuracy: 0.4483\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2055 - accuracy: 0.7130 - val_loss: 0.2777 - val_accuracy: 0.4483\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1961 - accuracy: 0.7652 - val_loss: 0.2768 - val_accuracy: 0.4483\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2007 - accuracy: 0.7130 - val_loss: 0.2758 - val_accuracy: 0.4828\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1986 - accuracy: 0.7304 - val_loss: 0.2749 - val_accuracy: 0.4828\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1982 - accuracy: 0.7304 - val_loss: 0.2740 - val_accuracy: 0.4828\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1945 - accuracy: 0.7478 - val_loss: 0.2731 - val_accuracy: 0.4828\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2060 - accuracy: 0.7217 - val_loss: 0.2723 - val_accuracy: 0.4828\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1959 - accuracy: 0.7565 - val_loss: 0.2715 - val_accuracy: 0.4828\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1999 - accuracy: 0.7217 - val_loss: 0.2705 - val_accuracy: 0.5172\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1933 - accuracy: 0.7217 - val_loss: 0.2694 - val_accuracy: 0.5172\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1963 - accuracy: 0.7130 - val_loss: 0.2682 - val_accuracy: 0.5172\n",
      "0.6458333134651184\n",
      "fitness pass\n",
      "[(0.6875, 957462487713885), (0.625, 923441258232480), (0.59375, 957148127537610), (0.59375, 923447748520394), (0.6666666865348816, 923447748438474), (0.6145833134651184, 923441258232480), (0.6875, 957146807617629), (0.71875, 923447748520394), (0.9895833134651184, 923447748520394), (0.5729166865348816, 957462487713885), (0.6458333134651184, 923447748520394)]\n",
      "[923447748520394, 923447748520394]\n",
      "[923447748520394, 923447748520394, 957462487713885, 957146807617629, 957148127537610, 957462487713885]\n",
      "selection pass\n",
      "target_count:\n",
      "5\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "0\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "1\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "2\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "3\n",
      "957146807617629\n",
      "11011001101000010100011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "4\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "5\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "6\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "7\n",
      "923447748675677\n",
      "11010001111101111011101111000001110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "8\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "9\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "10\n",
      "923447748520413\n",
      "11010001111101111011101111000001001110100111011101\n",
      "crossover pass\n",
      "變異後的種群\n",
      "染色體：\n",
      "0\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "1\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "2\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "3\n",
      "957146807617629\n",
      "11011001101000010100011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "4\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "5\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "6\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "7\n",
      "923447748675677\n",
      "11010001111101111011101111000001110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "8\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "9\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "10\n",
      "923447748520413\n",
      "11010001111101111011101111000001001110100111011101\n",
      "mutation pass\n",
      "迭代次數： 8\n",
      "8\n",
      "所選擇的染色體：\n",
      "11010001111101111011101111000001001110100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_176 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_177 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 0.1839 - accuracy: 0.8174 - val_loss: 0.2018 - val_accuracy: 0.8276\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1517 - accuracy: 0.8870 - val_loss: 0.2492 - val_accuracy: 0.8276\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1800 - accuracy: 0.8696 - val_loss: 0.2240 - val_accuracy: 0.7931\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1302 - accuracy: 0.9652 - val_loss: 0.1492 - val_accuracy: 0.9655\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1184 - accuracy: 0.9565 - val_loss: 0.1743 - val_accuracy: 0.9655\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0879 - accuracy: 0.9652 - val_loss: 0.1550 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1202 - accuracy: 0.9478 - val_loss: 0.1300 - val_accuracy: 0.9655\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0797 - accuracy: 0.9652 - val_loss: 0.1120 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0751 - accuracy: 0.9826 - val_loss: 0.1338 - val_accuracy: 0.9310\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0695 - accuracy: 0.9913 - val_loss: 0.1301 - val_accuracy: 0.9310\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0612 - accuracy: 0.9913 - val_loss: 0.0992 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.0797 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 8.5348e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "1.0\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101111011101111000001001110100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_178 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_179 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 193ms/step - loss: 0.2685 - accuracy: 0.5913 - val_loss: 0.4884 - val_accuracy: 0.3103\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2635 - accuracy: 0.6696 - val_loss: 0.4042 - val_accuracy: 0.4483\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2886 - accuracy: 0.6000 - val_loss: 0.2944 - val_accuracy: 0.5862\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2792 - accuracy: 0.6174 - val_loss: 0.3358 - val_accuracy: 0.7241\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2833 - accuracy: 0.5565 - val_loss: 0.3882 - val_accuracy: 0.6897\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2647 - accuracy: 0.5739 - val_loss: 0.3517 - val_accuracy: 0.7586\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2908 - accuracy: 0.5478 - val_loss: 0.3475 - val_accuracy: 0.5517\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2825 - accuracy: 0.5913 - val_loss: 0.3762 - val_accuracy: 0.3793\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3024 - accuracy: 0.5652 - val_loss: 0.3150 - val_accuracy: 0.5517\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3106 - accuracy: 0.5826 - val_loss: 0.3189 - val_accuracy: 0.6207\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2780 - accuracy: 0.6609 - val_loss: 0.3057 - val_accuracy: 0.5517\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2904 - accuracy: 0.6087 - val_loss: 0.3211 - val_accuracy: 0.6552\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2863 - accuracy: 0.6261 - val_loss: 0.2975 - val_accuracy: 0.6552\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2619 - accuracy: 0.6870 - val_loss: 0.3013 - val_accuracy: 0.5517\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2730 - accuracy: 0.6087 - val_loss: 0.3277 - val_accuracy: 0.5517\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2667 - accuracy: 0.6696 - val_loss: 0.3401 - val_accuracy: 0.6552\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2695 - accuracy: 0.6870 - val_loss: 0.3600 - val_accuracy: 0.6207\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2534 - accuracy: 0.6870 - val_loss: 0.3666 - val_accuracy: 0.5862\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2694 - accuracy: 0.5826 - val_loss: 0.3443 - val_accuracy: 0.5172\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2795 - accuracy: 0.5913 - val_loss: 0.3033 - val_accuracy: 0.6207\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2977 - accuracy: 0.5652 - val_loss: 0.3251 - val_accuracy: 0.5517\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2897 - accuracy: 0.6174 - val_loss: 0.3279 - val_accuracy: 0.5862\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2782 - accuracy: 0.5739 - val_loss: 0.2994 - val_accuracy: 0.4483\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2558 - accuracy: 0.6174 - val_loss: 0.2725 - val_accuracy: 0.5862\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2804 - accuracy: 0.5652 - val_loss: 0.2831 - val_accuracy: 0.5172\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2526 - accuracy: 0.6609 - val_loss: 0.2562 - val_accuracy: 0.5862\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2417 - accuracy: 0.7130 - val_loss: 0.2883 - val_accuracy: 0.6897\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2850 - accuracy: 0.5565 - val_loss: 0.3021 - val_accuracy: 0.4138\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.3154 - accuracy: 0.4000 - val_loss: 0.3501 - val_accuracy: 0.4138\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2944 - accuracy: 0.4870 - val_loss: 0.3109 - val_accuracy: 0.5517\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2952 - accuracy: 0.4609 - val_loss: 0.2926 - val_accuracy: 0.4138\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2858 - accuracy: 0.4957 - val_loss: 0.2596 - val_accuracy: 0.4138\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2756 - accuracy: 0.5217 - val_loss: 0.2583 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2677 - accuracy: 0.5652 - val_loss: 0.2626 - val_accuracy: 0.4138\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.3005 - accuracy: 0.4870 - val_loss: 0.2572 - val_accuracy: 0.4138\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2745 - accuracy: 0.6000 - val_loss: 0.2582 - val_accuracy: 0.4138\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2730 - accuracy: 0.5826 - val_loss: 0.2592 - val_accuracy: 0.4138\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2843 - accuracy: 0.5217 - val_loss: 0.2637 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2893 - accuracy: 0.5391 - val_loss: 0.2640 - val_accuracy: 0.4138\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2796 - accuracy: 0.5391 - val_loss: 0.2643 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2734 - accuracy: 0.5913 - val_loss: 0.2649 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2776 - accuracy: 0.5304 - val_loss: 0.2655 - val_accuracy: 0.4138\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2697 - accuracy: 0.6000 - val_loss: 0.2659 - val_accuracy: 0.4138\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2752 - accuracy: 0.6261 - val_loss: 0.2662 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2764 - accuracy: 0.6174 - val_loss: 0.2666 - val_accuracy: 0.4138\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2731 - accuracy: 0.6261 - val_loss: 0.2670 - val_accuracy: 0.4138\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2662 - accuracy: 0.6522 - val_loss: 0.2674 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2596 - accuracy: 0.6783 - val_loss: 0.2679 - val_accuracy: 0.4138\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2639 - accuracy: 0.6522 - val_loss: 0.2683 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2533 - accuracy: 0.6870 - val_loss: 0.2687 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2553 - accuracy: 0.6870 - val_loss: 0.2691 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2541 - accuracy: 0.6609 - val_loss: 0.2695 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2588 - accuracy: 0.6261 - val_loss: 0.2699 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2455 - accuracy: 0.6783 - val_loss: 0.2702 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2464 - accuracy: 0.6783 - val_loss: 0.2706 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2422 - accuracy: 0.6783 - val_loss: 0.2708 - val_accuracy: 0.4138\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2330 - accuracy: 0.7130 - val_loss: 0.2709 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2424 - accuracy: 0.6783 - val_loss: 0.2713 - val_accuracy: 0.4138\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2386 - accuracy: 0.6957 - val_loss: 0.2716 - val_accuracy: 0.4138\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2396 - accuracy: 0.6870 - val_loss: 0.2718 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2339 - accuracy: 0.7304 - val_loss: 0.2720 - val_accuracy: 0.4138\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2334 - accuracy: 0.6783 - val_loss: 0.2721 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2355 - accuracy: 0.7217 - val_loss: 0.2721 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2245 - accuracy: 0.7130 - val_loss: 0.2722 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2247 - accuracy: 0.6783 - val_loss: 0.2725 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2198 - accuracy: 0.7217 - val_loss: 0.2731 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2158 - accuracy: 0.7304 - val_loss: 0.2741 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2196 - accuracy: 0.7217 - val_loss: 0.2748 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2138 - accuracy: 0.7391 - val_loss: 0.2751 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2245 - accuracy: 0.6783 - val_loss: 0.2751 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2107 - accuracy: 0.7304 - val_loss: 0.2748 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2041 - accuracy: 0.7652 - val_loss: 0.2743 - val_accuracy: 0.4138\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2105 - accuracy: 0.7565 - val_loss: 0.2734 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2092 - accuracy: 0.7304 - val_loss: 0.2729 - val_accuracy: 0.4138\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2037 - accuracy: 0.7391 - val_loss: 0.2727 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2046 - accuracy: 0.7565 - val_loss: 0.2729 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1999 - accuracy: 0.7565 - val_loss: 0.2726 - val_accuracy: 0.4138\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2039 - accuracy: 0.7478 - val_loss: 0.2718 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2002 - accuracy: 0.7391 - val_loss: 0.2711 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2102 - accuracy: 0.7217 - val_loss: 0.2710 - val_accuracy: 0.4138\n",
      "0.625\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101100111010011011011101110100100001011101\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_180 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_181 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 193ms/step - loss: 0.2570 - accuracy: 0.6087 - val_loss: 0.1903 - val_accuracy: 0.7241\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1958 - accuracy: 0.7739 - val_loss: 0.2419 - val_accuracy: 0.7931\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1651 - accuracy: 0.8783 - val_loss: 0.2860 - val_accuracy: 0.7931\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2104 - accuracy: 0.7130 - val_loss: 0.2802 - val_accuracy: 0.5862\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2513 - accuracy: 0.5565 - val_loss: 0.3001 - val_accuracy: 0.7241\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2579 - accuracy: 0.6174 - val_loss: 0.2884 - val_accuracy: 0.6897\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2831 - accuracy: 0.6000 - val_loss: 0.3057 - val_accuracy: 0.5172\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2864 - accuracy: 0.5130 - val_loss: 0.3195 - val_accuracy: 0.4483\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2849 - accuracy: 0.5826 - val_loss: 0.3253 - val_accuracy: 0.4483\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2971 - accuracy: 0.5565 - val_loss: 0.3287 - val_accuracy: 0.4483\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3074 - accuracy: 0.4783 - val_loss: 0.3300 - val_accuracy: 0.4483\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2966 - accuracy: 0.5478 - val_loss: 0.3376 - val_accuracy: 0.4483\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2706 - accuracy: 0.5739 - val_loss: 0.3229 - val_accuracy: 0.4138\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2835 - accuracy: 0.5565 - val_loss: 0.3267 - val_accuracy: 0.3793\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2726 - accuracy: 0.6000 - val_loss: 0.3201 - val_accuracy: 0.3793\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2705 - accuracy: 0.6609 - val_loss: 0.3224 - val_accuracy: 0.3793\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2634 - accuracy: 0.6522 - val_loss: 0.3182 - val_accuracy: 0.3793\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2626 - accuracy: 0.6522 - val_loss: 0.3063 - val_accuracy: 0.3793\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2620 - accuracy: 0.6348 - val_loss: 0.3147 - val_accuracy: 0.3793\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2612 - accuracy: 0.6174 - val_loss: 0.3088 - val_accuracy: 0.4138\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2529 - accuracy: 0.6261 - val_loss: 0.3051 - val_accuracy: 0.4138\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2522 - accuracy: 0.6435 - val_loss: 0.3022 - val_accuracy: 0.4483\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2478 - accuracy: 0.6435 - val_loss: 0.3003 - val_accuracy: 0.4483\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2369 - accuracy: 0.6696 - val_loss: 0.2976 - val_accuracy: 0.4483\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2301 - accuracy: 0.6783 - val_loss: 0.2947 - val_accuracy: 0.4828\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2345 - accuracy: 0.6522 - val_loss: 0.2913 - val_accuracy: 0.4828\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2257 - accuracy: 0.6609 - val_loss: 0.2882 - val_accuracy: 0.5172\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2209 - accuracy: 0.7217 - val_loss: 0.2842 - val_accuracy: 0.5172\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2196 - accuracy: 0.6957 - val_loss: 0.2805 - val_accuracy: 0.5517\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2142 - accuracy: 0.7217 - val_loss: 0.2774 - val_accuracy: 0.5862\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2156 - accuracy: 0.7043 - val_loss: 0.2749 - val_accuracy: 0.6207\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2081 - accuracy: 0.7478 - val_loss: 0.2729 - val_accuracy: 0.5862\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2085 - accuracy: 0.7304 - val_loss: 0.2708 - val_accuracy: 0.5862\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2080 - accuracy: 0.7391 - val_loss: 0.2690 - val_accuracy: 0.6207\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2031 - accuracy: 0.7652 - val_loss: 0.2670 - val_accuracy: 0.6552\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1954 - accuracy: 0.7652 - val_loss: 0.2649 - val_accuracy: 0.6552\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1918 - accuracy: 0.7739 - val_loss: 0.2629 - val_accuracy: 0.6552\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1908 - accuracy: 0.8000 - val_loss: 0.2609 - val_accuracy: 0.6552\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1887 - accuracy: 0.7913 - val_loss: 0.2591 - val_accuracy: 0.6552\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1887 - accuracy: 0.7913 - val_loss: 0.2516 - val_accuracy: 0.6552\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1776 - accuracy: 0.7826 - val_loss: 0.2570 - val_accuracy: 0.6552\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1764 - accuracy: 0.8174 - val_loss: 0.2554 - val_accuracy: 0.6552\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1738 - accuracy: 0.8087 - val_loss: 0.2535 - val_accuracy: 0.6552\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1764 - accuracy: 0.8435 - val_loss: 0.2524 - val_accuracy: 0.7241\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1737 - accuracy: 0.8261 - val_loss: 0.2516 - val_accuracy: 0.7241\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1837 - accuracy: 0.8000 - val_loss: 0.2496 - val_accuracy: 0.7241\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1735 - accuracy: 0.8348 - val_loss: 0.2481 - val_accuracy: 0.7586\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1694 - accuracy: 0.8261 - val_loss: 0.2456 - val_accuracy: 0.7586\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1629 - accuracy: 0.8000 - val_loss: 0.2444 - val_accuracy: 0.7586\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1653 - accuracy: 0.8348 - val_loss: 0.2433 - val_accuracy: 0.7586\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1572 - accuracy: 0.8261 - val_loss: 0.2353 - val_accuracy: 0.7586\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1595 - accuracy: 0.8261 - val_loss: 0.2337 - val_accuracy: 0.7586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1601 - accuracy: 0.8087 - val_loss: 0.2328 - val_accuracy: 0.7586\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1537 - accuracy: 0.8087 - val_loss: 0.2309 - val_accuracy: 0.7586\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1584 - accuracy: 0.8261 - val_loss: 0.2373 - val_accuracy: 0.7586\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1619 - accuracy: 0.8174 - val_loss: 0.2375 - val_accuracy: 0.7241\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1605 - accuracy: 0.8174 - val_loss: 0.2379 - val_accuracy: 0.7241\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1550 - accuracy: 0.8522 - val_loss: 0.2400 - val_accuracy: 0.7241\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1572 - accuracy: 0.8348 - val_loss: 0.2406 - val_accuracy: 0.7586\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1633 - accuracy: 0.8348 - val_loss: 0.2397 - val_accuracy: 0.7586\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1550 - accuracy: 0.8435 - val_loss: 0.2383 - val_accuracy: 0.7586\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1535 - accuracy: 0.8348 - val_loss: 0.2363 - val_accuracy: 0.7586\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1524 - accuracy: 0.8348 - val_loss: 0.2337 - val_accuracy: 0.7586\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1508 - accuracy: 0.8261 - val_loss: 0.2333 - val_accuracy: 0.7586\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1547 - accuracy: 0.8522 - val_loss: 0.2321 - val_accuracy: 0.7586\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1604 - accuracy: 0.8087 - val_loss: 0.2316 - val_accuracy: 0.7586\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1637 - accuracy: 0.8087 - val_loss: 0.2308 - val_accuracy: 0.7586\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1620 - accuracy: 0.8348 - val_loss: 0.2292 - val_accuracy: 0.7586\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1450 - accuracy: 0.8435 - val_loss: 0.2269 - val_accuracy: 0.7586\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1549 - accuracy: 0.8261 - val_loss: 0.2257 - val_accuracy: 0.7586\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1479 - accuracy: 0.8348 - val_loss: 0.2247 - val_accuracy: 0.7586\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1451 - accuracy: 0.8435 - val_loss: 0.2232 - val_accuracy: 0.7586\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1413 - accuracy: 0.8435 - val_loss: 0.2216 - val_accuracy: 0.7586\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1430 - accuracy: 0.8609 - val_loss: 0.2198 - val_accuracy: 0.7586\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1418 - accuracy: 0.8435 - val_loss: 0.2202 - val_accuracy: 0.7586\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1413 - accuracy: 0.8522 - val_loss: 0.2182 - val_accuracy: 0.7586\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1422 - accuracy: 0.8348 - val_loss: 0.2169 - val_accuracy: 0.7586\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1368 - accuracy: 0.8609 - val_loss: 0.2158 - val_accuracy: 0.7586\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1392 - accuracy: 0.8435 - val_loss: 0.2160 - val_accuracy: 0.7586\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1360 - accuracy: 0.8522 - val_loss: 0.2187 - val_accuracy: 0.7586\n",
      "0.6875\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101000010100011011011101110100100001011101\n",
      "24\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3120)\n",
      "(144, 100, 3120)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_182 (LSTM)              (None, 100, 20)           251280    \n",
      "_________________________________________________________________\n",
      "lstm_183 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 254,682\n",
      "Trainable params: 254,642\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 0.2302 - accuracy: 0.6957 - val_loss: 0.2129 - val_accuracy: 0.7931\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2085 - accuracy: 0.7304 - val_loss: 0.1767 - val_accuracy: 0.7931\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1746 - accuracy: 0.8609 - val_loss: 0.2174 - val_accuracy: 0.6897\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1804 - accuracy: 0.8957 - val_loss: 0.3387 - val_accuracy: 0.6552\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2554 - accuracy: 0.7043 - val_loss: 0.2786 - val_accuracy: 0.6897\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2966 - accuracy: 0.6261 - val_loss: 0.2549 - val_accuracy: 0.7241\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.3207 - accuracy: 0.5304 - val_loss: 0.2327 - val_accuracy: 0.7586\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.3213 - accuracy: 0.5565 - val_loss: 0.2635 - val_accuracy: 0.5862\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.3243 - accuracy: 0.4435 - val_loss: 0.2660 - val_accuracy: 0.4483\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2859 - accuracy: 0.6435 - val_loss: 0.2288 - val_accuracy: 0.4828\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3192 - accuracy: 0.4696 - val_loss: 0.2999 - val_accuracy: 0.4138\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3241 - accuracy: 0.4261 - val_loss: 0.2737 - val_accuracy: 0.3793\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2820 - accuracy: 0.5826 - val_loss: 0.2653 - val_accuracy: 0.5172\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2266 - accuracy: 0.8000 - val_loss: 0.2779 - val_accuracy: 0.5862\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2277 - accuracy: 0.6957 - val_loss: 0.2490 - val_accuracy: 0.5172\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2380 - accuracy: 0.6957 - val_loss: 0.2435 - val_accuracy: 0.6552\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2268 - accuracy: 0.6957 - val_loss: 0.2786 - val_accuracy: 0.5862\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2287 - accuracy: 0.7391 - val_loss: 0.2843 - val_accuracy: 0.5862\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2209 - accuracy: 0.6870 - val_loss: 0.2209 - val_accuracy: 0.7586\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1998 - accuracy: 0.7478 - val_loss: 0.2034 - val_accuracy: 0.8621\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1910 - accuracy: 0.7913 - val_loss: 0.1863 - val_accuracy: 0.7586\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1805 - accuracy: 0.7652 - val_loss: 0.1771 - val_accuracy: 0.7586\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1797 - accuracy: 0.8000 - val_loss: 0.1679 - val_accuracy: 0.7586\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1656 - accuracy: 0.8348 - val_loss: 0.1572 - val_accuracy: 0.8276\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1708 - accuracy: 0.8174 - val_loss: 0.1556 - val_accuracy: 0.8276\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1792 - accuracy: 0.8087 - val_loss: 0.1513 - val_accuracy: 0.8276\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1857 - accuracy: 0.7652 - val_loss: 0.1466 - val_accuracy: 0.8276\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1634 - accuracy: 0.8348 - val_loss: 0.1427 - val_accuracy: 0.8276\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1570 - accuracy: 0.8609 - val_loss: 0.1394 - val_accuracy: 0.8276\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1657 - accuracy: 0.8261 - val_loss: 0.1357 - val_accuracy: 0.8276\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1671 - accuracy: 0.8261 - val_loss: 0.1329 - val_accuracy: 0.8276\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1653 - accuracy: 0.8609 - val_loss: 0.1324 - val_accuracy: 0.8276\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1532 - accuracy: 0.8783 - val_loss: 0.1302 - val_accuracy: 0.8276\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1612 - accuracy: 0.8870 - val_loss: 0.1278 - val_accuracy: 0.8276\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1470 - accuracy: 0.8870 - val_loss: 0.1232 - val_accuracy: 0.8621\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1351 - accuracy: 0.8870 - val_loss: 0.1199 - val_accuracy: 0.8621\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1426 - accuracy: 0.8696 - val_loss: 0.1194 - val_accuracy: 0.8621\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1329 - accuracy: 0.8870 - val_loss: 0.1212 - val_accuracy: 0.8621\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1257 - accuracy: 0.8957 - val_loss: 0.1210 - val_accuracy: 0.8621\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1291 - accuracy: 0.9217 - val_loss: 0.1196 - val_accuracy: 0.8621\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1295 - accuracy: 0.8870 - val_loss: 0.1192 - val_accuracy: 0.8621\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1232 - accuracy: 0.9217 - val_loss: 0.1191 - val_accuracy: 0.8621\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1176 - accuracy: 0.9391 - val_loss: 0.1220 - val_accuracy: 0.8621\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1367 - accuracy: 0.9130 - val_loss: 0.1219 - val_accuracy: 0.8621\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1287 - accuracy: 0.9130 - val_loss: 0.1203 - val_accuracy: 0.8621\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1249 - accuracy: 0.9043 - val_loss: 0.1155 - val_accuracy: 0.8621\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1060 - accuracy: 0.9304 - val_loss: 0.1100 - val_accuracy: 0.8621\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1224 - accuracy: 0.9043 - val_loss: 0.1082 - val_accuracy: 0.8621\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1103 - accuracy: 0.9217 - val_loss: 0.1069 - val_accuracy: 0.8621\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1194 - accuracy: 0.9043 - val_loss: 0.1051 - val_accuracy: 0.8621\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1104 - accuracy: 0.9391 - val_loss: 0.1039 - val_accuracy: 0.8621\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1054 - accuracy: 0.9217 - val_loss: 0.1035 - val_accuracy: 0.8621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0984 - accuracy: 0.9304 - val_loss: 0.1021 - val_accuracy: 0.8621\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0999 - accuracy: 0.9391 - val_loss: 0.1019 - val_accuracy: 0.8621\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0974 - accuracy: 0.9391 - val_loss: 0.1010 - val_accuracy: 0.8621\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0934 - accuracy: 0.9391 - val_loss: 0.1002 - val_accuracy: 0.8621\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0947 - accuracy: 0.9130 - val_loss: 0.0984 - val_accuracy: 0.8621\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0945 - accuracy: 0.9391 - val_loss: 0.0986 - val_accuracy: 0.8621\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0846 - accuracy: 0.9391 - val_loss: 0.0975 - val_accuracy: 0.8621\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0996 - accuracy: 0.9391 - val_loss: 0.0942 - val_accuracy: 0.8621\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1005 - accuracy: 0.9391 - val_loss: 0.0923 - val_accuracy: 0.8621\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0988 - accuracy: 0.9304 - val_loss: 0.0957 - val_accuracy: 0.8621\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0920 - accuracy: 0.9565 - val_loss: 0.0956 - val_accuracy: 0.8966\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0889 - accuracy: 0.9217 - val_loss: 0.0965 - val_accuracy: 0.8621\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0896 - accuracy: 0.9391 - val_loss: 0.0981 - val_accuracy: 0.8621\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0979 - accuracy: 0.9217 - val_loss: 0.1020 - val_accuracy: 0.8621\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0931 - accuracy: 0.9565 - val_loss: 0.1008 - val_accuracy: 0.8621\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0935 - accuracy: 0.9391 - val_loss: 0.1005 - val_accuracy: 0.8621\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0917 - accuracy: 0.9478 - val_loss: 0.1033 - val_accuracy: 0.8621\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0963 - accuracy: 0.9130 - val_loss: 0.1036 - val_accuracy: 0.8621\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0877 - accuracy: 0.9304 - val_loss: 0.1022 - val_accuracy: 0.8621\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0802 - accuracy: 0.9304 - val_loss: 0.1036 - val_accuracy: 0.8621\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0780 - accuracy: 0.9565 - val_loss: 0.1048 - val_accuracy: 0.8276\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0854 - accuracy: 0.9304 - val_loss: 0.1054 - val_accuracy: 0.8276\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0781 - accuracy: 0.9478 - val_loss: 0.1030 - val_accuracy: 0.8276\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0718 - accuracy: 0.9565 - val_loss: 0.1052 - val_accuracy: 0.8276\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0718 - accuracy: 0.9391 - val_loss: 0.1033 - val_accuracy: 0.8276\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0701 - accuracy: 0.9565 - val_loss: 0.0979 - val_accuracy: 0.8276\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0697 - accuracy: 0.9565 - val_loss: 0.0996 - val_accuracy: 0.8276\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0645 - accuracy: 0.9652 - val_loss: 0.1006 - val_accuracy: 0.8276\n",
      "0.8854166865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101000010101101010001000111010100111001010\n",
      "26\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2880)\n",
      "(144, 100, 2880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_184 (LSTM)              (None, 100, 20)           232080    \n",
      "_________________________________________________________________\n",
      "lstm_185 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 235,482\n",
      "Trainable params: 235,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 0.3007 - accuracy: 0.4348 - val_loss: 0.2963 - val_accuracy: 0.4828\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2285 - accuracy: 0.6609 - val_loss: 0.3551 - val_accuracy: 0.4828\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2651 - accuracy: 0.5304 - val_loss: 0.2852 - val_accuracy: 0.6897\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2457 - accuracy: 0.5304 - val_loss: 0.2194 - val_accuracy: 0.7241\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2017 - accuracy: 0.6783 - val_loss: 0.2512 - val_accuracy: 0.6897\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2024 - accuracy: 0.6696 - val_loss: 0.2368 - val_accuracy: 0.7241\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2240 - accuracy: 0.6696 - val_loss: 0.2147 - val_accuracy: 0.6207\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2092 - accuracy: 0.7130 - val_loss: 0.2145 - val_accuracy: 0.6207\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2026 - accuracy: 0.7304 - val_loss: 0.2090 - val_accuracy: 0.8276\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2004 - accuracy: 0.6957 - val_loss: 0.2133 - val_accuracy: 0.5862\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1923 - accuracy: 0.7130 - val_loss: 0.2920 - val_accuracy: 0.6552\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1930 - accuracy: 0.7130 - val_loss: 0.3213 - val_accuracy: 0.5862\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1926 - accuracy: 0.7304 - val_loss: 0.2913 - val_accuracy: 0.6207\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1855 - accuracy: 0.7652 - val_loss: 0.2692 - val_accuracy: 0.6207\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1923 - accuracy: 0.8087 - val_loss: 0.2364 - val_accuracy: 0.6897\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1827 - accuracy: 0.8087 - val_loss: 0.2546 - val_accuracy: 0.6552\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1829 - accuracy: 0.8174 - val_loss: 0.2702 - val_accuracy: 0.6897\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1919 - accuracy: 0.7652 - val_loss: 0.2898 - val_accuracy: 0.6552\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1719 - accuracy: 0.8087 - val_loss: 0.2678 - val_accuracy: 0.6552\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1729 - accuracy: 0.8174 - val_loss: 0.2592 - val_accuracy: 0.6552\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1734 - accuracy: 0.8087 - val_loss: 0.2557 - val_accuracy: 0.6552\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1763 - accuracy: 0.7826 - val_loss: 0.2523 - val_accuracy: 0.6207\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1804 - accuracy: 0.8174 - val_loss: 0.2498 - val_accuracy: 0.6207\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1630 - accuracy: 0.8174 - val_loss: 0.2485 - val_accuracy: 0.6207\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1677 - accuracy: 0.7913 - val_loss: 0.2447 - val_accuracy: 0.6552\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1715 - accuracy: 0.8087 - val_loss: 0.2181 - val_accuracy: 0.6552\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1690 - accuracy: 0.8522 - val_loss: 0.2161 - val_accuracy: 0.6552\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1640 - accuracy: 0.8261 - val_loss: 0.2140 - val_accuracy: 0.6552\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1662 - accuracy: 0.8348 - val_loss: 0.2121 - val_accuracy: 0.6552\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1709 - accuracy: 0.8261 - val_loss: 0.2110 - val_accuracy: 0.6552\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1727 - accuracy: 0.8348 - val_loss: 0.2094 - val_accuracy: 0.6552\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1649 - accuracy: 0.8435 - val_loss: 0.2084 - val_accuracy: 0.6897\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1725 - accuracy: 0.8348 - val_loss: 0.2074 - val_accuracy: 0.6897\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1730 - accuracy: 0.8261 - val_loss: 0.2068 - val_accuracy: 0.6897\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1699 - accuracy: 0.8261 - val_loss: 0.2057 - val_accuracy: 0.6897\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1668 - accuracy: 0.8174 - val_loss: 0.2047 - val_accuracy: 0.6897\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1620 - accuracy: 0.8348 - val_loss: 0.2045 - val_accuracy: 0.6897\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1649 - accuracy: 0.8174 - val_loss: 0.2040 - val_accuracy: 0.7241\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1606 - accuracy: 0.8348 - val_loss: 0.2036 - val_accuracy: 0.7241\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1601 - accuracy: 0.8348 - val_loss: 0.2030 - val_accuracy: 0.7241\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1604 - accuracy: 0.8174 - val_loss: 0.2029 - val_accuracy: 0.7241\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1608 - accuracy: 0.8261 - val_loss: 0.2025 - val_accuracy: 0.7241\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1593 - accuracy: 0.8348 - val_loss: 0.2025 - val_accuracy: 0.7241\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1602 - accuracy: 0.8348 - val_loss: 0.2020 - val_accuracy: 0.7241\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1638 - accuracy: 0.8261 - val_loss: 0.2016 - val_accuracy: 0.7241\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1546 - accuracy: 0.8435 - val_loss: 0.2012 - val_accuracy: 0.7241\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1513 - accuracy: 0.8522 - val_loss: 0.2008 - val_accuracy: 0.7241\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1576 - accuracy: 0.8261 - val_loss: 0.2009 - val_accuracy: 0.7241\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1606 - accuracy: 0.8261 - val_loss: 0.1998 - val_accuracy: 0.7241\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1781 - accuracy: 0.8174 - val_loss: 0.1996 - val_accuracy: 0.7241\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1675 - accuracy: 0.8174 - val_loss: 0.1992 - val_accuracy: 0.7241\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1663 - accuracy: 0.8609 - val_loss: 0.1989 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1696 - accuracy: 0.8348 - val_loss: 0.1974 - val_accuracy: 0.7241\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1690 - accuracy: 0.8522 - val_loss: 0.1953 - val_accuracy: 0.7241\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1514 - accuracy: 0.8870 - val_loss: 0.1955 - val_accuracy: 0.7241\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1500 - accuracy: 0.8696 - val_loss: 0.1952 - val_accuracy: 0.7241\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1496 - accuracy: 0.8522 - val_loss: 0.1949 - val_accuracy: 0.7241\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1564 - accuracy: 0.8609 - val_loss: 0.1947 - val_accuracy: 0.7241\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1586 - accuracy: 0.8609 - val_loss: 0.1945 - val_accuracy: 0.7241\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1594 - accuracy: 0.8609 - val_loss: 0.1943 - val_accuracy: 0.7241\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1537 - accuracy: 0.8609 - val_loss: 0.1942 - val_accuracy: 0.7241\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1501 - accuracy: 0.8783 - val_loss: 0.1943 - val_accuracy: 0.7241\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1523 - accuracy: 0.8522 - val_loss: 0.1984 - val_accuracy: 0.7241\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1485 - accuracy: 0.8609 - val_loss: 0.1983 - val_accuracy: 0.7241\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1450 - accuracy: 0.8609 - val_loss: 0.1983 - val_accuracy: 0.7241\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1480 - accuracy: 0.8783 - val_loss: 0.1982 - val_accuracy: 0.7241\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1505 - accuracy: 0.8696 - val_loss: 0.1981 - val_accuracy: 0.7241\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1420 - accuracy: 0.8870 - val_loss: 0.1981 - val_accuracy: 0.7241\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1498 - accuracy: 0.8609 - val_loss: 0.1980 - val_accuracy: 0.7241\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1431 - accuracy: 0.8696 - val_loss: 0.1980 - val_accuracy: 0.7241\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1420 - accuracy: 0.8783 - val_loss: 0.1980 - val_accuracy: 0.7241\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1404 - accuracy: 0.8609 - val_loss: 0.1979 - val_accuracy: 0.7241\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1470 - accuracy: 0.8522 - val_loss: 0.1979 - val_accuracy: 0.7586\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1356 - accuracy: 0.8957 - val_loss: 0.1978 - val_accuracy: 0.7586\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.1478 - accuracy: 0.8609 - val_loss: 0.1977 - val_accuracy: 0.7586\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1421 - accuracy: 0.8609 - val_loss: 0.1977 - val_accuracy: 0.7586\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1378 - accuracy: 0.9043 - val_loss: 0.1976 - val_accuracy: 0.7586\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1391 - accuracy: 0.8696 - val_loss: 0.1975 - val_accuracy: 0.7586\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1415 - accuracy: 0.8696 - val_loss: 0.1975 - val_accuracy: 0.7586\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1416 - accuracy: 0.8609 - val_loss: 0.1974 - val_accuracy: 0.7586\n",
      "0.7604166865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101100111010011011011101110100100001011101\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_186 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_187 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 191ms/step - loss: 0.2587 - accuracy: 0.6000 - val_loss: 0.3219 - val_accuracy: 0.6552\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2396 - accuracy: 0.7652 - val_loss: 0.3543 - val_accuracy: 0.5172\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2394 - accuracy: 0.6870 - val_loss: 0.3717 - val_accuracy: 0.5172\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2702 - accuracy: 0.6261 - val_loss: 0.3257 - val_accuracy: 0.6207\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2442 - accuracy: 0.6609 - val_loss: 0.3603 - val_accuracy: 0.5862\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2332 - accuracy: 0.7217 - val_loss: 0.2957 - val_accuracy: 0.6552\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2532 - accuracy: 0.6870 - val_loss: 0.3454 - val_accuracy: 0.5172\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2685 - accuracy: 0.6696 - val_loss: 0.3000 - val_accuracy: 0.6897\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2789 - accuracy: 0.6348 - val_loss: 0.3817 - val_accuracy: 0.5172\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2851 - accuracy: 0.6348 - val_loss: 0.3776 - val_accuracy: 0.4138\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2994 - accuracy: 0.5478 - val_loss: 0.3323 - val_accuracy: 0.4483\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2865 - accuracy: 0.6522 - val_loss: 0.3477 - val_accuracy: 0.4483\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2808 - accuracy: 0.6261 - val_loss: 0.3476 - val_accuracy: 0.4828\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2861 - accuracy: 0.6696 - val_loss: 0.3118 - val_accuracy: 0.5172\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2772 - accuracy: 0.6696 - val_loss: 0.3767 - val_accuracy: 0.4483\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.3001 - accuracy: 0.6000 - val_loss: 0.3652 - val_accuracy: 0.4828\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2967 - accuracy: 0.5913 - val_loss: 0.3288 - val_accuracy: 0.4138\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3030 - accuracy: 0.6000 - val_loss: 0.3283 - val_accuracy: 0.5172\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3024 - accuracy: 0.5739 - val_loss: 0.3255 - val_accuracy: 0.5172\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.3022 - accuracy: 0.6174 - val_loss: 0.3262 - val_accuracy: 0.5517\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2959 - accuracy: 0.6261 - val_loss: 0.3343 - val_accuracy: 0.5172\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2925 - accuracy: 0.5913 - val_loss: 0.3624 - val_accuracy: 0.4828\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2963 - accuracy: 0.6000 - val_loss: 0.3269 - val_accuracy: 0.5172\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2909 - accuracy: 0.6174 - val_loss: 0.3364 - val_accuracy: 0.4828\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2845 - accuracy: 0.6348 - val_loss: 0.3069 - val_accuracy: 0.5517\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2850 - accuracy: 0.6609 - val_loss: 0.3378 - val_accuracy: 0.4828\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2532 - accuracy: 0.7043 - val_loss: 0.3330 - val_accuracy: 0.5517\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2457 - accuracy: 0.7130 - val_loss: 0.3112 - val_accuracy: 0.5517\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2661 - accuracy: 0.6609 - val_loss: 0.3246 - val_accuracy: 0.5172\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2598 - accuracy: 0.6174 - val_loss: 0.3030 - val_accuracy: 0.6207\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2555 - accuracy: 0.6174 - val_loss: 0.3025 - val_accuracy: 0.5172\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2543 - accuracy: 0.6696 - val_loss: 0.3253 - val_accuracy: 0.4138\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2606 - accuracy: 0.6087 - val_loss: 0.3779 - val_accuracy: 0.4483\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2715 - accuracy: 0.6000 - val_loss: 0.3278 - val_accuracy: 0.5862\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2628 - accuracy: 0.6261 - val_loss: 0.3263 - val_accuracy: 0.5172\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2757 - accuracy: 0.5913 - val_loss: 0.3567 - val_accuracy: 0.3793\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2385 - accuracy: 0.6522 - val_loss: 0.3049 - val_accuracy: 0.4828\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2552 - accuracy: 0.6522 - val_loss: 0.3877 - val_accuracy: 0.3448\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2571 - accuracy: 0.6522 - val_loss: 0.3196 - val_accuracy: 0.5517\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2393 - accuracy: 0.6696 - val_loss: 0.3614 - val_accuracy: 0.3448\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2618 - accuracy: 0.6000 - val_loss: 0.3363 - val_accuracy: 0.5172\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2891 - accuracy: 0.6261 - val_loss: 0.3649 - val_accuracy: 0.5172\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2828 - accuracy: 0.6000 - val_loss: 0.3478 - val_accuracy: 0.4483\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2774 - accuracy: 0.5652 - val_loss: 0.3720 - val_accuracy: 0.6207\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.3003 - accuracy: 0.5565 - val_loss: 0.4292 - val_accuracy: 0.3793\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2957 - accuracy: 0.5913 - val_loss: 0.3653 - val_accuracy: 0.5517\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2930 - accuracy: 0.5565 - val_loss: 0.3406 - val_accuracy: 0.5862\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2811 - accuracy: 0.5652 - val_loss: 0.3337 - val_accuracy: 0.6552\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2978 - accuracy: 0.5565 - val_loss: 0.3061 - val_accuracy: 0.5172\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2938 - accuracy: 0.5391 - val_loss: 0.3005 - val_accuracy: 0.5172\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2667 - accuracy: 0.6261 - val_loss: 0.2523 - val_accuracy: 0.6552\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2460 - accuracy: 0.6609 - val_loss: 0.2458 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2319 - accuracy: 0.6609 - val_loss: 0.2929 - val_accuracy: 0.5517\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2562 - accuracy: 0.6348 - val_loss: 0.2892 - val_accuracy: 0.5517\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2534 - accuracy: 0.6348 - val_loss: 0.2623 - val_accuracy: 0.5862\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2562 - accuracy: 0.6348 - val_loss: 0.2590 - val_accuracy: 0.5862\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2638 - accuracy: 0.6870 - val_loss: 0.2889 - val_accuracy: 0.5517\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2450 - accuracy: 0.6261 - val_loss: 0.2462 - val_accuracy: 0.6897\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2664 - accuracy: 0.6609 - val_loss: 0.3023 - val_accuracy: 0.5862\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2836 - accuracy: 0.5478 - val_loss: 0.3304 - val_accuracy: 0.5172\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2814 - accuracy: 0.6000 - val_loss: 0.2777 - val_accuracy: 0.5517\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2672 - accuracy: 0.6261 - val_loss: 0.3072 - val_accuracy: 0.5862\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2771 - accuracy: 0.6261 - val_loss: 0.3344 - val_accuracy: 0.5172\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2554 - accuracy: 0.6261 - val_loss: 0.2156 - val_accuracy: 0.6897\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2675 - accuracy: 0.6261 - val_loss: 0.2819 - val_accuracy: 0.5862\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2762 - accuracy: 0.6261 - val_loss: 0.2723 - val_accuracy: 0.6552\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2833 - accuracy: 0.6174 - val_loss: 0.3104 - val_accuracy: 0.4828\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2494 - accuracy: 0.6609 - val_loss: 0.2940 - val_accuracy: 0.5517\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2708 - accuracy: 0.6261 - val_loss: 0.3214 - val_accuracy: 0.5517\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2852 - accuracy: 0.5739 - val_loss: 0.2915 - val_accuracy: 0.5862\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2622 - accuracy: 0.6435 - val_loss: 0.3115 - val_accuracy: 0.5517\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2665 - accuracy: 0.6522 - val_loss: 0.3098 - val_accuracy: 0.5172\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2637 - accuracy: 0.6435 - val_loss: 0.3467 - val_accuracy: 0.4483\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2492 - accuracy: 0.6957 - val_loss: 0.3292 - val_accuracy: 0.5172\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2382 - accuracy: 0.6870 - val_loss: 0.3086 - val_accuracy: 0.5172\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2702 - accuracy: 0.6174 - val_loss: 0.3025 - val_accuracy: 0.5862\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2585 - accuracy: 0.6174 - val_loss: 0.2800 - val_accuracy: 0.6207\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2475 - accuracy: 0.6261 - val_loss: 0.2984 - val_accuracy: 0.5517\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2447 - accuracy: 0.6435 - val_loss: 0.2767 - val_accuracy: 0.5517\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2656 - accuracy: 0.6174 - val_loss: 0.2930 - val_accuracy: 0.5172\n",
      "0.7708333134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101111011101111000001001110100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n",
      "(144, 100, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_188 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_189 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 0.3149 - accuracy: 0.5043 - val_loss: 0.3086 - val_accuracy: 0.3793\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2799 - accuracy: 0.6174 - val_loss: 0.3283 - val_accuracy: 0.4138\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2730 - accuracy: 0.7391 - val_loss: 0.2699 - val_accuracy: 0.5862\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2710 - accuracy: 0.6348 - val_loss: 0.3121 - val_accuracy: 0.4828\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2847 - accuracy: 0.5826 - val_loss: 0.2623 - val_accuracy: 0.4483\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2222 - accuracy: 0.6870 - val_loss: 0.2617 - val_accuracy: 0.4828\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2574 - accuracy: 0.5826 - val_loss: 0.2670 - val_accuracy: 0.4138\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2895 - accuracy: 0.4783 - val_loss: 0.2576 - val_accuracy: 0.4483\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2766 - accuracy: 0.5565 - val_loss: 0.3353 - val_accuracy: 0.6207\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.3132 - accuracy: 0.4783 - val_loss: 0.3311 - val_accuracy: 0.5172\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.3139 - accuracy: 0.4783 - val_loss: 0.3370 - val_accuracy: 0.5172\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2887 - accuracy: 0.5565 - val_loss: 0.3651 - val_accuracy: 0.6207\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2918 - accuracy: 0.5739 - val_loss: 0.3512 - val_accuracy: 0.6207\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2991 - accuracy: 0.4870 - val_loss: 0.2935 - val_accuracy: 0.7586\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2603 - accuracy: 0.5043 - val_loss: 0.2937 - val_accuracy: 0.7931\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2645 - accuracy: 0.4783 - val_loss: 0.3100 - val_accuracy: 0.7586\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2372 - accuracy: 0.5478 - val_loss: 0.3345 - val_accuracy: 0.7586\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2619 - accuracy: 0.4783 - val_loss: 0.3289 - val_accuracy: 0.8621\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2475 - accuracy: 0.5304 - val_loss: 0.2958 - val_accuracy: 0.8276\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2726 - accuracy: 0.4870 - val_loss: 0.2304 - val_accuracy: 0.8621\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2416 - accuracy: 0.6261 - val_loss: 0.2497 - val_accuracy: 0.8276\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2335 - accuracy: 0.6783 - val_loss: 0.2670 - val_accuracy: 0.7241\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2246 - accuracy: 0.7043 - val_loss: 0.2503 - val_accuracy: 0.6207\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2252 - accuracy: 0.7739 - val_loss: 0.2364 - val_accuracy: 0.6897\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2026 - accuracy: 0.7826 - val_loss: 0.2754 - val_accuracy: 0.5517\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1898 - accuracy: 0.8174 - val_loss: 0.3471 - val_accuracy: 0.5517\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1849 - accuracy: 0.8783 - val_loss: 0.2607 - val_accuracy: 0.6897\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1803 - accuracy: 0.8261 - val_loss: 0.2566 - val_accuracy: 0.7241\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1744 - accuracy: 0.8435 - val_loss: 0.2531 - val_accuracy: 0.7241\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1638 - accuracy: 0.8957 - val_loss: 0.2508 - val_accuracy: 0.7241\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1470 - accuracy: 0.9304 - val_loss: 0.2472 - val_accuracy: 0.7931\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1425 - accuracy: 0.9043 - val_loss: 0.2437 - val_accuracy: 0.7931\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1349 - accuracy: 0.9130 - val_loss: 0.2453 - val_accuracy: 0.7931\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1439 - accuracy: 0.8957 - val_loss: 0.2393 - val_accuracy: 0.7931\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1367 - accuracy: 0.8957 - val_loss: 0.2326 - val_accuracy: 0.7931\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1348 - accuracy: 0.8870 - val_loss: 0.2256 - val_accuracy: 0.7931\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1320 - accuracy: 0.8696 - val_loss: 0.2206 - val_accuracy: 0.7931\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1222 - accuracy: 0.9130 - val_loss: 0.2146 - val_accuracy: 0.7931\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1106 - accuracy: 0.9043 - val_loss: 0.2090 - val_accuracy: 0.7931\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1100 - accuracy: 0.9130 - val_loss: 0.2025 - val_accuracy: 0.8621\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1013 - accuracy: 0.9217 - val_loss: 0.1975 - val_accuracy: 0.8621\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0948 - accuracy: 0.9478 - val_loss: 0.1917 - val_accuracy: 0.8621\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0991 - accuracy: 0.9304 - val_loss: 0.1850 - val_accuracy: 0.7586\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0966 - accuracy: 0.9304 - val_loss: 0.2041 - val_accuracy: 0.7586\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1156 - accuracy: 0.9304 - val_loss: 0.1513 - val_accuracy: 0.9310\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0935 - accuracy: 0.9043 - val_loss: 0.1406 - val_accuracy: 0.9310\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1052 - accuracy: 0.9217 - val_loss: 0.1090 - val_accuracy: 0.9655\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0931 - accuracy: 0.9391 - val_loss: 0.0984 - val_accuracy: 0.9655\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0839 - accuracy: 0.9130 - val_loss: 0.0928 - val_accuracy: 0.9655\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1143 - accuracy: 0.8783 - val_loss: 0.0824 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1281 - accuracy: 0.8696 - val_loss: 0.0915 - val_accuracy: 0.9655\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1409 - accuracy: 0.8348 - val_loss: 0.0874 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1456 - accuracy: 0.9217 - val_loss: 0.1038 - val_accuracy: 0.9655\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1615 - accuracy: 0.8087 - val_loss: 0.1651 - val_accuracy: 0.8621\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1764 - accuracy: 0.8000 - val_loss: 0.1702 - val_accuracy: 0.8276\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1722 - accuracy: 0.8087 - val_loss: 0.2235 - val_accuracy: 0.7241\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2092 - accuracy: 0.7391 - val_loss: 0.2719 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2473 - accuracy: 0.6348 - val_loss: 0.3410 - val_accuracy: 0.3103\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.3354 - accuracy: 0.5391 - val_loss: 0.3024 - val_accuracy: 0.3103\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.3192 - accuracy: 0.4435 - val_loss: 0.3054 - val_accuracy: 0.4138\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2786 - accuracy: 0.5478 - val_loss: 0.3454 - val_accuracy: 0.3103\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.3723 - accuracy: 0.3826 - val_loss: 0.3774 - val_accuracy: 0.2759\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2707 - accuracy: 0.5565 - val_loss: 0.4085 - val_accuracy: 0.3103\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.3237 - accuracy: 0.5217 - val_loss: 0.3934 - val_accuracy: 0.3103\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2511 - accuracy: 0.6696 - val_loss: 0.3608 - val_accuracy: 0.3103\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2404 - accuracy: 0.7043 - val_loss: 0.3368 - val_accuracy: 0.3103\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2245 - accuracy: 0.7652 - val_loss: 0.3039 - val_accuracy: 0.3793\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2398 - accuracy: 0.6957 - val_loss: 0.2967 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2296 - accuracy: 0.7043 - val_loss: 0.2909 - val_accuracy: 0.5172\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2336 - accuracy: 0.6957 - val_loss: 0.2902 - val_accuracy: 0.5517\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2311 - accuracy: 0.6957 - val_loss: 0.2968 - val_accuracy: 0.5517\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2322 - accuracy: 0.7391 - val_loss: 0.2996 - val_accuracy: 0.5517\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2413 - accuracy: 0.7217 - val_loss: 0.3082 - val_accuracy: 0.5172\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2443 - accuracy: 0.6957 - val_loss: 0.3073 - val_accuracy: 0.5172\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2376 - accuracy: 0.7043 - val_loss: 0.3058 - val_accuracy: 0.5172\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2288 - accuracy: 0.7304 - val_loss: 0.3052 - val_accuracy: 0.4828\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2330 - accuracy: 0.7043 - val_loss: 0.3197 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.3072 - accuracy: 0.5217 - val_loss: 0.3083 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2678 - accuracy: 0.5652 - val_loss: 0.2900 - val_accuracy: 0.5172\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2055 - accuracy: 0.7391 - val_loss: 0.2892 - val_accuracy: 0.5172\n",
      "0.7395833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101111011101111000001110100100001011101\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_190 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_191 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 0.2616 - accuracy: 0.5478 - val_loss: 0.3034 - val_accuracy: 0.6552\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2099 - accuracy: 0.7217 - val_loss: 0.2105 - val_accuracy: 0.7586\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2219 - accuracy: 0.7565 - val_loss: 0.2088 - val_accuracy: 0.7241\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2241 - accuracy: 0.8174 - val_loss: 0.1347 - val_accuracy: 0.9310\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1811 - accuracy: 0.8348 - val_loss: 0.1437 - val_accuracy: 0.8966\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1948 - accuracy: 0.8000 - val_loss: 0.1581 - val_accuracy: 0.9655\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2247 - accuracy: 0.7739 - val_loss: 0.2084 - val_accuracy: 0.7586\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2074 - accuracy: 0.7652 - val_loss: 0.1995 - val_accuracy: 0.7241\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2043 - accuracy: 0.7913 - val_loss: 0.1962 - val_accuracy: 0.7241\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1996 - accuracy: 0.7565 - val_loss: 0.2017 - val_accuracy: 0.7586\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1905 - accuracy: 0.7826 - val_loss: 0.2072 - val_accuracy: 0.6897\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2124 - accuracy: 0.7304 - val_loss: 0.2080 - val_accuracy: 0.6897\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1975 - accuracy: 0.7217 - val_loss: 0.2061 - val_accuracy: 0.6897\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1920 - accuracy: 0.7391 - val_loss: 0.2379 - val_accuracy: 0.5862\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1953 - accuracy: 0.7826 - val_loss: 0.2745 - val_accuracy: 0.5172\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2275 - accuracy: 0.6000 - val_loss: 0.2882 - val_accuracy: 0.5172\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2334 - accuracy: 0.6087 - val_loss: 0.2835 - val_accuracy: 0.5172\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2197 - accuracy: 0.5826 - val_loss: 0.2732 - val_accuracy: 0.5862\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2517 - accuracy: 0.6174 - val_loss: 0.2785 - val_accuracy: 0.5862\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2578 - accuracy: 0.6696 - val_loss: 0.2740 - val_accuracy: 0.5862\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2868 - accuracy: 0.6174 - val_loss: 0.2661 - val_accuracy: 0.6207\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2941 - accuracy: 0.6261 - val_loss: 0.2933 - val_accuracy: 0.5517\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2681 - accuracy: 0.6609 - val_loss: 0.2705 - val_accuracy: 0.5862\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2582 - accuracy: 0.6957 - val_loss: 0.2772 - val_accuracy: 0.5862\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2794 - accuracy: 0.6609 - val_loss: 0.2761 - val_accuracy: 0.5517\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2493 - accuracy: 0.6957 - val_loss: 0.2648 - val_accuracy: 0.5862\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2379 - accuracy: 0.7130 - val_loss: 0.2600 - val_accuracy: 0.5517\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2324 - accuracy: 0.6783 - val_loss: 0.2651 - val_accuracy: 0.5172\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2125 - accuracy: 0.7217 - val_loss: 0.2547 - val_accuracy: 0.5172\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2065 - accuracy: 0.7043 - val_loss: 0.2494 - val_accuracy: 0.5517\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2304 - accuracy: 0.6783 - val_loss: 0.2812 - val_accuracy: 0.5517\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1974 - accuracy: 0.7304 - val_loss: 0.2579 - val_accuracy: 0.5517\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2099 - accuracy: 0.6435 - val_loss: 0.2485 - val_accuracy: 0.5862\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1974 - accuracy: 0.6870 - val_loss: 0.2449 - val_accuracy: 0.5517\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1936 - accuracy: 0.6609 - val_loss: 0.2524 - val_accuracy: 0.5517\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1987 - accuracy: 0.6696 - val_loss: 0.2477 - val_accuracy: 0.5517\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1892 - accuracy: 0.6783 - val_loss: 0.2644 - val_accuracy: 0.5172\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1917 - accuracy: 0.7217 - val_loss: 0.2609 - val_accuracy: 0.5172\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1801 - accuracy: 0.7391 - val_loss: 0.2429 - val_accuracy: 0.5517\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1852 - accuracy: 0.7739 - val_loss: 0.2422 - val_accuracy: 0.5517\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1826 - accuracy: 0.7565 - val_loss: 0.2414 - val_accuracy: 0.5517\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1813 - accuracy: 0.6609 - val_loss: 0.2405 - val_accuracy: 0.5517\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1841 - accuracy: 0.7478 - val_loss: 0.2398 - val_accuracy: 0.5517\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1804 - accuracy: 0.7391 - val_loss: 0.2393 - val_accuracy: 0.5517\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1779 - accuracy: 0.7217 - val_loss: 0.2424 - val_accuracy: 0.5517\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1724 - accuracy: 0.7391 - val_loss: 0.2414 - val_accuracy: 0.5517\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1666 - accuracy: 0.8261 - val_loss: 0.2408 - val_accuracy: 0.5862\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1705 - accuracy: 0.7565 - val_loss: 0.2401 - val_accuracy: 0.6207\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1670 - accuracy: 0.8087 - val_loss: 0.2393 - val_accuracy: 0.6207\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1744 - accuracy: 0.7652 - val_loss: 0.2387 - val_accuracy: 0.6207\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1678 - accuracy: 0.7565 - val_loss: 0.2380 - val_accuracy: 0.6207\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1617 - accuracy: 0.7652 - val_loss: 0.2374 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1614 - accuracy: 0.8087 - val_loss: 0.2367 - val_accuracy: 0.6207\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1526 - accuracy: 0.7826 - val_loss: 0.2359 - val_accuracy: 0.6207\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1532 - accuracy: 0.8348 - val_loss: 0.2351 - val_accuracy: 0.6207\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1548 - accuracy: 0.7826 - val_loss: 0.2338 - val_accuracy: 0.6207\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1498 - accuracy: 0.8261 - val_loss: 0.2329 - val_accuracy: 0.6207\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1475 - accuracy: 0.8000 - val_loss: 0.2317 - val_accuracy: 0.6207\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1539 - accuracy: 0.8000 - val_loss: 0.2304 - val_accuracy: 0.6207\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1863 - accuracy: 0.7391 - val_loss: 0.2297 - val_accuracy: 0.6207\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1893 - accuracy: 0.8000 - val_loss: 0.2289 - val_accuracy: 0.6207\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1867 - accuracy: 0.7478 - val_loss: 0.2281 - val_accuracy: 0.6207\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1953 - accuracy: 0.7217 - val_loss: 0.2272 - val_accuracy: 0.6207\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1839 - accuracy: 0.7652 - val_loss: 0.2261 - val_accuracy: 0.6207\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1642 - accuracy: 0.8087 - val_loss: 0.2259 - val_accuracy: 0.6207\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1436 - accuracy: 0.8522 - val_loss: 0.2252 - val_accuracy: 0.6207\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1527 - accuracy: 0.8000 - val_loss: 0.2246 - val_accuracy: 0.6207\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1446 - accuracy: 0.8000 - val_loss: 0.2234 - val_accuracy: 0.6207\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1395 - accuracy: 0.8435 - val_loss: 0.2223 - val_accuracy: 0.6207\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1390 - accuracy: 0.8348 - val_loss: 0.2210 - val_accuracy: 0.6207\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1361 - accuracy: 0.8522 - val_loss: 0.2202 - val_accuracy: 0.6207\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1384 - accuracy: 0.8609 - val_loss: 0.2191 - val_accuracy: 0.6207\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1345 - accuracy: 0.8696 - val_loss: 0.2185 - val_accuracy: 0.6207\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1310 - accuracy: 0.8348 - val_loss: 0.2179 - val_accuracy: 0.6207\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1319 - accuracy: 0.8783 - val_loss: 0.2172 - val_accuracy: 0.6207\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1346 - accuracy: 0.8522 - val_loss: 0.2161 - val_accuracy: 0.6207\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1340 - accuracy: 0.8261 - val_loss: 0.2148 - val_accuracy: 0.6207\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1304 - accuracy: 0.8609 - val_loss: 0.2134 - val_accuracy: 0.6207\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.1315 - accuracy: 0.8348 - val_loss: 0.2124 - val_accuracy: 0.6207\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1261 - accuracy: 0.8870 - val_loss: 0.2109 - val_accuracy: 0.6207\n",
      "0.7395833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101100111010011011011101110100100001011101\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_192 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_193 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 0.3378 - accuracy: 0.4348 - val_loss: 0.4830 - val_accuracy: 0.4138\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.4570 - accuracy: 0.2087 - val_loss: 0.4833 - val_accuracy: 0.4138\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.4155 - accuracy: 0.3043 - val_loss: 0.5825 - val_accuracy: 0.3103\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.4802 - accuracy: 0.2000 - val_loss: 0.5886 - val_accuracy: 0.3103\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.4631 - accuracy: 0.2174 - val_loss: 0.6082 - val_accuracy: 0.2414\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.4500 - accuracy: 0.2174 - val_loss: 0.5705 - val_accuracy: 0.2759\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.4232 - accuracy: 0.2348 - val_loss: 0.5544 - val_accuracy: 0.2759\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.4161 - accuracy: 0.2348 - val_loss: 0.5351 - val_accuracy: 0.3103\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.4124 - accuracy: 0.2522 - val_loss: 0.5197 - val_accuracy: 0.3103\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.4018 - accuracy: 0.2435 - val_loss: 0.5167 - val_accuracy: 0.3103\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.3973 - accuracy: 0.2435 - val_loss: 0.4994 - val_accuracy: 0.3103\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.3920 - accuracy: 0.3043 - val_loss: 0.4771 - val_accuracy: 0.3103\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.3984 - accuracy: 0.2348 - val_loss: 0.4541 - val_accuracy: 0.3103\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.3942 - accuracy: 0.2783 - val_loss: 0.4475 - val_accuracy: 0.3103\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.3666 - accuracy: 0.3478 - val_loss: 0.4344 - val_accuracy: 0.3103\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.3751 - accuracy: 0.3043 - val_loss: 0.4239 - val_accuracy: 0.3103\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.3805 - accuracy: 0.3304 - val_loss: 0.4248 - val_accuracy: 0.2759\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.3744 - accuracy: 0.3391 - val_loss: 0.4161 - val_accuracy: 0.3103\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.3597 - accuracy: 0.3826 - val_loss: 0.4087 - val_accuracy: 0.3103\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.3416 - accuracy: 0.3913 - val_loss: 0.4143 - val_accuracy: 0.3103\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.3309 - accuracy: 0.4087 - val_loss: 0.4222 - val_accuracy: 0.3103\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.3263 - accuracy: 0.4522 - val_loss: 0.4064 - val_accuracy: 0.3448\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.3451 - accuracy: 0.4174 - val_loss: 0.4395 - val_accuracy: 0.3793\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.3431 - accuracy: 0.3913 - val_loss: 0.5455 - val_accuracy: 0.4138\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.3408 - accuracy: 0.3043 - val_loss: 0.5275 - val_accuracy: 0.4138\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.3386 - accuracy: 0.3043 - val_loss: 0.5101 - val_accuracy: 0.3793\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.3213 - accuracy: 0.4000 - val_loss: 0.4841 - val_accuracy: 0.4483\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.3025 - accuracy: 0.4435 - val_loss: 0.4530 - val_accuracy: 0.4828\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2994 - accuracy: 0.4522 - val_loss: 0.3683 - val_accuracy: 0.5517\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2897 - accuracy: 0.4957 - val_loss: 0.2937 - val_accuracy: 0.7241\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2504 - accuracy: 0.6261 - val_loss: 0.2240 - val_accuracy: 0.8276\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2383 - accuracy: 0.7130 - val_loss: 0.2655 - val_accuracy: 0.7586\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2685 - accuracy: 0.6522 - val_loss: 0.3160 - val_accuracy: 0.5862\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2919 - accuracy: 0.5565 - val_loss: 0.2744 - val_accuracy: 0.7931\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2593 - accuracy: 0.6609 - val_loss: 0.2315 - val_accuracy: 0.8966\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2715 - accuracy: 0.6435 - val_loss: 0.2653 - val_accuracy: 0.7241\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2767 - accuracy: 0.6087 - val_loss: 0.2490 - val_accuracy: 0.5862\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2411 - accuracy: 0.7043 - val_loss: 0.2672 - val_accuracy: 0.5862\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2414 - accuracy: 0.6522 - val_loss: 0.2538 - val_accuracy: 0.5862\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2736 - accuracy: 0.6174 - val_loss: 0.2630 - val_accuracy: 0.5517\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2654 - accuracy: 0.6261 - val_loss: 0.2595 - val_accuracy: 0.5517\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2485 - accuracy: 0.7130 - val_loss: 0.2449 - val_accuracy: 0.5862\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2703 - accuracy: 0.6348 - val_loss: 0.2761 - val_accuracy: 0.5862\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2524 - accuracy: 0.7043 - val_loss: 0.2830 - val_accuracy: 0.5862\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2617 - accuracy: 0.6522 - val_loss: 0.2821 - val_accuracy: 0.5862\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2738 - accuracy: 0.6174 - val_loss: 0.2718 - val_accuracy: 0.5862\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2686 - accuracy: 0.6696 - val_loss: 0.2710 - val_accuracy: 0.5862\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2689 - accuracy: 0.7130 - val_loss: 0.2538 - val_accuracy: 0.6207\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2499 - accuracy: 0.6783 - val_loss: 0.2588 - val_accuracy: 0.5862\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2538 - accuracy: 0.6783 - val_loss: 0.2478 - val_accuracy: 0.5862\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2266 - accuracy: 0.6783 - val_loss: 0.2461 - val_accuracy: 0.5862\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2301 - accuracy: 0.7043 - val_loss: 0.2438 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2199 - accuracy: 0.7043 - val_loss: 0.2427 - val_accuracy: 0.5862\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2137 - accuracy: 0.7304 - val_loss: 0.2425 - val_accuracy: 0.5862\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2062 - accuracy: 0.7304 - val_loss: 0.2430 - val_accuracy: 0.5862\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2035 - accuracy: 0.7130 - val_loss: 0.2454 - val_accuracy: 0.5862\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2090 - accuracy: 0.7130 - val_loss: 0.2454 - val_accuracy: 0.5862\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2024 - accuracy: 0.7304 - val_loss: 0.2464 - val_accuracy: 0.5862\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1904 - accuracy: 0.7565 - val_loss: 0.2460 - val_accuracy: 0.5862\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1874 - accuracy: 0.7217 - val_loss: 0.2449 - val_accuracy: 0.5862\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1845 - accuracy: 0.7565 - val_loss: 0.2442 - val_accuracy: 0.5862\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2025 - accuracy: 0.6957 - val_loss: 0.2439 - val_accuracy: 0.5862\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1768 - accuracy: 0.8000 - val_loss: 0.2441 - val_accuracy: 0.5862\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1773 - accuracy: 0.7739 - val_loss: 0.2441 - val_accuracy: 0.5862\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1667 - accuracy: 0.7739 - val_loss: 0.2440 - val_accuracy: 0.5862\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1753 - accuracy: 0.7826 - val_loss: 0.2440 - val_accuracy: 0.5862\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1656 - accuracy: 0.8000 - val_loss: 0.2439 - val_accuracy: 0.5862\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1710 - accuracy: 0.7826 - val_loss: 0.2438 - val_accuracy: 0.5862\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1712 - accuracy: 0.8087 - val_loss: 0.2459 - val_accuracy: 0.5862\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1556 - accuracy: 0.8348 - val_loss: 0.2458 - val_accuracy: 0.5862\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1615 - accuracy: 0.8000 - val_loss: 0.2446 - val_accuracy: 0.5862\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1554 - accuracy: 0.8261 - val_loss: 0.2425 - val_accuracy: 0.5862\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1593 - accuracy: 0.8261 - val_loss: 0.2411 - val_accuracy: 0.6207\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1668 - accuracy: 0.7913 - val_loss: 0.2394 - val_accuracy: 0.6552\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1565 - accuracy: 0.8435 - val_loss: 0.2388 - val_accuracy: 0.6552\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1509 - accuracy: 0.8348 - val_loss: 0.2403 - val_accuracy: 0.6552\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1478 - accuracy: 0.8522 - val_loss: 0.2415 - val_accuracy: 0.6207\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1483 - accuracy: 0.8435 - val_loss: 0.2442 - val_accuracy: 0.6207\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1409 - accuracy: 0.8522 - val_loss: 0.2436 - val_accuracy: 0.6552\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1384 - accuracy: 0.8435 - val_loss: 0.2428 - val_accuracy: 0.6552\n",
      "0.78125\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101000010101101010001000111010100111001010\n",
      "26\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2880)\n",
      "(144, 100, 2880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_194 (LSTM)              (None, 100, 20)           232080    \n",
      "_________________________________________________________________\n",
      "lstm_195 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 235,482\n",
      "Trainable params: 235,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.2853 - accuracy: 0.5304 - val_loss: 0.4961 - val_accuracy: 0.4483\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2590 - accuracy: 0.6000 - val_loss: 0.4199 - val_accuracy: 0.5862\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2823 - accuracy: 0.5826 - val_loss: 0.3686 - val_accuracy: 0.5517\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2418 - accuracy: 0.6348 - val_loss: 0.3554 - val_accuracy: 0.4828\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2335 - accuracy: 0.6870 - val_loss: 0.3289 - val_accuracy: 0.4828\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2351 - accuracy: 0.6957 - val_loss: 0.4401 - val_accuracy: 0.4138\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2982 - accuracy: 0.4261 - val_loss: 0.3981 - val_accuracy: 0.4483\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2784 - accuracy: 0.4609 - val_loss: 0.3389 - val_accuracy: 0.5172\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2644 - accuracy: 0.5304 - val_loss: 0.3097 - val_accuracy: 0.4828\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2906 - accuracy: 0.4087 - val_loss: 0.3729 - val_accuracy: 0.3103\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2873 - accuracy: 0.4522 - val_loss: 0.4090 - val_accuracy: 0.3448\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2974 - accuracy: 0.3739 - val_loss: 0.3746 - val_accuracy: 0.3448\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2890 - accuracy: 0.4870 - val_loss: 0.3194 - val_accuracy: 0.3793\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2633 - accuracy: 0.6522 - val_loss: 0.2672 - val_accuracy: 0.3448\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2559 - accuracy: 0.5565 - val_loss: 0.3003 - val_accuracy: 0.2759\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2774 - accuracy: 0.5652 - val_loss: 0.2938 - val_accuracy: 0.3448\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2606 - accuracy: 0.6000 - val_loss: 0.3566 - val_accuracy: 0.5517\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2962 - accuracy: 0.5826 - val_loss: 0.4281 - val_accuracy: 0.4138\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2911 - accuracy: 0.5739 - val_loss: 0.3473 - val_accuracy: 0.5862\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2825 - accuracy: 0.6261 - val_loss: 0.3492 - val_accuracy: 0.4828\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3047 - accuracy: 0.4348 - val_loss: 0.4502 - val_accuracy: 0.2414\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2771 - accuracy: 0.5217 - val_loss: 0.2840 - val_accuracy: 0.5517\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2657 - accuracy: 0.6261 - val_loss: 0.3103 - val_accuracy: 0.3793\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2427 - accuracy: 0.6522 - val_loss: 0.3186 - val_accuracy: 0.5517\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2244 - accuracy: 0.6435 - val_loss: 0.2905 - val_accuracy: 0.5172\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2562 - accuracy: 0.5913 - val_loss: 0.3024 - val_accuracy: 0.5862\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2372 - accuracy: 0.5826 - val_loss: 0.2596 - val_accuracy: 0.6897\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2316 - accuracy: 0.6087 - val_loss: 0.3355 - val_accuracy: 0.4483\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2496 - accuracy: 0.5739 - val_loss: 0.3641 - val_accuracy: 0.5172\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2585 - accuracy: 0.5652 - val_loss: 0.3405 - val_accuracy: 0.5862\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2925 - accuracy: 0.4000 - val_loss: 0.3415 - val_accuracy: 0.3793\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.3261 - accuracy: 0.3565 - val_loss: 0.4255 - val_accuracy: 0.3448\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3462 - accuracy: 0.2609 - val_loss: 0.4242 - val_accuracy: 0.2069\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3473 - accuracy: 0.3304 - val_loss: 0.4371 - val_accuracy: 0.2414\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3425 - accuracy: 0.3913 - val_loss: 0.4981 - val_accuracy: 0.2414\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.3560 - accuracy: 0.3478 - val_loss: 0.5165 - val_accuracy: 0.2069\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3663 - accuracy: 0.3304 - val_loss: 0.5227 - val_accuracy: 0.2069\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3841 - accuracy: 0.3130 - val_loss: 0.5253 - val_accuracy: 0.2069\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3932 - accuracy: 0.3043 - val_loss: 0.5306 - val_accuracy: 0.2069\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3898 - accuracy: 0.2870 - val_loss: 0.5376 - val_accuracy: 0.2069\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3770 - accuracy: 0.2870 - val_loss: 0.5322 - val_accuracy: 0.2069\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3758 - accuracy: 0.3043 - val_loss: 0.5217 - val_accuracy: 0.2069\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.3658 - accuracy: 0.3739 - val_loss: 0.4919 - val_accuracy: 0.2069\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.3526 - accuracy: 0.3478 - val_loss: 0.4237 - val_accuracy: 0.2414\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3357 - accuracy: 0.3913 - val_loss: 0.4224 - val_accuracy: 0.3103\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.3158 - accuracy: 0.4174 - val_loss: 0.4067 - val_accuracy: 0.2759\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.3163 - accuracy: 0.4174 - val_loss: 0.3750 - val_accuracy: 0.3103\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3206 - accuracy: 0.4348 - val_loss: 0.3926 - val_accuracy: 0.3103\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3114 - accuracy: 0.4435 - val_loss: 0.3924 - val_accuracy: 0.3448\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.3099 - accuracy: 0.4522 - val_loss: 0.3751 - val_accuracy: 0.3448\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.3082 - accuracy: 0.4957 - val_loss: 0.3430 - val_accuracy: 0.5172\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2937 - accuracy: 0.5391 - val_loss: 0.3411 - val_accuracy: 0.4828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2872 - accuracy: 0.5391 - val_loss: 0.3430 - val_accuracy: 0.4828\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2827 - accuracy: 0.5391 - val_loss: 0.3282 - val_accuracy: 0.5172\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2772 - accuracy: 0.6261 - val_loss: 0.3153 - val_accuracy: 0.5172\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2733 - accuracy: 0.5913 - val_loss: 0.3077 - val_accuracy: 0.5172\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2698 - accuracy: 0.6087 - val_loss: 0.3065 - val_accuracy: 0.5172\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2732 - accuracy: 0.6174 - val_loss: 0.2794 - val_accuracy: 0.5862\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2697 - accuracy: 0.6696 - val_loss: 0.2856 - val_accuracy: 0.5862\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2633 - accuracy: 0.6609 - val_loss: 0.2766 - val_accuracy: 0.5517\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2748 - accuracy: 0.6435 - val_loss: 0.2748 - val_accuracy: 0.5862\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2707 - accuracy: 0.6696 - val_loss: 0.2785 - val_accuracy: 0.5862\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2698 - accuracy: 0.6522 - val_loss: 0.2914 - val_accuracy: 0.5862\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2692 - accuracy: 0.6609 - val_loss: 0.2973 - val_accuracy: 0.5172\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2718 - accuracy: 0.6435 - val_loss: 0.3009 - val_accuracy: 0.5172\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2636 - accuracy: 0.6609 - val_loss: 0.2962 - val_accuracy: 0.5862\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2662 - accuracy: 0.6696 - val_loss: 0.2973 - val_accuracy: 0.6207\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2650 - accuracy: 0.6000 - val_loss: 0.2919 - val_accuracy: 0.5862\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2487 - accuracy: 0.6435 - val_loss: 0.2714 - val_accuracy: 0.6552\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2448 - accuracy: 0.6348 - val_loss: 0.2491 - val_accuracy: 0.6207\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2360 - accuracy: 0.7043 - val_loss: 0.2492 - val_accuracy: 0.5862\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.2256 - accuracy: 0.6870 - val_loss: 0.2465 - val_accuracy: 0.5862\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.2323 - accuracy: 0.6696 - val_loss: 0.2434 - val_accuracy: 0.5862\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2402 - accuracy: 0.6348 - val_loss: 0.2362 - val_accuracy: 0.5862\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2209 - accuracy: 0.6957 - val_loss: 0.2340 - val_accuracy: 0.6207\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.2201 - accuracy: 0.7130 - val_loss: 0.2408 - val_accuracy: 0.5862\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2227 - accuracy: 0.6957 - val_loss: 0.2449 - val_accuracy: 0.5862\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2400 - accuracy: 0.6957 - val_loss: 0.2386 - val_accuracy: 0.5862\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.2377 - accuracy: 0.7043 - val_loss: 0.2452 - val_accuracy: 0.5862\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.2405 - accuracy: 0.6957 - val_loss: 0.2460 - val_accuracy: 0.5862\n",
      "0.6770833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101111011101111000001001110100111011101\n",
      "19\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3720)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3720)\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_196 (LSTM)              (None, 100, 20)           299280    \n",
      "_________________________________________________________________\n",
      "lstm_197 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 302,682\n",
      "Trainable params: 302,642\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.3085 - accuracy: 0.5130 - val_loss: 0.3018 - val_accuracy: 0.4828\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.1683 - accuracy: 0.8522 - val_loss: 0.2630 - val_accuracy: 0.6897\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.2089 - accuracy: 0.7217 - val_loss: 0.2343 - val_accuracy: 0.7931\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.2437 - accuracy: 0.6783 - val_loss: 0.1546 - val_accuracy: 0.8276\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2350 - accuracy: 0.7217 - val_loss: 0.2549 - val_accuracy: 0.7931\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.2354 - accuracy: 0.6783 - val_loss: 0.2651 - val_accuracy: 0.6897\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2031 - accuracy: 0.7217 - val_loss: 0.1603 - val_accuracy: 0.8276\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2001 - accuracy: 0.7739 - val_loss: 0.1646 - val_accuracy: 0.8276\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2190 - accuracy: 0.6957 - val_loss: 0.1698 - val_accuracy: 0.8621\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2078 - accuracy: 0.7391 - val_loss: 0.1539 - val_accuracy: 0.8621\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.1959 - accuracy: 0.7652 - val_loss: 0.1999 - val_accuracy: 0.7241\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2225 - accuracy: 0.7130 - val_loss: 0.1835 - val_accuracy: 0.8621\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.2036 - accuracy: 0.7391 - val_loss: 0.2252 - val_accuracy: 0.7586\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1945 - accuracy: 0.7391 - val_loss: 0.2119 - val_accuracy: 0.7586\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.2290 - accuracy: 0.7043 - val_loss: 0.1613 - val_accuracy: 0.8621\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2154 - accuracy: 0.7217 - val_loss: 0.1192 - val_accuracy: 0.8966\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.1809 - accuracy: 0.7652 - val_loss: 0.1124 - val_accuracy: 0.8621\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.1805 - accuracy: 0.7652 - val_loss: 0.1282 - val_accuracy: 0.8276\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1766 - accuracy: 0.7913 - val_loss: 0.1399 - val_accuracy: 0.7931\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.1575 - accuracy: 0.8174 - val_loss: 0.1503 - val_accuracy: 0.8276\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1638 - accuracy: 0.7826 - val_loss: 0.1459 - val_accuracy: 0.8276\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.1566 - accuracy: 0.8000 - val_loss: 0.1410 - val_accuracy: 0.8276\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1513 - accuracy: 0.8522 - val_loss: 0.1423 - val_accuracy: 0.8276\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1485 - accuracy: 0.8174 - val_loss: 0.1427 - val_accuracy: 0.8276\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.1543 - accuracy: 0.8174 - val_loss: 0.1314 - val_accuracy: 0.8621\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.1505 - accuracy: 0.8087 - val_loss: 0.1387 - val_accuracy: 0.8276\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1427 - accuracy: 0.8348 - val_loss: 0.1225 - val_accuracy: 0.8966\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1292 - accuracy: 0.8783 - val_loss: 0.1208 - val_accuracy: 0.8621\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.1228 - accuracy: 0.8870 - val_loss: 0.1314 - val_accuracy: 0.8621\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.1138 - accuracy: 0.9304 - val_loss: 0.1204 - val_accuracy: 0.8621\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1159 - accuracy: 0.9304 - val_loss: 0.1144 - val_accuracy: 0.8966\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.1122 - accuracy: 0.9043 - val_loss: 0.1291 - val_accuracy: 0.8966\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.1084 - accuracy: 0.9130 - val_loss: 0.1270 - val_accuracy: 0.8966\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1121 - accuracy: 0.9304 - val_loss: 0.1287 - val_accuracy: 0.8966\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1035 - accuracy: 0.9130 - val_loss: 0.1492 - val_accuracy: 0.8966\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1007 - accuracy: 0.9565 - val_loss: 0.1504 - val_accuracy: 0.8966\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0916 - accuracy: 0.9565 - val_loss: 0.1442 - val_accuracy: 0.8966\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0945 - accuracy: 0.9565 - val_loss: 0.1706 - val_accuracy: 0.8966\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0907 - accuracy: 0.9652 - val_loss: 0.1626 - val_accuracy: 0.8966\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0849 - accuracy: 0.9565 - val_loss: 0.1649 - val_accuracy: 0.8966\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0870 - accuracy: 0.9652 - val_loss: 0.1671 - val_accuracy: 0.8966\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0903 - accuracy: 0.9478 - val_loss: 0.1417 - val_accuracy: 0.8966\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0809 - accuracy: 0.9652 - val_loss: 0.1686 - val_accuracy: 0.8966\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0828 - accuracy: 0.9304 - val_loss: 0.1450 - val_accuracy: 0.8966\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0771 - accuracy: 0.9739 - val_loss: 0.1466 - val_accuracy: 0.8966\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0750 - accuracy: 0.9652 - val_loss: 0.1475 - val_accuracy: 0.8966\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0810 - accuracy: 0.9304 - val_loss: 0.1464 - val_accuracy: 0.8966\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0781 - accuracy: 0.9304 - val_loss: 0.1474 - val_accuracy: 0.8966\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0732 - accuracy: 0.9652 - val_loss: 0.1468 - val_accuracy: 0.8966\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0697 - accuracy: 0.9565 - val_loss: 0.1450 - val_accuracy: 0.8966\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0760 - accuracy: 0.9478 - val_loss: 0.1432 - val_accuracy: 0.8966\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0682 - accuracy: 0.9826 - val_loss: 0.1425 - val_accuracy: 0.8966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0693 - accuracy: 0.9478 - val_loss: 0.1647 - val_accuracy: 0.8966\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0673 - accuracy: 0.9652 - val_loss: 0.1473 - val_accuracy: 0.8966\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0648 - accuracy: 0.9652 - val_loss: 0.1602 - val_accuracy: 0.8966\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0615 - accuracy: 0.9739 - val_loss: 0.1621 - val_accuracy: 0.8621\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0638 - accuracy: 0.9652 - val_loss: 0.1540 - val_accuracy: 0.8966\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0632 - accuracy: 0.9565 - val_loss: 0.1312 - val_accuracy: 0.8966\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0643 - accuracy: 0.9652 - val_loss: 0.1044 - val_accuracy: 0.8966\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0816 - accuracy: 0.9391 - val_loss: 0.1180 - val_accuracy: 0.8966\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0801 - accuracy: 0.9304 - val_loss: 0.1235 - val_accuracy: 0.8966\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0799 - accuracy: 0.9391 - val_loss: 0.1014 - val_accuracy: 0.8966\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0705 - accuracy: 0.9478 - val_loss: 0.1190 - val_accuracy: 0.8966\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0739 - accuracy: 0.9565 - val_loss: 0.1172 - val_accuracy: 0.8966\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0846 - accuracy: 0.9478 - val_loss: 0.1441 - val_accuracy: 0.8966\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0795 - accuracy: 0.9565 - val_loss: 0.1268 - val_accuracy: 0.8966\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0809 - accuracy: 0.9565 - val_loss: 0.1204 - val_accuracy: 0.8966\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0852 - accuracy: 0.9565 - val_loss: 0.1433 - val_accuracy: 0.8621\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0831 - accuracy: 0.9565 - val_loss: 0.1366 - val_accuracy: 0.8621\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0869 - accuracy: 0.9565 - val_loss: 0.1261 - val_accuracy: 0.8621\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0885 - accuracy: 0.9565 - val_loss: 0.0987 - val_accuracy: 0.8621\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0875 - accuracy: 0.9565 - val_loss: 0.1095 - val_accuracy: 0.8966\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0746 - accuracy: 0.9565 - val_loss: 0.1616 - val_accuracy: 0.8621\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0735 - accuracy: 0.9565 - val_loss: 0.1766 - val_accuracy: 0.8621\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0723 - accuracy: 0.9652 - val_loss: 0.1811 - val_accuracy: 0.8621\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0866 - accuracy: 0.9217 - val_loss: 0.1792 - val_accuracy: 0.8621\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0745 - accuracy: 0.9478 - val_loss: 0.1732 - val_accuracy: 0.8621\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0786 - accuracy: 0.9652 - val_loss: 0.1831 - val_accuracy: 0.8621\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0812 - accuracy: 0.9478 - val_loss: 0.1760 - val_accuracy: 0.8621\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0745 - accuracy: 0.9565 - val_loss: 0.1742 - val_accuracy: 0.8621\n",
      "0.9166666865348816\n",
      "fitness pass\n",
      "[(1.0, 923447748520394), (0.625, 923447748520394), (0.6875, 957462487713885), (0.8854166865348816, 957146807617629), (0.7604166865348816, 957148127537610), (0.7708333134651184, 957462487713885), (0.7395833134651184, 923447748520394), (0.7395833134651184, 923447748675677), (0.78125, 957462487713885), (0.6770833134651184, 957148127537610), (0.9166666865348816, 923447748520413)]\n",
      "[923447748520394, 923447748520413]\n",
      "[923447748520394, 923447748520413, 957146807617629, 957462487713885, 957462487713885, 957148127537610]\n",
      "selection pass\n",
      "target_count:\n",
      "5\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "0\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "1\n",
      "923447748520413\n",
      "11010001111101111011101111000001001110100111011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "2\n",
      "957146807617629\n",
      "11011001101000010100011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "3\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "4\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "5\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "6\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "7\n",
      "921963755448778\n",
      "11010001101000010101101010001000111010100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "8\n",
      "957146807617629\n",
      "11011001101000010100011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "9\n",
      "923447751821405\n",
      "11010001111101111011101111001101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "10\n",
      "957462487714269\n",
      "11011001101100111010011011011101110100100111011101\n",
      "crossover pass\n",
      "變異後的種群\n",
      "染色體：\n",
      "0\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "1\n",
      "923447748520413\n",
      "11010001111101111011101111000001001110100111011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "2\n",
      "957146807617629\n",
      "11011001101000010100011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "3\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "4\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "5\n",
      "957148127537610\n",
      "11011001101000010101101010001000111010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "6\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "7\n",
      "921963755448778\n",
      "11010001101000010101101010001000111010100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "8\n",
      "957146807617629\n",
      "11011001101000010100011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "9\n",
      "923447751821405\n",
      "11010001111101111011101111001101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "10\n",
      "957462487714269\n",
      "11011001101100111010011011011101110100100111011101\n",
      "mutation pass\n",
      "迭代次數： 9\n",
      "9\n",
      "所選擇的染色體：\n",
      "11010001111101111011101111000001001110100111001010\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_198 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_199 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 0.2381 - accuracy: 0.6696 - val_loss: 0.2807 - val_accuracy: 0.7241\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2987 - accuracy: 0.4783 - val_loss: 0.2893 - val_accuracy: 0.5172\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.2988 - accuracy: 0.5478 - val_loss: 0.2824 - val_accuracy: 0.6552\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2945 - accuracy: 0.5130 - val_loss: 0.3266 - val_accuracy: 0.6552\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2900 - accuracy: 0.5739 - val_loss: 0.2876 - val_accuracy: 0.3103\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2663 - accuracy: 0.5304 - val_loss: 0.3131 - val_accuracy: 0.3103\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.3146 - accuracy: 0.4609 - val_loss: 0.2301 - val_accuracy: 0.6552\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2591 - accuracy: 0.5478 - val_loss: 0.2574 - val_accuracy: 0.6552\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.3083 - accuracy: 0.4348 - val_loss: 0.2628 - val_accuracy: 0.5172\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.3749 - accuracy: 0.2696 - val_loss: 0.2944 - val_accuracy: 0.6207\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.3704 - accuracy: 0.2261 - val_loss: 0.2729 - val_accuracy: 0.7241\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.3675 - accuracy: 0.2870 - val_loss: 0.3009 - val_accuracy: 0.6897\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.3739 - accuracy: 0.3478 - val_loss: 0.3015 - val_accuracy: 0.6897\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.3669 - accuracy: 0.3130 - val_loss: 0.3143 - val_accuracy: 0.6552\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.3537 - accuracy: 0.3478 - val_loss: 0.3332 - val_accuracy: 0.4828\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.3529 - accuracy: 0.3913 - val_loss: 0.3313 - val_accuracy: 0.4138\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.3298 - accuracy: 0.3826 - val_loss: 0.3329 - val_accuracy: 0.4138\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.3191 - accuracy: 0.4174 - val_loss: 0.3415 - val_accuracy: 0.3793\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2936 - accuracy: 0.5826 - val_loss: 0.3401 - val_accuracy: 0.4138\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2660 - accuracy: 0.6870 - val_loss: 0.3363 - val_accuracy: 0.4138\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2549 - accuracy: 0.6957 - val_loss: 0.3405 - val_accuracy: 0.4138\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2452 - accuracy: 0.6870 - val_loss: 0.3334 - val_accuracy: 0.5172\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2428 - accuracy: 0.6870 - val_loss: 0.3228 - val_accuracy: 0.5172\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2313 - accuracy: 0.6783 - val_loss: 0.3122 - val_accuracy: 0.5172\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2263 - accuracy: 0.7217 - val_loss: 0.3083 - val_accuracy: 0.5517\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2062 - accuracy: 0.6957 - val_loss: 0.2895 - val_accuracy: 0.5517\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2029 - accuracy: 0.6609 - val_loss: 0.2718 - val_accuracy: 0.5862\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1887 - accuracy: 0.7913 - val_loss: 0.2537 - val_accuracy: 0.6552\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1842 - accuracy: 0.8783 - val_loss: 0.2393 - val_accuracy: 0.7241\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1779 - accuracy: 0.8957 - val_loss: 0.2148 - val_accuracy: 0.7586\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1727 - accuracy: 0.8957 - val_loss: 0.2049 - val_accuracy: 0.7931\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1766 - accuracy: 0.8783 - val_loss: 0.1929 - val_accuracy: 0.7931\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2037 - accuracy: 0.7217 - val_loss: 0.1885 - val_accuracy: 0.7931\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2006 - accuracy: 0.8000 - val_loss: 0.1853 - val_accuracy: 0.7931\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1892 - accuracy: 0.7478 - val_loss: 0.1820 - val_accuracy: 0.7931\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1904 - accuracy: 0.7652 - val_loss: 0.1783 - val_accuracy: 0.7931\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1805 - accuracy: 0.7826 - val_loss: 0.1735 - val_accuracy: 0.8276\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1747 - accuracy: 0.7826 - val_loss: 0.1687 - val_accuracy: 0.8621\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1706 - accuracy: 0.8261 - val_loss: 0.1652 - val_accuracy: 0.8621\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1647 - accuracy: 0.8435 - val_loss: 0.1614 - val_accuracy: 0.8621\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1507 - accuracy: 0.8609 - val_loss: 0.1584 - val_accuracy: 0.8621\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1515 - accuracy: 0.8696 - val_loss: 0.1551 - val_accuracy: 0.8621\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1449 - accuracy: 0.8783 - val_loss: 0.1522 - val_accuracy: 0.8621\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1394 - accuracy: 0.8957 - val_loss: 0.1495 - val_accuracy: 0.8621\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1394 - accuracy: 0.8957 - val_loss: 0.1473 - val_accuracy: 0.8621\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1339 - accuracy: 0.8870 - val_loss: 0.1439 - val_accuracy: 0.8621\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1245 - accuracy: 0.9043 - val_loss: 0.1408 - val_accuracy: 0.8621\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1194 - accuracy: 0.9217 - val_loss: 0.1374 - val_accuracy: 0.8966\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1147 - accuracy: 0.9217 - val_loss: 0.1339 - val_accuracy: 0.8966\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1144 - accuracy: 0.9217 - val_loss: 0.1325 - val_accuracy: 0.8966\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1083 - accuracy: 0.9217 - val_loss: 0.1333 - val_accuracy: 0.9310\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1058 - accuracy: 0.9130 - val_loss: 0.1336 - val_accuracy: 0.9310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0971 - accuracy: 0.9565 - val_loss: 0.1322 - val_accuracy: 0.9310\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0952 - accuracy: 0.9565 - val_loss: 0.1300 - val_accuracy: 0.9310\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0948 - accuracy: 0.9478 - val_loss: 0.1259 - val_accuracy: 0.9310\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0874 - accuracy: 0.9826 - val_loss: 0.1203 - val_accuracy: 0.9310\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0879 - accuracy: 0.9478 - val_loss: 0.1156 - val_accuracy: 0.9310\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0807 - accuracy: 0.9652 - val_loss: 0.1131 - val_accuracy: 0.9310\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0818 - accuracy: 0.9739 - val_loss: 0.1127 - val_accuracy: 0.9310\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0791 - accuracy: 0.9652 - val_loss: 0.1106 - val_accuracy: 0.9310\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0731 - accuracy: 0.9826 - val_loss: 0.1063 - val_accuracy: 0.9310\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0700 - accuracy: 0.9826 - val_loss: 0.1006 - val_accuracy: 0.9655\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0690 - accuracy: 0.9739 - val_loss: 0.1010 - val_accuracy: 0.9655\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0711 - accuracy: 0.9565 - val_loss: 0.1010 - val_accuracy: 0.9655\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0655 - accuracy: 0.9652 - val_loss: 0.0953 - val_accuracy: 0.9655\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0596 - accuracy: 0.9826 - val_loss: 0.0909 - val_accuracy: 0.9655\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0550 - accuracy: 0.9826 - val_loss: 0.0880 - val_accuracy: 0.9655\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0502 - accuracy: 0.9913 - val_loss: 0.0859 - val_accuracy: 0.9655\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0483 - accuracy: 0.9826 - val_loss: 0.0866 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0518 - accuracy: 0.9913 - val_loss: 0.0838 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0525 - accuracy: 0.9826 - val_loss: 0.0717 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0554 - accuracy: 0.9739 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0425 - accuracy: 0.9913 - val_loss: 0.0661 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0403 - accuracy: 0.9913 - val_loss: 0.0657 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0411 - accuracy: 0.9826 - val_loss: 0.0629 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.0571 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0393 - accuracy: 0.9913 - val_loss: 0.0514 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0385 - accuracy: 0.9913 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "1.0\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101111011101111000001001110100111011101\n",
      "19\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3720)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3720)\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_200 (LSTM)              (None, 100, 20)           299280    \n",
      "_________________________________________________________________\n",
      "lstm_201 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 302,682\n",
      "Trainable params: 302,642\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.2972 - accuracy: 0.6174 - val_loss: 0.1629 - val_accuracy: 0.8621\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.2143 - accuracy: 0.7826 - val_loss: 0.2395 - val_accuracy: 0.6897\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.2513 - accuracy: 0.6435 - val_loss: 0.1615 - val_accuracy: 0.8276\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2467 - accuracy: 0.6435 - val_loss: 0.2105 - val_accuracy: 0.7586\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.2257 - accuracy: 0.7217 - val_loss: 0.1978 - val_accuracy: 0.7931\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.2171 - accuracy: 0.7478 - val_loss: 0.1878 - val_accuracy: 0.8276\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2007 - accuracy: 0.7130 - val_loss: 0.1698 - val_accuracy: 0.9310\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1979 - accuracy: 0.8087 - val_loss: 0.1645 - val_accuracy: 0.8621\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.1877 - accuracy: 0.7739 - val_loss: 0.1695 - val_accuracy: 0.8621\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.1897 - accuracy: 0.8000 - val_loss: 0.1874 - val_accuracy: 0.7586\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1897 - accuracy: 0.7913 - val_loss: 0.1844 - val_accuracy: 0.8276\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1781 - accuracy: 0.8522 - val_loss: 0.1874 - val_accuracy: 0.7586\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.1796 - accuracy: 0.8522 - val_loss: 0.1629 - val_accuracy: 0.7931\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.1732 - accuracy: 0.8609 - val_loss: 0.1289 - val_accuracy: 0.8621\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.1523 - accuracy: 0.8696 - val_loss: 0.1251 - val_accuracy: 0.8966\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1471 - accuracy: 0.8435 - val_loss: 0.1383 - val_accuracy: 0.8621\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1570 - accuracy: 0.8522 - val_loss: 0.1552 - val_accuracy: 0.8621\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.1801 - accuracy: 0.7826 - val_loss: 0.1154 - val_accuracy: 0.8966\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1757 - accuracy: 0.8174 - val_loss: 0.1472 - val_accuracy: 0.8276\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.1751 - accuracy: 0.8087 - val_loss: 0.1413 - val_accuracy: 0.7586\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.1657 - accuracy: 0.8435 - val_loss: 0.1272 - val_accuracy: 0.8621\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1591 - accuracy: 0.8522 - val_loss: 0.1263 - val_accuracy: 0.8621\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.1561 - accuracy: 0.8696 - val_loss: 0.1118 - val_accuracy: 0.8621\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.1668 - accuracy: 0.8609 - val_loss: 0.1278 - val_accuracy: 0.9310\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.1469 - accuracy: 0.8435 - val_loss: 0.1394 - val_accuracy: 0.8621\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1607 - accuracy: 0.8348 - val_loss: 0.1291 - val_accuracy: 0.8621\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1769 - accuracy: 0.7913 - val_loss: 0.1161 - val_accuracy: 0.9310\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.1462 - accuracy: 0.8435 - val_loss: 0.1760 - val_accuracy: 0.6897\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.1812 - accuracy: 0.8000 - val_loss: 0.3195 - val_accuracy: 0.6552\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.2219 - accuracy: 0.7043 - val_loss: 0.4032 - val_accuracy: 0.4828\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2361 - accuracy: 0.7130 - val_loss: 0.2699 - val_accuracy: 0.6552\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1968 - accuracy: 0.7391 - val_loss: 0.2464 - val_accuracy: 0.6207\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1885 - accuracy: 0.7478 - val_loss: 0.2221 - val_accuracy: 0.6897\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1884 - accuracy: 0.7565 - val_loss: 0.1993 - val_accuracy: 0.6552\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.1716 - accuracy: 0.8000 - val_loss: 0.2161 - val_accuracy: 0.5862\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.1900 - accuracy: 0.7652 - val_loss: 0.1996 - val_accuracy: 0.6552\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1821 - accuracy: 0.8174 - val_loss: 0.2221 - val_accuracy: 0.7241\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.2012 - accuracy: 0.7304 - val_loss: 0.2197 - val_accuracy: 0.6897\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1828 - accuracy: 0.7913 - val_loss: 0.2372 - val_accuracy: 0.7241\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.1823 - accuracy: 0.7739 - val_loss: 0.2167 - val_accuracy: 0.6897\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1796 - accuracy: 0.8087 - val_loss: 0.2187 - val_accuracy: 0.7586\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2051 - accuracy: 0.7391 - val_loss: 0.2449 - val_accuracy: 0.6897\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.2103 - accuracy: 0.7304 - val_loss: 0.2373 - val_accuracy: 0.7241\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.1882 - accuracy: 0.7304 - val_loss: 0.2357 - val_accuracy: 0.6552\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2082 - accuracy: 0.7130 - val_loss: 0.2002 - val_accuracy: 0.6897\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.1751 - accuracy: 0.7739 - val_loss: 0.1185 - val_accuracy: 0.8621\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1418 - accuracy: 0.8348 - val_loss: 0.1803 - val_accuracy: 0.7586\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.1529 - accuracy: 0.8348 - val_loss: 0.1407 - val_accuracy: 0.8966\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1871 - accuracy: 0.7478 - val_loss: 0.2642 - val_accuracy: 0.6552\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.2477 - accuracy: 0.6435 - val_loss: 0.1956 - val_accuracy: 0.7586\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.1957 - accuracy: 0.7304 - val_loss: 0.1999 - val_accuracy: 0.7931\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.1996 - accuracy: 0.6522 - val_loss: 0.1758 - val_accuracy: 0.7931\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.1948 - accuracy: 0.7130 - val_loss: 0.1806 - val_accuracy: 0.8276\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2003 - accuracy: 0.6783 - val_loss: 0.2029 - val_accuracy: 0.7241\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2450 - accuracy: 0.6174 - val_loss: 0.1697 - val_accuracy: 0.7931\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2344 - accuracy: 0.6348 - val_loss: 0.1667 - val_accuracy: 0.7586\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2219 - accuracy: 0.6435 - val_loss: 0.1491 - val_accuracy: 0.8621\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.2042 - accuracy: 0.7565 - val_loss: 0.1483 - val_accuracy: 0.8276\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.1914 - accuracy: 0.7130 - val_loss: 0.1817 - val_accuracy: 0.7586\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.2238 - accuracy: 0.7043 - val_loss: 0.1871 - val_accuracy: 0.8276\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.2092 - accuracy: 0.7043 - val_loss: 0.2384 - val_accuracy: 0.6552\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2048 - accuracy: 0.7217 - val_loss: 0.2137 - val_accuracy: 0.7586\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1608 - accuracy: 0.7913 - val_loss: 0.2597 - val_accuracy: 0.6552\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2067 - accuracy: 0.6957 - val_loss: 0.2232 - val_accuracy: 0.6897\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.1514 - accuracy: 0.7913 - val_loss: 0.3061 - val_accuracy: 0.5517\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.2126 - accuracy: 0.7130 - val_loss: 0.3124 - val_accuracy: 0.5517\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2358 - accuracy: 0.6261 - val_loss: 0.3293 - val_accuracy: 0.5517\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.2752 - accuracy: 0.5652 - val_loss: 0.3585 - val_accuracy: 0.4483\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.2703 - accuracy: 0.5826 - val_loss: 0.3344 - val_accuracy: 0.5862\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.2650 - accuracy: 0.5478 - val_loss: 0.3258 - val_accuracy: 0.5517\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.2174 - accuracy: 0.6783 - val_loss: 0.2328 - val_accuracy: 0.6207\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.2758 - accuracy: 0.5304 - val_loss: 0.2672 - val_accuracy: 0.6897\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.2521 - accuracy: 0.6174 - val_loss: 0.2904 - val_accuracy: 0.5862\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2872 - accuracy: 0.5565 - val_loss: 0.2544 - val_accuracy: 0.7241\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2398 - accuracy: 0.6348 - val_loss: 0.2135 - val_accuracy: 0.7931\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.2294 - accuracy: 0.6435 - val_loss: 0.2090 - val_accuracy: 0.7241\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2051 - accuracy: 0.6957 - val_loss: 0.1736 - val_accuracy: 0.8276\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.2117 - accuracy: 0.6957 - val_loss: 0.1757 - val_accuracy: 0.8966\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2140 - accuracy: 0.6957 - val_loss: 0.2095 - val_accuracy: 0.8276\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2211 - accuracy: 0.6783 - val_loss: 0.2429 - val_accuracy: 0.6897\n",
      "0.8020833134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101000010100011011011101110100100001011101\n",
      "24\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3120)\n",
      "(144, 100, 3120)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_202 (LSTM)              (None, 100, 20)           251280    \n",
      "_________________________________________________________________\n",
      "lstm_203 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 254,682\n",
      "Trainable params: 254,642\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 183ms/step - loss: 0.3068 - accuracy: 0.4522 - val_loss: 0.4443 - val_accuracy: 0.4138\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2621 - accuracy: 0.5565 - val_loss: 0.2479 - val_accuracy: 0.4483\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2341 - accuracy: 0.7739 - val_loss: 0.2566 - val_accuracy: 0.3793\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2675 - accuracy: 0.5130 - val_loss: 0.2549 - val_accuracy: 0.3448\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2659 - accuracy: 0.5130 - val_loss: 0.2565 - val_accuracy: 0.4138\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2520 - accuracy: 0.5913 - val_loss: 0.2579 - val_accuracy: 0.3793\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2613 - accuracy: 0.6696 - val_loss: 0.2651 - val_accuracy: 0.3793\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2535 - accuracy: 0.6348 - val_loss: 0.2701 - val_accuracy: 0.3448\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2870 - accuracy: 0.5478 - val_loss: 0.2627 - val_accuracy: 0.4138\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2593 - accuracy: 0.6609 - val_loss: 0.2630 - val_accuracy: 0.4483\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2567 - accuracy: 0.6522 - val_loss: 0.2633 - val_accuracy: 0.4828\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2573 - accuracy: 0.6174 - val_loss: 0.2638 - val_accuracy: 0.4828\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2520 - accuracy: 0.6609 - val_loss: 0.2644 - val_accuracy: 0.4828\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2481 - accuracy: 0.6609 - val_loss: 0.2541 - val_accuracy: 0.5172\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2452 - accuracy: 0.7043 - val_loss: 0.2482 - val_accuracy: 0.5172\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2442 - accuracy: 0.6783 - val_loss: 0.2495 - val_accuracy: 0.4828\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2373 - accuracy: 0.7043 - val_loss: 0.2499 - val_accuracy: 0.4828\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2370 - accuracy: 0.7043 - val_loss: 0.2456 - val_accuracy: 0.5172\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2358 - accuracy: 0.7043 - val_loss: 0.2445 - val_accuracy: 0.5172\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2308 - accuracy: 0.7217 - val_loss: 0.2452 - val_accuracy: 0.5172\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2339 - accuracy: 0.7043 - val_loss: 0.2456 - val_accuracy: 0.5172\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2290 - accuracy: 0.7130 - val_loss: 0.2393 - val_accuracy: 0.5517\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2323 - accuracy: 0.7043 - val_loss: 0.2366 - val_accuracy: 0.5862\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2263 - accuracy: 0.7130 - val_loss: 0.2343 - val_accuracy: 0.5517\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2269 - accuracy: 0.7304 - val_loss: 0.2338 - val_accuracy: 0.5862\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2228 - accuracy: 0.7304 - val_loss: 0.2357 - val_accuracy: 0.5517\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2215 - accuracy: 0.7304 - val_loss: 0.2277 - val_accuracy: 0.7931\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2239 - accuracy: 0.7217 - val_loss: 0.2278 - val_accuracy: 0.7586\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2273 - accuracy: 0.6783 - val_loss: 0.2269 - val_accuracy: 0.7241\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2211 - accuracy: 0.7391 - val_loss: 0.2249 - val_accuracy: 0.6552\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2231 - accuracy: 0.7043 - val_loss: 0.2225 - val_accuracy: 0.5862\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2175 - accuracy: 0.7391 - val_loss: 0.2211 - val_accuracy: 0.5517\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2175 - accuracy: 0.7217 - val_loss: 0.2197 - val_accuracy: 0.5517\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2151 - accuracy: 0.7391 - val_loss: 0.2178 - val_accuracy: 0.5517\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2171 - accuracy: 0.7130 - val_loss: 0.2163 - val_accuracy: 0.5862\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2116 - accuracy: 0.7391 - val_loss: 0.2159 - val_accuracy: 0.5862\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2094 - accuracy: 0.7391 - val_loss: 0.2152 - val_accuracy: 0.5862\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2091 - accuracy: 0.7304 - val_loss: 0.2140 - val_accuracy: 0.5862\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2105 - accuracy: 0.7304 - val_loss: 0.2130 - val_accuracy: 0.6207\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2067 - accuracy: 0.7304 - val_loss: 0.2122 - val_accuracy: 0.6207\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2045 - accuracy: 0.7304 - val_loss: 0.2116 - val_accuracy: 0.6207\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2046 - accuracy: 0.7304 - val_loss: 0.2113 - val_accuracy: 0.6207\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2030 - accuracy: 0.7304 - val_loss: 0.2111 - val_accuracy: 0.6207\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2027 - accuracy: 0.7304 - val_loss: 0.2109 - val_accuracy: 0.6207\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2016 - accuracy: 0.7304 - val_loss: 0.2108 - val_accuracy: 0.6207\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2004 - accuracy: 0.7304 - val_loss: 0.2104 - val_accuracy: 0.6207\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1969 - accuracy: 0.7304 - val_loss: 0.2102 - val_accuracy: 0.6207\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1966 - accuracy: 0.7391 - val_loss: 0.2099 - val_accuracy: 0.6207\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1964 - accuracy: 0.7304 - val_loss: 0.2099 - val_accuracy: 0.6207\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1954 - accuracy: 0.7391 - val_loss: 0.2095 - val_accuracy: 0.6207\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1953 - accuracy: 0.7391 - val_loss: 0.2091 - val_accuracy: 0.6207\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1946 - accuracy: 0.7478 - val_loss: 0.2087 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1938 - accuracy: 0.7478 - val_loss: 0.2082 - val_accuracy: 0.6207\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1904 - accuracy: 0.7565 - val_loss: 0.2079 - val_accuracy: 0.6207\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1891 - accuracy: 0.7478 - val_loss: 0.2080 - val_accuracy: 0.6207\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1899 - accuracy: 0.7478 - val_loss: 0.2089 - val_accuracy: 0.6207\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1884 - accuracy: 0.7478 - val_loss: 0.2098 - val_accuracy: 0.6207\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1865 - accuracy: 0.7478 - val_loss: 0.2106 - val_accuracy: 0.6207\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1895 - accuracy: 0.7304 - val_loss: 0.2111 - val_accuracy: 0.6207\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1858 - accuracy: 0.7304 - val_loss: 0.2111 - val_accuracy: 0.6207\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1908 - accuracy: 0.7304 - val_loss: 0.2106 - val_accuracy: 0.6207\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1847 - accuracy: 0.7304 - val_loss: 0.2104 - val_accuracy: 0.6207\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1811 - accuracy: 0.7478 - val_loss: 0.2102 - val_accuracy: 0.6207\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1800 - accuracy: 0.7565 - val_loss: 0.2105 - val_accuracy: 0.6207\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1785 - accuracy: 0.7565 - val_loss: 0.2104 - val_accuracy: 0.6207\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1807 - accuracy: 0.7478 - val_loss: 0.2104 - val_accuracy: 0.6207\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1758 - accuracy: 0.7478 - val_loss: 0.2099 - val_accuracy: 0.6207\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1745 - accuracy: 0.7739 - val_loss: 0.2087 - val_accuracy: 0.6207\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1730 - accuracy: 0.7478 - val_loss: 0.2087 - val_accuracy: 0.6207\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1728 - accuracy: 0.7478 - val_loss: 0.2073 - val_accuracy: 0.6207\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1697 - accuracy: 0.7478 - val_loss: 0.2026 - val_accuracy: 0.6207\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1657 - accuracy: 0.7565 - val_loss: 0.2029 - val_accuracy: 0.6207\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1685 - accuracy: 0.7304 - val_loss: 0.2064 - val_accuracy: 0.6207\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1655 - accuracy: 0.7478 - val_loss: 0.2133 - val_accuracy: 0.5172\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1666 - accuracy: 0.7304 - val_loss: 0.2275 - val_accuracy: 0.4828\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1673 - accuracy: 0.7217 - val_loss: 0.2260 - val_accuracy: 0.4828\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1643 - accuracy: 0.7391 - val_loss: 0.2033 - val_accuracy: 0.6552\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1636 - accuracy: 0.7478 - val_loss: 0.1951 - val_accuracy: 0.6552\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1631 - accuracy: 0.7304 - val_loss: 0.1930 - val_accuracy: 0.6552\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1578 - accuracy: 0.7391 - val_loss: 0.1932 - val_accuracy: 0.6552\n",
      "0.7708333134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101100111010011011011101110100100001011101\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_204 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_205 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 0.2839 - accuracy: 0.5565 - val_loss: 0.3091 - val_accuracy: 0.6552\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2836 - accuracy: 0.5826 - val_loss: 0.3099 - val_accuracy: 0.6897\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2748 - accuracy: 0.5130 - val_loss: 0.2260 - val_accuracy: 0.5862\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2524 - accuracy: 0.6348 - val_loss: 0.2888 - val_accuracy: 0.5517\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2475 - accuracy: 0.6696 - val_loss: 0.2889 - val_accuracy: 0.6552\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2345 - accuracy: 0.6783 - val_loss: 0.2997 - val_accuracy: 0.4483\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2218 - accuracy: 0.7217 - val_loss: 0.3169 - val_accuracy: 0.3103\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2475 - accuracy: 0.6522 - val_loss: 0.2997 - val_accuracy: 0.5172\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2788 - accuracy: 0.5652 - val_loss: 0.2804 - val_accuracy: 0.4828\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2889 - accuracy: 0.5913 - val_loss: 0.2430 - val_accuracy: 0.4483\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2301 - accuracy: 0.6783 - val_loss: 0.2336 - val_accuracy: 0.5172\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2804 - accuracy: 0.5826 - val_loss: 0.2622 - val_accuracy: 0.3793\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2907 - accuracy: 0.5478 - val_loss: 0.2157 - val_accuracy: 0.8276\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2817 - accuracy: 0.6261 - val_loss: 0.1996 - val_accuracy: 0.7931\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2489 - accuracy: 0.6957 - val_loss: 0.1777 - val_accuracy: 0.9655\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2519 - accuracy: 0.6348 - val_loss: 0.1648 - val_accuracy: 0.9655\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2207 - accuracy: 0.7478 - val_loss: 0.1710 - val_accuracy: 0.9310\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2591 - accuracy: 0.5913 - val_loss: 0.1993 - val_accuracy: 0.7586\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2414 - accuracy: 0.6870 - val_loss: 0.1951 - val_accuracy: 0.7931\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2543 - accuracy: 0.6174 - val_loss: 0.1856 - val_accuracy: 0.8276\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2434 - accuracy: 0.6348 - val_loss: 0.1775 - val_accuracy: 0.8621\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2438 - accuracy: 0.6870 - val_loss: 0.1806 - val_accuracy: 0.8621\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2790 - accuracy: 0.6174 - val_loss: 0.1897 - val_accuracy: 0.8276\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2733 - accuracy: 0.5217 - val_loss: 0.1859 - val_accuracy: 0.8276\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2410 - accuracy: 0.7217 - val_loss: 0.1753 - val_accuracy: 0.8966\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2640 - accuracy: 0.5652 - val_loss: 0.1808 - val_accuracy: 0.8276\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2501 - accuracy: 0.6174 - val_loss: 0.1763 - val_accuracy: 0.8966\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2557 - accuracy: 0.6087 - val_loss: 0.1875 - val_accuracy: 0.8276\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2724 - accuracy: 0.5739 - val_loss: 0.2238 - val_accuracy: 0.7241\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2464 - accuracy: 0.6000 - val_loss: 0.2550 - val_accuracy: 0.4828\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.3016 - accuracy: 0.4870 - val_loss: 0.2883 - val_accuracy: 0.4138\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2855 - accuracy: 0.5130 - val_loss: 0.3005 - val_accuracy: 0.3793\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.3092 - accuracy: 0.4957 - val_loss: 0.2838 - val_accuracy: 0.3793\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.3267 - accuracy: 0.4348 - val_loss: 0.2990 - val_accuracy: 0.3103\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2889 - accuracy: 0.5478 - val_loss: 0.3144 - val_accuracy: 0.3103\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2864 - accuracy: 0.6174 - val_loss: 0.3085 - val_accuracy: 0.3103\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2919 - accuracy: 0.5565 - val_loss: 0.3000 - val_accuracy: 0.3448\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2997 - accuracy: 0.5478 - val_loss: 0.2915 - val_accuracy: 0.3793\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2892 - accuracy: 0.5826 - val_loss: 0.2991 - val_accuracy: 0.3448\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.2676 - accuracy: 0.5913 - val_loss: 0.2976 - val_accuracy: 0.3448\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2610 - accuracy: 0.6435 - val_loss: 0.2993 - val_accuracy: 0.3448\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2541 - accuracy: 0.6522 - val_loss: 0.2933 - val_accuracy: 0.3448\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2775 - accuracy: 0.5652 - val_loss: 0.2962 - val_accuracy: 0.3448\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2784 - accuracy: 0.5478 - val_loss: 0.2939 - val_accuracy: 0.3448\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2831 - accuracy: 0.5391 - val_loss: 0.2923 - val_accuracy: 0.3448\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2872 - accuracy: 0.5652 - val_loss: 0.2930 - val_accuracy: 0.3448\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2953 - accuracy: 0.5826 - val_loss: 0.2922 - val_accuracy: 0.4138\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2966 - accuracy: 0.5391 - val_loss: 0.2924 - val_accuracy: 0.4138\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2972 - accuracy: 0.5565 - val_loss: 0.2884 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2825 - accuracy: 0.5739 - val_loss: 0.2850 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2811 - accuracy: 0.5739 - val_loss: 0.2872 - val_accuracy: 0.4138\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2983 - accuracy: 0.5652 - val_loss: 0.2810 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2672 - accuracy: 0.6261 - val_loss: 0.2807 - val_accuracy: 0.4138\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2738 - accuracy: 0.6087 - val_loss: 0.2843 - val_accuracy: 0.4138\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2848 - accuracy: 0.5652 - val_loss: 0.2819 - val_accuracy: 0.4483\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2795 - accuracy: 0.5565 - val_loss: 0.2812 - val_accuracy: 0.4483\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.2693 - accuracy: 0.6000 - val_loss: 0.2778 - val_accuracy: 0.4483\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2593 - accuracy: 0.6261 - val_loss: 0.2784 - val_accuracy: 0.4483\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2601 - accuracy: 0.6174 - val_loss: 0.2752 - val_accuracy: 0.4483\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2533 - accuracy: 0.6174 - val_loss: 0.2736 - val_accuracy: 0.4483\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2599 - accuracy: 0.6000 - val_loss: 0.2738 - val_accuracy: 0.4483\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2602 - accuracy: 0.6261 - val_loss: 0.2692 - val_accuracy: 0.4138\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2485 - accuracy: 0.6783 - val_loss: 0.2663 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2179 - accuracy: 0.7217 - val_loss: 0.2534 - val_accuracy: 0.4828\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2193 - accuracy: 0.6783 - val_loss: 0.2487 - val_accuracy: 0.4828\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2342 - accuracy: 0.6435 - val_loss: 0.2729 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2530 - accuracy: 0.5739 - val_loss: 0.2729 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2392 - accuracy: 0.6348 - val_loss: 0.2730 - val_accuracy: 0.4138\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2461 - accuracy: 0.6087 - val_loss: 0.2715 - val_accuracy: 0.4138\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2422 - accuracy: 0.6348 - val_loss: 0.2719 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2508 - accuracy: 0.6261 - val_loss: 0.2716 - val_accuracy: 0.4483\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2491 - accuracy: 0.6174 - val_loss: 0.2710 - val_accuracy: 0.4483\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2493 - accuracy: 0.6435 - val_loss: 0.2709 - val_accuracy: 0.4483\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2330 - accuracy: 0.6348 - val_loss: 0.2709 - val_accuracy: 0.4483\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2355 - accuracy: 0.6609 - val_loss: 0.2710 - val_accuracy: 0.4483\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2412 - accuracy: 0.6696 - val_loss: 0.2711 - val_accuracy: 0.4483\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2375 - accuracy: 0.6261 - val_loss: 0.2711 - val_accuracy: 0.4483\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2371 - accuracy: 0.6435 - val_loss: 0.2712 - val_accuracy: 0.4483\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2468 - accuracy: 0.6000 - val_loss: 0.2711 - val_accuracy: 0.4483\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2206 - accuracy: 0.6783 - val_loss: 0.2709 - val_accuracy: 0.4483\n",
      "0.65625\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101100111010011011011101110100100001011101\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_206 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_207 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 0.1963 - accuracy: 0.8000 - val_loss: 0.2433 - val_accuracy: 0.6552\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.1427 - accuracy: 0.9217 - val_loss: 0.2424 - val_accuracy: 0.8276\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1116 - accuracy: 0.9478 - val_loss: 0.2253 - val_accuracy: 0.8966\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1160 - accuracy: 0.9217 - val_loss: 0.1135 - val_accuracy: 0.9655\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0709 - accuracy: 0.9739 - val_loss: 0.1120 - val_accuracy: 0.9655\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0723 - accuracy: 0.9739 - val_loss: 0.1935 - val_accuracy: 0.9310\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1083 - accuracy: 0.9652 - val_loss: 0.1285 - val_accuracy: 0.9655\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9310\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1127 - accuracy: 0.9304 - val_loss: 0.1322 - val_accuracy: 0.8966\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1526 - accuracy: 0.8783 - val_loss: 0.1584 - val_accuracy: 0.8621\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1845 - accuracy: 0.8000 - val_loss: 0.1694 - val_accuracy: 0.7931\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1773 - accuracy: 0.8000 - val_loss: 0.2146 - val_accuracy: 0.8966\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2238 - accuracy: 0.7304 - val_loss: 0.2228 - val_accuracy: 0.7586\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1914 - accuracy: 0.7391 - val_loss: 0.1894 - val_accuracy: 0.9310\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1776 - accuracy: 0.8174 - val_loss: 0.2224 - val_accuracy: 0.8621\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1907 - accuracy: 0.7913 - val_loss: 0.2488 - val_accuracy: 0.6552\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2189 - accuracy: 0.7217 - val_loss: 0.2113 - val_accuracy: 0.7586\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1969 - accuracy: 0.7826 - val_loss: 0.1712 - val_accuracy: 0.8966\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2282 - accuracy: 0.7217 - val_loss: 0.1828 - val_accuracy: 0.9655\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2827 - accuracy: 0.6174 - val_loss: 0.2842 - val_accuracy: 0.6207\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2684 - accuracy: 0.5739 - val_loss: 0.2577 - val_accuracy: 0.8621\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2172 - accuracy: 0.7304 - val_loss: 0.2406 - val_accuracy: 0.8621\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1955 - accuracy: 0.7304 - val_loss: 0.2516 - val_accuracy: 0.7931\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1806 - accuracy: 0.7826 - val_loss: 0.2803 - val_accuracy: 0.6897\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2111 - accuracy: 0.7565 - val_loss: 0.2667 - val_accuracy: 0.6207\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2220 - accuracy: 0.7043 - val_loss: 0.2445 - val_accuracy: 0.7241\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2187 - accuracy: 0.7130 - val_loss: 0.2409 - val_accuracy: 0.8621\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2139 - accuracy: 0.7478 - val_loss: 0.2860 - val_accuracy: 0.6552\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2256 - accuracy: 0.6696 - val_loss: 0.2477 - val_accuracy: 0.7586\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1958 - accuracy: 0.7826 - val_loss: 0.2526 - val_accuracy: 0.7241\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2700 - accuracy: 0.5739 - val_loss: 0.3112 - val_accuracy: 0.6207\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.3010 - accuracy: 0.5304 - val_loss: 0.3317 - val_accuracy: 0.6207\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2276 - accuracy: 0.6783 - val_loss: 0.2296 - val_accuracy: 0.7931\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2446 - accuracy: 0.6609 - val_loss: 0.2518 - val_accuracy: 0.6552\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2483 - accuracy: 0.6522 - val_loss: 0.2191 - val_accuracy: 0.7241\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2085 - accuracy: 0.7130 - val_loss: 0.2179 - val_accuracy: 0.7931\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2341 - accuracy: 0.6696 - val_loss: 0.3600 - val_accuracy: 0.5517\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2822 - accuracy: 0.5826 - val_loss: 0.2856 - val_accuracy: 0.6552\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2457 - accuracy: 0.6435 - val_loss: 0.1803 - val_accuracy: 0.8276\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2535 - accuracy: 0.6261 - val_loss: 0.2650 - val_accuracy: 0.6552\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2597 - accuracy: 0.5739 - val_loss: 0.2569 - val_accuracy: 0.7241\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2591 - accuracy: 0.6000 - val_loss: 0.2501 - val_accuracy: 0.6552\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2561 - accuracy: 0.6522 - val_loss: 0.2407 - val_accuracy: 0.6897\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2687 - accuracy: 0.6087 - val_loss: 0.2627 - val_accuracy: 0.6207\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2724 - accuracy: 0.5826 - val_loss: 0.2220 - val_accuracy: 0.6552\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2351 - accuracy: 0.6609 - val_loss: 0.2067 - val_accuracy: 0.7931\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1829 - accuracy: 0.8348 - val_loss: 0.2053 - val_accuracy: 0.8276\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2025 - accuracy: 0.7652 - val_loss: 0.2139 - val_accuracy: 0.6897\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2150 - accuracy: 0.7217 - val_loss: 0.2052 - val_accuracy: 0.7586\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1885 - accuracy: 0.7652 - val_loss: 0.1857 - val_accuracy: 0.8276\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1896 - accuracy: 0.7565 - val_loss: 0.1705 - val_accuracy: 0.7931\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1782 - accuracy: 0.8087 - val_loss: 0.1848 - val_accuracy: 0.7586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1557 - accuracy: 0.8348 - val_loss: 0.1495 - val_accuracy: 0.8276\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1632 - accuracy: 0.8261 - val_loss: 0.2106 - val_accuracy: 0.6552\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1931 - accuracy: 0.7391 - val_loss: 0.2468 - val_accuracy: 0.6207\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2244 - accuracy: 0.6957 - val_loss: 0.2211 - val_accuracy: 0.5862\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2262 - accuracy: 0.7304 - val_loss: 0.2211 - val_accuracy: 0.6552\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1800 - accuracy: 0.8000 - val_loss: 0.2073 - val_accuracy: 0.6552\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1807 - accuracy: 0.7739 - val_loss: 0.1768 - val_accuracy: 0.7931\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1697 - accuracy: 0.8087 - val_loss: 0.3003 - val_accuracy: 0.5862\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1730 - accuracy: 0.7826 - val_loss: 0.2490 - val_accuracy: 0.6207\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1955 - accuracy: 0.7652 - val_loss: 0.2453 - val_accuracy: 0.5172\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2121 - accuracy: 0.7565 - val_loss: 0.2515 - val_accuracy: 0.6897\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1699 - accuracy: 0.8348 - val_loss: 0.2679 - val_accuracy: 0.6207\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2011 - accuracy: 0.7913 - val_loss: 0.2088 - val_accuracy: 0.7241\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1630 - accuracy: 0.8087 - val_loss: 0.1980 - val_accuracy: 0.7586\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1463 - accuracy: 0.8522 - val_loss: 0.2161 - val_accuracy: 0.6552\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1585 - accuracy: 0.8261 - val_loss: 0.2397 - val_accuracy: 0.7241\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1692 - accuracy: 0.8348 - val_loss: 0.2445 - val_accuracy: 0.7241\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1691 - accuracy: 0.8000 - val_loss: 0.2691 - val_accuracy: 0.7241\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1747 - accuracy: 0.8000 - val_loss: 0.2566 - val_accuracy: 0.7241\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1606 - accuracy: 0.8696 - val_loss: 0.2788 - val_accuracy: 0.6552\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.1742 - accuracy: 0.8261 - val_loss: 0.2672 - val_accuracy: 0.7241\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1523 - accuracy: 0.8261 - val_loss: 0.2707 - val_accuracy: 0.6897\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1426 - accuracy: 0.8435 - val_loss: 0.2442 - val_accuracy: 0.6897\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1249 - accuracy: 0.8696 - val_loss: 0.2388 - val_accuracy: 0.6897\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1485 - accuracy: 0.8174 - val_loss: 0.2461 - val_accuracy: 0.6552\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1335 - accuracy: 0.8522 - val_loss: 0.2205 - val_accuracy: 0.6552\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1521 - accuracy: 0.8261 - val_loss: 0.2553 - val_accuracy: 0.5517\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1699 - accuracy: 0.7913 - val_loss: 0.2638 - val_accuracy: 0.5517\n",
      "0.78125\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101000010101101010001000111010100111001010\n",
      "26\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 2880)\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_208 (LSTM)              (None, 100, 20)           232080    \n",
      "_________________________________________________________________\n",
      "lstm_209 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 235,482\n",
      "Trainable params: 235,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 180ms/step - loss: 0.2932 - accuracy: 0.5565 - val_loss: 0.2588 - val_accuracy: 0.6207\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.3175 - accuracy: 0.5391 - val_loss: 0.4077 - val_accuracy: 0.5517\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.3081 - accuracy: 0.5565 - val_loss: 0.4868 - val_accuracy: 0.4483\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.3044 - accuracy: 0.6000 - val_loss: 0.4884 - val_accuracy: 0.4828\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2744 - accuracy: 0.6261 - val_loss: 0.3588 - val_accuracy: 0.4828\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2581 - accuracy: 0.6609 - val_loss: 0.4359 - val_accuracy: 0.3793\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2457 - accuracy: 0.6522 - val_loss: 0.3014 - val_accuracy: 0.4828\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2708 - accuracy: 0.6000 - val_loss: 0.2221 - val_accuracy: 0.6552\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2794 - accuracy: 0.6000 - val_loss: 0.2543 - val_accuracy: 0.7241\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2855 - accuracy: 0.5652 - val_loss: 0.2298 - val_accuracy: 0.5517\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2808 - accuracy: 0.5652 - val_loss: 0.2717 - val_accuracy: 0.4483\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2647 - accuracy: 0.6174 - val_loss: 0.3024 - val_accuracy: 0.4483\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2721 - accuracy: 0.6261 - val_loss: 0.2246 - val_accuracy: 0.6897\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2514 - accuracy: 0.6609 - val_loss: 0.2147 - val_accuracy: 0.6552\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2665 - accuracy: 0.5391 - val_loss: 0.2847 - val_accuracy: 0.4483\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.3003 - accuracy: 0.5304 - val_loss: 0.2896 - val_accuracy: 0.4828\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3031 - accuracy: 0.5217 - val_loss: 0.2461 - val_accuracy: 0.5172\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2832 - accuracy: 0.5565 - val_loss: 0.2733 - val_accuracy: 0.4483\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2854 - accuracy: 0.5739 - val_loss: 0.2880 - val_accuracy: 0.5172\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2795 - accuracy: 0.6087 - val_loss: 0.2610 - val_accuracy: 0.5862\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2982 - accuracy: 0.5304 - val_loss: 0.2432 - val_accuracy: 0.6207\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2785 - accuracy: 0.6261 - val_loss: 0.2841 - val_accuracy: 0.4828\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2542 - accuracy: 0.6522 - val_loss: 0.3211 - val_accuracy: 0.3103\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2633 - accuracy: 0.5913 - val_loss: 0.3144 - val_accuracy: 0.3103\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2341 - accuracy: 0.6783 - val_loss: 0.3073 - val_accuracy: 0.5172\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2508 - accuracy: 0.6348 - val_loss: 0.2995 - val_accuracy: 0.4483\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2420 - accuracy: 0.6783 - val_loss: 0.2689 - val_accuracy: 0.5172\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2609 - accuracy: 0.6348 - val_loss: 0.3116 - val_accuracy: 0.4138\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2523 - accuracy: 0.6000 - val_loss: 0.3082 - val_accuracy: 0.4828\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2807 - accuracy: 0.5739 - val_loss: 0.3589 - val_accuracy: 0.3103\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2785 - accuracy: 0.5478 - val_loss: 0.3385 - val_accuracy: 0.3793\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2570 - accuracy: 0.6174 - val_loss: 0.3126 - val_accuracy: 0.2759\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2716 - accuracy: 0.6174 - val_loss: 0.3232 - val_accuracy: 0.3103\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2724 - accuracy: 0.5913 - val_loss: 0.3225 - val_accuracy: 0.2414\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2809 - accuracy: 0.5739 - val_loss: 0.3030 - val_accuracy: 0.3793\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2613 - accuracy: 0.6087 - val_loss: 0.2962 - val_accuracy: 0.4483\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2629 - accuracy: 0.6000 - val_loss: 0.2874 - val_accuracy: 0.4828\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2945 - accuracy: 0.5304 - val_loss: 0.2921 - val_accuracy: 0.4828\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2504 - accuracy: 0.6609 - val_loss: 0.2549 - val_accuracy: 0.6207\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2776 - accuracy: 0.5652 - val_loss: 0.2990 - val_accuracy: 0.5172\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2891 - accuracy: 0.5478 - val_loss: 0.3023 - val_accuracy: 0.4138\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2799 - accuracy: 0.6087 - val_loss: 0.2830 - val_accuracy: 0.6207\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2917 - accuracy: 0.5913 - val_loss: 0.3261 - val_accuracy: 0.5172\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2799 - accuracy: 0.5913 - val_loss: 0.3544 - val_accuracy: 0.4828\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.3259 - accuracy: 0.4957 - val_loss: 0.2905 - val_accuracy: 0.5862\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2892 - accuracy: 0.5565 - val_loss: 0.3210 - val_accuracy: 0.5517\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2512 - accuracy: 0.6348 - val_loss: 0.3409 - val_accuracy: 0.5172\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2813 - accuracy: 0.5913 - val_loss: 0.3728 - val_accuracy: 0.4483\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2827 - accuracy: 0.6348 - val_loss: 0.3480 - val_accuracy: 0.4138\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.2527 - accuracy: 0.6783 - val_loss: 0.3377 - val_accuracy: 0.5517\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2568 - accuracy: 0.6261 - val_loss: 0.3489 - val_accuracy: 0.3448\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2772 - accuracy: 0.5913 - val_loss: 0.3262 - val_accuracy: 0.4828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2765 - accuracy: 0.5826 - val_loss: 0.3348 - val_accuracy: 0.5172\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2380 - accuracy: 0.7043 - val_loss: 0.3171 - val_accuracy: 0.4828\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2657 - accuracy: 0.6261 - val_loss: 0.3042 - val_accuracy: 0.4828\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2709 - accuracy: 0.6000 - val_loss: 0.3806 - val_accuracy: 0.4828\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2402 - accuracy: 0.6870 - val_loss: 0.2630 - val_accuracy: 0.4828\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2555 - accuracy: 0.6783 - val_loss: 0.2796 - val_accuracy: 0.5517\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2677 - accuracy: 0.6522 - val_loss: 0.2881 - val_accuracy: 0.5172\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2749 - accuracy: 0.6000 - val_loss: 0.3140 - val_accuracy: 0.4828\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2917 - accuracy: 0.5739 - val_loss: 0.3559 - val_accuracy: 0.4483\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2686 - accuracy: 0.6348 - val_loss: 0.3319 - val_accuracy: 0.5172\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2654 - accuracy: 0.6696 - val_loss: 0.2791 - val_accuracy: 0.5517\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2785 - accuracy: 0.6087 - val_loss: 0.3409 - val_accuracy: 0.5172\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2814 - accuracy: 0.6174 - val_loss: 0.3458 - val_accuracy: 0.5517\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2570 - accuracy: 0.6609 - val_loss: 0.3011 - val_accuracy: 0.5517\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2401 - accuracy: 0.7043 - val_loss: 0.3182 - val_accuracy: 0.5172\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2467 - accuracy: 0.7043 - val_loss: 0.3258 - val_accuracy: 0.5517\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2643 - accuracy: 0.6783 - val_loss: 0.2935 - val_accuracy: 0.5172\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2700 - accuracy: 0.6174 - val_loss: 0.3130 - val_accuracy: 0.4483\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2676 - accuracy: 0.6261 - val_loss: 0.3287 - val_accuracy: 0.4483\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2550 - accuracy: 0.6696 - val_loss: 0.2870 - val_accuracy: 0.5172\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2543 - accuracy: 0.6522 - val_loss: 0.2945 - val_accuracy: 0.4828\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2390 - accuracy: 0.6609 - val_loss: 0.2934 - val_accuracy: 0.5172\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2232 - accuracy: 0.6957 - val_loss: 0.2614 - val_accuracy: 0.6207\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2265 - accuracy: 0.7217 - val_loss: 0.3223 - val_accuracy: 0.5517\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2166 - accuracy: 0.7304 - val_loss: 0.2836 - val_accuracy: 0.5172\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2222 - accuracy: 0.7043 - val_loss: 0.2780 - val_accuracy: 0.6207\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2240 - accuracy: 0.7304 - val_loss: 0.2732 - val_accuracy: 0.4828\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2302 - accuracy: 0.7130 - val_loss: 0.2906 - val_accuracy: 0.5172\n",
      "0.7083333134651184\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101100111010011011011101110100100001011101\n",
      "21\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3480)\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_210 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_211 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 0.2629 - accuracy: 0.5478 - val_loss: 0.6681 - val_accuracy: 0.2069\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2737 - accuracy: 0.5739 - val_loss: 0.3388 - val_accuracy: 0.4828\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2779 - accuracy: 0.5217 - val_loss: 0.3453 - val_accuracy: 0.3448\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2877 - accuracy: 0.4696 - val_loss: 0.2792 - val_accuracy: 0.6207\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2710 - accuracy: 0.5739 - val_loss: 0.2400 - val_accuracy: 0.6897\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.3012 - accuracy: 0.4783 - val_loss: 0.2976 - val_accuracy: 0.4483\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2858 - accuracy: 0.5217 - val_loss: 0.2303 - val_accuracy: 0.5862\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2657 - accuracy: 0.5913 - val_loss: 0.2356 - val_accuracy: 0.5862\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2635 - accuracy: 0.6261 - val_loss: 0.3291 - val_accuracy: 0.4138\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2677 - accuracy: 0.5478 - val_loss: 0.2900 - val_accuracy: 0.4483\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2680 - accuracy: 0.5304 - val_loss: 0.2960 - val_accuracy: 0.4483\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2610 - accuracy: 0.5217 - val_loss: 0.3059 - val_accuracy: 0.4138\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2481 - accuracy: 0.5652 - val_loss: 0.2849 - val_accuracy: 0.4483\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2576 - accuracy: 0.5913 - val_loss: 0.2630 - val_accuracy: 0.4828\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2487 - accuracy: 0.5304 - val_loss: 0.2672 - val_accuracy: 0.4483\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2604 - accuracy: 0.5304 - val_loss: 0.2808 - val_accuracy: 0.4828\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2512 - accuracy: 0.5478 - val_loss: 0.2781 - val_accuracy: 0.4138\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2553 - accuracy: 0.5217 - val_loss: 0.2748 - val_accuracy: 0.3793\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2470 - accuracy: 0.5391 - val_loss: 0.2912 - val_accuracy: 0.4483\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2435 - accuracy: 0.5478 - val_loss: 0.2721 - val_accuracy: 0.4138\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2619 - accuracy: 0.4174 - val_loss: 0.2657 - val_accuracy: 0.4483\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2426 - accuracy: 0.6000 - val_loss: 0.3063 - val_accuracy: 0.4483\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2410 - accuracy: 0.6174 - val_loss: 0.2364 - val_accuracy: 0.5517\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2572 - accuracy: 0.5652 - val_loss: 0.2779 - val_accuracy: 0.5862\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2358 - accuracy: 0.6870 - val_loss: 0.2916 - val_accuracy: 0.4483\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2376 - accuracy: 0.6174 - val_loss: 0.2883 - val_accuracy: 0.5517\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2557 - accuracy: 0.6000 - val_loss: 0.2801 - val_accuracy: 0.4483\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2358 - accuracy: 0.6087 - val_loss: 0.2848 - val_accuracy: 0.4138\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2418 - accuracy: 0.5739 - val_loss: 0.2828 - val_accuracy: 0.3793\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2487 - accuracy: 0.5391 - val_loss: 0.2874 - val_accuracy: 0.3103\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2438 - accuracy: 0.6261 - val_loss: 0.2722 - val_accuracy: 0.3448\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2430 - accuracy: 0.5043 - val_loss: 0.2663 - val_accuracy: 0.4483\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2472 - accuracy: 0.5391 - val_loss: 0.2653 - val_accuracy: 0.3793\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2409 - accuracy: 0.5913 - val_loss: 0.2657 - val_accuracy: 0.3448\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2340 - accuracy: 0.6000 - val_loss: 0.2638 - val_accuracy: 0.3793\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2346 - accuracy: 0.5478 - val_loss: 0.2642 - val_accuracy: 0.3793\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2401 - accuracy: 0.5652 - val_loss: 0.2706 - val_accuracy: 0.3793\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2406 - accuracy: 0.5652 - val_loss: 0.2738 - val_accuracy: 0.3793\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2442 - accuracy: 0.5652 - val_loss: 0.2765 - val_accuracy: 0.3793\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2418 - accuracy: 0.5739 - val_loss: 0.2766 - val_accuracy: 0.3793\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2463 - accuracy: 0.6087 - val_loss: 0.2763 - val_accuracy: 0.3793\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2423 - accuracy: 0.5826 - val_loss: 0.2766 - val_accuracy: 0.3793\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2464 - accuracy: 0.5826 - val_loss: 0.2765 - val_accuracy: 0.3793\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2471 - accuracy: 0.6000 - val_loss: 0.2757 - val_accuracy: 0.3793\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2372 - accuracy: 0.6435 - val_loss: 0.2751 - val_accuracy: 0.3793\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2351 - accuracy: 0.6435 - val_loss: 0.2734 - val_accuracy: 0.3793\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2328 - accuracy: 0.6435 - val_loss: 0.2679 - val_accuracy: 0.3793\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2250 - accuracy: 0.6435 - val_loss: 0.2700 - val_accuracy: 0.3793\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2275 - accuracy: 0.6609 - val_loss: 0.2706 - val_accuracy: 0.3793\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2214 - accuracy: 0.6783 - val_loss: 0.2713 - val_accuracy: 0.3793\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2180 - accuracy: 0.6609 - val_loss: 0.2725 - val_accuracy: 0.3793\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2239 - accuracy: 0.6435 - val_loss: 0.2737 - val_accuracy: 0.3793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2133 - accuracy: 0.6870 - val_loss: 0.2748 - val_accuracy: 0.3793\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2081 - accuracy: 0.6870 - val_loss: 0.2757 - val_accuracy: 0.3793\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.65 - 0s 131ms/step - loss: 0.2125 - accuracy: 0.6522 - val_loss: 0.2766 - val_accuracy: 0.3793\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2139 - accuracy: 0.6348 - val_loss: 0.2769 - val_accuracy: 0.3793\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2102 - accuracy: 0.6696 - val_loss: 0.2772 - val_accuracy: 0.3793\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2013 - accuracy: 0.6783 - val_loss: 0.2770 - val_accuracy: 0.3793\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2020 - accuracy: 0.7043 - val_loss: 0.2751 - val_accuracy: 0.3793\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2031 - accuracy: 0.6783 - val_loss: 0.2746 - val_accuracy: 0.3793\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2015 - accuracy: 0.6870 - val_loss: 0.2727 - val_accuracy: 0.3793\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2034 - accuracy: 0.6870 - val_loss: 0.2731 - val_accuracy: 0.3793\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1937 - accuracy: 0.7130 - val_loss: 0.2658 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1944 - accuracy: 0.7217 - val_loss: 0.2644 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1943 - accuracy: 0.6870 - val_loss: 0.2633 - val_accuracy: 0.4138\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1949 - accuracy: 0.7043 - val_loss: 0.2626 - val_accuracy: 0.4483\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1908 - accuracy: 0.6870 - val_loss: 0.2629 - val_accuracy: 0.4483\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1842 - accuracy: 0.7478 - val_loss: 0.2630 - val_accuracy: 0.4483\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1969 - accuracy: 0.7217 - val_loss: 0.2534 - val_accuracy: 0.4828\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1872 - accuracy: 0.7391 - val_loss: 0.2538 - val_accuracy: 0.4828\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1785 - accuracy: 0.7478 - val_loss: 0.2542 - val_accuracy: 0.4828\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1856 - accuracy: 0.7130 - val_loss: 0.2530 - val_accuracy: 0.4828\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1964 - accuracy: 0.6957 - val_loss: 0.2505 - val_accuracy: 0.4828\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1884 - accuracy: 0.7130 - val_loss: 0.2500 - val_accuracy: 0.4828\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1783 - accuracy: 0.7391 - val_loss: 0.2554 - val_accuracy: 0.4828\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1725 - accuracy: 0.7739 - val_loss: 0.2555 - val_accuracy: 0.4828\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1766 - accuracy: 0.7391 - val_loss: 0.2553 - val_accuracy: 0.4828\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1735 - accuracy: 0.7391 - val_loss: 0.2554 - val_accuracy: 0.4828\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1700 - accuracy: 0.7391 - val_loss: 0.2553 - val_accuracy: 0.4828\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1627 - accuracy: 0.8000 - val_loss: 0.2544 - val_accuracy: 0.4828\n",
      "0.75\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001101000010101101010001000111010100111001010\n",
      "27\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 2760)\n",
      "(144, 100, 2760)\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_212 (LSTM)              (None, 100, 20)           222480    \n",
      "_________________________________________________________________\n",
      "lstm_213 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 225,882\n",
      "Trainable params: 225,842\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 0.2573 - accuracy: 0.5478 - val_loss: 0.4246 - val_accuracy: 0.5862\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3240 - accuracy: 0.3913 - val_loss: 0.2905 - val_accuracy: 0.5517\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.3077 - accuracy: 0.4609 - val_loss: 0.3124 - val_accuracy: 0.6207\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3121 - accuracy: 0.4261 - val_loss: 0.3445 - val_accuracy: 0.5172\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.2916 - accuracy: 0.6087 - val_loss: 0.4089 - val_accuracy: 0.3448\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2779 - accuracy: 0.6261 - val_loss: 0.2909 - val_accuracy: 0.5862\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2706 - accuracy: 0.6000 - val_loss: 0.3017 - val_accuracy: 0.5172\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2541 - accuracy: 0.5826 - val_loss: 0.2652 - val_accuracy: 0.4483\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2814 - accuracy: 0.5652 - val_loss: 0.2712 - val_accuracy: 0.5862\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2614 - accuracy: 0.5913 - val_loss: 0.2899 - val_accuracy: 0.6552\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2547 - accuracy: 0.5913 - val_loss: 0.2383 - val_accuracy: 0.6552\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2582 - accuracy: 0.6000 - val_loss: 0.2601 - val_accuracy: 0.6552\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2600 - accuracy: 0.5478 - val_loss: 0.2124 - val_accuracy: 0.6207\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2334 - accuracy: 0.6696 - val_loss: 0.2205 - val_accuracy: 0.5862\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2424 - accuracy: 0.6261 - val_loss: 0.2396 - val_accuracy: 0.6207\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2613 - accuracy: 0.6174 - val_loss: 0.2301 - val_accuracy: 0.6207\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2419 - accuracy: 0.6087 - val_loss: 0.2282 - val_accuracy: 0.6552\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2405 - accuracy: 0.6870 - val_loss: 0.2379 - val_accuracy: 0.6552\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2195 - accuracy: 0.7652 - val_loss: 0.2351 - val_accuracy: 0.6552\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2222 - accuracy: 0.7478 - val_loss: 0.2372 - val_accuracy: 0.6207\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.2138 - accuracy: 0.7913 - val_loss: 0.2408 - val_accuracy: 0.6207\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2184 - accuracy: 0.7565 - val_loss: 0.2422 - val_accuracy: 0.6207\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2253 - accuracy: 0.7304 - val_loss: 0.2302 - val_accuracy: 0.6552\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2264 - accuracy: 0.6696 - val_loss: 0.1793 - val_accuracy: 0.7241\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2084 - accuracy: 0.7217 - val_loss: 0.1792 - val_accuracy: 0.7241\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2098 - accuracy: 0.7565 - val_loss: 0.1793 - val_accuracy: 0.7241\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2101 - accuracy: 0.7304 - val_loss: 0.1936 - val_accuracy: 0.7586\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2137 - accuracy: 0.7391 - val_loss: 0.1875 - val_accuracy: 0.7241\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2047 - accuracy: 0.7391 - val_loss: 0.1737 - val_accuracy: 0.7586\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2096 - accuracy: 0.7478 - val_loss: 0.1973 - val_accuracy: 0.6897\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2040 - accuracy: 0.7217 - val_loss: 0.1639 - val_accuracy: 0.7931\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2163 - accuracy: 0.6870 - val_loss: 0.1708 - val_accuracy: 0.7586\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2087 - accuracy: 0.7217 - val_loss: 0.1645 - val_accuracy: 0.7931\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.2042 - accuracy: 0.7304 - val_loss: 0.1781 - val_accuracy: 0.7931\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.2008 - accuracy: 0.7217 - val_loss: 0.1786 - val_accuracy: 0.7931\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.2037 - accuracy: 0.7565 - val_loss: 0.1917 - val_accuracy: 0.8276\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1973 - accuracy: 0.7130 - val_loss: 0.1900 - val_accuracy: 0.8276\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1943 - accuracy: 0.7304 - val_loss: 0.1893 - val_accuracy: 0.8276\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1980 - accuracy: 0.7478 - val_loss: 0.1748 - val_accuracy: 0.8276\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1910 - accuracy: 0.7739 - val_loss: 0.1933 - val_accuracy: 0.8276\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1905 - accuracy: 0.7565 - val_loss: 0.1850 - val_accuracy: 0.8276\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1908 - accuracy: 0.7739 - val_loss: 0.2019 - val_accuracy: 0.7931\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1932 - accuracy: 0.7391 - val_loss: 0.1774 - val_accuracy: 0.8276\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1808 - accuracy: 0.7478 - val_loss: 0.1788 - val_accuracy: 0.8276\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1877 - accuracy: 0.7739 - val_loss: 0.1765 - val_accuracy: 0.8276\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1781 - accuracy: 0.8087 - val_loss: 0.1751 - val_accuracy: 0.8276\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1828 - accuracy: 0.7652 - val_loss: 0.1896 - val_accuracy: 0.7931\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1772 - accuracy: 0.7565 - val_loss: 0.1893 - val_accuracy: 0.7931\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1776 - accuracy: 0.8000 - val_loss: 0.1884 - val_accuracy: 0.7931\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1797 - accuracy: 0.7913 - val_loss: 0.1994 - val_accuracy: 0.7931\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1796 - accuracy: 0.7652 - val_loss: 0.1967 - val_accuracy: 0.7931\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1678 - accuracy: 0.7826 - val_loss: 0.1921 - val_accuracy: 0.7931\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1781 - accuracy: 0.8261 - val_loss: 0.1942 - val_accuracy: 0.7931\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1689 - accuracy: 0.8174 - val_loss: 0.1973 - val_accuracy: 0.7931\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1670 - accuracy: 0.7913 - val_loss: 0.1880 - val_accuracy: 0.8276\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1716 - accuracy: 0.8087 - val_loss: 0.1885 - val_accuracy: 0.7931\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1689 - accuracy: 0.8087 - val_loss: 0.1835 - val_accuracy: 0.8276\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1603 - accuracy: 0.8174 - val_loss: 0.1867 - val_accuracy: 0.8276\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1648 - accuracy: 0.8261 - val_loss: 0.1748 - val_accuracy: 0.8621\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1749 - accuracy: 0.8000 - val_loss: 0.1790 - val_accuracy: 0.8276\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1641 - accuracy: 0.8000 - val_loss: 0.1788 - val_accuracy: 0.8276\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1608 - accuracy: 0.8261 - val_loss: 0.1733 - val_accuracy: 0.8621\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1504 - accuracy: 0.8522 - val_loss: 0.1776 - val_accuracy: 0.8276\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1603 - accuracy: 0.8174 - val_loss: 0.1738 - val_accuracy: 0.8621\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1626 - accuracy: 0.8174 - val_loss: 0.1804 - val_accuracy: 0.8276\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.1622 - accuracy: 0.8087 - val_loss: 0.1758 - val_accuracy: 0.8621\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1634 - accuracy: 0.8000 - val_loss: 0.1810 - val_accuracy: 0.8276\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1631 - accuracy: 0.8174 - val_loss: 0.1737 - val_accuracy: 0.8621\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1552 - accuracy: 0.8435 - val_loss: 0.1727 - val_accuracy: 0.8621\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1463 - accuracy: 0.8174 - val_loss: 0.1780 - val_accuracy: 0.8276\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1504 - accuracy: 0.8348 - val_loss: 0.1716 - val_accuracy: 0.8621\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1606 - accuracy: 0.8348 - val_loss: 0.1712 - val_accuracy: 0.8621\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1556 - accuracy: 0.8000 - val_loss: 0.1711 - val_accuracy: 0.8276\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1463 - accuracy: 0.8435 - val_loss: 0.1764 - val_accuracy: 0.8276\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1494 - accuracy: 0.8522 - val_loss: 0.1849 - val_accuracy: 0.7931\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1394 - accuracy: 0.8783 - val_loss: 0.1837 - val_accuracy: 0.7931\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1448 - accuracy: 0.8522 - val_loss: 0.1809 - val_accuracy: 0.7931\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1396 - accuracy: 0.8522 - val_loss: 0.1827 - val_accuracy: 0.7931\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1361 - accuracy: 0.8348 - val_loss: 0.1859 - val_accuracy: 0.7931\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1473 - accuracy: 0.8522 - val_loss: 0.1711 - val_accuracy: 0.8276\n",
      "0.8125\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101000010100011011011101110100100001011101\n",
      "24\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3120)\n",
      "(144, 100, 3120)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_214 (LSTM)              (None, 100, 20)           251280    \n",
      "_________________________________________________________________\n",
      "lstm_215 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_107 (Bat (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 254,682\n",
      "Trainable params: 254,642\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 318ms/step - loss: 0.3309 - accuracy: 0.3391 - val_loss: 0.6054 - val_accuracy: 0.2414\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2717 - accuracy: 0.6000 - val_loss: 0.3174 - val_accuracy: 0.5172\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2551 - accuracy: 0.6609 - val_loss: 0.3498 - val_accuracy: 0.5862\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2339 - accuracy: 0.7304 - val_loss: 0.2737 - val_accuracy: 0.5862\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2818 - accuracy: 0.6261 - val_loss: 0.3143 - val_accuracy: 0.6207\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2464 - accuracy: 0.6609 - val_loss: 0.2767 - val_accuracy: 0.4483\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3050 - accuracy: 0.5391 - val_loss: 0.2540 - val_accuracy: 0.6897\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2621 - accuracy: 0.6174 - val_loss: 0.2094 - val_accuracy: 0.7931\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2283 - accuracy: 0.7043 - val_loss: 0.2498 - val_accuracy: 0.6207\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2277 - accuracy: 0.7043 - val_loss: 0.2726 - val_accuracy: 0.5862\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2330 - accuracy: 0.6522 - val_loss: 0.2523 - val_accuracy: 0.7241\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2462 - accuracy: 0.6261 - val_loss: 0.2133 - val_accuracy: 0.6552\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2187 - accuracy: 0.6696 - val_loss: 0.2414 - val_accuracy: 0.6897\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2336 - accuracy: 0.6522 - val_loss: 0.2464 - val_accuracy: 0.6207\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2368 - accuracy: 0.6522 - val_loss: 0.2676 - val_accuracy: 0.6207\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2272 - accuracy: 0.6000 - val_loss: 0.2121 - val_accuracy: 0.5862\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2332 - accuracy: 0.6522 - val_loss: 0.2351 - val_accuracy: 0.5172\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2281 - accuracy: 0.6348 - val_loss: 0.2433 - val_accuracy: 0.4828\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2332 - accuracy: 0.6870 - val_loss: 0.2859 - val_accuracy: 0.4828\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2450 - accuracy: 0.6522 - val_loss: 0.2473 - val_accuracy: 0.5517\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2454 - accuracy: 0.6348 - val_loss: 0.2691 - val_accuracy: 0.3793\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2370 - accuracy: 0.6261 - val_loss: 0.2828 - val_accuracy: 0.4138\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2385 - accuracy: 0.6087 - val_loss: 0.3431 - val_accuracy: 0.3448\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2390 - accuracy: 0.6348 - val_loss: 0.3170 - val_accuracy: 0.4138\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2427 - accuracy: 0.6348 - val_loss: 0.2947 - val_accuracy: 0.3793\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2534 - accuracy: 0.5739 - val_loss: 0.2894 - val_accuracy: 0.4828\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2609 - accuracy: 0.5739 - val_loss: 0.3006 - val_accuracy: 0.4828\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2882 - accuracy: 0.5652 - val_loss: 0.3104 - val_accuracy: 0.4828\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2752 - accuracy: 0.5565 - val_loss: 0.2796 - val_accuracy: 0.4483\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2790 - accuracy: 0.5652 - val_loss: 0.2715 - val_accuracy: 0.4483\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2708 - accuracy: 0.5130 - val_loss: 0.3338 - val_accuracy: 0.4483\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2574 - accuracy: 0.5913 - val_loss: 0.3185 - val_accuracy: 0.4828\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2732 - accuracy: 0.5304 - val_loss: 0.3286 - val_accuracy: 0.4483\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2698 - accuracy: 0.5304 - val_loss: 0.3265 - val_accuracy: 0.4483\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2487 - accuracy: 0.5739 - val_loss: 0.4028 - val_accuracy: 0.3448\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2853 - accuracy: 0.5130 - val_loss: 0.3311 - val_accuracy: 0.4828\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2744 - accuracy: 0.5826 - val_loss: 0.3635 - val_accuracy: 0.3793\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2676 - accuracy: 0.5652 - val_loss: 0.3621 - val_accuracy: 0.4138\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2681 - accuracy: 0.6000 - val_loss: 0.3180 - val_accuracy: 0.4828\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2509 - accuracy: 0.6696 - val_loss: 0.3421 - val_accuracy: 0.4138\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2515 - accuracy: 0.6348 - val_loss: 0.2983 - val_accuracy: 0.5172\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2543 - accuracy: 0.6435 - val_loss: 0.3447 - val_accuracy: 0.4138\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2472 - accuracy: 0.6870 - val_loss: 0.3275 - val_accuracy: 0.4483\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2597 - accuracy: 0.5826 - val_loss: 0.3300 - val_accuracy: 0.4138\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2625 - accuracy: 0.5652 - val_loss: 0.3698 - val_accuracy: 0.3793\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2613 - accuracy: 0.5565 - val_loss: 0.3313 - val_accuracy: 0.4483\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.2900 - accuracy: 0.5217 - val_loss: 0.3125 - val_accuracy: 0.4483\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2678 - accuracy: 0.5391 - val_loss: 0.3320 - val_accuracy: 0.3448\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2477 - accuracy: 0.5739 - val_loss: 0.3494 - val_accuracy: 0.3103\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2544 - accuracy: 0.6087 - val_loss: 0.3011 - val_accuracy: 0.3448\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2274 - accuracy: 0.6522 - val_loss: 0.2612 - val_accuracy: 0.4828\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2482 - accuracy: 0.6174 - val_loss: 0.2964 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2222 - accuracy: 0.6609 - val_loss: 0.2743 - val_accuracy: 0.4483\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2183 - accuracy: 0.6783 - val_loss: 0.3055 - val_accuracy: 0.3448\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2462 - accuracy: 0.6261 - val_loss: 0.3180 - val_accuracy: 0.3793\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2477 - accuracy: 0.6522 - val_loss: 0.2683 - val_accuracy: 0.5172\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2420 - accuracy: 0.6870 - val_loss: 0.2696 - val_accuracy: 0.4828\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2561 - accuracy: 0.5652 - val_loss: 0.3162 - val_accuracy: 0.3448\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2546 - accuracy: 0.6261 - val_loss: 0.3632 - val_accuracy: 0.3103\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2568 - accuracy: 0.6000 - val_loss: 0.3217 - val_accuracy: 0.3793\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2755 - accuracy: 0.6000 - val_loss: 0.3455 - val_accuracy: 0.4483\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2813 - accuracy: 0.5652 - val_loss: 0.3241 - val_accuracy: 0.4483\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2664 - accuracy: 0.5739 - val_loss: 0.3370 - val_accuracy: 0.4138\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2742 - accuracy: 0.5913 - val_loss: 0.3426 - val_accuracy: 0.4828\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2542 - accuracy: 0.6348 - val_loss: 0.3685 - val_accuracy: 0.4483\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2664 - accuracy: 0.6174 - val_loss: 0.3662 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2539 - accuracy: 0.6435 - val_loss: 0.3980 - val_accuracy: 0.3448\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2859 - accuracy: 0.5652 - val_loss: 0.3256 - val_accuracy: 0.5172\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2712 - accuracy: 0.6696 - val_loss: 0.3378 - val_accuracy: 0.4483\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2691 - accuracy: 0.6435 - val_loss: 0.3217 - val_accuracy: 0.4828\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2769 - accuracy: 0.6348 - val_loss: 0.3649 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2919 - accuracy: 0.5652 - val_loss: 0.3326 - val_accuracy: 0.4828\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2830 - accuracy: 0.5391 - val_loss: 0.3205 - val_accuracy: 0.4483\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.2791 - accuracy: 0.6348 - val_loss: 0.3149 - val_accuracy: 0.4828\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2738 - accuracy: 0.6261 - val_loss: 0.3058 - val_accuracy: 0.4828\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2699 - accuracy: 0.6087 - val_loss: 0.3025 - val_accuracy: 0.4483\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2778 - accuracy: 0.5913 - val_loss: 0.3212 - val_accuracy: 0.4828\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2615 - accuracy: 0.6348 - val_loss: 0.3197 - val_accuracy: 0.4828\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2747 - accuracy: 0.5913 - val_loss: 0.3159 - val_accuracy: 0.4828\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.2728 - accuracy: 0.5739 - val_loss: 0.2960 - val_accuracy: 0.5172\n",
      "0.6041666865348816\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11010001111101111011101111001101110100100001011101\n",
      "19\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3720)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3720)\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_216 (LSTM)              (None, 100, 20)           299280    \n",
      "_________________________________________________________________\n",
      "lstm_217 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 302,682\n",
      "Trainable params: 302,642\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.2839 - accuracy: 0.5043 - val_loss: 0.3546 - val_accuracy: 0.4138\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.3181 - accuracy: 0.4087 - val_loss: 0.3852 - val_accuracy: 0.3793\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.3196 - accuracy: 0.4522 - val_loss: 0.4216 - val_accuracy: 0.3103\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2987 - accuracy: 0.4783 - val_loss: 0.4724 - val_accuracy: 0.3793\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.3437 - accuracy: 0.3391 - val_loss: 0.4998 - val_accuracy: 0.3448\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.3227 - accuracy: 0.3826 - val_loss: 0.4732 - val_accuracy: 0.4483\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.3308 - accuracy: 0.4000 - val_loss: 0.4720 - val_accuracy: 0.4138\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.3064 - accuracy: 0.4261 - val_loss: 0.3901 - val_accuracy: 0.4483\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2974 - accuracy: 0.3913 - val_loss: 0.4508 - val_accuracy: 0.4138\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.3092 - accuracy: 0.4174 - val_loss: 0.3274 - val_accuracy: 0.4828\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.3112 - accuracy: 0.5043 - val_loss: 0.3528 - val_accuracy: 0.4483\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.2785 - accuracy: 0.5565 - val_loss: 0.3708 - val_accuracy: 0.4138\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.3094 - accuracy: 0.4783 - val_loss: 0.3441 - val_accuracy: 0.5517\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.3321 - accuracy: 0.4174 - val_loss: 0.3416 - val_accuracy: 0.3793\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.2650 - accuracy: 0.5130 - val_loss: 0.3961 - val_accuracy: 0.3793\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2812 - accuracy: 0.5304 - val_loss: 0.3404 - val_accuracy: 0.5172\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2839 - accuracy: 0.5043 - val_loss: 0.3594 - val_accuracy: 0.4483\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2676 - accuracy: 0.5565 - val_loss: 0.3965 - val_accuracy: 0.4483\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2754 - accuracy: 0.4957 - val_loss: 0.3678 - val_accuracy: 0.3448\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.2783 - accuracy: 0.4870 - val_loss: 0.3162 - val_accuracy: 0.4483\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.2856 - accuracy: 0.4348 - val_loss: 0.3388 - val_accuracy: 0.4483\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.3043 - accuracy: 0.5130 - val_loss: 0.3458 - val_accuracy: 0.4483\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.3161 - accuracy: 0.4609 - val_loss: 0.3335 - val_accuracy: 0.4483\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2663 - accuracy: 0.5217 - val_loss: 0.3717 - val_accuracy: 0.4828\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2892 - accuracy: 0.5478 - val_loss: 0.2951 - val_accuracy: 0.4138\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2886 - accuracy: 0.5043 - val_loss: 0.3424 - val_accuracy: 0.4483\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.2661 - accuracy: 0.5652 - val_loss: 0.3555 - val_accuracy: 0.4483\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.2599 - accuracy: 0.5304 - val_loss: 0.3131 - val_accuracy: 0.4483\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2713 - accuracy: 0.5130 - val_loss: 0.4056 - val_accuracy: 0.4138\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.2828 - accuracy: 0.5391 - val_loss: 0.3279 - val_accuracy: 0.4828\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2957 - accuracy: 0.5130 - val_loss: 0.3399 - val_accuracy: 0.5517\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2859 - accuracy: 0.5217 - val_loss: 0.4069 - val_accuracy: 0.4138\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2895 - accuracy: 0.5913 - val_loss: 0.3695 - val_accuracy: 0.4138\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2741 - accuracy: 0.6087 - val_loss: 0.3683 - val_accuracy: 0.4138\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2710 - accuracy: 0.6435 - val_loss: 0.3004 - val_accuracy: 0.4828\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.2692 - accuracy: 0.5565 - val_loss: 0.3040 - val_accuracy: 0.4828\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.2628 - accuracy: 0.6000 - val_loss: 0.3337 - val_accuracy: 0.4483\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2695 - accuracy: 0.5826 - val_loss: 0.3179 - val_accuracy: 0.4483\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2382 - accuracy: 0.6696 - val_loss: 0.3200 - val_accuracy: 0.4483\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.2442 - accuracy: 0.5913 - val_loss: 0.3705 - val_accuracy: 0.3793\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2315 - accuracy: 0.6870 - val_loss: 0.3636 - val_accuracy: 0.4483\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2643 - accuracy: 0.6000 - val_loss: 0.3131 - val_accuracy: 0.5172\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2237 - accuracy: 0.7130 - val_loss: 0.3664 - val_accuracy: 0.3793\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.2604 - accuracy: 0.6783 - val_loss: 0.3020 - val_accuracy: 0.4828\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.2219 - accuracy: 0.7130 - val_loss: 0.3657 - val_accuracy: 0.4138\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2482 - accuracy: 0.6696 - val_loss: 0.3662 - val_accuracy: 0.3793\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2221 - accuracy: 0.7478 - val_loss: 0.2846 - val_accuracy: 0.5517\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2309 - accuracy: 0.6783 - val_loss: 0.3091 - val_accuracy: 0.5517\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2446 - accuracy: 0.6696 - val_loss: 0.3545 - val_accuracy: 0.4483\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.2362 - accuracy: 0.7304 - val_loss: 0.2990 - val_accuracy: 0.4138\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.2406 - accuracy: 0.7130 - val_loss: 0.3452 - val_accuracy: 0.3793\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2544 - accuracy: 0.6261 - val_loss: 0.4013 - val_accuracy: 0.4483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.2113 - accuracy: 0.7217 - val_loss: 0.2853 - val_accuracy: 0.4483\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2157 - accuracy: 0.7217 - val_loss: 0.2733 - val_accuracy: 0.5172\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.2328 - accuracy: 0.6522 - val_loss: 0.2700 - val_accuracy: 0.4138\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2244 - accuracy: 0.7391 - val_loss: 0.2770 - val_accuracy: 0.5517\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.2392 - accuracy: 0.6609 - val_loss: 0.3155 - val_accuracy: 0.4138\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.2439 - accuracy: 0.6609 - val_loss: 0.2806 - val_accuracy: 0.4828\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.2288 - accuracy: 0.7217 - val_loss: 0.2958 - val_accuracy: 0.4483\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.2378 - accuracy: 0.6696 - val_loss: 0.2926 - val_accuracy: 0.4828\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.2464 - accuracy: 0.6870 - val_loss: 0.3007 - val_accuracy: 0.4483\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.2450 - accuracy: 0.7043 - val_loss: 0.2880 - val_accuracy: 0.4828\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2318 - accuracy: 0.6957 - val_loss: 0.2862 - val_accuracy: 0.4483\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2225 - accuracy: 0.6957 - val_loss: 0.3035 - val_accuracy: 0.4138\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.2642 - accuracy: 0.6000 - val_loss: 0.2795 - val_accuracy: 0.4828\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2207 - accuracy: 0.6957 - val_loss: 0.3168 - val_accuracy: 0.4138\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.2365 - accuracy: 0.6609 - val_loss: 0.3072 - val_accuracy: 0.4138\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.2133 - accuracy: 0.7043 - val_loss: 0.3060 - val_accuracy: 0.4483\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2414 - accuracy: 0.6522 - val_loss: 0.2872 - val_accuracy: 0.4483\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2397 - accuracy: 0.7043 - val_loss: 0.3294 - val_accuracy: 0.4138\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2410 - accuracy: 0.6609 - val_loss: 0.2899 - val_accuracy: 0.4138\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.2584 - accuracy: 0.5913 - val_loss: 0.2960 - val_accuracy: 0.4483\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2206 - accuracy: 0.6696 - val_loss: 0.3351 - val_accuracy: 0.4138\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.2126 - accuracy: 0.7130 - val_loss: 0.2896 - val_accuracy: 0.4483\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.2280 - accuracy: 0.6783 - val_loss: 0.2862 - val_accuracy: 0.4138\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2078 - accuracy: 0.6696 - val_loss: 0.2859 - val_accuracy: 0.4138\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2369 - accuracy: 0.6522 - val_loss: 0.3031 - val_accuracy: 0.3793\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.2112 - accuracy: 0.7043 - val_loss: 0.3183 - val_accuracy: 0.4138\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.2306 - accuracy: 0.6696 - val_loss: 0.2787 - val_accuracy: 0.4138\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2146 - accuracy: 0.7217 - val_loss: 0.3119 - val_accuracy: 0.4483\n",
      "0.625\n",
      "fitness pass\n",
      "所選擇的染色體：\n",
      "11011001101100111010011011011101110100100111011101\n",
      "19\n",
      "240\n",
      "200\n",
      "[[842.31366 842.25574 842.2272  ...   0.        0.        0.     ]\n",
      " [786.4423  789.2577  789.3059  ...   0.        0.        0.     ]\n",
      " [907.01166 906.9641  904.2041  ...   0.        0.        0.     ]\n",
      " ...\n",
      " [880.5698  880.48395 880.3809  ...   0.        0.        0.     ]\n",
      " [865.7729  859.95154 860.04517 ...   0.        0.        0.     ]\n",
      " [871.67523 871.6645  871.72784 ...   0.        0.        0.     ]]\n",
      "(240,)\n",
      "(240, 3720)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100, 3720)\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_218 (LSTM)              (None, 100, 20)           299280    \n",
      "_________________________________________________________________\n",
      "lstm_219 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_109 (Bat (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 302,682\n",
      "Trainable params: 302,642\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "3/3 [==============================] - 1s 369ms/step - loss: 0.2219 - accuracy: 0.7130 - val_loss: 0.1591 - val_accuracy: 0.7586\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.1912 - accuracy: 0.7652 - val_loss: 0.2373 - val_accuracy: 0.6552\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.1845 - accuracy: 0.8087 - val_loss: 0.2479 - val_accuracy: 0.5862\n",
      "Epoch 4/80\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.1821 - accuracy: 0.8174 - val_loss: 0.2178 - val_accuracy: 0.6207\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.1729 - accuracy: 0.8000 - val_loss: 0.2408 - val_accuracy: 0.6897\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.1843 - accuracy: 0.7913 - val_loss: 0.2789 - val_accuracy: 0.6552\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.1580 - accuracy: 0.8696 - val_loss: 0.1873 - val_accuracy: 0.7586\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.1603 - accuracy: 0.8435 - val_loss: 0.1742 - val_accuracy: 0.7931\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.1402 - accuracy: 0.8870 - val_loss: 0.3019 - val_accuracy: 0.6552\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.2954 - accuracy: 0.5217 - val_loss: 0.3188 - val_accuracy: 0.5862\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.2174 - accuracy: 0.6609 - val_loss: 0.3077 - val_accuracy: 0.4828\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.2705 - accuracy: 0.5565 - val_loss: 0.3640 - val_accuracy: 0.5517\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.2781 - accuracy: 0.5913 - val_loss: 0.2356 - val_accuracy: 0.8276\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2417 - accuracy: 0.6435 - val_loss: 0.3029 - val_accuracy: 0.4483\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2756 - accuracy: 0.5565 - val_loss: 0.3365 - val_accuracy: 0.4483\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.3114 - accuracy: 0.5043 - val_loss: 0.2609 - val_accuracy: 0.5517\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.2629 - accuracy: 0.6087 - val_loss: 0.2618 - val_accuracy: 0.6207\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.2458 - accuracy: 0.6348 - val_loss: 0.2624 - val_accuracy: 0.5517\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.2348 - accuracy: 0.6435 - val_loss: 0.2622 - val_accuracy: 0.5862\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.2340 - accuracy: 0.6696 - val_loss: 0.2544 - val_accuracy: 0.6207\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.2543 - accuracy: 0.6087 - val_loss: 0.2520 - val_accuracy: 0.6207\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.2428 - accuracy: 0.6174 - val_loss: 0.2517 - val_accuracy: 0.6207\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.2329 - accuracy: 0.6696 - val_loss: 0.2526 - val_accuracy: 0.6207\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.2336 - accuracy: 0.7043 - val_loss: 0.2528 - val_accuracy: 0.6207\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.2265 - accuracy: 0.6609 - val_loss: 0.2528 - val_accuracy: 0.6207\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.2280 - accuracy: 0.6870 - val_loss: 0.2525 - val_accuracy: 0.6207\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.2129 - accuracy: 0.6957 - val_loss: 0.2521 - val_accuracy: 0.5862\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.2202 - accuracy: 0.7043 - val_loss: 0.2517 - val_accuracy: 0.5862\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.2063 - accuracy: 0.7304 - val_loss: 0.2511 - val_accuracy: 0.5862\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.2072 - accuracy: 0.7217 - val_loss: 0.2505 - val_accuracy: 0.6207\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.2102 - accuracy: 0.7217 - val_loss: 0.2497 - val_accuracy: 0.6207\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.1883 - accuracy: 0.7652 - val_loss: 0.2489 - val_accuracy: 0.6207\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.1965 - accuracy: 0.7304 - val_loss: 0.2485 - val_accuracy: 0.6207\n",
      "Epoch 34/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.1901 - accuracy: 0.7391 - val_loss: 0.2483 - val_accuracy: 0.5862\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.1722 - accuracy: 0.7826 - val_loss: 0.2480 - val_accuracy: 0.5862\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.1687 - accuracy: 0.8000 - val_loss: 0.2473 - val_accuracy: 0.5862\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.1774 - accuracy: 0.7826 - val_loss: 0.2466 - val_accuracy: 0.5862\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.1756 - accuracy: 0.7478 - val_loss: 0.2458 - val_accuracy: 0.5862\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.1694 - accuracy: 0.7739 - val_loss: 0.2452 - val_accuracy: 0.5862\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.1675 - accuracy: 0.7652 - val_loss: 0.2446 - val_accuracy: 0.5862\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.1637 - accuracy: 0.7826 - val_loss: 0.2438 - val_accuracy: 0.5862\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.1575 - accuracy: 0.7826 - val_loss: 0.2426 - val_accuracy: 0.5862\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.1506 - accuracy: 0.8261 - val_loss: 0.2413 - val_accuracy: 0.5862\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.1679 - accuracy: 0.7913 - val_loss: 0.2407 - val_accuracy: 0.5862\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.1492 - accuracy: 0.8174 - val_loss: 0.2401 - val_accuracy: 0.5862\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.1459 - accuracy: 0.8174 - val_loss: 0.2401 - val_accuracy: 0.5862\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.1455 - accuracy: 0.8087 - val_loss: 0.2400 - val_accuracy: 0.5862\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.1430 - accuracy: 0.8435 - val_loss: 0.2393 - val_accuracy: 0.5862\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.1331 - accuracy: 0.8435 - val_loss: 0.2379 - val_accuracy: 0.5862\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.1344 - accuracy: 0.8783 - val_loss: 0.2361 - val_accuracy: 0.5862\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.1343 - accuracy: 0.8348 - val_loss: 0.2347 - val_accuracy: 0.6207\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.1270 - accuracy: 0.9043 - val_loss: 0.2337 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.1244 - accuracy: 0.8609 - val_loss: 0.2333 - val_accuracy: 0.6207\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.1249 - accuracy: 0.8870 - val_loss: 0.2328 - val_accuracy: 0.6207\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.1216 - accuracy: 0.8696 - val_loss: 0.2319 - val_accuracy: 0.6207\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.1193 - accuracy: 0.8957 - val_loss: 0.2312 - val_accuracy: 0.6207\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.1143 - accuracy: 0.8957 - val_loss: 0.2302 - val_accuracy: 0.6207\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.1143 - accuracy: 0.9043 - val_loss: 0.2288 - val_accuracy: 0.6207\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.1135 - accuracy: 0.8957 - val_loss: 0.2277 - val_accuracy: 0.6207\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.1154 - accuracy: 0.8957 - val_loss: 0.2081 - val_accuracy: 0.6897\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.1033 - accuracy: 0.8957 - val_loss: 0.1850 - val_accuracy: 0.6552\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0956 - accuracy: 0.9130 - val_loss: 0.2056 - val_accuracy: 0.6897\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0950 - accuracy: 0.9130 - val_loss: 0.2000 - val_accuracy: 0.6897\n",
      "Epoch 64/80\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0855 - accuracy: 0.9565 - val_loss: 0.2065 - val_accuracy: 0.6897\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0927 - accuracy: 0.9478 - val_loss: 0.1818 - val_accuracy: 0.6552\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0888 - accuracy: 0.9478 - val_loss: 0.1826 - val_accuracy: 0.6897\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0939 - accuracy: 0.9478 - val_loss: 0.1796 - val_accuracy: 0.7241\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0854 - accuracy: 0.9391 - val_loss: 0.1838 - val_accuracy: 0.6552\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0797 - accuracy: 0.9652 - val_loss: 0.1839 - val_accuracy: 0.6552\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0870 - accuracy: 0.9565 - val_loss: 0.1810 - val_accuracy: 0.6552\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0820 - accuracy: 0.9478 - val_loss: 0.1686 - val_accuracy: 0.7241\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0720 - accuracy: 0.9565 - val_loss: 0.1679 - val_accuracy: 0.7586\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0823 - accuracy: 0.9043 - val_loss: 0.1594 - val_accuracy: 0.7586\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0731 - accuracy: 0.9391 - val_loss: 0.1586 - val_accuracy: 0.7586\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0753 - accuracy: 0.9130 - val_loss: 0.1594 - val_accuracy: 0.7586\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0698 - accuracy: 0.9304 - val_loss: 0.1615 - val_accuracy: 0.7586\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0654 - accuracy: 0.9826 - val_loss: 0.1619 - val_accuracy: 0.7241\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0718 - accuracy: 0.9391 - val_loss: 0.1625 - val_accuracy: 0.7241\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0641 - accuracy: 0.9739 - val_loss: 0.1611 - val_accuracy: 0.7241\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0632 - accuracy: 0.9826 - val_loss: 0.1594 - val_accuracy: 0.7586\n",
      "0.8541666865348816\n",
      "fitness pass\n",
      "[(1.0, 923447748520394), (0.8020833134651184, 923447748520413), (0.7708333134651184, 957146807617629), (0.65625, 957462487713885), (0.78125, 957462487713885), (0.7083333134651184, 957148127537610), (0.75, 957462487713885), (0.8125, 921963755448778), (0.6041666865348816, 957146807617629), (0.625, 923447751821405), (0.8541666865348816, 957462487714269)]\n",
      "[923447748520394, 957462487714269]\n",
      "[923447748520394, 957462487714269, 957462487713885, 957146807617629]\n",
      "selection pass\n",
      "target_count:\n",
      "7\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "0\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "1\n",
      "957462487714269\n",
      "11011001101100111010011011011101110100100111011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "2\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "3\n",
      "957146807617629\n",
      "11011001101000010100011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "4\n",
      "957146800122314\n",
      "11011001101000010100011011000001001110100111001010\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "5\n",
      "957146807618013\n",
      "11011001101000010100011011011101110100100111011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "6\n",
      "957462487714269\n",
      "11011001101100111010011011011101110100100111011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "7\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "8\n",
      "957462487714269\n",
      "11011001101100111010011011011101110100100111011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "9\n",
      "957146807618013\n",
      "11011001101000010100011011011101110100100111011101\n",
      "生成新一代的種群\n",
      "染色體：\n",
      "10\n",
      "957153250068957\n",
      "11011001101000011010011011011101110100100111011101\n",
      "crossover pass\n",
      "變異後的種群\n",
      "染色體：\n",
      "0\n",
      "923447748520394\n",
      "11010001111101111011101111000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "1\n",
      "957462487714269\n",
      "11011001101100111010011011011101110100100111011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "2\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "3\n",
      "957146807617629\n",
      "11011001101000010100011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "4\n",
      "957146800122314\n",
      "11011001101000010100011011000001001110100111001010\n",
      "變異後的種群\n",
      "染色體：\n",
      "5\n",
      "957146807618013\n",
      "11011001101000010100011011011101110100100111011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "6\n",
      "957462487714269\n",
      "11011001101100111010011011011101110100100111011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "7\n",
      "957462487713885\n",
      "11011001101100111010011011011101110100100001011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "8\n",
      "957462487714269\n",
      "11011001101100111010011011011101110100100111011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "9\n",
      "957146807618013\n",
      "11011001101000010100011011011101110100100111011101\n",
      "變異後的種群\n",
      "染色體：\n",
      "10\n",
      "957153250068957\n",
      "11011001101000011010011011011101110100100111011101\n",
      "mutation pass\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 染色體長度為76， 種群數量為20\n",
    "    #26列\n",
    "    count=0#计算当下迭代次数\n",
    "    ga = GA(50,10)\n",
    "    # 10次進化迭代\n",
    "    for x in range(10):\n",
    "        print(\"迭代次數：\",x)\n",
    "        print(x)\n",
    "        ga.evolve()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11010001111101111011101111000001001110100111001010\n"
     ]
    }
   ],
   "source": [
    "#geni_string=ga.result()\n",
    "#11000110111000010000000011010000001001101011011110舊\n",
    "#10000011101110101011100111101101001100101010001010新-1\n",
    "#10010100101111110111111001010110001101111001000110\n",
    "#1100111010101101100010011000011011\n",
    "#1111101011001111101110111001111111 34變數 step150 epo50 迭代20\n",
    "#1110100011000110011111011101111100\n",
    "#1111000011111000001010010010111100\n",
    "#1111000011111000001010010111001100\n",
    "#11011001100000111100111100110100110000011100100011 new\n",
    "#10001100001100100010000110000001011111110010010000\n",
    "#11011100111010110111000000111101001111100100011010 10/06\n",
    "#11100111010001000001100000001110001101101011010011 10/06-2\n",
    "geni_string=\"11010001111101111011101111000001001110100111001010\"\n",
    "#geni_string=\"1111000011111000001010010111001100\"\n",
    "print (geni_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "159\n",
      "145\n",
      "[[  0.        0.      627.4512  ...   0.        0.        0.     ]\n",
      " [611.73627 603.82605   0.      ...   0.        0.        0.     ]\n",
      " [  0.        0.        0.      ...   0.        0.        0.     ]\n",
      " ...\n",
      " [856.98865 856.96844 857.0011  ...   0.        0.        0.     ]\n",
      " [886.5086  886.5275  886.45917 ...   0.        0.        0.     ]\n",
      " [880.42114 880.563   880.5173  ...   0.        0.        0.     ]]\n",
      "(159,)\n",
      "(159, 3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:194: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:211: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "class_dirdata1='正手測/'\n",
    "class_dirdata2='反手測/'\n",
    "#特征篩選\n",
    "class_data1,class_label1,class_data2,class_label2=classdatapredeal(class_dirdata1,class_dirdata2,geni_string)\n",
    "time_step=100#時間序列設置\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 3480)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#數據和標籤設定\n",
    "class_All_data,class_All_label=classdataReorganization1(class_data1,class_label1,class_data2,class_label2,time_step)\n",
    "#訓練集測試集分割\n",
    "train_X,test_X, train_y, test_y=datasplit1(class_All_data,class_All_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_228 (LSTM)              (None, 100, 20)           280080    \n",
      "_________________________________________________________________\n",
      "lstm_229 (LSTM)              (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_114 (Bat (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 283,482\n",
      "Trainable params: 283,442\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.3389 - accuracy: 0.1463 - val_loss: 0.6364 - val_accuracy: 0.2727\n",
      "Epoch 2/80\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2743 - accuracy: 0.5122 - val_loss: 0.3637 - val_accuracy: 0.5455\n",
      "Epoch 3/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3002 - accuracy: 0.3171 - val_loss: 0.5394 - val_accuracy: 0.1818\n",
      "Epoch 4/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2867 - accuracy: 0.5122 - val_loss: 0.4575 - val_accuracy: 0.1818\n",
      "Epoch 5/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2881 - accuracy: 0.4878 - val_loss: 0.3334 - val_accuracy: 0.2727\n",
      "Epoch 6/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2863 - accuracy: 0.4634 - val_loss: 0.3400 - val_accuracy: 0.6364\n",
      "Epoch 7/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3161 - accuracy: 0.4634 - val_loss: 0.3396 - val_accuracy: 0.7273\n",
      "Epoch 8/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2971 - accuracy: 0.3415 - val_loss: 0.2637 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2430 - accuracy: 0.6098 - val_loss: 0.3087 - val_accuracy: 0.7273\n",
      "Epoch 10/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2448 - accuracy: 0.6341 - val_loss: 0.2545 - val_accuracy: 0.8182\n",
      "Epoch 11/80\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2533 - accuracy: 0.5854 - val_loss: 0.2776 - val_accuracy: 0.7273\n",
      "Epoch 12/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2529 - accuracy: 0.5610 - val_loss: 0.2711 - val_accuracy: 0.6364\n",
      "Epoch 13/80\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2384 - accuracy: 0.6829 - val_loss: 0.1921 - val_accuracy: 0.9091\n",
      "Epoch 14/80\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2062 - accuracy: 0.7561 - val_loss: 0.2219 - val_accuracy: 0.8182\n",
      "Epoch 15/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1920 - accuracy: 0.6829 - val_loss: 0.2481 - val_accuracy: 0.7273\n",
      "Epoch 16/80\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1899 - accuracy: 0.7317 - val_loss: 0.2357 - val_accuracy: 0.8182\n",
      "Epoch 17/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1820 - accuracy: 0.7561 - val_loss: 0.2240 - val_accuracy: 0.7273\n",
      "Epoch 18/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1914 - accuracy: 0.7073 - val_loss: 0.2183 - val_accuracy: 0.8182\n",
      "Epoch 19/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2135 - accuracy: 0.7561 - val_loss: 0.2350 - val_accuracy: 0.7273\n",
      "Epoch 20/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2236 - accuracy: 0.7561 - val_loss: 0.2876 - val_accuracy: 0.6364\n",
      "Epoch 21/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2268 - accuracy: 0.7561 - val_loss: 0.2255 - val_accuracy: 0.7273\n",
      "Epoch 22/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1994 - accuracy: 0.7561 - val_loss: 0.1783 - val_accuracy: 0.9091\n",
      "Epoch 23/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2010 - accuracy: 0.7561 - val_loss: 0.2150 - val_accuracy: 0.8182\n",
      "Epoch 24/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1910 - accuracy: 0.7561 - val_loss: 0.1778 - val_accuracy: 0.8182\n",
      "Epoch 25/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1875 - accuracy: 0.7561 - val_loss: 0.1845 - val_accuracy: 0.8182\n",
      "Epoch 26/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1818 - accuracy: 0.7805 - val_loss: 0.2130 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1872 - accuracy: 0.7317 - val_loss: 0.1705 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1834 - accuracy: 0.7561 - val_loss: 0.1697 - val_accuracy: 0.9091\n",
      "Epoch 29/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1807 - accuracy: 0.8049 - val_loss: 0.1896 - val_accuracy: 0.9091\n",
      "Epoch 30/80\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1840 - accuracy: 0.7805 - val_loss: 0.1845 - val_accuracy: 0.8182\n",
      "Epoch 31/80\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1891 - accuracy: 0.7805 - val_loss: 0.2064 - val_accuracy: 0.8182\n",
      "Epoch 32/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1820 - accuracy: 0.8293 - val_loss: 0.1828 - val_accuracy: 0.8182\n",
      "Epoch 33/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1791 - accuracy: 0.8537 - val_loss: 0.1835 - val_accuracy: 0.8182\n",
      "Epoch 34/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1990 - accuracy: 0.8293 - val_loss: 0.1787 - val_accuracy: 0.9091\n",
      "Epoch 35/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1942 - accuracy: 0.8780 - val_loss: 0.2223 - val_accuracy: 0.8182\n",
      "Epoch 36/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1888 - accuracy: 0.8780 - val_loss: 0.2009 - val_accuracy: 0.8182\n",
      "Epoch 37/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2037 - accuracy: 0.7805 - val_loss: 0.2078 - val_accuracy: 0.9091\n",
      "Epoch 38/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1963 - accuracy: 0.8293 - val_loss: 0.2459 - val_accuracy: 0.7273\n",
      "Epoch 39/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1877 - accuracy: 0.8293 - val_loss: 0.2442 - val_accuracy: 0.7273\n",
      "Epoch 40/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1997 - accuracy: 0.8293 - val_loss: 0.2425 - val_accuracy: 0.7273\n",
      "Epoch 41/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2836 - accuracy: 0.6829 - val_loss: 0.2403 - val_accuracy: 0.7273\n",
      "Epoch 42/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1983 - accuracy: 0.8049 - val_loss: 0.2511 - val_accuracy: 0.7273\n",
      "Epoch 43/80\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1911 - accuracy: 0.8049 - val_loss: 0.2258 - val_accuracy: 0.8182\n",
      "Epoch 44/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1878 - accuracy: 0.8537 - val_loss: 0.2248 - val_accuracy: 0.8182\n",
      "Epoch 45/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1862 - accuracy: 0.8780 - val_loss: 0.2243 - val_accuracy: 0.8182\n",
      "Epoch 46/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1643 - accuracy: 0.8780 - val_loss: 0.2312 - val_accuracy: 0.8182\n",
      "Epoch 47/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1668 - accuracy: 0.8780 - val_loss: 0.2050 - val_accuracy: 0.9091\n",
      "Epoch 48/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1779 - accuracy: 0.8780 - val_loss: 0.2030 - val_accuracy: 0.9091\n",
      "Epoch 49/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1824 - accuracy: 0.8780 - val_loss: 0.2440 - val_accuracy: 0.7273\n",
      "Epoch 50/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1841 - accuracy: 0.8780 - val_loss: 0.2079 - val_accuracy: 0.8182\n",
      "Epoch 51/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1861 - accuracy: 0.9024 - val_loss: 0.2075 - val_accuracy: 0.8182\n",
      "Epoch 52/80\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1840 - accuracy: 0.9024 - val_loss: 0.2071 - val_accuracy: 0.8182\n",
      "Epoch 53/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1825 - accuracy: 0.9024 - val_loss: 0.2067 - val_accuracy: 0.8182\n",
      "Epoch 54/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1813 - accuracy: 0.9024 - val_loss: 0.2300 - val_accuracy: 0.7273\n",
      "Epoch 55/80\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1831 - accuracy: 0.8780 - val_loss: 0.1847 - val_accuracy: 0.8182\n",
      "Epoch 56/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1797 - accuracy: 0.9024 - val_loss: 0.2058 - val_accuracy: 0.8182\n",
      "Epoch 57/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1786 - accuracy: 0.9024 - val_loss: 0.2058 - val_accuracy: 0.8182\n",
      "Epoch 58/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1777 - accuracy: 0.9024 - val_loss: 0.2057 - val_accuracy: 0.8182\n",
      "Epoch 59/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1771 - accuracy: 0.9024 - val_loss: 0.2173 - val_accuracy: 0.8182\n",
      "Epoch 60/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1543 - accuracy: 0.9024 - val_loss: 0.2057 - val_accuracy: 0.8182\n",
      "Epoch 61/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1558 - accuracy: 0.9024 - val_loss: 0.2075 - val_accuracy: 0.8182\n",
      "Epoch 62/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1541 - accuracy: 0.8780 - val_loss: 0.2157 - val_accuracy: 0.8182\n",
      "Epoch 63/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1514 - accuracy: 0.9024 - val_loss: 0.2153 - val_accuracy: 0.8182\n",
      "Epoch 64/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1509 - accuracy: 0.9024 - val_loss: 0.2146 - val_accuracy: 0.8182\n",
      "Epoch 65/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1475 - accuracy: 0.9512 - val_loss: 0.2134 - val_accuracy: 0.8182\n",
      "Epoch 66/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1466 - accuracy: 0.9512 - val_loss: 0.2133 - val_accuracy: 0.8182\n",
      "Epoch 67/80\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1456 - accuracy: 0.9512 - val_loss: 0.2127 - val_accuracy: 0.8182\n",
      "Epoch 68/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1448 - accuracy: 0.9512 - val_loss: 0.2120 - val_accuracy: 0.8182\n",
      "Epoch 69/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1384 - accuracy: 0.9512 - val_loss: 0.2115 - val_accuracy: 0.8182\n",
      "Epoch 70/80\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1430 - accuracy: 0.9512 - val_loss: 0.2112 - val_accuracy: 0.9091\n",
      "Epoch 71/80\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1333 - accuracy: 0.9512 - val_loss: 0.2111 - val_accuracy: 0.9091\n",
      "Epoch 72/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1365 - accuracy: 0.9512 - val_loss: 0.2142 - val_accuracy: 0.8182\n",
      "Epoch 73/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1432 - accuracy: 0.9268 - val_loss: 0.2145 - val_accuracy: 0.8182\n",
      "Epoch 74/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1452 - accuracy: 0.9512 - val_loss: 0.2079 - val_accuracy: 0.9091\n",
      "Epoch 75/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1417 - accuracy: 0.9512 - val_loss: 0.2134 - val_accuracy: 0.9091\n",
      "Epoch 76/80\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1445 - accuracy: 0.9756 - val_loss: 0.2167 - val_accuracy: 0.8182\n",
      "Epoch 77/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1423 - accuracy: 0.9512 - val_loss: 0.1951 - val_accuracy: 0.8182\n",
      "Epoch 78/80\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1376 - accuracy: 0.9512 - val_loss: 0.2126 - val_accuracy: 0.9091\n",
      "Epoch 79/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1424 - accuracy: 0.9512 - val_loss: 0.1908 - val_accuracy: 0.9091\n",
      "Epoch 80/80\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1431 - accuracy: 0.9512 - val_loss: 0.1948 - val_accuracy: 0.8182\n"
     ]
    }
   ],
   "source": [
    "#模型訓練\n",
    "timemodel=timeModel1(train_X,time_step)\n",
    "history = timemodel.fit(train_X,train_y,epochs=80, validation_split=0.2,batch_size=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "t = f.suptitle('class model evaluate', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "class_epoch_list = list(range(1,81))\n",
    "ax1.plot(class_epoch_list, history.history['accuracy'], label='class_Train Accuracy')\n",
    "ax1.plot(class_epoch_list, history.history['val_accuracy'], label='class_Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(0, 81, 5))\n",
    "ax1.set_ylabel('class_Accuracy Value')\n",
    "ax1.set_xlabel('class_Epoch')\n",
    "ax1.set_title('class_Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(class_epoch_list, history.history['loss'], label='class_Train Loss')\n",
    "ax2.plot(class_epoch_list, history.history['val_loss'], label='class_Validation Loss')\n",
    "ax2.set_xticks(np.arange(0, 81, 5))\n",
    "ax2.set_ylabel('class_Loss Value')\n",
    "ax2.set_xlabel('class_Epoch')\n",
    "ax2.set_title('class_Loss')\n",
    "l2 = ax2.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s\n"
     ]
    }
   ],
   "source": [
    "#對分類區中的test進行預測\n",
    "time_pre=timemodel.predict(test_X,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78882825, 0.23449934],\n",
       "       [0.4607967 , 0.40208986],\n",
       "       [0.08275142, 0.01977947]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_pre[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.401\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(test_y, time_pre))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.argmax(time_pre,axis=1)\n",
    "Y_test = np.argmax(test_y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  0]\n",
      " [ 9 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        32\n",
      "           1       1.00      0.55      0.71        20\n",
      "\n",
      "    accuracy                           0.83        52\n",
      "   macro avg       0.89      0.78      0.79        52\n",
      "weighted avg       0.86      0.83      0.81        52\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = confusion_matrix(Y_test,Y_pred)\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.heatmap(mat,square=True,annot=True,fmt='d',cbar=False)\n",
    "\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.xlabel('pred label')\n",
    "plt.ylabel('true label')\n",
    "\n",
    "t = ['0','1']\n",
    "print(mat)\n",
    "print(classification_report(Y_test,Y_pred,target_names=t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Predicted label (first 100)')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "\n",
    "\n",
    "# plt.subplot(3,1,1)\n",
    "plt.plot(Y_test[:150], color = 'black', linewidth=1, label = 'True value')\n",
    "plt.plot(time_pre[:150], color = 'red', label = 'Predicted')\n",
    "plt.legend(frameon=False)\n",
    "plt.ylabel(\"label forecast\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.title(\"Predicted label (first 100)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timemodel.save('80epo-lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
